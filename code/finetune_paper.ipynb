{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34ca4ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def setup_reproducibility(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available(): torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.use_deterministic_algorithms(False, warn_only=True)\n",
    "    torch.set_float32_matmul_precision(\"high\")\n",
    "    \n",
    "SEED = 1000\n",
    "setup_reproducibility(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb8c02b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import get_cosine_schedule_with_warmup\n",
    "from scipy import signal\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from huggingface_hub import login, snapshot_download\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "def get_ckpt(path):\n",
    "    return torch.load(path, weights_only=False)\n",
    "\n",
    "\n",
    "def cuda_to_np(tensor):\n",
    "    return tensor.cpu().detach().numpy()\n",
    "\n",
    "\n",
    "def get_scheduler(optimizer, train_dl, epochs):\n",
    "    total_training_steps = len(train_dl) * epochs\n",
    "    warmup_steps = int(total_training_steps * 0.05)  # e.g. 5% warmup\n",
    "    \n",
    "    return get_cosine_schedule_with_warmup(\n",
    "        optimizer=optimizer,\n",
    "        num_warmup_steps=warmup_steps,\n",
    "        num_training_steps=total_training_steps\n",
    "    )\n",
    "\n",
    "\n",
    "def get_stats(tensor, p=True, r=False, minmax=False):\n",
    "    if minmax:\n",
    "        min, max = tensor.min(), tensor.max()\n",
    "        mean, std = tensor.mean(), tensor.std()\n",
    "        if p: print(f\"Min: {min}, Max: {max} ,Mean: {mean}, Std: {std}\")\n",
    "        if r: return min, max, mean, std\n",
    "    else:\n",
    "        mean, std = tensor.mean(), tensor.std()\n",
    "        if p: print(f\"Mean: {mean}, Std: {std}\")\n",
    "        if r: return mean, std\n",
    "    \n",
    "    \n",
    "def zscore(tensor, mean=None, std=None):\n",
    "    if mean is None: mean = tensor.mean()\n",
    "    if std is None: std = tensor.std()\n",
    "    return (tensor - mean) / (std + 1e-8)\n",
    "\n",
    "\n",
    "def get_model_size(model):\n",
    "    print(sum(p.numel() for p in model.parameters()) / 1e6)\n",
    "    \n",
    "\n",
    "def get_index(iterable):\n",
    "    return random.randint(0, len(iterable) - 1)\n",
    "\n",
    "\n",
    "def get_indices(iterable, n):\n",
    "    return random.sample(range(len(iterable)), n)\n",
    "\n",
    "\n",
    "def split(inputs, targets, seed):\n",
    "    return train_test_split(\n",
    "        inputs,\n",
    "        targets, \n",
    "        test_size=0.2,\n",
    "        shuffle=True, \n",
    "        random_state=seed\n",
    "    ) \n",
    "\n",
    "\n",
    "def show_waves(waves, dpi=100):\n",
    "    \"\"\"\n",
    "    waves: numpy array of shape (3, N)\n",
    "    Creates three separate figures that stretch wide.\n",
    "    \"\"\"\n",
    "    N = waves.shape[1]\n",
    "    t = np.arange(N)\n",
    "\n",
    "    # Wide aspect ratio; height modest so each window fills width\n",
    "    for i in range(waves.shape[0]):\n",
    "        fig = plt.figure(figsize=(14, 4), dpi=dpi)  # wide figure\n",
    "        ax = fig.add_subplot(111)\n",
    "        ax.plot(t, waves[i], linewidth=1)\n",
    "        ax.set_title(f\"Wave {i+1}\")\n",
    "        ax.set_xlabel(\"Sample\")\n",
    "        ax.set_ylabel(\"Amplitude\")\n",
    "        ax.grid(True)\n",
    "        fig.tight_layout()  # reduce margins to use width\n",
    "        \n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "def hf_ds_download(hf_token, repo_id):\n",
    "    login(hf_token[1:])\n",
    "    return snapshot_download(repo_id, repo_type=\"dataset\")\n",
    "\n",
    "\n",
    "def get_spectra_features(X, b=False):\n",
    "    \"\"\"Create multi-channel features from spectra: raw, 1st derivative, 2nd derivative.\"\"\"\n",
    "    X_processed = np.zeros_like(X)\n",
    "    # Baseline correction and SNV\n",
    "    for i in tqdm(range(X.shape[0])):\n",
    "        poly = np.polyfit(np.arange(X.shape[1]), X[i], 3)\n",
    "        baseline = np.polyval(poly, np.arange(X.shape[1]))\n",
    "        corrected_spec = X[i] - baseline\n",
    "        #X_processed[i] = (corrected_spec - corrected_spec.mean()) / (corrected_spec.std() + 1e-8)\n",
    "        X_processed[i] = corrected_spec\n",
    "        \n",
    "    # Calculate derivatives\n",
    "    deriv1 = signal.savgol_filter(X_processed, window_length=11, polyorder=3, deriv=1, axis=1)\n",
    "    deriv2 = signal.savgol_filter(X_processed, window_length=11, polyorder=3, deriv=2, axis=1)\n",
    "\n",
    "    if b: return np.stack([X_processed, deriv1, deriv2], axis=1)\n",
    "    return np.stack([deriv1, deriv2], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2cfbbe45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 'sample_submission.csv'),\n",
       " (1, 'timegate.csv'),\n",
       " (2, 'mettler_toledo.csv'),\n",
       " (3, 'kaiser.csv'),\n",
       " (4, 'anton_532.csv'),\n",
       " (5, 'transfer_plate.csv'),\n",
       " (6, '96_samples.csv'),\n",
       " (7, 'tornado.csv'),\n",
       " (8, 'tec5.csv'),\n",
       " (9, 'metrohm.csv'),\n",
       " (10, 'anton_785.csv')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "path = \"/kaggle/input/dig-4-bio-raman-transfer-learning-challenge\"\n",
    "files = os.listdir(path)\n",
    "[(i, files[i]) for i in range(len(files))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "62074de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_test_data():\n",
    "    test = pd.read_csv(os.path.join(path, files[6]))\n",
    "\n",
    "    row1 = test.columns[1:].to_numpy().copy()\n",
    "    row1[-1] = \"5611\"\n",
    "    row1 = row1.astype(np.float64)\n",
    "\n",
    "\n",
    "    cols = test.columns[1:]\n",
    "    test = test[cols]\n",
    "    test[\" 5611]\"] = test[\" 5611]\"].str.replace('[\\[\\]]', '', regex=True).astype('int64')\n",
    "    test = test.to_numpy()\n",
    "\n",
    "    test = np.insert(test, 0, row1, axis=0)\n",
    "    return test.reshape(-1, 2, 2048).mean(axis=1)\n",
    "\n",
    "\n",
    "def get_test_data():\n",
    "    inputs = load_test_data()\n",
    "    \n",
    "    spectra_selection = np.logical_and(\n",
    "        300 <= np.array([float(one) for one in range(2048)]),\n",
    "        np.array([float(one) for one in range(2048)]) <= 1942,\n",
    "    )\n",
    "    \n",
    "    inputs = inputs[:, spectra_selection]\n",
    "\n",
    "    wns = np.array([\n",
    "        float(one) for one in range(2048)\n",
    "    ])[spectra_selection]\n",
    "    wavenumbers = np.arange(300, 1943)\n",
    "\n",
    "    interpolated_data = np.array(\n",
    "        [np.interp(wavenumbers, xp=wns, fp=i) for i in inputs]\n",
    "    )\n",
    "\n",
    "    normed_spectra = interpolated_data / np.max(interpolated_data)\n",
    "    return normed_spectra\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab1f5e97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((96, 1643), (96, 3))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def load_transfer_data():\n",
    "    csv_path = os.path.join(path, files[5])\n",
    "    df = pd.read_csv(csv_path)\n",
    "\n",
    "    input_cols = df.columns[1:2049]\n",
    "    target_cols = df.columns[2050:]\n",
    "\n",
    "    targets  = df[target_cols].dropna().to_numpy()\n",
    "\n",
    "    df = df[input_cols]\n",
    "    df['Unnamed: 1'] = df['Unnamed: 1'].str.replace(\"[\\[\\]]\", \"\", regex=True).astype('int64')\n",
    "    df['Unnamed: 2048'] = df['Unnamed: 2048'].str.replace(\"[\\[\\]]\", \"\", regex=True).astype('int64')\n",
    "\n",
    "    inputs = df.to_numpy().reshape(-1, 2, 2048)\n",
    "    inputs = inputs.mean(axis=1)\n",
    "    \n",
    "    return inputs, targets\n",
    "\n",
    "\n",
    "def preprocess_transfer_data():\n",
    "    inputs, targets = load_transfer_data()\n",
    "    \n",
    "    spectra_selection = np.logical_and(\n",
    "        300 <= np.array([float(one) for one in range(2048)]),\n",
    "        np.array([float(one) for one in range(2048)]) <= 1942,\n",
    "    )\n",
    "    \n",
    "    inputs = inputs[:, spectra_selection]\n",
    "    \n",
    "    wns = np.array([\n",
    "        float(one) for one in range(2048)\n",
    "    ])[spectra_selection]\n",
    "    wavenumbers = np.arange(300, 1943)\n",
    "    \n",
    "    interpolated_data = np.array(\n",
    "        [np.interp(wavenumbers, xp=wns, fp=i) for i in inputs]\n",
    "    )\n",
    "    \n",
    "    normed_spectra = interpolated_data / np.max(interpolated_data)\n",
    "    return normed_spectra, targets\n",
    "\n",
    "inputs, targets = preprocess_transfer_data()\n",
    "inputs.shape, targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ba2c070",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import scipy.optimize\n",
    "\n",
    "\n",
    "np_dtype_from_torch = {\n",
    "    torch.float32: np.float32,\n",
    "    torch.float64: np.float64,\n",
    "}\n",
    "\n",
    "class SpectralDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        spectra,\n",
    "        concentrations,\n",
    "        dtype=None,\n",
    "        spectra_mean_std=None,\n",
    "        concentration_mean_std=None,\n",
    "        combine_spectra_range=0.0,\n",
    "        baseline_factor_bound=0.0,\n",
    "        baseline_period_lower_bound=100.0,\n",
    "        baseline_period_upper_bound=200.0,\n",
    "        augment_slope_std=0.0,\n",
    "        augment_intersept_std=0.0,\n",
    "        rolling_bound=0,\n",
    "        spectrum_rolling_sigma=0.0,\n",
    "        augmentation_weight=0.1,\n",
    "        original_datapoint_weight=1.,\n",
    "    ):\n",
    "        self.dtype = dtype or torch.float32\n",
    "        self.combine_spectra_range = combine_spectra_range\n",
    "        self.baseline_factor_bound = baseline_factor_bound\n",
    "        self.augment_slope_std = augment_slope_std\n",
    "        self.augment_intercept_std = augment_intersept_std\n",
    "        self.baseline_period_lower_bound = baseline_period_lower_bound\n",
    "        self.baseline_period_upper_bound = baseline_period_upper_bound\n",
    "        self.rolling_bound = rolling_bound\n",
    "        self.spectrum_rolling_sigma = spectrum_rolling_sigma\n",
    "        self.augmentation_weight = torch.tensor(augmentation_weight, dtype=dtype)\n",
    "        self.original_dp_weight = original_datapoint_weight\n",
    "\n",
    "        # normalize spectra\n",
    "        spectra = torch.tensor(spectra, dtype=dtype)\n",
    "\n",
    "        if spectra_mean_std is None:\n",
    "            self.s_mean = torch.mean(spectra)\n",
    "            self.s_std = torch.std(spectra)\n",
    "        else:\n",
    "            self.s_mean, self.s_std = spectra_mean_std\n",
    "\n",
    "        self.spectra = torch.divide(\n",
    "            torch.subtract(spectra, self.s_mean),\n",
    "            self.s_std,\n",
    "        )\n",
    "\n",
    "        self.dummy_wns = np.tile(\n",
    "            np.arange(\n",
    "                0., 1., 1. / self.spectra.shape[2],\n",
    "                dtype=np_dtype_from_torch[self.dtype]\n",
    "            )[None, :self.spectra.shape[2]],\n",
    "            (self.spectra.shape[1], 1),\n",
    "        )\n",
    "\n",
    "        # normalize concentrations\n",
    "        concentrations = torch.tensor(concentrations, dtype=dtype)\n",
    "        if concentration_mean_std is None:\n",
    "            self.concentration_means = torch.nanmean(concentrations, dim=0)\n",
    "\n",
    "            self.concentration_stds = torch.maximum(\n",
    "                torch.tensor(\n",
    "                    [\n",
    "                        torch.std(col[torch.logical_not(torch.isnan(col))])\n",
    "                        for col in concentrations.T\n",
    "                    ]\n",
    "                ),\n",
    "                torch.tensor([1e-3] * concentrations.shape[1]),\n",
    "            )\n",
    "        else:\n",
    "            self.concentration_means = concentration_mean_std[0]\n",
    "            self.concentration_stds = concentration_mean_std[1]\n",
    "\n",
    "        self.concentrations = torch.divide(\n",
    "            torch.subtract(\n",
    "                concentrations,\n",
    "                self.concentration_means,\n",
    "            ),\n",
    "            self.concentration_stds,\n",
    "        )\n",
    "\n",
    "    def pick_two(self, max_idx=None):\n",
    "        max_idx = max_idx or len(self)\n",
    "        return random.choices(range(max_idx), k=2)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.concentrations)\n",
    "\n",
    "    def augment_spectra(self, spectra):\n",
    "        if self.augment_slope_std > 0.0:\n",
    "\n",
    "            def spectrum_approximation(x, slope, intercept):\n",
    "                return (slope * x + intercept).reshape(-1, 1)[:, 0]\n",
    "\n",
    "            slope, inter = scipy.optimize.curve_fit(\n",
    "                spectrum_approximation,\n",
    "                self.dummy_wns,\n",
    "                spectra.reshape(-1, 1)[:, 0],\n",
    "                p0=np.random.rand(2),\n",
    "            )[0]\n",
    "\n",
    "            new_slope = slope * (\n",
    "                    np.random.gamma(\n",
    "                        shape=1. / self.augment_slope_std,\n",
    "                        scale=self.augment_slope_std,\n",
    "                        size=1,\n",
    "                    )\n",
    "            )[0]\n",
    "            new_intercept = inter * (\n",
    "                1.0 + np.random.randn(1) * self.augment_intercept_std\n",
    "            )[0]\n",
    "            spectra += torch.tensor(\n",
    "                (new_slope - slope)\n",
    "            ) * self.dummy_wns + new_intercept - inter\n",
    "\n",
    "        factor = self.baseline_factor_bound * torch.rand(size=(1,))\n",
    "        offset = torch.rand(size=(1,)) * 2.0 * torch.pi\n",
    "        period = self.baseline_period_lower_bound + (\n",
    "            self.baseline_period_upper_bound - self.baseline_period_lower_bound\n",
    "        ) * torch.rand(size=(1,))\n",
    "        permutations = factor * torch.cos(\n",
    "            2.0 * torch.pi / period * self.dummy_wns + offset\n",
    "        )\n",
    "        return self.roll_spectrum(\n",
    "            spectra + permutations * spectra,\n",
    "            delta=random.randint(-self.rolling_bound, self.rolling_bound),\n",
    "        )\n",
    "\n",
    "    def roll_spectrum(self, spectra, delta):\n",
    "        num_spectra = spectra.shape[0]\n",
    "        rolled_spectra = np.roll(spectra, delta, axis=1)\n",
    "        if delta > 0:\n",
    "            rolled_spectra[:, :delta] = (\n",
    "                np.random.rand(num_spectra, delta) * self.spectrum_rolling_sigma + 1\n",
    "            ) * rolled_spectra[:, delta:(delta + 1)]\n",
    "        elif delta < 0:\n",
    "            rolled_spectra[:, delta:] = (\n",
    "                np.random.rand(num_spectra, -delta) * self.spectrum_rolling_sigma + 1\n",
    "            ) * rolled_spectra[:, delta - 1:delta]\n",
    "        return rolled_spectra\n",
    "\n",
    "    def combine_k_items(self, indices, weights):\n",
    "        return (\n",
    "            # spectra\n",
    "            torch.sum(\n",
    "                torch.mul(weights[:, None, None], self.spectra[indices, :, :]),\n",
    "                dim=0,\n",
    "            ),\n",
    "            # concentrations\n",
    "            torch.sum(\n",
    "                torch.mul(weights[:, None], self.concentrations[indices, :]),\n",
    "                dim=0,\n",
    "            )\n",
    "        )\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.combine_spectra_range < 1e-12:\n",
    "            spectrum = self.spectra[idx]\n",
    "            spectrum = self.augment_spectra(spectrum)\n",
    "            return {\n",
    "                \"spectra\": spectrum,\n",
    "                \"concentrations\": self.concentrations[idx],\n",
    "                \"label_weight\": torch.tensor(1.0, dtype=self.dtype),\n",
    "            }\n",
    "        else:\n",
    "            if random.random() < self.original_dp_weight:\n",
    "                one_weight = 1.\n",
    "                label_weight = torch.tensor(1.0, dtype=self.dtype)\n",
    "            else:\n",
    "                one_weight = random.uniform(0.0, self.combine_spectra_range)\n",
    "                label_weight = self.augmentation_weight\n",
    "            weights = torch.tensor([one_weight, (1 - one_weight)])\n",
    "            # just pick two random indices\n",
    "            indices = random.choices(range(len(self)), k=2)\n",
    "\n",
    "            mixed_spectra, mixed_concentrations = self.combine_k_items(\n",
    "                indices=indices,\n",
    "                weights=weights,\n",
    "            )\n",
    "            mixed_spectra = self.augment_spectra(mixed_spectra)\n",
    "            return mixed_spectra, mixed_concentrations, label_weight\n",
    "\n",
    "\n",
    "config = {\n",
    "    'initial_cnn_channels': 32,\n",
    "    'cnn_channel_factor': 1.279574024454846,\n",
    "    'num_cnn_layers': 8,\n",
    "    'kernel_size': 3,\n",
    "    'stride': 2,\n",
    "    'activation_function': 'ELU',\n",
    "    'fc_dropout': 0.10361700399831791,\n",
    "    'lr': 0.001,\n",
    "    'gamma': 0.9649606352621118,\n",
    "    'baseline_factor_bound': 0.748262317340447,\n",
    "    'baseline_period_lower_bound': 0.9703081695287203,\n",
    "    'baseline_period_span': 19.79744237606427,\n",
    "    'original_datapoint_weight': 0.4335003268130408,\n",
    "    'augment_slope_std': 0.08171025264382692,\n",
    "    'batch_size': 32,\n",
    "    'fc_dims': 226,\n",
    "    'rolling_bound': 2,\n",
    "    'num_blocks': 2,\n",
    "}\n",
    "\n",
    "def get_dataset(inputs, targets, config, inputs_mean_std=None, targets_mean_std=None):\n",
    "    return SpectralDataset(\n",
    "        spectra=inputs[:, None, :],\n",
    "        concentrations=targets,\n",
    "        dtype=torch.float32,\n",
    "        spectra_mean_std=inputs_mean_std,\n",
    "        concentration_mean_std=targets_mean_std,\n",
    "        combine_spectra_range=1.0,\n",
    "        baseline_factor_bound=config[\"baseline_factor_bound\"],\n",
    "        baseline_period_lower_bound=config[\"baseline_period_lower_bound\"],\n",
    "        baseline_period_upper_bound=(config[\"baseline_period_lower_bound\"] + config[\"baseline_period_span\"]),\n",
    "        augment_slope_std=config[\"augment_slope_std\"],\n",
    "        augment_intersept_std=0.0,\n",
    "        rolling_bound=config[\"rolling_bound\"],\n",
    "        spectrum_rolling_sigma=0.01,\n",
    "        augmentation_weight=0.1,\n",
    "        original_datapoint_weight=1.,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9c11034d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "def build_loader(\n",
    "    SEED,\n",
    "    ds,\n",
    "    train=True,\n",
    "    batch_size=1,\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    "    drop_last=True,\n",
    "    pin_memory=True,\n",
    "    persistent_workers=False,\n",
    "):\n",
    "    def seed_worker(worker_id):\n",
    "        worker_seed = torch.initial_seed() % 2**32\n",
    "        np.random.seed(worker_seed)\n",
    "        random.seed(worker_seed)\n",
    "\n",
    "    generator = torch.Generator()\n",
    "    generator.manual_seed(SEED if train else SEED+5232)\n",
    "\n",
    "    return DataLoader(\n",
    "        ds,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=pin_memory,\n",
    "        drop_last=drop_last,\n",
    "        persistent_workers=persistent_workers,\n",
    "        worker_init_fn=seed_worker,\n",
    "        generator=generator,\n",
    "        #sampler=DistributedSampler(\n",
    "        #    train_ds,\n",
    "        #    shuffle=True,\n",
    "        #    drop_last=True,\n",
    "        #    seed=config.seed\n",
    "        #)\n",
    "    )\n",
    "    \n",
    "    \n",
    "def return_dls(train_ds, eval_ds, train_batch_size, eval_batch_size):\n",
    "    train_dl = build_loader(\n",
    "        SEED,\n",
    "        train_ds,\n",
    "        train=True,\n",
    "        batch_size=train_batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=0,\n",
    "        drop_last=False,\n",
    "        pin_memory=True,\n",
    "        persistent_workers=False,\n",
    "    )\n",
    "\n",
    "    eval_dl = build_loader(\n",
    "        SEED,\n",
    "        eval_ds,\n",
    "        train=False,\n",
    "        batch_size=eval_batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=0,\n",
    "        drop_last=False,\n",
    "        pin_memory=True,\n",
    "        persistent_workers=False,\n",
    "    )\n",
    "    \n",
    "    return train_dl, eval_dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e343398b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import neptune\n",
    "\n",
    "\n",
    "def setup_neptune():\n",
    "    if not RESUME:\n",
    "        neptune_run = neptune.init_run(\n",
    "            project=\"arbaaz/kaggle-spect\",\n",
    "            name=MODEL_NAME,\n",
    "            api_token=\"eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiJlOGE2YjNiZS1mZGUyLTRjYjItYTg5Yy1mZWJkZTIzNzE1NmIifQ==\"\n",
    "        )\n",
    "\n",
    "        neptune_run[\"h_parameters\"] = {\n",
    "            \"seed\": SEED,\n",
    "            \"model_name\": MODEL_NAME,\n",
    "            \"optimizer_name\": \"nadam\",\n",
    "            \"learning_rate\": LR,\n",
    "            \"scheduler_name\": \"default\",\n",
    "            \"weight_decay\": WD,\n",
    "            \"num_epochs\": EPOCHS,\n",
    "            \"batch_size\": BATCH_SIZE,\n",
    "        }\n",
    "        if DROPOUT: neptune_run[\"h_parameters\"] = {\"dropout\": DROPOUT}\n",
    "        if DROP_PATH_RATE: neptune_run[\"h_parameters\"] = {\"drop_path_rate\": DROP_PATH_RATE}\n",
    "    else:\n",
    "        neptune_run = neptune.init_run(\n",
    "            project=\"arbaaz/crunchdao-structural-break\",\n",
    "            with_id=config.with_id,\n",
    "            api_token=\"eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiJlOGE2YjNiZS1mZGUyLTRjYjItYTg5Yy1mZWJkZTIzNzE1NmIifQ==\"\n",
    "        )\n",
    "\n",
    "    return neptune_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d4227b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "from torch.nn.modules.loss import _Loss\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "\n",
    "def loss_fn(logits, targets):\n",
    "    logits = logits.view(-1)\n",
    "    targets = targets.view(-1)\n",
    "    return F.mse_loss(logits, targets)\n",
    "\n",
    "\n",
    "def metric_fn(logits, targets):\n",
    "    preds = logits.cpu().detach().numpy()\n",
    "    targets = targets.cpu().detach().numpy()\n",
    "    \n",
    "    dim1 = r2_score(targets[:, 0], preds[:, 0])\n",
    "    dim2 = r2_score(targets[:, 1], preds[:, 1])\n",
    "    dim3 = r2_score(targets[:, 2], preds[:, 2])\n",
    "    \n",
    "    return dim1, dim2, dim3, r2_score(targets, logits)\n",
    "\n",
    "\n",
    "class MSEIgnoreNans(_Loss):\n",
    "    def forward(\n",
    "        self,\n",
    "        input: torch.Tensor,\n",
    "        target: torch.Tensor,\n",
    "        weights: torch.Tensor,\n",
    "    ) -> torch.Tensor:\n",
    "        mask = torch.isfinite(target)\n",
    "        mse = torch.mean(\n",
    "            torch.mul(\n",
    "                torch.square(input[mask] - target[mask]),\n",
    "                torch.tile(weights[:, None], dims=(1, target.shape[1]))[mask],\n",
    "            )\n",
    "        )\n",
    "        return torch.where(\n",
    "            torch.isfinite(mse),\n",
    "            mse,\n",
    "            torch.tensor(0.).to(target.device),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6ccc0a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "\n",
    "class Identity(torch.torch.nn.Module):\n",
    "    def forward(self, x):\n",
    "        return x\n",
    "\n",
    "\n",
    "# this is not a resnet yet\n",
    "class ReZeroBlock(torch.torch.nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels,\n",
    "        out_channels,\n",
    "        activation_function,\n",
    "        kernel_size,\n",
    "        stride,\n",
    "        dtype,\n",
    "        norm_layer=None,\n",
    "    ):\n",
    "        super(ReZeroBlock, self).__init__()\n",
    "        if norm_layer is None:\n",
    "            norm_layer = torch.torch.nn.BatchNorm1d\n",
    "\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        self.padding = divmod(kernel_size, 2)[0] if stride == 1 else 0\n",
    "\n",
    "        # does not change spatial dimension\n",
    "        self.conv1 = torch.nn.Conv1d(\n",
    "            in_channels,\n",
    "            out_channels,\n",
    "            kernel_size=1,\n",
    "            stride=1,\n",
    "            bias=False,\n",
    "            dtype=dtype,\n",
    "        )\n",
    "        self.bn1 = norm_layer(out_channels, dtype=dtype)\n",
    "        # Both self.conv2 and self.downsample layers\n",
    "        # downsample the input when stride != 1\n",
    "        self.conv2 = torch.nn.Conv1d(\n",
    "            out_channels,\n",
    "            out_channels,\n",
    "            kernel_size=kernel_size,\n",
    "            stride=stride,\n",
    "            groups=out_channels,\n",
    "            bias=False,\n",
    "            dtype=dtype,\n",
    "            padding=self.padding,\n",
    "        )\n",
    "        if stride > 1:\n",
    "            down_conv = torch.nn.Conv1d(\n",
    "                in_channels,\n",
    "                out_channels,\n",
    "                kernel_size=kernel_size,\n",
    "                stride=stride,\n",
    "                bias=False,\n",
    "                dtype=dtype,\n",
    "                # groups=out_channels,\n",
    "            )\n",
    "        else:\n",
    "            down_conv = Identity()\n",
    "\n",
    "        self.down_sample = torch.nn.Sequential(\n",
    "            down_conv,\n",
    "            norm_layer(out_channels),\n",
    "        )\n",
    "        self.bn2 = norm_layer(out_channels, dtype=dtype)\n",
    "        # does not change the spatial dimension\n",
    "        self.conv3 = torch.nn.Conv1d(\n",
    "            out_channels,\n",
    "            out_channels,\n",
    "            kernel_size=1,\n",
    "            stride=1,\n",
    "            bias=False,\n",
    "            dtype=dtype,\n",
    "        )\n",
    "        self.bn3 = norm_layer(out_channels, dtype=dtype)\n",
    "        self.activation = activation_function(inplace=True)\n",
    "        self.factor = torch.torch.nn.parameter.Parameter(torch.tensor(0.0, dtype=dtype))\n",
    "\n",
    "    def next_spatial_dim(self, last_spatial_dim):\n",
    "        return math.floor(\n",
    "            (last_spatial_dim + 2 * self.padding - self.kernel_size)\n",
    "            / self.stride + 1\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.activation(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.activation(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        # not really the identity, but kind of\n",
    "        identity = self.down_sample(x)\n",
    "\n",
    "        return self.activation(out * self.factor + identity)\n",
    "\n",
    "\n",
    "class ResNetEncoder(torch.torch.nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        spectrum_size,\n",
    "        cnn_encoder_channel_dims,\n",
    "        activation_function,\n",
    "        kernel_size,\n",
    "        stride,\n",
    "        dtype,\n",
    "        num_blocks,\n",
    "        verbose=False,\n",
    "    ):\n",
    "        super(ResNetEncoder, self).__init__()\n",
    "\n",
    "        self.spatial_dims = [spectrum_size]\n",
    "        layers = []\n",
    "        for in_channels, out_channels in zip(\n",
    "            cnn_encoder_channel_dims[:-1],\n",
    "            cnn_encoder_channel_dims[1:],\n",
    "        ):\n",
    "            block = ReZeroBlock(\n",
    "                in_channels=in_channels,\n",
    "                out_channels=out_channels,\n",
    "                activation_function=activation_function,\n",
    "                kernel_size=kernel_size,\n",
    "                stride=stride,\n",
    "                dtype=dtype,\n",
    "            )\n",
    "            layers.append(block)\n",
    "            self.spatial_dims.append(block.next_spatial_dim(self.spatial_dims[-1]))\n",
    "            for _ in range(num_blocks - 1):\n",
    "                block = ReZeroBlock(\n",
    "                    in_channels=out_channels,\n",
    "                    out_channels=out_channels,\n",
    "                    activation_function=activation_function,\n",
    "                    kernel_size=kernel_size,\n",
    "                    stride=1,\n",
    "                    dtype=dtype,\n",
    "                )\n",
    "                layers.append(block)\n",
    "                self.spatial_dims.append(block.next_spatial_dim(self.spatial_dims[-1]))\n",
    "\n",
    "        self.resnet_layers = torch.torch.nn.Sequential(*layers)\n",
    "        if verbose:\n",
    "            print(\"CNN Encoder Channel Dims: %s\" % (cnn_encoder_channel_dims))\n",
    "            print(\"CNN Encoder Spatial Dims: %s\" % (self.spatial_dims))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.resnet_layers(x)\n",
    "\n",
    "\n",
    "class ReZeroNet(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        spectra_channels,\n",
    "        spectra_size,\n",
    "        initial_cnn_channels,\n",
    "        cnn_channel_factor,\n",
    "        num_cnn_layers,\n",
    "        kernel_size,\n",
    "        stride,\n",
    "        activation_function,\n",
    "        fc_dims,\n",
    "        fc_dropout=0.0,\n",
    "        dtype=None,\n",
    "        verbose=False,\n",
    "        fc_output_channels=1,\n",
    "        num_blocks=1,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.fc_output_channels = fc_output_channels\n",
    "        self.dtype = dtype or torch.float32\n",
    "\n",
    "        activation_function = getattr(torch.nn, activation_function)\n",
    "\n",
    "        # Setup CNN Encoder\n",
    "        cnn_encoder_channel_dims = [spectra_channels] + [\n",
    "            int(initial_cnn_channels * (cnn_channel_factor**idx))\n",
    "            for idx in range(num_cnn_layers)\n",
    "        ]\n",
    "        self.cnn_encoder = ResNetEncoder(\n",
    "            spectrum_size=spectra_size,\n",
    "            cnn_encoder_channel_dims=cnn_encoder_channel_dims,\n",
    "            activation_function=activation_function,\n",
    "            kernel_size=kernel_size,\n",
    "            stride=stride,\n",
    "            num_blocks=num_blocks,\n",
    "            dtype=dtype,\n",
    "            verbose=verbose,\n",
    "        )\n",
    "        self.fc_dims = [\n",
    "            int(\n",
    "                self.cnn_encoder.spatial_dims[-1]\n",
    "            ) * int(cnn_encoder_channel_dims[-1])\n",
    "        ] + fc_dims\n",
    "\n",
    "        if verbose:\n",
    "            print(\"Fc Dims: %s\" % self.fc_dims)\n",
    "        fc_layers = []\n",
    "        for idx, (in_dim, out_dim) in enumerate(\n",
    "                zip(self.fc_dims[:-2], self.fc_dims[1:-1])\n",
    "        ):\n",
    "            fc_layers.append(torch.nn.Linear(in_dim, out_dim))\n",
    "            fc_layers.append(torch.nn.ELU())\n",
    "            fc_layers.append(torch.nn.Dropout(fc_dropout / (2 ** idx)))\n",
    "        fc_layers.append(\n",
    "            torch.nn.Linear(\n",
    "                self.fc_dims[-2],\n",
    "                self.fc_dims[-1] * self.fc_output_channels,\n",
    "            ),\n",
    "        )\n",
    "        self.fc_net = torch.nn.Sequential(*fc_layers)\n",
    "        if verbose:\n",
    "            num_params = sum(p.numel() for p in self.parameters())\n",
    "            print(\"Number of Parameters: %s\" % num_params)\n",
    "\n",
    "    def forward(self, spectra):\n",
    "        embeddings = self.cnn_encoder(spectra)\n",
    "        forecast = self.fc_net(embeddings.view(-1, self.fc_dims[0]))\n",
    "        if self.fc_output_channels > 1:\n",
    "            forecast = forecast.reshape(\n",
    "                -1, self.fc_output_channels, self.fc_dims[-1]\n",
    "            )\n",
    "        return forecast\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "035dd91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "mse_loss_function = MSEIgnoreNans()\n",
    "\n",
    "def train(\n",
    "    model, \n",
    "    optimizer,\n",
    "    device,\n",
    "    scaler, \n",
    "    scheduler,\n",
    "    train_dl,\n",
    "    eval_dl,\n",
    "    loss_fn,\n",
    "    epochs,\n",
    "    checkpoint_name,\n",
    "    score=-float(\"inf\"),\n",
    "    neptune_run=None,\n",
    "    p=True,\n",
    "):  \n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "        all_logits = []\n",
    "        all_targets = []\n",
    "        \n",
    "        for inputs, targets, weights in train_dl:\n",
    "            inputs = inputs.to(device, non_blocking=True)\n",
    "            targets = targets.to(device, non_blocking=True)\n",
    "            weights = weights.to(device, non_blocking=True)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            with torch.amp.autocast(device_type=device, dtype=torch.float16, cache_enabled=True):\n",
    "                logits = model(inputs)\n",
    "                loss = loss_fn(logits, targets)\n",
    "                            \n",
    "            #loss.backward()\n",
    "            #optimizer.step()\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            scheduler.step()\n",
    "            if neptune_run is not None:  neptune_run[\"lr_step\"].append(scheduler.get_last_lr()[0])\n",
    "            \n",
    "            total_loss += loss.detach().cpu()\n",
    "            all_logits.append(logits.detach().cpu())\n",
    "            all_targets.append(targets.detach().cpu())\n",
    "        \n",
    "        all_logits = torch.cat(all_logits)\n",
    "        all_targets = torch.cat(all_targets)\n",
    "\n",
    "        one, two, three, r2 = metric_fn(all_logits, all_targets)\n",
    "        total_loss = total_loss / len(train_dl)\n",
    "        \n",
    "        model.eval()\n",
    "        eval_total_loss = 0.0\n",
    "        eval_all_logits = []\n",
    "        eval_all_targets = []\n",
    "\n",
    "        for inputs, targets, weights in eval_dl:\n",
    "            inputs = inputs.to(device, non_blocking=True)\n",
    "            targets = targets.to(device, non_blocking=True)\n",
    "            weights = weights.to(device, non_blocking=True)\n",
    "\n",
    "            with torch.inference_mode():\n",
    "                #with torch.amp.autocast(device_type=device, dtype=torch.float16, cache_enabled=True):\n",
    "                logits = model(inputs)\n",
    "                loss = loss_fn(logits, targets)\n",
    "\n",
    "            eval_total_loss += loss.detach().cpu()\n",
    "            eval_all_logits.append(logits.detach().cpu())\n",
    "            eval_all_targets.append(targets.detach().cpu())\n",
    "        \n",
    "        eval_all_logits = torch.cat(eval_all_logits)\n",
    "        eval_all_targets = torch.cat(eval_all_targets)\n",
    "\n",
    "        eval_one, eval_two, eval_three, eval_r2 = metric_fn(eval_all_logits, eval_all_targets)\n",
    "        eval_total_loss = eval_total_loss / len(eval_dl)\n",
    "        \n",
    "        if eval_r2 > score:\n",
    "            score = eval_r2\n",
    "            data = {\"state_dict\": model.state_dict()}\n",
    "            data[\"epoch\"] = epoch \n",
    "            data[\"score\"] = score\n",
    "            torch.save(data, f\"/kaggle/working/{checkpoint_name}\")\n",
    "        \n",
    "        if neptune_run is not None:\n",
    "            neptune_run[\"train/loss\"].append(total_loss)\n",
    "            neptune_run[\"eval/loss\"].append(eval_total_loss)\n",
    "            neptune_run[\"train/r2\"].append(r2)\n",
    "            neptune_run[\"eval/r2\"].append(eval_r2)\n",
    "            neptune_run[\"train/one\"].append(one)\n",
    "            neptune_run[\"train/two\"].append(two)\n",
    "            neptune_run[\"train/three\"].append(three)\n",
    "            neptune_run[\"eval/one\"].append(eval_one)\n",
    "            neptune_run[\"eval/two\"].append(eval_two)\n",
    "            neptune_run[\"eval/three\"].append(eval_three)\n",
    "            \n",
    "        if p and epoch % 5 == 0:\n",
    "            print(\n",
    "                f\"Epoch: {epoch}, \"\n",
    "                f\"train/loss: {total_loss:.4f}, \"\n",
    "                f\"eval/loss: {eval_total_loss:.4f}, \"\n",
    "                f\"train/r2: {r2:.4f}, \"\n",
    "                f\"eval/r2: {eval_r2:.4f}, \"\n",
    "                f\"train/one: {one:.4f}, \"\n",
    "                f\"train/two: {two:.4f}, \"\n",
    "                f\"train/three: {three:.4f}, \"\n",
    "                f\"eval/one: {eval_one:.4f}, \"\n",
    "                f\"eval/two: {eval_two:.4f}, \"\n",
    "                f\"eval/three: {eval_three:.4f} \"\n",
    "            )\n",
    "            \n",
    "    if neptune_run is not None: neptune_run.stop()\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8dd5d0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings#; warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "EPOCHS = 100\n",
    "WD = 1e-3\n",
    "LR = 1e-4\n",
    "\n",
    "DROPOUT = 0.5\n",
    "DROP_PATH_RATE = None\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "RESUME = False\n",
    "\n",
    "config[\"dtype\"] = torch.float32\n",
    "config[\"spectra_size\"] = 1643\n",
    "config[\"spectra_channels\"] = 1\n",
    "config[\"fc_dims\"] = [\n",
    "    config[\"fc_dims\"],\n",
    "    int(config[\"fc_dims\"] / 2),\n",
    "    3,\n",
    "]\n",
    "\n",
    "#mse_loss_function = MSEIgnoreNans()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "54dd678c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.734309\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[neptune] [warning] NeptuneWarning: By default, these monitoring options are disabled in interactive sessions: 'capture_stdout', 'capture_stderr', 'capture_traceback', 'capture_hardware_metrics'. You can set them to 'True' when initializing the run and the monitoring will continue until you call run.stop() or the kernel stops. NOTE: To track the source files, pass their paths to the 'source_code' argument. For help, see: https://docs-legacy.neptune.ai/logging/source_code/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[neptune] [info   ] Neptune initialized. Open in the app: https://app.neptune.ai/arbaaz/kaggle-spect/e/KAG-142\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1f5b5776117460d92a85592a7bda33d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, train/loss: 1.0172, eval/loss: 0.8975, train/r2: -0.0174, eval/r2: -0.1450, train/one: -0.0145, train/two: -0.0211, train/three: -0.0165, eval/one: -0.0090, eval/two: -0.0265, eval/three: -0.3995 \n",
      "Epoch: 5, train/loss: 0.9550, eval/loss: 1.0531, train/r2: -0.0542, eval/r2: -0.1901, train/one: -0.0872, train/two: -0.0243, train/three: -0.0510, eval/one: -0.3751, eval/two: -0.1024, eval/three: -0.0927 \n",
      "Epoch: 10, train/loss: 0.8852, eval/loss: 0.9818, train/r2: 0.0553, eval/r2: -0.1184, train/one: 0.0075, train/two: -0.0007, train/three: 0.1592, eval/one: 0.0162, eval/two: -0.2655, eval/three: -0.1058 \n",
      "Epoch: 15, train/loss: 0.7898, eval/loss: 0.9467, train/r2: 0.1760, eval/r2: 0.0186, train/one: -0.0006, train/two: 0.0167, train/three: 0.5119, eval/one: -0.0052, eval/two: -0.1404, eval/three: 0.2014 \n",
      "Epoch: 20, train/loss: 0.6852, eval/loss: 0.8563, train/r2: 0.2832, eval/r2: -0.0017, train/one: 0.0799, train/two: 0.0056, train/three: 0.7640, eval/one: -0.0913, eval/two: -0.1328, eval/three: 0.2188 \n",
      "Epoch: 25, train/loss: 0.6024, eval/loss: 0.7899, train/r2: 0.3539, eval/r2: 0.1234, train/one: 0.1907, train/two: 0.0385, train/three: 0.8324, eval/one: -0.2673, eval/two: -0.2190, eval/three: 0.8566 \n",
      "Epoch: 30, train/loss: 0.6041, eval/loss: 0.5590, train/r2: 0.3685, eval/r2: 0.0275, train/one: 0.2141, train/two: 0.0996, train/three: 0.7919, eval/one: -0.4148, eval/two: -0.3157, eval/three: 0.8130 \n",
      "Epoch: 35, train/loss: 0.5645, eval/loss: 0.4514, train/r2: 0.4469, eval/r2: 0.2296, train/one: 0.4384, train/two: 0.0351, train/three: 0.8673, eval/one: 0.1734, eval/two: -0.3561, eval/three: 0.8716 \n",
      "Epoch: 40, train/loss: 0.4491, eval/loss: 0.4735, train/r2: 0.5621, eval/r2: 0.3607, train/one: 0.7059, train/two: 0.1135, train/three: 0.8668, eval/one: 0.5029, eval/two: -0.3155, eval/three: 0.8948 \n",
      "Epoch: 45, train/loss: 0.3822, eval/loss: 0.4132, train/r2: 0.6566, eval/r2: 0.5391, train/one: 0.7680, train/two: 0.3200, train/three: 0.8819, eval/one: 0.7528, eval/two: -0.0474, eval/three: 0.9119 \n",
      "Epoch: 50, train/loss: 0.3689, eval/loss: 0.4393, train/r2: 0.6600, eval/r2: 0.4154, train/one: 0.7784, train/two: 0.3484, train/three: 0.8533, eval/one: 0.4819, eval/two: -0.1392, eval/three: 0.9035 \n",
      "Epoch: 55, train/loss: 0.3122, eval/loss: 0.3130, train/r2: 0.6957, eval/r2: 0.5583, train/one: 0.8303, train/two: 0.3622, train/three: 0.8947, eval/one: 0.8132, eval/two: 0.3345, eval/three: 0.5272 \n",
      "Epoch: 60, train/loss: 0.2841, eval/loss: 0.3577, train/r2: 0.6648, eval/r2: 0.6080, train/one: 0.8192, train/two: 0.3166, train/three: 0.8586, eval/one: 0.7753, eval/two: 0.1657, eval/three: 0.8830 \n",
      "Epoch: 65, train/loss: 0.2647, eval/loss: 0.2122, train/r2: 0.7460, eval/r2: 0.6164, train/one: 0.8673, train/two: 0.4796, train/three: 0.8909, eval/one: 0.7770, eval/two: 0.4680, eval/three: 0.6041 \n",
      "Epoch: 70, train/loss: 0.2650, eval/loss: 0.3061, train/r2: 0.7231, eval/r2: 0.5800, train/one: 0.8174, train/two: 0.4359, train/three: 0.9161, eval/one: 0.6582, eval/two: 0.2099, eval/three: 0.8719 \n",
      "Epoch: 75, train/loss: 0.2455, eval/loss: 0.3875, train/r2: 0.7702, eval/r2: 0.5819, train/one: 0.8744, train/two: 0.5022, train/three: 0.9341, eval/one: 0.6253, eval/two: 0.2358, eval/three: 0.8847 \n",
      "Epoch: 80, train/loss: 0.2389, eval/loss: 0.4057, train/r2: 0.7641, eval/r2: 0.6513, train/one: 0.8390, train/two: 0.5485, train/three: 0.9048, eval/one: 0.7783, eval/two: 0.2431, eval/three: 0.9324 \n",
      "Epoch: 85, train/loss: 0.2336, eval/loss: 0.2236, train/r2: 0.7526, eval/r2: 0.6546, train/one: 0.8395, train/two: 0.4887, train/three: 0.9296, eval/one: 0.7890, eval/two: 0.3456, eval/three: 0.8293 \n",
      "Epoch: 90, train/loss: 0.2246, eval/loss: 0.3432, train/r2: 0.7647, eval/r2: 0.6303, train/one: 0.8211, train/two: 0.5675, train/three: 0.9056, eval/one: 0.6557, eval/two: 0.3078, eval/three: 0.9275 \n",
      "Epoch: 95, train/loss: 0.2475, eval/loss: 0.2310, train/r2: 0.7985, eval/r2: 0.6847, train/one: 0.8600, train/two: 0.6416, train/three: 0.8938, eval/one: 0.7877, eval/two: 0.3632, eval/three: 0.9032 \n",
      "[neptune] [info   ] Shutting down background jobs, please wait a moment...\n",
      "[neptune] [info   ] Done!\n",
      "[neptune] [info   ] Waiting for the remaining 154 operations to synchronize with Neptune. Do not kill this process.\n",
      "[neptune] [info   ] All 154 operations synced, thanks for waiting!\n",
      "[neptune] [info   ] Explore the metadata in the Neptune app: https://app.neptune.ai/arbaaz/kaggle-spect/e/KAG-142/metadata\n",
      "[neptune] [info   ] Neptune initialized. Open in the app: https://app.neptune.ai/arbaaz/kaggle-spect/e/KAG-143\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c93ddd4c41b4ef3a71c9266a7ee2f45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, train/loss: 1.0662, eval/loss: 0.9719, train/r2: -0.0370, eval/r2: -0.1358, train/one: -0.0619, train/two: -0.0200, train/three: -0.0290, eval/one: -0.1062, eval/two: -0.2865, eval/three: -0.0146 \n",
      "Epoch: 5, train/loss: 0.9967, eval/loss: 0.8060, train/r2: -0.0066, eval/r2: -0.0233, train/one: -0.0946, train/two: 0.0366, train/three: 0.0381, eval/one: -0.0210, eval/two: -0.0227, eval/three: -0.0261 \n",
      "Epoch: 10, train/loss: 0.9565, eval/loss: 0.8314, train/r2: 0.0433, eval/r2: -0.0323, train/one: -0.0366, train/two: 0.0116, train/three: 0.1549, eval/one: 0.0169, eval/two: -0.0285, eval/three: -0.0853 \n",
      "Epoch: 15, train/loss: 0.8958, eval/loss: 0.7879, train/r2: 0.1576, eval/r2: 0.0651, train/one: 0.0261, train/two: 0.0364, train/three: 0.4103, eval/one: 0.1362, eval/two: -0.1639, eval/three: 0.2229 \n",
      "Epoch: 20, train/loss: 0.6828, eval/loss: 1.0552, train/r2: 0.2818, eval/r2: 0.1194, train/one: 0.0795, train/two: 0.0309, train/three: 0.7349, eval/one: -0.0327, eval/two: -0.3818, eval/three: 0.7727 \n",
      "Epoch: 25, train/loss: 0.7119, eval/loss: 0.9610, train/r2: 0.2583, eval/r2: -0.1990, train/one: 0.0611, train/two: -0.0051, train/three: 0.7189, eval/one: -0.5114, eval/two: -0.8911, eval/three: 0.8057 \n",
      "Epoch: 30, train/loss: 0.7684, eval/loss: 0.6164, train/r2: 0.3026, eval/r2: 0.2754, train/one: 0.1113, train/two: -0.0398, train/three: 0.8362, eval/one: 0.2191, eval/two: -0.2574, eval/three: 0.8644 \n",
      "Epoch: 35, train/loss: 0.5710, eval/loss: 0.7295, train/r2: 0.4059, eval/r2: 0.3471, train/one: 0.2772, train/two: 0.0335, train/three: 0.9070, eval/one: 0.1714, eval/two: 0.0493, eval/three: 0.8206 \n",
      "Epoch: 40, train/loss: 0.4927, eval/loss: 0.6182, train/r2: 0.4690, eval/r2: 0.3737, train/one: 0.3929, train/two: 0.1211, train/three: 0.8930, eval/one: 0.3997, eval/two: -0.0246, eval/three: 0.7459 \n",
      "Epoch: 45, train/loss: 0.5492, eval/loss: 0.5931, train/r2: 0.4575, eval/r2: 0.3211, train/one: 0.4335, train/two: 0.1099, train/three: 0.8290, eval/one: 0.0691, eval/two: 0.0316, eval/three: 0.8628 \n",
      "Epoch: 50, train/loss: 0.4452, eval/loss: 0.5783, train/r2: 0.5783, eval/r2: 0.4884, train/one: 0.5480, train/two: 0.2879, train/three: 0.8989, eval/one: 0.5655, eval/two: 0.0174, eval/three: 0.8823 \n",
      "Epoch: 55, train/loss: 0.3627, eval/loss: 0.4475, train/r2: 0.6248, eval/r2: 0.4128, train/one: 0.6647, train/two: 0.3141, train/three: 0.8956, eval/one: 0.5499, eval/two: -0.0210, eval/three: 0.7095 \n",
      "Epoch: 60, train/loss: 0.3703, eval/loss: 0.3505, train/r2: 0.6518, eval/r2: 0.5973, train/one: 0.7430, train/two: 0.3455, train/three: 0.8668, eval/one: 0.7644, eval/two: 0.2217, eval/three: 0.8057 \n",
      "Epoch: 65, train/loss: 0.3206, eval/loss: 0.3476, train/r2: 0.6890, eval/r2: 0.4377, train/one: 0.7712, train/two: 0.3927, train/three: 0.9032, eval/one: 0.1435, eval/two: 0.2666, eval/three: 0.9029 \n",
      "Epoch: 70, train/loss: 0.3258, eval/loss: 0.3819, train/r2: 0.6876, eval/r2: 0.6024, train/one: 0.8163, train/two: 0.3865, train/three: 0.8601, eval/one: 0.7557, eval/two: 0.2480, eval/three: 0.8034 \n",
      "Epoch: 75, train/loss: 0.2664, eval/loss: 0.3788, train/r2: 0.7542, eval/r2: 0.6251, train/one: 0.8236, train/two: 0.5485, train/three: 0.8905, eval/one: 0.7819, eval/two: 0.1885, eval/three: 0.9048 \n",
      "Epoch: 80, train/loss: 0.3007, eval/loss: 0.2873, train/r2: 0.7014, eval/r2: 0.6495, train/one: 0.7617, train/two: 0.4394, train/three: 0.9030, eval/one: 0.9002, eval/two: 0.1057, eval/three: 0.9426 \n",
      "Epoch: 85, train/loss: 0.2663, eval/loss: 0.2345, train/r2: 0.7010, eval/r2: 0.7108, train/one: 0.8191, train/two: 0.3905, train/three: 0.8934, eval/one: 0.8797, eval/two: 0.4187, eval/three: 0.8340 \n",
      "Epoch: 90, train/loss: 0.2373, eval/loss: 0.2544, train/r2: 0.7410, eval/r2: 0.7170, train/one: 0.7545, train/two: 0.5942, train/three: 0.8742, eval/one: 0.8588, eval/two: 0.4217, eval/three: 0.8703 \n",
      "Epoch: 95, train/loss: 0.2179, eval/loss: 0.2303, train/r2: 0.7596, eval/r2: 0.7144, train/one: 0.8357, train/two: 0.5311, train/three: 0.9121, eval/one: 0.8214, eval/two: 0.5078, eval/three: 0.8140 \n",
      "[neptune] [info   ] Shutting down background jobs, please wait a moment...\n",
      "[neptune] [info   ] Done!\n",
      "[neptune] [info   ] Waiting for the remaining 116 operations to synchronize with Neptune. Do not kill this process.\n",
      "[neptune] [info   ] All 116 operations synced, thanks for waiting!\n",
      "[neptune] [info   ] Explore the metadata in the Neptune app: https://app.neptune.ai/arbaaz/kaggle-spect/e/KAG-143/metadata\n",
      "[neptune] [info   ] Neptune initialized. Open in the app: https://app.neptune.ai/arbaaz/kaggle-spect/e/KAG-144\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "931d9b8093ce42aa9089d775df363322",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, train/loss: 0.9722, eval/loss: 1.3871, train/r2: -0.0502, eval/r2: -0.0175, train/one: -0.0565, train/two: -0.0225, train/three: -0.0717, eval/one: -0.0154, eval/two: -0.0283, eval/three: -0.0088 \n",
      "Epoch: 5, train/loss: 0.8818, eval/loss: 0.9453, train/r2: 0.0544, eval/r2: -0.2008, train/one: 0.0222, train/two: -0.0020, train/three: 0.1431, eval/one: -0.2375, eval/two: -0.0686, eval/three: -0.2962 \n",
      "Epoch: 10, train/loss: 0.8742, eval/loss: 1.1500, train/r2: 0.1055, eval/r2: -0.0568, train/one: -0.1785, train/two: 0.0545, train/three: 0.4406, eval/one: -0.0503, eval/two: -0.2058, eval/three: 0.0858 \n",
      "Epoch: 15, train/loss: 0.7490, eval/loss: 0.8851, train/r2: 0.2426, eval/r2: -0.0534, train/one: 0.0025, train/two: -0.0267, train/three: 0.7519, eval/one: 0.0059, eval/two: -0.2729, eval/three: 0.1069 \n",
      "Epoch: 20, train/loss: 0.6988, eval/loss: 0.7717, train/r2: 0.3139, eval/r2: 0.1832, train/one: 0.0799, train/two: 0.0354, train/three: 0.8263, eval/one: 0.1243, eval/two: -0.4333, eval/three: 0.8586 \n",
      "Epoch: 25, train/loss: 0.6060, eval/loss: 0.7128, train/r2: 0.3091, eval/r2: 0.1734, train/one: 0.1155, train/two: -0.0127, train/three: 0.8246, eval/one: 0.0016, eval/two: -0.3598, eval/three: 0.8784 \n",
      "Epoch: 30, train/loss: 0.6064, eval/loss: 0.4985, train/r2: 0.3725, eval/r2: 0.2759, train/one: 0.2159, train/two: 0.0592, train/three: 0.8425, eval/one: 0.1903, eval/two: -0.2494, eval/three: 0.8870 \n",
      "Epoch: 35, train/loss: 0.5501, eval/loss: 0.6114, train/r2: 0.4370, eval/r2: 0.2389, train/one: 0.3337, train/two: 0.0902, train/three: 0.8872, eval/one: -0.1445, eval/two: 0.0116, eval/three: 0.8497 \n",
      "Epoch: 40, train/loss: 0.5694, eval/loss: 0.6051, train/r2: 0.4610, eval/r2: 0.2670, train/one: 0.3232, train/two: 0.1739, train/three: 0.8859, eval/one: 0.3598, eval/two: -0.4442, eval/three: 0.8853 \n",
      "Epoch: 45, train/loss: 0.4513, eval/loss: 0.5669, train/r2: 0.5333, eval/r2: 0.2644, train/one: 0.4635, train/two: 0.2081, train/three: 0.9282, eval/one: 0.2140, eval/two: -0.2681, eval/three: 0.8473 \n",
      "Epoch: 50, train/loss: 0.4081, eval/loss: 0.4186, train/r2: 0.6320, eval/r2: 0.5068, train/one: 0.7247, train/two: 0.2483, train/three: 0.9230, eval/one: 0.6913, eval/two: -0.0042, eval/three: 0.8334 \n",
      "Epoch: 55, train/loss: 0.3426, eval/loss: 0.4536, train/r2: 0.6245, eval/r2: 0.4793, train/one: 0.7075, train/two: 0.2676, train/three: 0.8983, eval/one: 0.5550, eval/two: 0.0783, eval/three: 0.8045 \n",
      "Epoch: 60, train/loss: 0.3144, eval/loss: 0.6250, train/r2: 0.6413, eval/r2: 0.2446, train/one: 0.7569, train/two: 0.2603, train/three: 0.9066, eval/one: -0.2279, eval/two: 0.0925, eval/three: 0.8693 \n",
      "Epoch: 65, train/loss: 0.2869, eval/loss: 0.4086, train/r2: 0.7103, eval/r2: 0.5340, train/one: 0.8318, train/two: 0.3957, train/three: 0.9035, eval/one: 0.6317, eval/two: 0.0908, eval/three: 0.8795 \n",
      "Epoch: 70, train/loss: 0.3126, eval/loss: 0.2659, train/r2: 0.7015, eval/r2: 0.5442, train/one: 0.7978, train/two: 0.3942, train/three: 0.9125, eval/one: 0.7196, eval/two: -0.0166, eval/three: 0.9294 \n",
      "Epoch: 75, train/loss: 0.2439, eval/loss: 0.3322, train/r2: 0.7536, eval/r2: 0.6289, train/one: 0.8604, train/two: 0.4992, train/three: 0.9012, eval/one: 0.6938, eval/two: 0.2437, eval/three: 0.9493 \n",
      "Epoch: 80, train/loss: 0.2587, eval/loss: 0.3181, train/r2: 0.7454, eval/r2: 0.5623, train/one: 0.8696, train/two: 0.4530, train/three: 0.9138, eval/one: 0.7711, eval/two: -0.0297, eval/three: 0.9454 \n",
      "Epoch: 85, train/loss: 0.2583, eval/loss: 0.3549, train/r2: 0.7212, eval/r2: 0.6285, train/one: 0.7804, train/two: 0.4760, train/three: 0.9071, eval/one: 0.7359, eval/two: 0.2664, eval/three: 0.8834 \n",
      "Epoch: 90, train/loss: 0.2975, eval/loss: 0.2906, train/r2: 0.7266, eval/r2: 0.5076, train/one: 0.8025, train/two: 0.4880, train/three: 0.8892, eval/one: 0.6170, eval/two: 0.0161, eval/three: 0.8897 \n",
      "Epoch: 95, train/loss: 0.2615, eval/loss: 0.2208, train/r2: 0.7466, eval/r2: 0.6799, train/one: 0.8583, train/two: 0.4929, train/three: 0.8888, eval/one: 0.7941, eval/two: 0.3047, eval/three: 0.9410 \n",
      "[neptune] [info   ] Shutting down background jobs, please wait a moment...\n",
      "[neptune] [info   ] Done!\n",
      "[neptune] [info   ] Waiting for the remaining 90 operations to synchronize with Neptune. Do not kill this process.\n",
      "[neptune] [info   ] All 90 operations synced, thanks for waiting!\n",
      "[neptune] [info   ] Explore the metadata in the Neptune app: https://app.neptune.ai/arbaaz/kaggle-spect/e/KAG-144/metadata\n",
      "[neptune] [info   ] Neptune initialized. Open in the app: https://app.neptune.ai/arbaaz/kaggle-spect/e/KAG-145\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f58d3d7ce33b4c84b04840f762abeaee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, train/loss: 1.0620, eval/loss: 1.5301, train/r2: -0.0398, eval/r2: -0.1701, train/one: -0.0475, train/two: -0.0497, train/three: -0.0222, eval/one: -0.2129, eval/two: -0.0005, eval/three: -0.2968 \n",
      "Epoch: 5, train/loss: 0.8770, eval/loss: 1.2654, train/r2: -0.0471, eval/r2: -0.4644, train/one: -0.1050, train/two: -0.1523, train/three: 0.1161, eval/one: -0.1151, eval/two: -0.4687, eval/three: -0.8092 \n",
      "Epoch: 10, train/loss: 0.9722, eval/loss: 1.5542, train/r2: 0.0684, eval/r2: -0.5664, train/one: -0.1025, train/two: -0.0182, train/three: 0.3259, eval/one: -1.5822, eval/two: -0.0949, eval/three: -0.0221 \n",
      "Epoch: 15, train/loss: 0.7635, eval/loss: 1.2672, train/r2: 0.2363, eval/r2: 0.0639, train/one: 0.0928, train/two: -0.0154, train/three: 0.6316, eval/one: -0.0314, eval/two: -0.0280, eval/three: 0.2512 \n",
      "Epoch: 20, train/loss: 0.6283, eval/loss: 0.8415, train/r2: 0.3027, eval/r2: 0.1728, train/one: 0.1165, train/two: 0.0138, train/three: 0.7778, eval/one: -0.1826, eval/two: -0.0854, eval/three: 0.7862 \n",
      "Epoch: 25, train/loss: 0.6735, eval/loss: 0.7336, train/r2: 0.3496, eval/r2: 0.3149, train/one: 0.1901, train/two: 0.0207, train/three: 0.8379, eval/one: 0.1892, eval/two: -0.0875, eval/three: 0.8431 \n",
      "Epoch: 30, train/loss: 0.6556, eval/loss: 1.0173, train/r2: 0.3553, eval/r2: 0.3641, train/one: 0.2635, train/two: 0.0246, train/three: 0.7779, eval/one: 0.0756, eval/two: 0.1076, eval/three: 0.9092 \n",
      "Epoch: 35, train/loss: 0.5631, eval/loss: 0.8833, train/r2: 0.4433, eval/r2: 0.3580, train/one: 0.4269, train/two: 0.0519, train/three: 0.8512, eval/one: 0.3155, eval/two: -0.0470, eval/three: 0.8055 \n",
      "Epoch: 40, train/loss: 0.5573, eval/loss: 0.9257, train/r2: 0.4977, eval/r2: 0.3437, train/one: 0.4991, train/two: 0.1020, train/three: 0.8921, eval/one: 0.5734, eval/two: -0.0893, eval/three: 0.5470 \n",
      "Epoch: 45, train/loss: 0.4237, eval/loss: 0.6167, train/r2: 0.5949, eval/r2: 0.4702, train/one: 0.8064, train/two: 0.1086, train/three: 0.8696, eval/one: 0.6055, eval/two: -0.0404, eval/three: 0.8457 \n",
      "Epoch: 50, train/loss: 0.4748, eval/loss: 0.7247, train/r2: 0.5512, eval/r2: 0.4079, train/one: 0.7483, train/two: 0.0203, train/three: 0.8851, eval/one: 0.6642, eval/two: -0.1121, eval/three: 0.6716 \n",
      "Epoch: 55, train/loss: 0.4355, eval/loss: 0.6696, train/r2: 0.5446, eval/r2: 0.5100, train/one: 0.6465, train/two: 0.1105, train/three: 0.8767, eval/one: 0.6286, eval/two: 0.0611, eval/three: 0.8403 \n",
      "Epoch: 60, train/loss: 0.3757, eval/loss: 0.5609, train/r2: 0.6340, eval/r2: 0.4945, train/one: 0.8220, train/two: 0.1922, train/three: 0.8879, eval/one: 0.7428, eval/two: -0.0406, eval/three: 0.7813 \n",
      "Epoch: 65, train/loss: 0.4150, eval/loss: 0.6149, train/r2: 0.6176, eval/r2: 0.4991, train/one: 0.7934, train/two: 0.1850, train/three: 0.8743, eval/one: 0.8452, eval/two: -0.0311, eval/three: 0.6832 \n",
      "Epoch: 70, train/loss: 0.3196, eval/loss: 0.5590, train/r2: 0.6520, eval/r2: 0.5968, train/one: 0.8499, train/two: 0.2467, train/three: 0.8595, eval/one: 0.8366, eval/two: 0.0762, eval/three: 0.8775 \n",
      "Epoch: 75, train/loss: 0.3768, eval/loss: 0.6347, train/r2: 0.6663, eval/r2: 0.4484, train/one: 0.8145, train/two: 0.2862, train/three: 0.8982, eval/one: 0.7737, eval/two: -0.1768, eval/three: 0.7484 \n",
      "Epoch: 80, train/loss: 0.3546, eval/loss: 0.6393, train/r2: 0.6383, eval/r2: 0.5356, train/one: 0.8561, train/two: 0.1758, train/three: 0.8829, eval/one: 0.8060, eval/two: 0.0255, eval/three: 0.7752 \n",
      "Epoch: 85, train/loss: 0.3164, eval/loss: 0.3741, train/r2: 0.6833, eval/r2: 0.6093, train/one: 0.8683, train/two: 0.2949, train/three: 0.8867, eval/one: 0.8272, eval/two: 0.1615, eval/three: 0.8393 \n",
      "Epoch: 90, train/loss: 0.3915, eval/loss: 0.5045, train/r2: 0.6448, eval/r2: 0.5131, train/one: 0.8637, train/two: 0.1757, train/three: 0.8952, eval/one: 0.8321, eval/two: 0.0886, eval/three: 0.6187 \n",
      "Epoch: 95, train/loss: 0.3204, eval/loss: 0.6571, train/r2: 0.6707, eval/r2: 0.5677, train/one: 0.8641, train/two: 0.2266, train/three: 0.9216, eval/one: 0.8805, eval/two: 0.0412, eval/three: 0.7813 \n",
      "[neptune] [info   ] Shutting down background jobs, please wait a moment...\n",
      "[neptune] [info   ] Done!\n",
      "[neptune] [info   ] Waiting for the remaining 142 operations to synchronize with Neptune. Do not kill this process.\n",
      "[neptune] [info   ] All 142 operations synced, thanks for waiting!\n",
      "[neptune] [info   ] Explore the metadata in the Neptune app: https://app.neptune.ai/arbaaz/kaggle-spect/e/KAG-145/metadata\n",
      "[neptune] [info   ] Neptune initialized. Open in the app: https://app.neptune.ai/arbaaz/kaggle-spect/e/KAG-146\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "256c8c0cb5d3493a98dc51bdd1559250",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, train/loss: 1.0808, eval/loss: 1.0260, train/r2: -0.0205, eval/r2: -0.0890, train/one: -0.0268, train/two: -0.0008, train/three: -0.0339, eval/one: -0.0003, eval/two: -0.0745, eval/three: -0.1923 \n",
      "Epoch: 5, train/loss: 0.9602, eval/loss: 1.0597, train/r2: 0.0363, eval/r2: -0.4079, train/one: 0.0270, train/two: -0.0573, train/three: 0.1391, eval/one: -0.0051, eval/two: -0.4082, eval/three: -0.8103 \n",
      "Epoch: 10, train/loss: 0.8727, eval/loss: 0.9772, train/r2: 0.1424, eval/r2: -0.1881, train/one: 0.0082, train/two: 0.0501, train/three: 0.3689, eval/one: -0.0086, eval/two: -0.1166, eval/three: -0.4392 \n",
      "Epoch: 15, train/loss: 0.7427, eval/loss: 0.7210, train/r2: 0.2755, eval/r2: 0.0007, train/one: 0.0092, train/two: 0.1236, train/three: 0.6937, eval/one: 0.0056, eval/two: -0.1648, eval/three: 0.1613 \n",
      "Epoch: 20, train/loss: 0.7057, eval/loss: 0.6411, train/r2: 0.3123, eval/r2: 0.1305, train/one: 0.0867, train/two: 0.0071, train/three: 0.8431, eval/one: -0.0727, eval/two: -0.1333, eval/three: 0.5975 \n",
      "Epoch: 25, train/loss: 0.6866, eval/loss: 0.6321, train/r2: 0.3641, eval/r2: 0.1194, train/one: 0.1684, train/two: 0.0872, train/three: 0.8366, eval/one: -0.3487, eval/two: -0.1355, eval/three: 0.8425 \n",
      "Epoch: 30, train/loss: 0.5932, eval/loss: 0.5612, train/r2: 0.3347, eval/r2: 0.2827, train/one: 0.1399, train/two: -0.0035, train/three: 0.8676, eval/one: 0.0542, eval/two: -0.0647, eval/three: 0.8585 \n",
      "Epoch: 35, train/loss: 0.4905, eval/loss: 0.5100, train/r2: 0.4327, eval/r2: 0.1441, train/one: 0.3100, train/two: 0.1385, train/three: 0.8494, eval/one: 0.0059, eval/two: -0.3950, eval/three: 0.8215 \n",
      "Epoch: 40, train/loss: 0.5548, eval/loss: 0.3559, train/r2: 0.4318, eval/r2: 0.5500, train/one: 0.3343, train/two: 0.1039, train/three: 0.8572, eval/one: 0.4513, eval/two: 0.2378, eval/three: 0.9610 \n",
      "Epoch: 45, train/loss: 0.4454, eval/loss: 0.3438, train/r2: 0.5765, eval/r2: 0.4136, train/one: 0.6102, train/two: 0.2516, train/three: 0.8678, eval/one: 0.3639, eval/two: -0.0579, eval/three: 0.9348 \n",
      "Epoch: 50, train/loss: 0.3668, eval/loss: 0.3149, train/r2: 0.6521, eval/r2: 0.5825, train/one: 0.7178, train/two: 0.3573, train/three: 0.8814, eval/one: 0.7074, eval/two: 0.1621, eval/three: 0.8779 \n",
      "Epoch: 55, train/loss: 0.3329, eval/loss: 0.2554, train/r2: 0.6564, eval/r2: 0.7097, train/one: 0.8085, train/two: 0.2771, train/three: 0.8836, eval/one: 0.7339, eval/two: 0.4454, eval/three: 0.9500 \n",
      "Epoch: 60, train/loss: 0.3182, eval/loss: 0.2443, train/r2: 0.6828, eval/r2: 0.6212, train/one: 0.7736, train/two: 0.4131, train/three: 0.8616, eval/one: 0.5534, eval/two: 0.5730, eval/three: 0.7371 \n",
      "Epoch: 65, train/loss: 0.2609, eval/loss: 0.2373, train/r2: 0.7305, eval/r2: 0.7454, train/one: 0.8267, train/two: 0.4751, train/three: 0.8897, eval/one: 0.6819, eval/two: 0.6168, eval/three: 0.9376 \n",
      "Epoch: 70, train/loss: 0.2849, eval/loss: 0.3712, train/r2: 0.6990, eval/r2: 0.6380, train/one: 0.7792, train/two: 0.4111, train/three: 0.9065, eval/one: 0.6872, eval/two: 0.3667, eval/three: 0.8601 \n",
      "Epoch: 75, train/loss: 0.2518, eval/loss: 0.2577, train/r2: 0.7549, eval/r2: 0.6585, train/one: 0.8184, train/two: 0.5353, train/three: 0.9111, eval/one: 0.5083, eval/two: 0.5892, eval/three: 0.8780 \n",
      "Epoch: 80, train/loss: 0.2504, eval/loss: 0.2148, train/r2: 0.7578, eval/r2: 0.6481, train/one: 0.8498, train/two: 0.5335, train/three: 0.8900, eval/one: 0.6136, eval/two: 0.4283, eval/three: 0.9023 \n",
      "Epoch: 85, train/loss: 0.2284, eval/loss: 0.2966, train/r2: 0.7570, eval/r2: 0.6754, train/one: 0.8095, train/two: 0.5846, train/three: 0.8770, eval/one: 0.7697, eval/two: 0.3484, eval/three: 0.9082 \n",
      "Epoch: 90, train/loss: 0.2219, eval/loss: 0.1534, train/r2: 0.7799, eval/r2: 0.7295, train/one: 0.8563, train/two: 0.5822, train/three: 0.9014, eval/one: 0.8234, eval/two: 0.5151, eval/three: 0.8499 \n",
      "Epoch: 95, train/loss: 0.2291, eval/loss: 0.2100, train/r2: 0.7758, eval/r2: 0.6755, train/one: 0.8323, train/two: 0.6030, train/three: 0.8920, eval/one: 0.7492, eval/two: 0.4781, eval/three: 0.7991 \n",
      "[neptune] [info   ] Shutting down background jobs, please wait a moment...\n",
      "[neptune] [info   ] Done!\n",
      "[neptune] [info   ] Waiting for the remaining 130 operations to synchronize with Neptune. Do not kill this process.\n",
      "[neptune] [info   ] All 130 operations synced, thanks for waiting!\n",
      "[neptune] [info   ] Explore the metadata in the Neptune app: https://app.neptune.ai/arbaaz/kaggle-spect/e/KAG-146/metadata\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "\n",
    "inputs_mean_std = []\n",
    "targets_mean_std = []\n",
    "scores = []\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=SEED)\n",
    "splits = kfold.split(inputs)\n",
    "\n",
    "for fold, (train_idx, eval_idx) in enumerate(splits):\n",
    "    MODEL_NAME = f\"resnet.paper.direct.train.fold.{fold}\"\n",
    "    checkpoint_name = f\"paper.direct.train.fold.{fold}.pt\"\n",
    "    \n",
    "    train_inputs = inputs[train_idx]\n",
    "    train_targets = targets[train_idx]\n",
    "    eval_inputs = inputs[eval_idx]\n",
    "    eval_targets = targets[eval_idx]\n",
    "\n",
    "    train_ds = get_dataset(train_inputs, train_targets, config)\n",
    "    \n",
    "    inputs_mean_std.append((fold, train_ds.s_mean, train_ds.s_std))\n",
    "    targets_mean_std.append((fold, train_ds.concentration_means, train_ds.concentration_stds))\n",
    "    \n",
    "    eval_ds = get_dataset(eval_inputs, eval_targets, config, (train_ds.s_mean, train_ds.s_std), (train_ds.concentration_means, train_ds.concentration_stds))\n",
    "    \n",
    "    BATCH_SIZE = 32\n",
    "    train_dl, eval_dl = return_dls(train_ds, eval_ds, BATCH_SIZE, len(eval_ds))\n",
    "    \n",
    "    #model = ResNet(input_channels=1, dropout=DROPOUT).to(device)\n",
    "    model = ReZeroNet(**config).to(device)\n",
    "    if fold == 0: print(get_model_size(model))\n",
    "    \n",
    "    #ckpt = get_ckpt(\"/kaggle/working/paper.pretrain.fold.3.pt\")\n",
    "    #model.load_state_dict(ckpt[\"state_dict\"])\n",
    "    \n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=LR, weight_decay=WD, foreach=True)\n",
    "    scaler = torch.amp.GradScaler(device)\n",
    "    scheduler = get_scheduler(optimizer, train_dl, EPOCHS)\n",
    "    \n",
    "    score = train(\n",
    "            model, \n",
    "            optimizer, \n",
    "            device,\n",
    "            scaler,\n",
    "            scheduler,\n",
    "            train_dl, \n",
    "            eval_dl,\n",
    "            loss_fn,\n",
    "            EPOCHS,\n",
    "            checkpoint_name,\n",
    "            neptune_run=setup_neptune(),\n",
    "        )\n",
    "    \n",
    "    scores.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d7516c09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/paper.direct.train.fold.0.pt 93 0.7429719215168401\n",
      "/kaggle/working/paper.direct.train.fold.1.pt 68 0.7380484356754696\n",
      "/kaggle/working/paper.direct.train.fold.2.pt 95 0.6799178597928467\n",
      "/kaggle/working/paper.direct.train.fold.3.pt 94 0.6614433341484437\n",
      "/kaggle/working/paper.direct.train.fold.4.pt 92 0.7835582747349822\n"
     ]
    }
   ],
   "source": [
    "output_dir = \"/kaggle/working\"\n",
    "output_files = sorted(os.listdir(output_dir))\n",
    "\n",
    "ckpt_paths = []\n",
    "for f in output_files:\n",
    "    if \"paper.direct.train\" in f and \"csv\" not in f:\n",
    "        ckpt_path = os.path.join(output_dir, f)\n",
    "        ckpt_paths.append(ckpt_path)\n",
    "        ckpt = torch.load(ckpt_path, weights_only=False)\n",
    "        print(ckpt_path, ckpt[\"epoch\"], ckpt[\"score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bf20310b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(92, 0.7835582747349822)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_ckpt(path):\n",
    "    return torch.load(path, weights_only=False)\n",
    "\n",
    "ckpt = get_ckpt(\"/kaggle/working/paper.direct.train.fold.4.pt\")\n",
    "ckpt[\"epoch\"], ckpt[\"score\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0da523e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ReZeroNet(**config).to(device)\n",
    "model.load_state_dict(ckpt[\"state_dict\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bd3e6403",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((96, 1643), 0.19117267486879463, 1.0)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_inputs = get_test_data()\n",
    "test_inputs.shape, test_inputs.min(), test_inputs.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "fce434c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpectralTestDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        spectra,\n",
    "        concentrations,\n",
    "        dtype=None,\n",
    "        spectra_mean_std=None,\n",
    "        concentration_mean_std=None,\n",
    "        combine_spectra_range=0.0,\n",
    "        baseline_factor_bound=0.0,\n",
    "        baseline_period_lower_bound=100.0,\n",
    "        baseline_period_upper_bound=200.0,\n",
    "        augment_slope_std=0.0,\n",
    "        augment_intersept_std=0.0,\n",
    "        rolling_bound=0,\n",
    "        spectrum_rolling_sigma=0.0,\n",
    "        augmentation_weight=0.1,\n",
    "        original_datapoint_weight=1.,\n",
    "    ):\n",
    "        self.dtype = dtype or torch.float32\n",
    "        self.combine_spectra_range = combine_spectra_range\n",
    "        self.baseline_factor_bound = baseline_factor_bound\n",
    "        self.augment_slope_std = augment_slope_std\n",
    "        self.augment_intercept_std = augment_intersept_std\n",
    "        self.baseline_period_lower_bound = baseline_period_lower_bound\n",
    "        self.baseline_period_upper_bound = baseline_period_upper_bound\n",
    "        self.rolling_bound = rolling_bound\n",
    "        self.spectrum_rolling_sigma = spectrum_rolling_sigma\n",
    "        self.augmentation_weight = torch.tensor(augmentation_weight, dtype=dtype)\n",
    "        self.original_dp_weight = original_datapoint_weight\n",
    "\n",
    "        # normalize spectra\n",
    "        spectra = torch.tensor(spectra, dtype=dtype)\n",
    "\n",
    "        if spectra_mean_std is None:\n",
    "            self.s_mean = torch.mean(spectra)\n",
    "            self.s_std = torch.std(spectra)\n",
    "        else:\n",
    "            self.s_mean, self.s_std = spectra_mean_std\n",
    "\n",
    "        self.spectra = torch.divide(\n",
    "            torch.subtract(spectra, self.s_mean),\n",
    "            self.s_std,\n",
    "        )\n",
    "\n",
    "        self.dummy_wns = np.tile(\n",
    "            np.arange(\n",
    "                0., 1., 1. / self.spectra.shape[2],\n",
    "                dtype=np_dtype_from_torch[self.dtype]\n",
    "            )[None, :self.spectra.shape[2]],\n",
    "            (self.spectra.shape[1], 1),\n",
    "        )\n",
    "\n",
    "        if False:\n",
    "            # normalize concentrations\n",
    "            concentrations = torch.tensor(concentrations, dtype=dtype)\n",
    "            if concentration_mean_std is None:\n",
    "                self.concentration_means = torch.nanmean(concentrations, dim=0)\n",
    "\n",
    "                self.concentration_stds = torch.maximum(\n",
    "                    torch.tensor(\n",
    "                        [\n",
    "                            torch.std(col[torch.logical_not(torch.isnan(col))])\n",
    "                            for col in concentrations.T\n",
    "                        ]\n",
    "                    ),\n",
    "                    torch.tensor([1e-3] * concentrations.shape[1]),\n",
    "                )\n",
    "            else:\n",
    "                self.concentration_means = concentration_mean_std[0]\n",
    "                self.concentration_stds = concentration_mean_std[1]\n",
    "\n",
    "            self.concentrations = torch.divide(\n",
    "                torch.subtract(\n",
    "                    concentrations,\n",
    "                    self.concentration_means,\n",
    "                ),\n",
    "                self.concentration_stds,\n",
    "            )\n",
    "\n",
    "    def pick_two(self, max_idx=None):\n",
    "        max_idx = max_idx or len(self)\n",
    "        return random.choices(range(max_idx), k=2)\n",
    "\n",
    "    def __len__(self):\n",
    "        return 96\n",
    "\n",
    "    def augment_spectra(self, spectra):\n",
    "        if self.augment_slope_std > 0.0:\n",
    "\n",
    "            def spectrum_approximation(x, slope, intercept):\n",
    "                return (slope * x + intercept).reshape(-1, 1)[:, 0]\n",
    "\n",
    "            slope, inter = scipy.optimize.curve_fit(\n",
    "                spectrum_approximation,\n",
    "                self.dummy_wns,\n",
    "                spectra.reshape(-1, 1)[:, 0],\n",
    "                p0=np.random.rand(2),\n",
    "            )[0]\n",
    "\n",
    "            new_slope = slope * (\n",
    "                    np.random.gamma(\n",
    "                        shape=1. / self.augment_slope_std,\n",
    "                        scale=self.augment_slope_std,\n",
    "                        size=1,\n",
    "                    )\n",
    "            )[0]\n",
    "            new_intercept = inter * (\n",
    "                1.0 + np.random.randn(1) * self.augment_intercept_std\n",
    "            )[0]\n",
    "            spectra += torch.tensor(\n",
    "                (new_slope - slope)\n",
    "            ) * self.dummy_wns + new_intercept - inter\n",
    "\n",
    "        factor = self.baseline_factor_bound * torch.rand(size=(1,))\n",
    "        offset = torch.rand(size=(1,)) * 2.0 * torch.pi\n",
    "        period = self.baseline_period_lower_bound + (\n",
    "            self.baseline_period_upper_bound - self.baseline_period_lower_bound\n",
    "        ) * torch.rand(size=(1,))\n",
    "        permutations = factor * torch.cos(\n",
    "            2.0 * torch.pi / period * self.dummy_wns + offset\n",
    "        )\n",
    "        return self.roll_spectrum(\n",
    "            spectra + permutations * spectra,\n",
    "            delta=random.randint(-self.rolling_bound, self.rolling_bound),\n",
    "        )\n",
    "\n",
    "    def roll_spectrum(self, spectra, delta):\n",
    "        num_spectra = spectra.shape[0]\n",
    "        rolled_spectra = np.roll(spectra, delta, axis=1)\n",
    "        if delta > 0:\n",
    "            rolled_spectra[:, :delta] = (\n",
    "                np.random.rand(num_spectra, delta) * self.spectrum_rolling_sigma + 1\n",
    "            ) * rolled_spectra[:, delta:(delta + 1)]\n",
    "        elif delta < 0:\n",
    "            rolled_spectra[:, delta:] = (\n",
    "                np.random.rand(num_spectra, -delta) * self.spectrum_rolling_sigma + 1\n",
    "            ) * rolled_spectra[:, delta - 1:delta]\n",
    "        return rolled_spectra\n",
    "\n",
    "    def combine_k_items(self, indices, weights):\n",
    "        return (\n",
    "            # spectra\n",
    "            torch.sum(\n",
    "                torch.mul(weights[:, None, None], self.spectra[indices, :, :]),\n",
    "                dim=0,\n",
    "            ),\n",
    "            # concentrations\n",
    "            #torch.sum(\n",
    "            #    torch.mul(weights[:, None], self.concentrations[indices, :]),\n",
    "            #    dim=0,\n",
    "            #)\n",
    "        )\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if True:#self.combine_spectra_range < 1e-12:\n",
    "            spectrum = self.spectra[idx]\n",
    "            #spectrum = self.augment_spectra(spectrum)\n",
    "            return spectrum\n",
    "        else:\n",
    "            if random.random() < self.original_dp_weight:\n",
    "                one_weight = 1.\n",
    "                label_weight = torch.tensor(1.0, dtype=self.dtype)\n",
    "            else:\n",
    "                one_weight = random.uniform(0.0, self.combine_spectra_range)\n",
    "                label_weight = self.augmentation_weight\n",
    "            weights = torch.tensor([one_weight, (1 - one_weight)])\n",
    "            # just pick two random indices\n",
    "            indices = random.choices(range(len(self)), k=2)\n",
    "\n",
    "            mixed_spectra = self.combine_k_items(\n",
    "                indices=indices,\n",
    "                weights=weights,\n",
    "            )\n",
    "            mixed_spectra = self.augment_spectra(mixed_spectra[0])\n",
    "            return mixed_spectra\n",
    "        \n",
    "        \n",
    "test_ds = SpectralTestDataset(\n",
    "    spectra=test_inputs[:, None, :],\n",
    "    concentrations=None,\n",
    "    dtype=torch.float32,\n",
    "    spectra_mean_std=inputs_mean_std[1][1:],\n",
    "    concentration_mean_std=targets_mean_std[1][1:],\n",
    "    combine_spectra_range=1.0,\n",
    "    baseline_factor_bound=config[\"baseline_factor_bound\"],\n",
    "    baseline_period_lower_bound=config[\"baseline_period_lower_bound\"],\n",
    "    baseline_period_upper_bound=(config[\"baseline_period_lower_bound\"] + config[\"baseline_period_span\"]),\n",
    "    augment_slope_std=config[\"augment_slope_std\"],\n",
    "    augment_intersept_std=0.0,\n",
    "    rolling_bound=config[\"rolling_bound\"],\n",
    "    spectrum_rolling_sigma=0.01,\n",
    "    augmentation_weight=0.1,\n",
    "    original_datapoint_weight=1.,\n",
    ")\n",
    "\n",
    "test_dl = DataLoader(test_ds, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "837182fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((tensor(0.3595), tensor(0.1597)),\n",
       " (tensor([6.8227, 1.1995, 1.6005]), tensor([2.9272, 0.5459, 0.6937])))"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_mean_std[1][1:], targets_mean_std[1][1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "7655e44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_dataset(inputs, inputs_mean_std, targets_mean_std):\n",
    "    return SpectralTestDataset(\n",
    "        spectra=test_inputs[:, None, :],\n",
    "        concentrations=None,\n",
    "        dtype=torch.float32,\n",
    "        spectra_mean_std=inputs_mean_std,\n",
    "        concentration_mean_std=targets_mean_std,\n",
    "        combine_spectra_range=1.0,\n",
    "        baseline_factor_bound=config[\"baseline_factor_bound\"],\n",
    "        baseline_period_lower_bound=config[\"baseline_period_lower_bound\"],\n",
    "        baseline_period_upper_bound=(config[\"baseline_period_lower_bound\"] + config[\"baseline_period_span\"]),\n",
    "        augment_slope_std=config[\"augment_slope_std\"],\n",
    "        augment_intersept_std=0.0,\n",
    "        rolling_bound=config[\"rolling_bound\"],\n",
    "        spectrum_rolling_sigma=0.01,\n",
    "        augmentation_weight=0.1,\n",
    "        original_datapoint_weight=1.,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9946ba2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_preds = []\n",
    "all_inputs = []\n",
    "model.eval()\n",
    "\n",
    "for i in test_dl:\n",
    "    #i = data[\"spectra\"].cuda()\n",
    "    i = i.cuda()\n",
    "    with torch.inference_mode():\n",
    "        preds = model(i)\n",
    "    all_inputs.append(i.cpu())\n",
    "    all_preds.append(cuda_to_np(preds.double()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f07ab093",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(96, 3)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = np.concatenate(all_preds)\n",
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5521a931",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.12889805,  0.76554817, -0.53647536],\n",
       "       [-1.30538452,  0.39789349, -0.82551134],\n",
       "       [-0.39988276,  0.63025367, -1.8318367 ],\n",
       "       [-1.37605441,  0.88060683, -0.07746108],\n",
       "       [-0.61503583,  0.60447729, -0.24853687],\n",
       "       [ 0.05681216,  0.49679908, -0.83895802],\n",
       "       [-0.49156347,  0.16905291,  0.16944259],\n",
       "       [-0.98279303,  0.03841651, -2.1095736 ],\n",
       "       [ 0.08147585, -0.78061247, -1.70073855],\n",
       "       [-0.97424752, -0.34118888, -0.12129673],\n",
       "       [-0.74376577,  0.01164164, -1.81835663],\n",
       "       [-0.88535959, -0.5206126 , -0.93554771],\n",
       "       [ 0.11631434, -0.85268688, -0.36983517],\n",
       "       [-0.72388369,  0.70626581, -0.22292535],\n",
       "       [-0.18011081,  0.38986945, -0.14631838],\n",
       "       [-1.30374539,  0.57094562, -1.84710085],\n",
       "       [-0.39249933,  0.67446804, -0.45921585],\n",
       "       [-0.44811502,  0.37662947, -0.4820644 ],\n",
       "       [-0.84195536,  0.8274883 ,  0.04623342],\n",
       "       [-1.14202714,  0.42112377,  0.13470052],\n",
       "       [-0.86488867,  0.62372047,  0.21041167],\n",
       "       [-0.62066633, -0.45713255, -0.28188139],\n",
       "       [ 0.02007564,  0.4493762 ,  0.02202664],\n",
       "       [-0.58899707,  0.47906628,  0.00304946],\n",
       "       [ 0.00720187,  0.39493099, -0.53818452],\n",
       "       [-1.03604949,  0.78992826,  0.25996622],\n",
       "       [-0.26953977,  0.39726737, -0.43974426],\n",
       "       [ 0.77548057, -0.2990022 , -0.92697465],\n",
       "       [-0.39522028,  0.53777665,  0.4105773 ],\n",
       "       [ 0.11331911,  0.55867082,  0.01595308],\n",
       "       [-0.69536042,  0.68340683,  0.01583956],\n",
       "       [-0.00748314,  0.82146013, -0.17846471],\n",
       "       [-0.61930692,  0.3947219 , -0.22776632],\n",
       "       [-0.88093829,  0.71734929, -0.1838565 ],\n",
       "       [-0.4122597 ,  0.42332771, -0.5643965 ],\n",
       "       [ 0.2474238 , -0.43075272, -0.13035733],\n",
       "       [-0.75770921,  0.0135618 , -2.05777454],\n",
       "       [ 0.67480606,  0.20750074,  0.05352283],\n",
       "       [-0.30711517,  0.49438077,  0.09766065],\n",
       "       [-1.51728904,  0.52316433, -1.24254882],\n",
       "       [-0.36961699,  0.46115944, -0.15465117],\n",
       "       [-0.36584601,  0.5673908 , -0.31972918],\n",
       "       [ 0.22283646, -0.44988513, -1.33402538],\n",
       "       [-1.30306399,  0.81676042, -1.34798014],\n",
       "       [-0.6816116 ,  0.7536276 ,  0.09128578],\n",
       "       [-0.01739694,  0.30461326,  0.55004275],\n",
       "       [-0.24036258,  0.64655018, -0.26599562],\n",
       "       [-0.77307922,  0.56674415, -0.07695295],\n",
       "       [ 0.72260576, -0.25452292, -0.88114941],\n",
       "       [-0.0253629 ,  0.3719357 ,  0.21998355],\n",
       "       [-0.1884197 , -0.57714224, -1.59277689],\n",
       "       [-0.74432909,  0.47164711,  0.12803359],\n",
       "       [-0.73852044,  0.58273113, -0.35889769],\n",
       "       [-0.42273077,  0.62727785, -0.15539958],\n",
       "       [-0.27821526,  0.47559246, -0.78496957],\n",
       "       [-0.45415226,  0.52608103, -0.01486594],\n",
       "       [-1.0528115 ,  0.38906422,  0.45558593],\n",
       "       [-0.26573882,  0.39454108, -1.98258758],\n",
       "       [-1.90996182,  0.4065311 , -1.71541798],\n",
       "       [-1.61714423,  0.42167374,  0.6287545 ],\n",
       "       [-1.01431632,  0.60884011, -0.24203196],\n",
       "       [ 0.58108693, -0.50279564, -1.28378117],\n",
       "       [-0.57088441,  0.58141828, -0.42428395],\n",
       "       [-0.77045214,  0.31696686,  0.23990586],\n",
       "       [-0.05412015, -0.67951465,  0.19392323],\n",
       "       [-0.49608436,  0.66636449, -0.19312163],\n",
       "       [-1.00210094,  0.60256451,  0.19268623],\n",
       "       [-0.57931238,  0.7042681 ,  0.08182502],\n",
       "       [ 0.01306376,  0.2719745 ,  0.02648902],\n",
       "       [-0.84600443,  0.51956314,  0.33485463],\n",
       "       [-0.64221323,  0.64791113, -0.25702471],\n",
       "       [-1.21585274,  0.44846943, -2.04936123],\n",
       "       [-0.6468243 ,  0.5932318 , -0.61347532],\n",
       "       [-0.18524727,  0.28704041, -0.95288265],\n",
       "       [ 0.40080941, -0.94044554, -0.95162249],\n",
       "       [-0.24163273,  0.50247258, -0.18450539],\n",
       "       [-0.15798217,  0.27062598, -0.91364443],\n",
       "       [-0.42612424,  0.66776812, -0.34594998],\n",
       "       [-0.5590207 ,  0.5828284 , -0.39841926],\n",
       "       [ 0.73371553, -0.57053745, -1.43264222],\n",
       "       [-1.23193872,  0.47924843, -0.16451764],\n",
       "       [-0.47469476,  0.65541697,  0.04338355],\n",
       "       [-0.45947525,  0.72352153, -0.14286101],\n",
       "       [ 0.09573849,  0.04896116, -1.7439177 ],\n",
       "       [ 0.45742834, -0.95540917, -0.1979765 ],\n",
       "       [-0.90284622,  0.98136634, -0.26323602],\n",
       "       [-0.32507339,  0.41340995,  0.03438658],\n",
       "       [-0.42274889,  0.27015594, -0.65523469],\n",
       "       [-0.81619877,  0.48227796,  0.10151458],\n",
       "       [-1.11459458,  0.37520862, -1.55693185],\n",
       "       [-0.29070565, -0.47698399, -1.20516574],\n",
       "       [-0.24316314,  0.38603535, -0.62527156],\n",
       "       [-0.05766913,  0.5887953 , -0.53353858],\n",
       "       [-0.23483634,  0.681229  , -1.43801129],\n",
       "       [-0.29697028,  0.74710071, -0.4381623 ],\n",
       "       [-0.61603063, -0.38291869, -1.14237452]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e6181909",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reverse_zscore(tensor, mu, sigma):\n",
    "    return (tensor * sigma) + mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0c9ce243",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.44541702, 1.6173766 , 1.22835177],\n",
       "       [3.00165989, 1.41666778, 1.02785038],\n",
       "       [5.65220302, 1.54351708, 0.32977248],\n",
       "       [2.79479823, 1.68018904, 1.54676541],\n",
       "       [5.02241685, 1.52944532, 1.42809183],\n",
       "       [6.98901944, 1.47066199, 1.01852255],\n",
       "       [5.38383947, 1.29173989, 1.71804004],\n",
       "       [3.94593486, 1.2204233 , 0.13710915],\n",
       "       [7.06121386, 0.77330172, 0.42071396],\n",
       "       [3.97094891, 1.01319039, 1.51635705],\n",
       "       [4.64560448, 1.20580645, 0.33912347],\n",
       "       [4.23113757, 0.91523999, 0.95151924],\n",
       "       [7.16319146, 0.7339551 , 1.34394841],\n",
       "       [4.7038024 , 1.58501337, 1.44585829],\n",
       "       [6.29550939, 1.41228732, 1.49899979],\n",
       "       [3.00645787, 1.51113982, 0.31918389],\n",
       "       [5.67381548, 1.56765444, 1.28194592],\n",
       "       [5.51101978, 1.4050594 , 1.26609611],\n",
       "       [4.35818842, 1.65119075, 1.63257105],\n",
       "       [3.4798321 , 1.42934958, 1.6939398 ],\n",
       "       [4.2910591 , 1.53995049, 1.74645987],\n",
       "       [5.00593553, 0.94989481, 1.40496107],\n",
       "       [6.88148598, 1.44477305, 1.61577905],\n",
       "       [5.09863633, 1.46098136, 1.60261477],\n",
       "       [6.84380245, 1.4150505 , 1.22716614],\n",
       "       [3.79004502, 1.6306861 , 1.78083538],\n",
       "       [6.03373704, 1.41632597, 1.29545317],\n",
       "       [9.09267258, 1.0362208 , 0.95746629],\n",
       "       [5.66585083, 1.49303233, 1.88531278],\n",
       "       [7.15442396, 1.50443881, 1.61156588],\n",
       "       [4.7872944 , 1.57253427, 1.61148714],\n",
       "       [6.80081718, 1.64789987, 1.4767002 ],\n",
       "       [5.00991471, 1.41493635, 1.44250016],\n",
       "       [4.24407938, 1.59106403, 1.47295996],\n",
       "       [5.61597383, 1.43055275, 1.20898315],\n",
       "       [7.54696906, 0.96429599, 1.51007181],\n",
       "       [4.6047899 , 1.2068547 , 0.17304164],\n",
       "       [8.79798278, 1.3127292 , 1.63762764],\n",
       "       [5.92374807, 1.4693418 , 1.66824561],\n",
       "       [2.38138269, 1.48505522, 0.73855562],\n",
       "       [5.74079562, 1.45120572, 1.49321942],\n",
       "       [5.75183385, 1.50919919, 1.37870644],\n",
       "       [7.47499814, 0.95385129, 0.67509924],\n",
       "       [3.00845243, 1.64533422, 0.66541896],\n",
       "       [4.82753932, 1.61086896, 1.66382343],\n",
       "       [6.77179795, 1.36574455, 1.98205858],\n",
       "       [6.11914316, 1.55241361, 1.41598087],\n",
       "       [4.55979951, 1.50884617, 1.5471179 ],\n",
       "       [8.93789988, 1.06050278, 0.9892548 ],\n",
       "       [6.74848036, 1.40249699, 1.75309979],\n",
       "       [6.27118799, 0.88437952, 0.49560589],\n",
       "       [4.64395555, 1.45693111, 1.68931502],\n",
       "       [4.66095836, 1.51757373, 1.35153563],\n",
       "       [5.58532338, 1.54189253, 1.49270025],\n",
       "       [6.00834255, 1.45908495, 1.0559738 ],\n",
       "       [5.49334786, 1.48664749, 1.59018704],\n",
       "       [3.74098001, 1.41184774, 1.91653482],\n",
       "       [6.04486303, 1.41483765, 0.22519809],\n",
       "       [1.23196898, 1.42138319, 0.41053099],\n",
       "       [2.08909118, 1.42964982, 2.03666014],\n",
       "       [3.85366134, 1.53182706, 1.43260423],\n",
       "       [8.52365246, 0.92496657, 0.70995315],\n",
       "       [5.15165487, 1.51685702, 1.30617783],\n",
       "       [4.56748936, 1.37248858, 1.76691971],\n",
       "       [6.66430348, 0.82849271, 1.73502201],\n",
       "       [5.37060612, 1.56323058, 1.46653284],\n",
       "       [3.88941763, 1.52840111, 1.73416391],\n",
       "       [5.12698488, 1.58392279, 1.65726059],\n",
       "       [6.86096112, 1.34792651, 1.61887456],\n",
       "       [4.34633619, 1.48308927, 1.83278472],\n",
       "       [4.94286443, 1.55315658, 1.42220391],\n",
       "       [3.2637332 , 1.44427803, 0.17887787],\n",
       "       [4.9293671 , 1.52330622, 1.17493766],\n",
       "       [6.28047418, 1.35615124, 0.93949417],\n",
       "       [7.99595237, 0.68604618, 0.94036833],\n",
       "       [6.11542525, 1.47375925, 1.47250984],\n",
       "       [6.36028333, 1.34719032, 0.96671333],\n",
       "       [5.57539017, 1.56399684, 1.36051733],\n",
       "       [5.18638177, 1.51762683, 1.32411991],\n",
       "       [8.97041989, 0.88798518, 0.60668972],\n",
       "       [3.21664705, 1.4610808 , 1.48637514],\n",
       "       [5.43321679, 1.55725414, 1.63059413],\n",
       "       [5.47776664, 1.59443356, 1.50139813],\n",
       "       [7.1029628 , 1.2261798 , 0.39076101],\n",
       "       [8.16168469, 0.67787729, 1.46316506],\n",
       "       [4.17995151, 1.73519534, 1.41789518],\n",
       "       [5.87118158, 1.42513847, 1.62435302],\n",
       "       [5.58527034, 1.34693372, 1.1459696 ],\n",
       "       [4.43358195, 1.46273467, 1.67091905],\n",
       "       [3.56013143, 1.40428373, 0.52047124],\n",
       "       [5.97178125, 0.93905757, 0.76448789],\n",
       "       [6.11094551, 1.41019423, 1.16675473],\n",
       "       [6.65391507, 1.52088426, 1.23038898],\n",
       "       [6.13531933, 1.57134536, 0.60296525],\n",
       "       [5.95344373, 1.60730583, 1.29655056],\n",
       "       [5.01950491, 0.99040939, 0.80804554]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mus = targets_mean_std[1][1:][0]\n",
    "sigmas = targets_mean_std[1][1:][1]\n",
    "\n",
    "for i in range(3):\n",
    "    preds[:, i] = reverse_zscore(preds[:, i], mus[i].numpy(), sigmas[i].numpy())\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4c7b248d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min: 0.13710914923041173, Max: 9.092672578832975 ,Mean: 2.6940206574223575, Std: 2.167201817302101\n"
     ]
    }
   ],
   "source": [
    "get_stats(preds, minmax=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "39f2af66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>Sodium Acetate</th>\n",
       "      <th>Magnesium Sulfate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>6.445417</td>\n",
       "      <td>1.617377</td>\n",
       "      <td>1.228352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3.001660</td>\n",
       "      <td>1.416668</td>\n",
       "      <td>1.027850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>5.652203</td>\n",
       "      <td>1.543517</td>\n",
       "      <td>0.329772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2.794798</td>\n",
       "      <td>1.680189</td>\n",
       "      <td>1.546765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5.022417</td>\n",
       "      <td>1.529445</td>\n",
       "      <td>1.428092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>92</td>\n",
       "      <td>6.110946</td>\n",
       "      <td>1.410194</td>\n",
       "      <td>1.166755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>93</td>\n",
       "      <td>6.653915</td>\n",
       "      <td>1.520884</td>\n",
       "      <td>1.230389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>94</td>\n",
       "      <td>6.135319</td>\n",
       "      <td>1.571345</td>\n",
       "      <td>0.602965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>95</td>\n",
       "      <td>5.953444</td>\n",
       "      <td>1.607306</td>\n",
       "      <td>1.296551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>96</td>\n",
       "      <td>5.019505</td>\n",
       "      <td>0.990409</td>\n",
       "      <td>0.808046</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>96 rows  4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    ID   Glucose  Sodium Acetate  Magnesium Sulfate\n",
       "0    1  6.445417        1.617377           1.228352\n",
       "1    2  3.001660        1.416668           1.027850\n",
       "2    3  5.652203        1.543517           0.329772\n",
       "3    4  2.794798        1.680189           1.546765\n",
       "4    5  5.022417        1.529445           1.428092\n",
       "..  ..       ...             ...                ...\n",
       "91  92  6.110946        1.410194           1.166755\n",
       "92  93  6.653915        1.520884           1.230389\n",
       "93  94  6.135319        1.571345           0.602965\n",
       "94  95  5.953444        1.607306           1.296551\n",
       "95  96  5.019505        0.990409           0.808046\n",
       "\n",
       "[96 rows x 4 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_names = ['Glucose', 'Sodium Acetate', 'Magnesium Sulfate']\n",
    "preds_df = pd.DataFrame(preds, columns=column_names)\n",
    "preds_df.insert(0, 'ID', [i+1 for i in range(len(preds_df))])\n",
    "preds_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ce7cb965",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7835582747349822"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckpt[\"score\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "21d05631",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>Sodium Acetate</th>\n",
       "      <th>Magnesium Sulfate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>6.445417</td>\n",
       "      <td>1.617377</td>\n",
       "      <td>1.228352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3.001660</td>\n",
       "      <td>1.416668</td>\n",
       "      <td>1.027850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>5.652203</td>\n",
       "      <td>1.543517</td>\n",
       "      <td>0.329772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2.794798</td>\n",
       "      <td>1.680189</td>\n",
       "      <td>1.546765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5.022417</td>\n",
       "      <td>1.529445</td>\n",
       "      <td>1.428092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>92</td>\n",
       "      <td>6.110946</td>\n",
       "      <td>1.410194</td>\n",
       "      <td>1.166755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>93</td>\n",
       "      <td>6.653915</td>\n",
       "      <td>1.520884</td>\n",
       "      <td>1.230389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>94</td>\n",
       "      <td>6.135319</td>\n",
       "      <td>1.571345</td>\n",
       "      <td>0.602965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>95</td>\n",
       "      <td>5.953444</td>\n",
       "      <td>1.607306</td>\n",
       "      <td>1.296551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>96</td>\n",
       "      <td>5.019505</td>\n",
       "      <td>0.990409</td>\n",
       "      <td>0.808046</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>96 rows  4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    ID   Glucose  Sodium Acetate  Magnesium Sulfate\n",
       "0    1  6.445417        1.617377           1.228352\n",
       "1    2  3.001660        1.416668           1.027850\n",
       "2    3  5.652203        1.543517           0.329772\n",
       "3    4  2.794798        1.680189           1.546765\n",
       "4    5  5.022417        1.529445           1.428092\n",
       "..  ..       ...             ...                ...\n",
       "91  92  6.110946        1.410194           1.166755\n",
       "92  93  6.653915        1.520884           1.230389\n",
       "93  94  6.135319        1.571345           0.602965\n",
       "94  95  5.953444        1.607306           1.296551\n",
       "95  96  5.019505        0.990409           0.808046\n",
       "\n",
       "[96 rows x 4 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name = \"paper.direct.train.augments.at.inference.7835.csv\"\n",
    "preds_df.to_csv(name, index=False)\n",
    "f = pd.read_csv(f\"/kaggle/working/{name}\")\n",
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "5f6e7342",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1489/1340775956.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "for i in range(4000):\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "64b84e1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.73206862,  1.30506718,  0.46157049],\n",
       "       [ 5.43849122,  1.39460257,  1.68025217],\n",
       "       [ 5.02283318,  0.98982292,  0.98071207],\n",
       "       [ 3.59836663,  1.42305321,  0.39213738],\n",
       "       [10.14436171,  0.8331019 ,  0.98423216],\n",
       "       [ 7.65942594,  1.2717677 ,  1.00165221],\n",
       "       [ 6.32538089,  1.21082884,  0.3484959 ],\n",
       "       [ 7.55196178,  1.31989633,  1.1601794 ],\n",
       "       [ 6.94738812,  1.48646357,  1.2152102 ],\n",
       "       [ 9.56747912,  0.95405478,  0.38146618],\n",
       "       [ 7.6343491 ,  1.41157516,  1.3987115 ],\n",
       "       [ 5.32565758,  1.50554824,  1.26598057],\n",
       "       [ 5.74219535,  1.46645673,  1.51402041],\n",
       "       [ 5.53060332,  1.49178362,  1.7117704 ],\n",
       "       [ 6.16797656,  1.47151561,  1.3737299 ],\n",
       "       [ 6.52887383,  1.47973257,  1.27042064],\n",
       "       [ 5.6896512 ,  1.52098184,  1.37336475],\n",
       "       [ 5.91704443,  1.51074395,  1.54322621],\n",
       "       [ 6.23655636,  1.51965464,  1.53387962],\n",
       "       [ 5.25693829,  1.47541854,  1.48599154],\n",
       "       [ 5.95017012,  1.45495154,  1.37275404],\n",
       "       [ 5.80525277,  1.48381327,  1.54298314],\n",
       "       [ 2.72781076,  1.56207099,  0.44212436],\n",
       "       [ 5.37292355,  1.44862357,  1.58750872],\n",
       "       [ 5.37541485,  1.50897702,  1.46925512],\n",
       "       [ 5.38895487,  1.54324697,  1.61003434],\n",
       "       [ 6.07060635,  1.49680534,  1.38924912],\n",
       "       [ 5.57761353,  1.56642993,  1.69413659],\n",
       "       [ 6.18799043,  1.46736523,  1.51596053],\n",
       "       [ 6.21630526,  1.12521242,  0.24063878],\n",
       "       [ 6.36621976,  1.47912477,  1.61043774],\n",
       "       [ 7.84970122,  0.98764795,  0.99466941],\n",
       "       [ 6.34637285,  1.45157332,  1.3980749 ],\n",
       "       [ 6.66667573,  1.45206684,  1.00192341],\n",
       "       [ 7.19255811,  1.09751336,  0.87006033],\n",
       "       [ 5.73944209,  1.08578837,  0.73272939],\n",
       "       [ 7.50284376,  1.08128226,  0.69710857],\n",
       "       [ 6.59143299,  1.43301159,  0.60054029],\n",
       "       [ 5.34094812,  1.45027233,  0.68433789],\n",
       "       [ 7.71622434,  1.38424788,  1.5747053 ],\n",
       "       [ 6.19841809,  1.47497664,  1.41605419],\n",
       "       [ 4.32060923,  1.40229613,  0.37250944],\n",
       "       [ 7.94966199,  0.80225786,  1.49427714],\n",
       "       [ 3.66671861,  1.10398529,  1.05169403],\n",
       "       [ 1.83564918,  1.49154968,  0.79479794],\n",
       "       [ 7.0047486 ,  0.99221331,  1.50497404],\n",
       "       [ 2.42179339,  1.2348689 ,  1.37412691],\n",
       "       [ 5.85093005,  1.43337848,  1.4239694 ],\n",
       "       [ 5.42699545,  1.46649724,  1.81136077],\n",
       "       [ 7.30816038,  0.95019603,  1.56490815],\n",
       "       [ 0.96478314,  1.47983266,  1.87407168],\n",
       "       [ 5.08849184,  1.45269653,  1.76859884],\n",
       "       [ 5.53279198,  1.40601652,  1.62505591],\n",
       "       [ 3.35566789,  1.4225898 ,  1.18005402],\n",
       "       [ 4.8720531 ,  1.4753805 ,  1.60846461],\n",
       "       [ 2.75309864,  1.43645277,  1.83836383],\n",
       "       [ 3.98587786,  1.43404464,  1.51954527],\n",
       "       [ 3.61209926,  1.3574536 ,  1.80994335],\n",
       "       [ 5.03238908,  1.00472881,  1.38641662],\n",
       "       [ 7.53896994,  1.09112532,  0.52598803],\n",
       "       [ 3.87953897,  1.24987254,  1.37241841],\n",
       "       [ 3.42127656,  1.48795236,  1.61521094],\n",
       "       [ 5.87670462,  1.52203379,  1.03502484],\n",
       "       [ 7.13254629,  1.48402855,  1.81010716],\n",
       "       [ 8.09497544,  1.19364997,  0.52062498],\n",
       "       [ 6.77879345,  1.06838057,  0.43609695],\n",
       "       [ 6.45572656,  1.50055784,  1.454522  ],\n",
       "       [ 5.52783903,  1.42917167,  0.80450522],\n",
       "       [ 7.05280468,  1.35261678,  1.03945143],\n",
       "       [ 7.66854007,  1.3736263 ,  1.19370715],\n",
       "       [ 7.49237014,  1.39825167,  1.37021806],\n",
       "       [ 7.24810792,  1.4472984 ,  1.51702308],\n",
       "       [ 4.77964938,  1.5096729 ,  1.72085929],\n",
       "       [ 7.55087308,  0.93023153,  1.07939426],\n",
       "       [ 5.3540414 ,  1.42894206,  1.6248204 ],\n",
       "       [ 7.83920763,  0.88713099,  1.11928342],\n",
       "       [ 4.93233571,  1.28947581,  0.2531791 ],\n",
       "       [ 5.503333  ,  1.47237561,  1.64744706],\n",
       "       [ 2.05345566,  1.49489124,  0.79809238],\n",
       "       [ 3.53115826,  1.03379067,  1.31756194],\n",
       "       [ 7.18970199,  1.07714832,  0.64788966],\n",
       "       [ 3.03807657,  1.28734731,  1.96120927],\n",
       "       [ 7.37884004,  1.11509394,  1.99011254],\n",
       "       [ 4.74921419,  1.26791397,  1.42206308],\n",
       "       [ 3.90192627,  1.24402493,  1.61808973],\n",
       "       [ 5.61439085,  1.53364608,  1.58615543],\n",
       "       [ 5.88562803,  1.42443393,  1.23652216],\n",
       "       [ 5.42366103,  1.41645368,  1.37580708],\n",
       "       [ 6.30403481,  1.50885905,  1.46089086],\n",
       "       [ 5.36817913,  1.51384841,  1.59513422],\n",
       "       [ 5.76191191,  1.48357804,  1.58539433],\n",
       "       [ 4.98949653,  1.50832059,  1.5945835 ],\n",
       "       [ 6.63851497,  0.89436232,  0.87320263],\n",
       "       [ 5.17540782,  1.10729753,  0.80357965],\n",
       "       [ 2.40259921,  1.46472204,  0.95556019],\n",
       "       [ 3.65642319,  1.56096354,  0.84021062]])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def ensemble_inference():\n",
    "    test_inputs = get_test_data()\n",
    "    all_preds = []\n",
    "\n",
    "    for i, ckpt_path in enumerate(ckpt_paths):\n",
    "        ckpt = get_ckpt(ckpt_path)\n",
    "        \n",
    "        model = ReZeroNet(**config).to(device)\n",
    "        model.load_state_dict(ckpt[\"state_dict\"])\n",
    "        model.eval()\n",
    "\n",
    "        test_ds = get_test_dataset(test_inputs, inputs_mean_std[i][1:], targets_mean_std[i][1:])\n",
    "        test_dl = DataLoader(test_ds, batch_size=32)\n",
    "        \n",
    "        fold_preds = []\n",
    "        for inputs in test_dl:\n",
    "            with torch.inference_mode():\n",
    "                preds = model(inputs.cuda())\n",
    "                preds = cuda_to_np(preds.double())\n",
    "                fold_preds.append(preds)\n",
    "                \n",
    "        fold_preds = np.concatenate(fold_preds)\n",
    "        \n",
    "        means = targets_mean_std[i][1:][0]\n",
    "        stds = targets_mean_std[i][1:][1]\n",
    "        for i in range(3):\n",
    "            fold_preds[:, i] = reverse_zscore(fold_preds[:, i], means[i].numpy(), stds[i].numpy())\n",
    "            \n",
    "        all_preds.append(fold_preds)\n",
    "\n",
    "    return np.mean(all_preds, axis=0)\n",
    "\n",
    "preds = ensemble_inference()\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "9b7f5f9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>Sodium Acetate</th>\n",
       "      <th>Magnesium Sulfate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3.732069</td>\n",
       "      <td>1.305067</td>\n",
       "      <td>0.461570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>5.438491</td>\n",
       "      <td>1.394603</td>\n",
       "      <td>1.680252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>5.022833</td>\n",
       "      <td>0.989823</td>\n",
       "      <td>0.980712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>3.598367</td>\n",
       "      <td>1.423053</td>\n",
       "      <td>0.392137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>10.144362</td>\n",
       "      <td>0.833102</td>\n",
       "      <td>0.984232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>92</td>\n",
       "      <td>4.989497</td>\n",
       "      <td>1.508321</td>\n",
       "      <td>1.594583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>93</td>\n",
       "      <td>6.638515</td>\n",
       "      <td>0.894362</td>\n",
       "      <td>0.873203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>94</td>\n",
       "      <td>5.175408</td>\n",
       "      <td>1.107298</td>\n",
       "      <td>0.803580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>95</td>\n",
       "      <td>2.402599</td>\n",
       "      <td>1.464722</td>\n",
       "      <td>0.955560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>96</td>\n",
       "      <td>3.656423</td>\n",
       "      <td>1.560964</td>\n",
       "      <td>0.840211</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>96 rows  4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    ID    Glucose  Sodium Acetate  Magnesium Sulfate\n",
       "0    1   3.732069        1.305067           0.461570\n",
       "1    2   5.438491        1.394603           1.680252\n",
       "2    3   5.022833        0.989823           0.980712\n",
       "3    4   3.598367        1.423053           0.392137\n",
       "4    5  10.144362        0.833102           0.984232\n",
       "..  ..        ...             ...                ...\n",
       "91  92   4.989497        1.508321           1.594583\n",
       "92  93   6.638515        0.894362           0.873203\n",
       "93  94   5.175408        1.107298           0.803580\n",
       "94  95   2.402599        1.464722           0.955560\n",
       "95  96   3.656423        1.560964           0.840211\n",
       "\n",
       "[96 rows x 4 columns]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_names = ['Glucose', 'Sodium Acetate', 'Magnesium Sulfate']\n",
    "preds_df = pd.DataFrame(preds, columns=column_names)\n",
    "preds_df.insert(0, 'ID', [i+1 for i in range(len(preds_df))])\n",
    "preds_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "e2df78f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>Sodium Acetate</th>\n",
       "      <th>Magnesium Sulfate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3.732069</td>\n",
       "      <td>1.305067</td>\n",
       "      <td>0.461570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>5.438491</td>\n",
       "      <td>1.394603</td>\n",
       "      <td>1.680252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>5.022833</td>\n",
       "      <td>0.989823</td>\n",
       "      <td>0.980712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>3.598367</td>\n",
       "      <td>1.423053</td>\n",
       "      <td>0.392137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>10.144362</td>\n",
       "      <td>0.833102</td>\n",
       "      <td>0.984232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>92</td>\n",
       "      <td>4.989497</td>\n",
       "      <td>1.508321</td>\n",
       "      <td>1.594583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>93</td>\n",
       "      <td>6.638515</td>\n",
       "      <td>0.894362</td>\n",
       "      <td>0.873203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>94</td>\n",
       "      <td>5.175408</td>\n",
       "      <td>1.107298</td>\n",
       "      <td>0.803580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>95</td>\n",
       "      <td>2.402599</td>\n",
       "      <td>1.464722</td>\n",
       "      <td>0.955560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>96</td>\n",
       "      <td>3.656423</td>\n",
       "      <td>1.560964</td>\n",
       "      <td>0.840211</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>96 rows  4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    ID    Glucose  Sodium Acetate  Magnesium Sulfate\n",
       "0    1   3.732069        1.305067           0.461570\n",
       "1    2   5.438491        1.394603           1.680252\n",
       "2    3   5.022833        0.989823           0.980712\n",
       "3    4   3.598367        1.423053           0.392137\n",
       "4    5  10.144362        0.833102           0.984232\n",
       "..  ..        ...             ...                ...\n",
       "91  92   4.989497        1.508321           1.594583\n",
       "92  93   6.638515        0.894362           0.873203\n",
       "93  94   5.175408        1.107298           0.803580\n",
       "94  95   2.402599        1.464722           0.955560\n",
       "95  96   3.656423        1.560964           0.840211\n",
       "\n",
       "[96 rows x 4 columns]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name = \"paper.direct.train.ensemble.csv\"\n",
    "preds_df.to_csv(name, index=False)\n",
    "f = pd.read_csv(f\"/kaggle/working/{name}\")\n",
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba72f2b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
