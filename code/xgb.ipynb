{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ecea469",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install -qU xgboost #pandas scipy scikit-learn matplotlib tqdm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1468113e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "SEED = 1000\n",
    "\n",
    "def setup_reproducibility():\n",
    "    random.seed(SEED)\n",
    "    np.random.seed(SEED)\n",
    "    torch.manual_seed(SEED)\n",
    "    if torch.cuda.is_available(): torch.cuda.manual_seed_all(SEED)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.use_deterministic_algorithms(False, warn_only=True)\n",
    "    torch.set_float32_matmul_precision(\"high\")\n",
    "\n",
    "setup_reproducibility()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ecaa449",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from huggingface_hub import login, snapshot_download\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def get_stats(tensor, p=True, r=False):\n",
    "    mean, std = tensor.mean(), tensor.std()\n",
    "    min, max =  tensor.min(), tensor.max()\n",
    "    \n",
    "    if p: print(f\"Min: {min}, Max: {max}, Mean: {mean}, Std: {std}\")\n",
    "    if r: return min, max, mean, std\n",
    "    \n",
    "    \n",
    "def zscore(tensor, mean=None, std=None):\n",
    "    if mean is None: mean = tensor.mean()\n",
    "    if std is None: std = tensor.std()\n",
    "    return (tensor - mean) / (std + 1e-6)\n",
    "\n",
    "\n",
    "def get_model_size(model):\n",
    "    print(sum(p.numel() for p in model.parameters()) / 1e6)\n",
    "    \n",
    "\n",
    "def get_index(iterable):\n",
    "    return random.randint(0, len(iterable) - 1)\n",
    "\n",
    "\n",
    "def split(inputs, targets, seed):\n",
    "    return train_test_split(\n",
    "        inputs,\n",
    "        targets, \n",
    "        test_size=0.2,\n",
    "        shuffle=True, \n",
    "        random_state=seed\n",
    "    ) \n",
    "    \n",
    "    \n",
    "def hf_ds_download(hf_token, repo_id):\n",
    "    login(hf_token[1:])\n",
    "    return snapshot_download(repo_id, repo_type=\"dataset\")\n",
    "\n",
    "\n",
    "def show_waves(waves, dpi=100):\n",
    "    \"\"\"\n",
    "    waves: numpy array of shape (3, N)\n",
    "    Creates three separate figures that stretch wide.\n",
    "    \"\"\"\n",
    "\n",
    "    N = waves.shape[1]\n",
    "    t = np.arange(N)\n",
    "\n",
    "    # Wide aspect ratio; height modest so each window fills width\n",
    "    for i in range(waves.shape[0]):\n",
    "        fig = plt.figure(figsize=(14, 4), dpi=dpi)  # wide figure\n",
    "        ax = fig.add_subplot(111)\n",
    "        ax.plot(t, waves[i], linewidth=1)\n",
    "        ax.set_title(f\"Wave {i+1}\")\n",
    "        ax.set_xlabel(\"Sample\")\n",
    "        ax.set_ylabel(\"Amplitude\")\n",
    "        ax.grid(True)\n",
    "        fig.tight_layout()  # reduce margins to use width\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e157058",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import signal\n",
    "from scipy.signal import find_peaks, peak_widths\n",
    "from scipy.stats import skew, kurtosis\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "def get_advanced_spectra_features(X, b=False):\n",
    "    \"\"\"Create multi-channel features from spectra: raw, 1st derivative, 2nd derivative.\"\"\"\n",
    "    X_processed = np.zeros_like(X)\n",
    "    \n",
    "    # Baseline correction and SNV\n",
    "    for i in tqdm(range(X.shape[0])):\n",
    "        poly = np.polyfit(np.arange(X.shape[1]), X[i], 3)\n",
    "        baseline = np.polyval(poly, np.arange(X.shape[1]))\n",
    "        corrected_spec = X[i] - baseline\n",
    "        X_processed[i] = corrected_spec\n",
    "        if b: return X_processed\n",
    "        \n",
    "    # Calculate derivatives\n",
    "    deriv1 = signal.savgol_filter(X_processed, window_length=11, polyorder=3, deriv=1, axis=1)\n",
    "    deriv2 = signal.savgol_filter(X_processed, window_length=11, polyorder=3, deriv=2, axis=1)\n",
    "    deriv3 = signal.savgol_filter(X_processed, window_length=11, polyorder=3, deriv=3, axis=1)\n",
    "    return np.stack([X_processed, deriv1, deriv2, deriv3], axis=1)\n",
    "    \n",
    "\n",
    "def compute_statistical_features(spectra):\n",
    "    \"\"\"Compute basic statistical features from spectra.\"\"\"\n",
    "    return np.stack([\n",
    "        np.mean(spectra, axis=1), np.std(spectra, axis=1),\n",
    "        skew(spectra, axis=1), kurtosis(spectra, axis=1)\n",
    "    ], axis=1)\n",
    "    \n",
    "    \n",
    "def extract_peak_features(spectra):\n",
    "    \"\"\"Extract features based on spectral peaks.\"\"\"\n",
    "    features = []\n",
    "    for spec in spectra:\n",
    "        peaks, _ = find_peaks(spec, height=np.percentile(spec, 90), prominence=1)\n",
    "        widths, _, _, _ = peak_widths(spec, peaks, rel_height=0.5)\n",
    "        features.append([\n",
    "            len(peaks),\n",
    "            np.sum(spec[peaks]) if len(peaks) > 0 else 0,\n",
    "            np.mean(spec[peaks]) if len(peaks) > 0 else 0,\n",
    "            np.mean(widths) if len(widths) > 0 else 0,\n",
    "        ])\n",
    "    return np.array(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b5aab7a-f5ae-450f-b72a-982922fd9342",
   "metadata": {},
   "outputs": [],
   "source": [
    "#HF_TOKEN = \"xhf_XURkoNhwOIPtEdHfNeRpVkjEwKSkhtigFi\"\n",
    "#path = hf_ds_download(HF_TOKEN, repo_id=\"ArbaazBeg/kaggle-spectogram\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81644e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "#path = \"/root/.cache/huggingface/hub/datasets--ArbaazBeg--kaggle-spectogram/snapshots/b61d17629d4886fcc89e5bd9ca022af4da493d73\"\n",
    "path = \"/kaggle/input/dig-4-bio-raman-transfer-learning-challenge\"\n",
    "files = sorted(os.listdir(path))\n",
    "[(i, files[i]) for i in range(len(files))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca6588a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "csv_path = os.path.join(path, files[10])\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "input_cols = df.columns[1:2049]\n",
    "target_cols = df.columns[2050:]\n",
    "\n",
    "targets  = df[target_cols].dropna().to_numpy()\n",
    "\n",
    "df = df[input_cols]\n",
    "df['Unnamed: 1'] = df['Unnamed: 1'].str.replace(\"[\\[\\]]\", \"\", regex=True).astype('int64')\n",
    "df['Unnamed: 2048'] = df['Unnamed: 2048'].str.replace(\"[\\[\\]]\", \"\", regex=True).astype('int64')\n",
    "\n",
    "inputs = df.to_numpy().reshape(-1, 2, 2048)\n",
    "inputs = inputs.mean(axis=1)\n",
    "\n",
    "inputs.shape, targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f44ae5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_transformed = get_advanced_spectra_features(inputs)\n",
    "inputs_transformed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "909fdad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_baseline_feature = inputs_transformed[:, 0]\n",
    "inputs_derive1 = inputs_transformed[:, 1]\n",
    "inputs_derive2 = inputs_transformed[:, 2]\n",
    "inputs_derive3 = inputs_transformed[:, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf53ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_baseline_feature.shape, inputs_derive1.shape, inputs_derive2.shape, inputs_derive3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63db1372",
   "metadata": {},
   "outputs": [],
   "source": [
    "#i = get_advanced_spectra_features(inputs, True)\n",
    "#statistical_features = compute_statistical_features(i)\n",
    "#peak_features = extract_peak_features(i)\n",
    "#statistical_features.shape, peak_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec04c142",
   "metadata": {},
   "outputs": [],
   "source": [
    "#inputs = inputs.reshape(-1, 3 * 2048).astype(np.float32)\n",
    "#inputs = np.hstack([inputs, peak_features, statistical_features])\n",
    "inputs.shape, targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a80358db",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inputs, eval_inputs, train_targets, eval_targets = split(inputs, targets, SEED)\n",
    "train_inputs_baseline, eval_inputs_baseline, train_targets_baseline, eval_targets_baseline = split(inputs_baseline_feature, targets, SEED)\n",
    "train_inputs_derive1, eval_inputs_derive1, train_targets_derive1, eval_targets_derive1 = split(inputs_derive1, targets, SEED)\n",
    "train_inputs_derive2, eval_inputs_derive2, train_targets_derive2, eval_targets_derive2 = split(inputs_derive2, targets, SEED)\n",
    "train_inputs_derive3, eval_inputs_derive3, train_targets_derive3, eval_targets_derive3 = split(inputs_derive3, targets, SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e99d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "min, max, mean, std = get_stats(train_inputs, r=True)\n",
    "train_inputs = zscore(train_inputs, mean, std)\n",
    "eval_inputs = zscore(eval_inputs, mean, std)\n",
    "get_stats(train_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb31b798",
   "metadata": {},
   "outputs": [],
   "source": [
    "min, max, mean_baseline, std_baseline = get_stats(train_inputs_baseline, r=True)\n",
    "train_inputs_baseline = zscore(train_inputs_baseline, mean_baseline, std_baseline)\n",
    "eval_inputs_baseline = zscore(eval_inputs_baseline, mean_baseline, std_baseline)\n",
    "get_stats(train_inputs_baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948b64e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "min, max, mean_derive1, std_derive1 = get_stats(train_inputs_derive1, r=True)\n",
    "train_inputs_derive1 = zscore(train_inputs_derive1, mean_derive1, std_derive1)\n",
    "eval_inputs_derive1 = zscore(eval_inputs_derive1, mean_derive1, std_derive1)\n",
    "get_stats(train_inputs_derive1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "908e5b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "min, max, mean_derive2, std_derive2 = get_stats(train_inputs_derive2, r=True)\n",
    "train_inputs_derive2 = zscore(train_inputs_derive2, mean_derive2, std_derive2)\n",
    "eval_inputs_derive2 = zscore(eval_inputs_derive2, mean_derive2, std_derive2)\n",
    "get_stats(train_inputs_derive2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6920bcbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "min, max, mean_derive3, std_derive3 = get_stats(train_inputs_derive3, r=True)\n",
    "train_inputs_derive3 = zscore(train_inputs_derive3, mean_derive3, std_derive3)\n",
    "eval_inputs_derive3 = zscore(eval_inputs_derive3, mean_derive3, std_derive3)\n",
    "get_stats(train_inputs_derive3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68f2fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_stats(train_inputs, True)\n",
    "get_stats(eval_inputs, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1d2911",
   "metadata": {},
   "outputs": [],
   "source": [
    "score = -float(\"inf\")\n",
    "best_params = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d95c6425",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "\n",
    "class hparams:\n",
    "    n_estimators = 4000\n",
    "    learning_rate = 0.001\n",
    "    max_depth = 10\n",
    "    #reg_lambda = 0.0001\n",
    "    \n",
    "    \n",
    "model = XGBRegressor(\n",
    "    n_estimators=hparams.n_estimators,\n",
    "    learning_rate=hparams.learning_rate,\n",
    "    max_depth=hparams.max_depth,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=SEED,\n",
    "    n_jobs=-1,\n",
    "    #reg_lambda=hparams.reg_lambda,\n",
    "    eval_metric=\"rmse\",  \n",
    "    #early_stopping_rounds=5,        \n",
    "    tree_method=\"hist\", \n",
    "    device=\"cuda\",\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    train_inputs, train_targets,\n",
    "    eval_set=[(eval_inputs, eval_targets)],\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "preds = model.predict(eval_inputs)\n",
    "r2 = r2_score(eval_targets, preds)\n",
    "\n",
    "if r2 > score:    \n",
    "    best_params[\"n_estimators\"] = hparams.n_estimators\n",
    "    best_params[\"learning_rate\"] = hparams.learning_rate\n",
    "    best_params[\"max_depth\"] = hparams.max_depth\n",
    "    #best_params[\"reg_lambda\"] = hparams.reg_lambda\n",
    "    print(best_params)\n",
    "    print(\"previous\", score)\n",
    "    score = r2\n",
    "    print(\"best\", score) \n",
    "else:\n",
    "    print(\"Failed\", r2, \"best\", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b40a3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Failed\", r2, \"best\", score) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee176f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "{'n_estimators': 4000,\n",
    " 'learning_rate': 0.001,\n",
    " 'max_depth': 10,\n",
    " 'reg_lambda': 0.0001}\n",
    "\n",
    "0.919169955244037"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d7bb2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import r2_score\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "seeds = [SEED]#np.random.randint(0, 10**6, size=10).tolist()\n",
    "models = {\"1\": [], \"2\": [], \"3\": []}\n",
    "\n",
    "for seed in tqdm(seeds):\n",
    "    print(f\"Seed {seed}\")\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "    scores_mean = []\n",
    "    \n",
    "    for i in range(3):\n",
    "        splits = kf.split(inputs, targets)\n",
    "        scores = []\n",
    "        \n",
    "        for j, (train_idx, eval_idx) in enumerate(splits):\n",
    "            train_inputs, train_targets = inputs[train_idx], targets[train_idx, i]\n",
    "            eval_inputs, eval_targets = inputs[eval_idx], targets[eval_idx, i]\n",
    "            \n",
    "            _, _, mean, std = get_stats(train_inputs, p=False, r=True)\n",
    "            train_inputs = zscore(train_inputs, mean, std)\n",
    "            eval_inputs = zscore(eval_inputs, mean, std)\n",
    "            \n",
    "            model = XGBRegressor(\n",
    "                n_estimators=200,\n",
    "                learning_rate=0.05,\n",
    "                max_depth=3,\n",
    "                subsample=0.8,\n",
    "                colsample_bytree=0.8,\n",
    "                random_state=seed,\n",
    "                n_jobs=-1,\n",
    "                #reg_lambda=1.0,\n",
    "                eval_metric=\"rmse\",  \n",
    "                #early_stopping_rounds=5,        \n",
    "                tree_method=\"hist\", \n",
    "                device=\"cuda\",\n",
    "            )\n",
    "            \n",
    "            model.fit(\n",
    "                train_inputs, train_targets,\n",
    "                eval_set=[(eval_inputs, eval_targets)],\n",
    "                verbose=False,\n",
    "            )\n",
    "            \n",
    "            preds = model.predict(eval_inputs)\n",
    "            score = r2_score(eval_targets, preds)\n",
    "            scores.append(score)\n",
    "            models[str(i+1)].append((score, model, mean, std))\n",
    "        \n",
    "        scores = np.mean(scores)\n",
    "        scores_mean.append(scores)\n",
    "        print(f\"Mean R2 (target {i}): {scores:.4f}\")\n",
    "    \n",
    "    scores_mean = np.mean(scores_mean)\n",
    "    print(f\"Final: {scores_mean:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d20fe9e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_models(models):\n",
    "    best_models = []\n",
    "    \n",
    "    for i in range(1, 4):\n",
    "        score = float('-inf')\n",
    "        for s, model, mean, std in models[str(i)]:\n",
    "            if s > score:\n",
    "                score = s\n",
    "                best = model\n",
    "                mu = mean\n",
    "                sigma = std\n",
    "        best_models.append((best, score, mu, sigma))\n",
    "            \n",
    "    return best_models\n",
    "\n",
    "best_models = get_best_models(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e78700",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = {\"1\": [], \"2\": [], \"3\": []}\n",
    "for i in range(1, 4):\n",
    "    for s, m, mean, std in models[str(i)]:\n",
    "        scores[str(i)].append(s)    \n",
    "    scores[str(i)] = np.mean(scores[str(i)])\n",
    "    \n",
    "scores, np.mean([scores[\"1\"], scores[\"2\"], scores[\"3\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ddca50",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "for m, s, mu, sigma in best_models:\n",
    "    scores.append(s)\n",
    "scores, np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f83b584",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = os.path.join(path, files[0])\n",
    "test_df = pd.read_csv(csv_path)\n",
    "\n",
    "\n",
    "row1 = test_df.columns[1:].to_numpy().copy()\n",
    "row1[-1] = \"5611\"\n",
    "row1 = row1.astype(np.float64)\n",
    "\n",
    "\n",
    "cols = test_df.columns[1:]\n",
    "test_df = test_df[cols]\n",
    "test_df[\" 5611]\"] = test_df[\" 5611]\"].str.replace('[\\[\\]]', '', regex=True).astype('int64')\n",
    "test = test_df.to_numpy()\n",
    "\n",
    "test = np.insert(test, 0, row1, axis=0)\n",
    "test = test.reshape(-1, 2, 2048).mean(axis=1)\n",
    "\n",
    "get_stats(test)\n",
    "#t = get_advanced_spectra_features(test, True)\n",
    "#test_statistical_features = compute_statistical_features(t)\n",
    "#test_peak_features = extract_peak_features(t)\n",
    "test = get_advanced_spectra_features(test)\n",
    "get_stats(test)\n",
    "test = test.reshape(-1, 3 * 2048)\n",
    "#test = np.hstack([test, test_peak_features, test_peak_features])\n",
    "test = zscore(test, mean, std)\n",
    "test.shape, test.dtype, get_stats(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a2ad78-1191-4c44-b5a2-b9e8ab913694",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(test)\n",
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad514f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []\n",
    "\n",
    "for i in range(3):\n",
    "    local_preds = []\n",
    "    for _, model, mean, std in models[str(i + 1)]:\n",
    "        t = zscore(test.copy(), mean, std)\n",
    "        p = model.predict(test)\n",
    "        local_preds.append(p)\n",
    "    \n",
    "    local_preds = np.stack(local_preds).mean(axis=0)\n",
    "    preds.append(local_preds)\n",
    "    \n",
    "preds = np.column_stack(preds)\n",
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c3ef61a",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []\n",
    "\n",
    "for model, s, mean, std in best_models:\n",
    "    print(mean, std)\n",
    "    t = zscore(test.copy(), mean, std)\n",
    "    p = model.predict(t)\n",
    "    preds.append(p)\n",
    "    \n",
    "preds = np.column_stack(preds)\n",
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f8c869",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = ['Glucose', 'Sodium Acetate', 'Magnesium Sulfate']\n",
    "preds_df = pd.DataFrame(preds, columns=column_names)\n",
    "preds_df.insert(0, 'ID', [i+1 for i in range(len(preds_df))])\n",
    "preds_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "401b302e",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"xgboost.9054.fixes.double.zscore.csv\"\n",
    "preds_df.to_csv(name, index=False)\n",
    "f = pd.read_csv(f\"{name}\")\n",
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd1db15",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
