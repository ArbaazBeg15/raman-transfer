{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ecea469",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install -qU xgboost optuna pandas scipy scikit-learn matplotlib tqdm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1468113e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "SEED = 1000\n",
    "\n",
    "def setup_reproducibility():\n",
    "    random.seed(SEED)\n",
    "    np.random.seed(SEED)\n",
    "    torch.manual_seed(SEED)\n",
    "    if torch.cuda.is_available(): torch.cuda.manual_seed_all(SEED)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.use_deterministic_algorithms(False, warn_only=True)\n",
    "    torch.set_float32_matmul_precision(\"high\")\n",
    "\n",
    "setup_reproducibility()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ecaa449",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "def get_stats(tensor, p=True, r=False):\n",
    "    mean, std = tensor.mean(), tensor.std()\n",
    "    min, max =  tensor.min(), tensor.max()\n",
    "    \n",
    "    if p: print(f\"Min: {min}, Max: {max}, Mean: {mean}, Std: {std}\")\n",
    "    \n",
    "    if r: return min, max, mean, std\n",
    "    \n",
    "    \n",
    "def zscore(tensor, mean=None, std=None):\n",
    "    if mean is None: mean = tensor.mean()\n",
    "    if std is None: std = tensor.std()\n",
    "    return (tensor - mean) / (std + 1e-6)\n",
    "\n",
    "\n",
    "def get_model_size(model):\n",
    "    print(sum(p.numel() for p in model.parameters()) / 1e6)\n",
    "    \n",
    "\n",
    "def get_index(iterable):\n",
    "    return random.randint(0, len(iterable) - 1)\n",
    "\n",
    "\n",
    "def split(inputs, targets, seed):\n",
    "    return train_test_split(\n",
    "        inputs,\n",
    "        targets, \n",
    "        test_size=0.2,\n",
    "        shuffle=True, \n",
    "        random_state=seed\n",
    "    ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb2962fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def show_waves(waves, dpi=100):\n",
    "    \"\"\"\n",
    "    waves: numpy array of shape (3, N)\n",
    "    Creates three separate figures that stretch wide.\n",
    "    \"\"\"\n",
    "\n",
    "    N = waves.shape[1]\n",
    "    t = np.arange(N)\n",
    "\n",
    "    # Wide aspect ratio; height modest so each window fills width\n",
    "    for i in range(waves.shape[0]):\n",
    "        fig = plt.figure(figsize=(14, 4), dpi=dpi)  # wide figure\n",
    "        ax = fig.add_subplot(111)\n",
    "        ax.plot(t, waves[i], linewidth=1)\n",
    "        ax.set_title(f\"Wave {i+1}\")\n",
    "        ax.set_xlabel(\"Sample\")\n",
    "        ax.set_ylabel(\"Amplitude\")\n",
    "        ax.grid(True)\n",
    "        fig.tight_layout()  # reduce margins to use width\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2b5aab7a-f5ae-450f-b72a-982922fd9342",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login, snapshot_download\n",
    "\n",
    "if False:\n",
    "    hf_token = \"xhf_uOkImkbEroqtIuyvGJrttTzaebfeIdPZID\"\n",
    "    login(hf_token)\n",
    "    repo_id = \"ArbaazBeg/kaggle-spectogram\"\n",
    "    dataset_path = snapshot_download(repo_id, repo_type=\"dataset\")\n",
    "    dataset_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0f753ce1-8254-4d5a-b287-340d341f5b6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/root/.cache/huggingface/hub/datasets--ArbaazBeg--kaggle-spectogram/snapshots/b61d17629d4886fcc89e5bd9ca022af4da493d73'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b81644e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, '.gitattributes'),\n",
       " (1, '96_samples.csv'),\n",
       " (2, 'anton_532.csv'),\n",
       " (3, 'anton_785.csv'),\n",
       " (4, 'kaiser.csv'),\n",
       " (5, 'metrohm.csv'),\n",
       " (6, 'mettler_toledo.csv'),\n",
       " (7, 'sample_submission.csv'),\n",
       " (8, 'tec5.csv'),\n",
       " (9, 'timegate.csv'),\n",
       " (10, 'tornado.csv'),\n",
       " (11, 'transfer_plate.csv')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "path = \"/root/.cache/huggingface/hub/datasets--ArbaazBeg--kaggle-spectogram/snapshots/b61d17629d4886fcc89e5bd9ca022af4da493d73\"\n",
    "files = sorted(os.listdir(path))\n",
    "[(i, files[i]) for i in range(len(files))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ca6588a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:13: SyntaxWarning: invalid escape sequence '\\['\n",
      "<>:14: SyntaxWarning: invalid escape sequence '\\['\n",
      "<>:13: SyntaxWarning: invalid escape sequence '\\['\n",
      "<>:14: SyntaxWarning: invalid escape sequence '\\['\n",
      "/tmp/ipykernel_3572/3793664017.py:13: SyntaxWarning: invalid escape sequence '\\['\n",
      "  df['Unnamed: 1'] = df['Unnamed: 1'].str.replace(\"[\\[\\]]\", \"\", regex=True).astype('int64')\n",
      "/tmp/ipykernel_3572/3793664017.py:14: SyntaxWarning: invalid escape sequence '\\['\n",
      "  df['Unnamed: 2048'] = df['Unnamed: 2048'].str.replace(\"[\\[\\]]\", \"\", regex=True).astype('int64')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((96, 2048), (96, 3))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "csv_path = os.path.join(path, files[11])\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "input_cols = df.columns[1:2049]\n",
    "target_cols = df.columns[2050:]\n",
    "\n",
    "targets  = df[target_cols].dropna().to_numpy()\n",
    "\n",
    "df = df[input_cols]\n",
    "df['Unnamed: 1'] = df['Unnamed: 1'].str.replace(\"[\\[\\]]\", \"\", regex=True).astype('int64')\n",
    "df['Unnamed: 2048'] = df['Unnamed: 2048'].str.replace(\"[\\[\\]]\", \"\", regex=True).astype('int64')\n",
    "\n",
    "inputs = df.to_numpy().reshape(-1, 2, 2048)\n",
    "inputs = inputs.mean(axis=1)\n",
    "\n",
    "inputs.shape, targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "494edfe7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6cb24bce68ad4254bfc35f7432c85813",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/96 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(96, 3, 2048)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy import signal\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "def get_advanced_spectra_features(X):\n",
    "    \"\"\"Create multi-channel features from spectra: raw, 1st derivative, 2nd derivative.\"\"\"\n",
    "    X_processed = np.zeros_like(X)\n",
    "    # Baseline correction and SNV\n",
    "    for i in tqdm(range(X.shape[0])):\n",
    "        poly = np.polyfit(np.arange(X.shape[1]), X[i], 3)\n",
    "        baseline = np.polyval(poly, np.arange(X.shape[1]))\n",
    "        corrected_spec = X[i] - baseline\n",
    "        X_processed[i] = (corrected_spec - corrected_spec.mean()) / (corrected_spec.std() + 1e-8)\n",
    "\n",
    "    # Calculate derivatives\n",
    "    deriv1 = signal.savgol_filter(X_processed, window_length=11, polyorder=3, deriv=1, axis=1)\n",
    "    deriv2 = signal.savgol_filter(X_processed, window_length=11, polyorder=3, deriv=2, axis=1)\n",
    "\n",
    "    # Stack as channels\n",
    "    return np.stack([X_processed, deriv1, deriv2], axis=1)\n",
    "\n",
    "inputs = get_advanced_spectra_features(inputs)\n",
    "inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ec04c142",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = inputs.reshape(-1, 3 * 2048).astype(np.float32)\n",
    "targets = targets.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a80358db",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inputs, eval_inputs, train_targets, eval_targets = split(inputs, targets, SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e0e99d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, _, mean, std = get_stats(train_inputs, p=False, r=True)\n",
    "train_inputs = zscore(train_inputs, mean, std)\n",
    "eval_inputs = zscore(eval_inputs, mean, std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cf8ecfeb-79c2-40b1-afde-1ebb342e28ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/venv/main/lib/python3.12/site-packages/xgboost/core.py:729: UserWarning: [09:23:10] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  return func(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9106852412223816"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import optuna\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model = XGBRegressor(\n",
    "    n_estimators=200,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=3,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=SEED,\n",
    "    n_jobs=-1,\n",
    "    #reg_lambda=1.0,\n",
    "    eval_metric=\"rmse\",  \n",
    "    #early_stopping_rounds=5,        \n",
    "    tree_method=\"hist\", \n",
    "    device=\"cuda\",\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    train_inputs, train_targets,\n",
    "    eval_set=[(eval_inputs, eval_targets)],\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "preds = model.predict(eval_inputs)\n",
    "r2_score(eval_targets, preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d95c6425",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-21 09:18:59,597] A new study created in memory with name: no-name-17b07af3-d4e7-4351-8697-d18bdb8f5b80\n",
      "/venv/main/lib/python3.12/site-packages/xgboost/core.py:729: UserWarning: [09:19:09] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  return func(**kwargs)\n",
      "[I 2025-08-21 09:19:09,629] Trial 0 finished with value: 0.9158778190612793 and parameters: {'n_estimators': 448, 'max_depth': 17, 'learning_rate': 0.08778923274424927}. Best is trial 0 with value: 0.9158778190612793.\n",
      "[I 2025-08-21 09:19:15,253] Trial 1 finished with value: 0.6503311991691589 and parameters: {'n_estimators': 832, 'max_depth': 5, 'learning_rate': 0.621709851808496}. Best is trial 0 with value: 0.9158778190612793.\n",
      "[I 2025-08-21 09:19:18,356] Trial 2 finished with value: 0.7831408381462097 and parameters: {'n_estimators': 229, 'max_depth': 7, 'learning_rate': 0.43901275815967356}. Best is trial 0 with value: 0.9158778190612793.\n",
      "[I 2025-08-21 09:19:23,772] Trial 3 finished with value: 0.8122555613517761 and parameters: {'n_estimators': 458, 'max_depth': 18, 'learning_rate': 0.3399497151585738}. Best is trial 0 with value: 0.9158778190612793.\n",
      "[I 2025-08-21 09:19:27,006] Trial 4 finished with value: 0.8384911417961121 and parameters: {'n_estimators': 368, 'max_depth': 4, 'learning_rate': 0.3122252170903482}. Best is trial 0 with value: 0.9158778190612793.\n",
      "[I 2025-08-21 09:19:38,153] Trial 5 finished with value: 0.89886474609375 and parameters: {'n_estimators': 798, 'max_depth': 12, 'learning_rate': 0.11031388744199183}. Best is trial 0 with value: 0.9158778190612793.\n",
      "[I 2025-08-21 09:19:46,943] Trial 6 finished with value: 0.8742215037345886 and parameters: {'n_estimators': 761, 'max_depth': 20, 'learning_rate': 0.2158004481840582}. Best is trial 0 with value: 0.9158778190612793.\n",
      "[I 2025-08-21 09:19:56,774] Trial 7 finished with value: 0.8806684017181396 and parameters: {'n_estimators': 724, 'max_depth': 10, 'learning_rate': 0.20538251279609976}. Best is trial 0 with value: 0.9158778190612793.\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    n_estimators = trial.suggest_int(\"n_estimators\", 200, 1000)\n",
    "    max_depth = trial.suggest_int(\"max_depth\", 3, 20)\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 0.0001, 0.8)\n",
    "    \n",
    "    model = XGBRegressor(\n",
    "        n_estimators=n_estimators,\n",
    "        learning_rate=learning_rate,\n",
    "        max_depth=max_depth,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        random_state=SEED,\n",
    "        n_jobs=-1,\n",
    "        #reg_lambda=1.0,\n",
    "        eval_metric=\"rmse\",  \n",
    "        #early_stopping_rounds=5,        \n",
    "        tree_method=\"hist\", \n",
    "        device=\"cuda\",\n",
    "    )\n",
    "\n",
    "    model.fit(\n",
    "        train_inputs, train_targets,\n",
    "        eval_set=[(eval_inputs, eval_targets)],\n",
    "        verbose=False,\n",
    "    )\n",
    "\n",
    "    preds = model.predict(eval_inputs)\n",
    "    return r2_score(eval_targets, preds)\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d7bb2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import r2_score\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "seeds = [SEED]#np.random.randint(0, 10**6, size=10).tolist()\n",
    "models = {\"1\": [], \"2\": [], \"3\": []}\n",
    "\n",
    "for seed in tqdm(seeds):\n",
    "    print(f\"Seed {seed}\")\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "    scores_mean = []\n",
    "    \n",
    "    for i in range(3):\n",
    "        splits = kf.split(inputs, targets)\n",
    "        scores = []\n",
    "        \n",
    "        for j, (train_idx, eval_idx) in enumerate(splits):\n",
    "            train_inputs, train_targets = inputs[train_idx], targets[train_idx, i]\n",
    "            eval_inputs, eval_targets = inputs[eval_idx], targets[eval_idx, i]\n",
    "            \n",
    "            _, _, mean, std = get_stats(train_inputs, p=False, r=True)\n",
    "            train_inputs = zscore(train_inputs, mean, std)\n",
    "            eval_inputs = zscore(eval_inputs, mean, std)\n",
    "            \n",
    "            model = XGBRegressor(\n",
    "                n_estimators=200,\n",
    "                learning_rate=0.05,\n",
    "                max_depth=3,\n",
    "                subsample=0.8,\n",
    "                colsample_bytree=0.8,\n",
    "                random_state=seed,\n",
    "                n_jobs=-1,\n",
    "                #reg_lambda=1.0,\n",
    "                eval_metric=\"rmse\",  \n",
    "                #early_stopping_rounds=5,        \n",
    "                tree_method=\"hist\", \n",
    "                device=\"cuda\",\n",
    "            )\n",
    "            \n",
    "            model.fit(\n",
    "                train_inputs, train_targets,\n",
    "                eval_set=[(eval_inputs, eval_targets)],\n",
    "                verbose=False,\n",
    "            )\n",
    "            \n",
    "            preds = model.predict(eval_inputs)\n",
    "            score = r2_score(eval_targets, preds)\n",
    "            scores.append(score)\n",
    "            models[str(i+1)].append((score, model, mean, std))\n",
    "        \n",
    "        scores = np.mean(scores)\n",
    "        scores_mean.append(scores)\n",
    "        print(f\"Mean R2 (target {i}): {scores:.4f}\")\n",
    "    \n",
    "    scores_mean = np.mean(scores_mean)\n",
    "    print(f\"Final: {scores_mean:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d20fe9e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_models(models):\n",
    "    best_models = []\n",
    "    \n",
    "    for i in range(1, 4):\n",
    "        score = float('-inf')\n",
    "        for s, model, mean, std in models[str(i)]:\n",
    "            if s > score:\n",
    "                score = s\n",
    "                best = model\n",
    "                mu = mean\n",
    "                sigma = std\n",
    "        best_models.append((best, score, mu, sigma))\n",
    "            \n",
    "    return best_models\n",
    "\n",
    "best_models = get_best_models(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e78700",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = {\"1\": [], \"2\": [], \"3\": []}\n",
    "for i in range(1, 4):\n",
    "    for s, m, mean, std in models[str(i)]:\n",
    "        scores[str(i)].append(s)    \n",
    "    scores[str(i)] = np.mean(scores[str(i)])\n",
    "    \n",
    "scores, np.mean([scores[\"1\"], scores[\"2\"], scores[\"3\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ddca50",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "for m, s, mu, sigma in best_models:\n",
    "    scores.append(s)\n",
    "scores, np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f83b584",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = os.path.join(path, files[6])\n",
    "test_df = pd.read_csv(csv_path)\n",
    "\n",
    "\n",
    "row1 = test_df.columns[1:].to_numpy().copy()\n",
    "row1[-1] = \"5611\"\n",
    "row1 = row1.astype(np.float64)\n",
    "\n",
    "\n",
    "cols = test_df.columns[1:]\n",
    "test_df = test_df[cols]\n",
    "test_df[\" 5611]\"] = test_df[\" 5611]\"].str.replace('[\\[\\]]', '', regex=True).astype('int64')\n",
    "test = test_df.to_numpy()\n",
    "\n",
    "test = np.insert(test, 0, row1, axis=0)\n",
    "test = test.reshape(-1, 2, 2048).mean(axis=1)\n",
    "\n",
    "get_stats(test)\n",
    "test = get_advanced_spectra_features(test)\n",
    "test = test.reshape(-1, 3 * 2048)\n",
    "test.shape, test.dtype, get_stats(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad514f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []\n",
    "\n",
    "for i in range(3):\n",
    "    local_preds = []\n",
    "    for _, model, mean, std in models[str(i + 1)]:\n",
    "        t = zscore(test.copy(), mean, std)\n",
    "        p = model.predict(test)\n",
    "        local_preds.append(p)\n",
    "    \n",
    "    local_preds = np.stack(local_preds).mean(axis=0)\n",
    "    preds.append(local_preds)\n",
    "    \n",
    "preds = np.column_stack(preds)\n",
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c3ef61a",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []\n",
    "\n",
    "for model, s, mean, std in best_models:\n",
    "    print(mean, std)\n",
    "    t = zscore(test.copy(), mean, std)\n",
    "    p = model.predict(t)\n",
    "    preds.append(p)\n",
    "    \n",
    "preds = np.column_stack(preds)\n",
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f8c869",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = ['Glucose', 'Sodium Acetate', 'Magnesium Sulfate']\n",
    "preds_df = pd.DataFrame(preds, columns=column_names)\n",
    "preds_df.insert(0, 'ID', [i+1 for i in range(len(preds_df))])\n",
    "preds_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "401b302e",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"xgboost.concat.10.seeds.top1.mu.sigma.done.csv\"\n",
    "preds_df.to_csv(name, index=False)\n",
    "f = pd.read_csv(f\"/kaggle/working/{name}\")\n",
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd1db15",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 (main venv)",
   "language": "python",
   "name": "main"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
