{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "314d6601",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34ca4ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def setup_reproducibility(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available(): torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.use_deterministic_algorithms(False, warn_only=True)\n",
    "    torch.set_float32_matmul_precision(\"high\")\n",
    "    \n",
    "SEED = 1000\n",
    "setup_reproducibility(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb8c02b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import OrderedDict\n",
    "from transformers import get_cosine_schedule_with_warmup\n",
    "from scipy import signal\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from huggingface_hub import login, snapshot_download\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "def average_state_dicts(state_dict_list):\n",
    "    n = len(state_dict_list)\n",
    "    # Ensure we don't modify the originals\n",
    "    avg_sd = OrderedDict()\n",
    "\n",
    "    # Iterate over every parameter/buffer key\n",
    "    for k in state_dict_list[0]:\n",
    "        # sum across models â†’ float32 to avoid overflow on int types\n",
    "        avg = sum(sd[k].float() for sd in state_dict_list) / n\n",
    "        # cast back to original dtype if needed\n",
    "        avg_sd[k] = avg.to(dtype=state_dict_list[0][k].dtype)\n",
    "\n",
    "    return avg_sd\n",
    "\n",
    "\n",
    "def get_ckpt_paths(output_dir, keyword):\n",
    "    output_files = sorted(os.listdir(output_dir))\n",
    "\n",
    "    ckpt_paths = []\n",
    "    for f in output_files:\n",
    "        if keyword in f and \"csv\" not in f:\n",
    "            ckpt_path = os.path.join(output_dir, f)\n",
    "            ckpt_paths.append(ckpt_path)\n",
    "            ckpt = torch.load(ckpt_path, weights_only=False)\n",
    "            print(ckpt_path, ckpt[\"epoch\"], ckpt[\"score\"])\n",
    "            \n",
    "    return ckpt_paths\n",
    "\n",
    "\n",
    "def rest(t=4000):\n",
    "    import time\n",
    "    [time.sleep(1) for i in range(t)]\n",
    "        \n",
    "        \n",
    "def generate_csv(preds, name):\n",
    "    column_names = ['Glucose', 'Sodium Acetate', 'Magnesium Sulfate']\n",
    "    preds_df = pd.DataFrame(preds, columns=column_names)\n",
    "    preds_df.insert(0, 'ID', [i+1 for i in range(len(preds_df))])\n",
    "    preds_df.to_csv(name, index=False)\n",
    "    \n",
    "    \n",
    "def get_ckpt(path):\n",
    "    return torch.load(path, weights_only=False)\n",
    "\n",
    "\n",
    "def cuda_to_np(tensor):\n",
    "    return tensor.cpu().detach().numpy()\n",
    "\n",
    "\n",
    "def get_scheduler(optimizer, train_dl, epochs):\n",
    "    total_training_steps = len(train_dl) * epochs\n",
    "    warmup_steps = int(total_training_steps * 0.05)  # e.g. 5% warmup\n",
    "    \n",
    "    return get_cosine_schedule_with_warmup(\n",
    "        optimizer=optimizer,\n",
    "        num_warmup_steps=warmup_steps,\n",
    "        num_training_steps=total_training_steps\n",
    "    )\n",
    "\n",
    "\n",
    "def get_stats(tensor, p=True, r=False, minmax=False):\n",
    "    if minmax:\n",
    "        min, max = tensor.min(), tensor.max()\n",
    "        mean, std = tensor.mean(), tensor.std()\n",
    "        if p: print(f\"Min: {min}, Max: {max}, Mean: {mean}, Std: {std}\")\n",
    "        if r: return min, max, mean, std\n",
    "    else:\n",
    "        mean, std = tensor.mean(), tensor.std()\n",
    "        if p: print(f\"Mean: {mean}, Std: {std}\")\n",
    "        if r: return mean, std\n",
    "    \n",
    "    \n",
    "def zscore(tensor, mean=None, std=None):\n",
    "    if mean is None: mean = tensor.mean()\n",
    "    if std is None: std = tensor.std()\n",
    "    return (tensor - mean) / (std + 1e-8)\n",
    "\n",
    "\n",
    "def reverse_zscore(tensor, mu, sigma):\n",
    "    return (tensor * sigma) + mu\n",
    "\n",
    "\n",
    "def get_model_size(model):\n",
    "    print(sum(p.numel() for p in model.parameters()) / 1e6)\n",
    "    \n",
    "\n",
    "def get_index(iterable):\n",
    "    return random.randint(0, len(iterable) - 1)\n",
    "\n",
    "\n",
    "def get_indices(iterable, n):\n",
    "    return random.sample(range(len(iterable)), n)\n",
    "\n",
    "\n",
    "def split(inputs, targets, seed):\n",
    "    return train_test_split(\n",
    "        inputs,\n",
    "        targets, \n",
    "        test_size=0.2,\n",
    "        shuffle=True, \n",
    "        random_state=seed\n",
    "    ) \n",
    "\n",
    "\n",
    "def show_waves(waves, dpi=100):\n",
    "    \"\"\"\n",
    "    waves: numpy array of shape (3, N)\n",
    "    Creates three separate figures that stretch wide.\n",
    "    \"\"\"\n",
    "    N = waves.shape[1]\n",
    "    t = np.arange(N)\n",
    "\n",
    "    # Wide aspect ratio; height modest so each window fills width\n",
    "    for i in range(waves.shape[0]):\n",
    "        fig = plt.figure(figsize=(14, 4), dpi=dpi)  # wide figure\n",
    "        ax = fig.add_subplot(111)\n",
    "        ax.plot(t, waves[i], linewidth=1)\n",
    "        ax.set_title(f\"Wave {i+1}\")\n",
    "        ax.set_xlabel(\"Sample\")\n",
    "        ax.set_ylabel(\"Amplitude\")\n",
    "        ax.grid(True)\n",
    "        fig.tight_layout()  # reduce margins to use width\n",
    "        \n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "def hf_ds_download(hf_token, repo_id):\n",
    "    login(hf_token[1:])\n",
    "    return snapshot_download(repo_id, repo_type=\"dataset\")\n",
    "\n",
    "\n",
    "def get_spectra_features(X, b=False):\n",
    "    \"\"\"Create multi-channel features from spectra: raw, 1st derivative, 2nd derivative.\"\"\"\n",
    "    X_processed = np.zeros_like(X)\n",
    "    # Baseline correction and SNV\n",
    "    for i in tqdm(range(X.shape[0])):\n",
    "        poly = np.polyfit(np.arange(X.shape[1]), X[i], 3)\n",
    "        baseline = np.polyval(poly, np.arange(X.shape[1]))\n",
    "        corrected_spec = X[i] - baseline\n",
    "        #X_processed[i] = (corrected_spec - corrected_spec.mean()) / (corrected_spec.std() + 1e-8)\n",
    "        X_processed[i] = corrected_spec\n",
    "        \n",
    "    # Calculate derivatives\n",
    "    deriv1 = signal.savgol_filter(X_processed, window_length=11, polyorder=3, deriv=1, axis=1)\n",
    "    deriv2 = signal.savgol_filter(X_processed, window_length=11, polyorder=3, deriv=2, axis=1)\n",
    "\n",
    "    if b: return np.stack([X_processed, deriv1, deriv2], axis=1)\n",
    "    return np.stack([deriv1, deriv2], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2cfbbe45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if False:\n",
    "    path = \"/kaggle/input/dig-4-bio-raman-transfer-learning-challenge\"\n",
    "    files = os.listdir(path)\n",
    "    [print((i, files[i])) for i in range(len(files))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "748ea179-9ff5-4979-b9ce-76c9bec9410e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b11a832e5090491394c2d22da912eaf9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 12 files:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if True:\n",
    "    hf_token = \"xhf_XURkoNhwOIPtEdHfNeRpVkjEwKSkhtigFi\"\n",
    "    path = hf_ds_download(hf_token, \"ArbaazBeg/kaggle-spectogram\")\n",
    "    files = os.listdir(path)\n",
    "    [(i, files[i]) for i in range(len(files))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "62074de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "def load_comp_data(filepath, is_train=True):\n",
    "    \"\"\"Load and preprocess the Raman spectroscopy data\"\"\"\n",
    "    if is_train:\n",
    "        df = pd.read_csv(filepath)\n",
    "        # Extract target variables\n",
    "        target_cols = ['Glucose (g/L)', 'Sodium Acetate (g/L)', 'Magnesium Acetate (g/L)']\n",
    "        y = df[target_cols].dropna().values\n",
    "        \n",
    "        # Process spectral data\n",
    "        X = df.iloc[:, :-4] # Remove last 4 columns (analyte info and targets)\n",
    "    else:\n",
    "        df = pd.read_csv(filepath, header=None)\n",
    "        X = df\n",
    "        y = None\n",
    "    \n",
    "    # Set column names\n",
    "    X.columns = [\"sample_id\"] + [str(i) for i in range(X.shape[1]-1)]\n",
    "    \n",
    "    # Fill sample_id using forward fill\n",
    "    X['sample_id'] = X['sample_id'].ffill()\n",
    "    \n",
    "    # Clean sample_id\n",
    "    if is_train:\n",
    "        X['sample_id'] = X['sample_id'].str.strip()\n",
    "    else:\n",
    "        X['sample_id'] = X['sample_id'].str.strip().str.replace('sample', '').astype(int)\n",
    "    \n",
    "    # Clean spectral data (remove brackets)\n",
    "    spectral_cols = X.columns[1:]\n",
    "    for col in spectral_cols:\n",
    "        X[col] = X[col].astype(str).str.replace('[', '', regex=False).str.replace(']', '', regex=False)\n",
    "        X[col] = pd.to_numeric(X[col], errors='coerce')\n",
    "\n",
    "    return X, y\n",
    "\n",
    "\n",
    "def fix_val_test_shape(X):\n",
    "    lower_wns = 300\n",
    "    upper_wns = 1942\n",
    "    joint_wns = np.arange(lower_wns, upper_wns + 1)\n",
    "    spectral_values = np.linspace(65, 3350, 2048)\n",
    "\n",
    "    spectra_selection = np.logical_and(\n",
    "        lower_wns <= spectral_values, spectral_values <= upper_wns,\n",
    "    )\n",
    "    wns = spectral_values[spectra_selection]\n",
    "    X = X[:, spectra_selection]\n",
    "    X = np.array([np.interp(joint_wns, xp=wns, fp=spectrum,)for spectrum in X])\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e86f5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs, targets = load_comp_data(os.path.join(path, 'transfer_plate.csv'), is_train=True)\n",
    "test_inputs, _ = load_comp_data(os.path.join(path, '96_samples.csv'), is_train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "824359e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = inputs.drop('sample_id', axis=1).values.reshape(-1, 2, 2048).mean(axis=1)\n",
    "test_inputs = test_inputs.drop('sample_id', axis=1).values.reshape(-1, 2, 2048).mean(axis=1)\n",
    "\n",
    "inputs = fix_val_test_shape(inputs)\n",
    "test_inputs = fix_val_test_shape(test_inputs)\n",
    "\n",
    "# Version 2 Update: Normalise Val and Test data like Train\n",
    "inputs = inputs / np.max(inputs)\n",
    "test_inputs = test_inputs / np.max(test_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e66bd721",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((96, 1643), (96, 3), (96, 1643))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.shape, targets.shape, test_inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4ba2c070",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import scipy.optimize\n",
    "\n",
    "\n",
    "np_dtype_from_torch = {\n",
    "    torch.float32: np.float32,\n",
    "    torch.float64: np.float64,\n",
    "}\n",
    "\n",
    "class SpectralDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        spectra,\n",
    "        concentrations,\n",
    "        dtype=None,\n",
    "        spectra_mean_std=None,\n",
    "        concentration_mean_std=None,\n",
    "        combine_spectra_range=0.0,\n",
    "        baseline_factor_bound=0.0,\n",
    "        baseline_period_lower_bound=100.0,\n",
    "        baseline_period_upper_bound=200.0,\n",
    "        augment_slope_std=0.0,\n",
    "        augment_intersept_std=0.0,\n",
    "        rolling_bound=0,\n",
    "        spectrum_rolling_sigma=0.0,\n",
    "        augmentation_weight=0.1,\n",
    "        original_datapoint_weight=1.,\n",
    "    ):\n",
    "        self.dtype = dtype or torch.float32\n",
    "        self.combine_spectra_range = combine_spectra_range\n",
    "        self.baseline_factor_bound = baseline_factor_bound\n",
    "        self.augment_slope_std = augment_slope_std\n",
    "        self.augment_intercept_std = augment_intersept_std\n",
    "        self.baseline_period_lower_bound = baseline_period_lower_bound\n",
    "        self.baseline_period_upper_bound = baseline_period_upper_bound\n",
    "        self.rolling_bound = rolling_bound\n",
    "        self.spectrum_rolling_sigma = spectrum_rolling_sigma\n",
    "        self.augmentation_weight = torch.tensor(augmentation_weight, dtype=dtype)\n",
    "        self.original_dp_weight = original_datapoint_weight\n",
    "\n",
    "        # normalize spectra\n",
    "        spectra = torch.tensor(spectra, dtype=dtype)\n",
    "\n",
    "        if spectra_mean_std is None:\n",
    "            self.s_mean = torch.mean(spectra)\n",
    "            self.s_std = torch.std(spectra)\n",
    "        else:\n",
    "            self.s_mean, self.s_std = spectra_mean_std\n",
    "\n",
    "        self.spectra = torch.divide(\n",
    "            torch.subtract(spectra, self.s_mean),\n",
    "            self.s_std,\n",
    "        )\n",
    "\n",
    "        self.dummy_wns = np.tile(\n",
    "            np.arange(\n",
    "                0., 1., 1. / self.spectra.shape[2],\n",
    "                dtype=np_dtype_from_torch[self.dtype]\n",
    "            )[None, :self.spectra.shape[2]],\n",
    "            (self.spectra.shape[1], 1),\n",
    "        )\n",
    "\n",
    "        # normalize concentrations\n",
    "        concentrations = torch.tensor(concentrations, dtype=dtype)\n",
    "        if concentration_mean_std is None:\n",
    "            self.concentration_means = torch.nanmean(concentrations, dim=0)\n",
    "\n",
    "            self.concentration_stds = torch.maximum(\n",
    "                torch.tensor(\n",
    "                    [\n",
    "                        torch.std(col[torch.logical_not(torch.isnan(col))])\n",
    "                        for col in concentrations.T\n",
    "                    ]\n",
    "                ),\n",
    "                torch.tensor([1e-3] * concentrations.shape[1]),\n",
    "            )\n",
    "        else:\n",
    "            self.concentration_means = concentration_mean_std[0]\n",
    "            self.concentration_stds = concentration_mean_std[1]\n",
    "\n",
    "        self.concentrations = torch.divide(\n",
    "            torch.subtract(\n",
    "                concentrations,\n",
    "                self.concentration_means,\n",
    "            ),\n",
    "            self.concentration_stds,\n",
    "        )\n",
    "\n",
    "    def pick_two(self, max_idx=None):\n",
    "        max_idx = max_idx or len(self)\n",
    "        return random.choices(range(max_idx), k=2)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.concentrations)\n",
    "\n",
    "    def augment_spectra(self, spectra):\n",
    "        if self.augment_slope_std > 0.0:\n",
    "\n",
    "            def spectrum_approximation(x, slope, intercept):\n",
    "                return (slope * x + intercept).reshape(-1, 1)[:, 0]\n",
    "\n",
    "            slope, inter = scipy.optimize.curve_fit(\n",
    "                spectrum_approximation,\n",
    "                self.dummy_wns,\n",
    "                spectra.reshape(-1, 1)[:, 0],\n",
    "                p0=np.random.rand(2),\n",
    "            )[0]\n",
    "\n",
    "            new_slope = slope * (\n",
    "                    np.random.gamma(\n",
    "                        shape=1. / self.augment_slope_std,\n",
    "                        scale=self.augment_slope_std,\n",
    "                        size=1,\n",
    "                    )\n",
    "            )[0]\n",
    "            new_intercept = inter * (\n",
    "                1.0 + np.random.randn(1) * self.augment_intercept_std\n",
    "            )[0]\n",
    "            spectra += torch.tensor(\n",
    "                (new_slope - slope)\n",
    "            ) * self.dummy_wns + new_intercept - inter\n",
    "\n",
    "        factor = self.baseline_factor_bound * torch.rand(size=(1,))\n",
    "        offset = torch.rand(size=(1,)) * 2.0 * torch.pi\n",
    "        period = self.baseline_period_lower_bound + (\n",
    "            self.baseline_period_upper_bound - self.baseline_period_lower_bound\n",
    "        ) * torch.rand(size=(1,))\n",
    "        permutations = factor * torch.cos(\n",
    "            2.0 * torch.pi / period * self.dummy_wns + offset\n",
    "        )\n",
    "        return self.roll_spectrum(\n",
    "            spectra + permutations * spectra,\n",
    "            delta=random.randint(-self.rolling_bound, self.rolling_bound),\n",
    "        )\n",
    "\n",
    "    def roll_spectrum(self, spectra, delta):\n",
    "        num_spectra = spectra.shape[0]\n",
    "        rolled_spectra = np.roll(spectra, delta, axis=1)\n",
    "        if delta > 0:\n",
    "            rolled_spectra[:, :delta] = (\n",
    "                np.random.rand(num_spectra, delta) * self.spectrum_rolling_sigma + 1\n",
    "            ) * rolled_spectra[:, delta:(delta + 1)]\n",
    "        elif delta < 0:\n",
    "            rolled_spectra[:, delta:] = (\n",
    "                np.random.rand(num_spectra, -delta) * self.spectrum_rolling_sigma + 1\n",
    "            ) * rolled_spectra[:, delta - 1:delta]\n",
    "        return rolled_spectra\n",
    "\n",
    "    def combine_k_items(self, indices, weights):\n",
    "        return (\n",
    "            # spectra\n",
    "            torch.sum(\n",
    "                torch.mul(weights[:, None, None], self.spectra[indices, :, :]),\n",
    "                dim=0,\n",
    "            ),\n",
    "            # concentrations\n",
    "            torch.sum(\n",
    "                torch.mul(weights[:, None], self.concentrations[indices, :]),\n",
    "                dim=0,\n",
    "            )\n",
    "        )\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.combine_spectra_range < 1e-12:\n",
    "            spectrum = self.spectra[idx]\n",
    "            spectrum = self.augment_spectra(spectrum)\n",
    "            return (\n",
    "                spectrum,\n",
    "                self.concentrations[idx],\n",
    "                torch.tensor(1.0, dtype=self.dtype),\n",
    "            )\n",
    "        else:\n",
    "            if random.random() < self.original_dp_weight:\n",
    "                one_weight = 1.\n",
    "                label_weight = torch.tensor(1.0, dtype=self.dtype)\n",
    "            else:\n",
    "                one_weight = random.uniform(0.0, self.combine_spectra_range)\n",
    "                label_weight = self.augmentation_weight\n",
    "            weights = torch.tensor([one_weight, (1 - one_weight)])\n",
    "            # just pick two random indices\n",
    "            indices = random.choices(range(len(self)), k=2)\n",
    "\n",
    "            mixed_spectra, mixed_concentrations = self.combine_k_items(\n",
    "                indices=indices,\n",
    "                weights=weights,\n",
    "            )\n",
    "            mixed_spectra = self.augment_spectra(mixed_spectra)\n",
    "            return mixed_spectra, mixed_concentrations, label_weight\n",
    "\n",
    "\n",
    "config = {\n",
    "    'initial_cnn_channels': 32,\n",
    "    'cnn_channel_factor': 1.279574024454846,\n",
    "    'num_cnn_layers': 8,\n",
    "    'kernel_size': 3,\n",
    "    'stride': 2,\n",
    "    'activation_function': 'ELU',\n",
    "    'fc_dropout': 0.10361700399831791,\n",
    "    'lr': 0.001,\n",
    "    'gamma': 0.9649606352621118,\n",
    "    'baseline_factor_bound': 0.748262317340447,\n",
    "    'baseline_period_lower_bound': 0.9703081695287203,\n",
    "    'baseline_period_span': 19.79744237606427,\n",
    "    'original_datapoint_weight': 0.4335003268130408,\n",
    "    'augment_slope_std': 0.08171025264382692,\n",
    "    'batch_size': 32,\n",
    "    'fc_dims': 226,\n",
    "    'rolling_bound': 2,\n",
    "    'num_blocks': 2,\n",
    "}\n",
    "\n",
    "def get_dataset(inputs, targets, config, inputs_mean_std=None, targets_mean_std=None):\n",
    "    return SpectralDataset(\n",
    "        spectra=inputs[:, None, :],\n",
    "        concentrations=targets,\n",
    "        dtype=torch.float32,\n",
    "        spectra_mean_std=inputs_mean_std,\n",
    "        concentration_mean_std=targets_mean_std,\n",
    "        combine_spectra_range=1.0,\n",
    "        baseline_factor_bound=config[\"baseline_factor_bound\"],\n",
    "        baseline_period_lower_bound=config[\"baseline_period_lower_bound\"],\n",
    "        baseline_period_upper_bound=(config[\"baseline_period_lower_bound\"] + config[\"baseline_period_span\"]),\n",
    "        augment_slope_std=config[\"augment_slope_std\"],\n",
    "        augment_intersept_std=0.0,\n",
    "        rolling_bound=config[\"rolling_bound\"],\n",
    "        spectrum_rolling_sigma=0.01,\n",
    "        augmentation_weight=0.1,\n",
    "        original_datapoint_weight=1.,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9c11034d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "def build_loader(\n",
    "    SEED,\n",
    "    ds,\n",
    "    train=True,\n",
    "    batch_size=1,\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    "    drop_last=True,\n",
    "    pin_memory=True,\n",
    "    persistent_workers=False,\n",
    "):\n",
    "    def seed_worker(worker_id):\n",
    "        worker_seed = torch.initial_seed() % 2**32\n",
    "        np.random.seed(worker_seed)\n",
    "        random.seed(worker_seed)\n",
    "\n",
    "    generator = torch.Generator()\n",
    "    generator.manual_seed(SEED if train else SEED+5232)\n",
    "\n",
    "    return DataLoader(\n",
    "        ds,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=pin_memory,\n",
    "        drop_last=drop_last,\n",
    "        persistent_workers=persistent_workers,\n",
    "        worker_init_fn=seed_worker,\n",
    "        generator=generator,\n",
    "        #sampler=DistributedSampler(\n",
    "        #    train_ds,\n",
    "        #    shuffle=True,\n",
    "        #    drop_last=True,\n",
    "        #    seed=config.seed\n",
    "        #)\n",
    "    )\n",
    "    \n",
    "    \n",
    "def return_dls(train_ds, eval_ds, train_batch_size, eval_batch_size):\n",
    "    train_dl = build_loader(\n",
    "        SEED,\n",
    "        train_ds,\n",
    "        train=True,\n",
    "        batch_size=train_batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=0,\n",
    "        drop_last=False,\n",
    "        pin_memory=True,\n",
    "        persistent_workers=False,\n",
    "    )\n",
    "\n",
    "    eval_dl = build_loader(\n",
    "        SEED,\n",
    "        eval_ds,\n",
    "        train=False,\n",
    "        batch_size=eval_batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=0,\n",
    "        drop_last=False,\n",
    "        pin_memory=True,\n",
    "        persistent_workers=False,\n",
    "    )\n",
    "    \n",
    "    return train_dl, eval_dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e343398b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import neptune\n",
    "\n",
    "\n",
    "def setup_neptune():\n",
    "    if not RESUME:\n",
    "        neptune_run = neptune.init_run(\n",
    "            project=\"arbaaz/kaggle-spect\",\n",
    "            name=MODEL_NAME,\n",
    "            api_token=\"eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiJlOGE2YjNiZS1mZGUyLTRjYjItYTg5Yy1mZWJkZTIzNzE1NmIifQ==\"\n",
    "        )\n",
    "\n",
    "        neptune_run[\"h_parameters\"] = {\n",
    "            \"seed\": SEED,\n",
    "            \"model_name\": MODEL_NAME,\n",
    "            \"optimizer_name\": \"nadam\",\n",
    "            \"learning_rate\": LR,\n",
    "            \"scheduler_name\": \"default\",\n",
    "            \"weight_decay\": WD,\n",
    "            \"num_epochs\": EPOCHS,\n",
    "            \"batch_size\": BATCH_SIZE,\n",
    "        }\n",
    "        if DROPOUT: neptune_run[\"h_parameters\"] = {\"dropout\": DROPOUT}\n",
    "        if DROP_PATH_RATE: neptune_run[\"h_parameters\"] = {\"drop_path_rate\": DROP_PATH_RATE}\n",
    "    else:\n",
    "        neptune_run = neptune.init_run(\n",
    "            project=\"arbaaz/crunchdao-structural-break\",\n",
    "            with_id=config.with_id,\n",
    "            api_token=\"eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiJlOGE2YjNiZS1mZGUyLTRjYjItYTg5Yy1mZWJkZTIzNzE1NmIifQ==\"\n",
    "        )\n",
    "\n",
    "    return neptune_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d4227b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "from torch.nn.modules.loss import _Loss\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "\n",
    "def loss_fn(logits, targets):\n",
    "    logits = logits.view(-1)\n",
    "    targets = targets.view(-1)\n",
    "    return F.mse_loss(logits, targets)\n",
    "\n",
    "\n",
    "def metric_fn(logits, targets):\n",
    "    preds = logits.cpu().detach().float().numpy()\n",
    "    targets = targets.cpu().detach().float().numpy()\n",
    "    \n",
    "    dim1 = r2_score(targets[:, 0], preds[:, 0])\n",
    "    dim2 = r2_score(targets[:, 1], preds[:, 1])\n",
    "    dim3 = r2_score(targets[:, 2], preds[:, 2])\n",
    "    \n",
    "    return dim1, dim2, dim3, r2_score(targets, preds)\n",
    "\n",
    "\n",
    "class MSEIgnoreNans(_Loss):\n",
    "    def forward(\n",
    "        self,\n",
    "        input: torch.Tensor,\n",
    "        target: torch.Tensor,\n",
    "        weights: torch.Tensor,\n",
    "    ) -> torch.Tensor:\n",
    "        mask = torch.isfinite(target)\n",
    "        mse = torch.mean(\n",
    "            torch.mul(\n",
    "                torch.square(input[mask] - target[mask]),\n",
    "                torch.tile(weights[:, None], dims=(1, target.shape[1]))[mask],\n",
    "            )\n",
    "        )\n",
    "        return torch.where(\n",
    "            torch.isfinite(mse),\n",
    "            mse,\n",
    "            torch.tensor(0.).to(target.device),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6ccc0a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "\n",
    "class Identity(torch.torch.nn.Module):\n",
    "    def forward(self, x):\n",
    "        return x\n",
    "\n",
    "\n",
    "# this is not a resnet yet\n",
    "class ReZeroBlock(torch.torch.nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels,\n",
    "        out_channels,\n",
    "        activation_function,\n",
    "        kernel_size,\n",
    "        stride,\n",
    "        dtype,\n",
    "        norm_layer=None,\n",
    "    ):\n",
    "        super(ReZeroBlock, self).__init__()\n",
    "        if norm_layer is None:\n",
    "            norm_layer = torch.torch.nn.BatchNorm1d\n",
    "\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        self.padding = divmod(kernel_size, 2)[0] if stride == 1 else 0\n",
    "\n",
    "        # does not change spatial dimension\n",
    "        self.conv1 = torch.nn.Conv1d(\n",
    "            in_channels,\n",
    "            out_channels,\n",
    "            kernel_size=1,\n",
    "            stride=1,\n",
    "            bias=False,\n",
    "            dtype=dtype,\n",
    "        )\n",
    "        self.bn1 = norm_layer(out_channels, dtype=dtype)\n",
    "        # Both self.conv2 and self.downsample layers\n",
    "        # downsample the input when stride != 1\n",
    "        self.conv2 = torch.nn.Conv1d(\n",
    "            out_channels,\n",
    "            out_channels,\n",
    "            kernel_size=kernel_size,\n",
    "            stride=stride,\n",
    "            groups=out_channels,\n",
    "            bias=False,\n",
    "            dtype=dtype,\n",
    "            padding=self.padding,\n",
    "        )\n",
    "        if stride > 1:\n",
    "            down_conv = torch.nn.Conv1d(\n",
    "                in_channels,\n",
    "                out_channels,\n",
    "                kernel_size=kernel_size,\n",
    "                stride=stride,\n",
    "                bias=False,\n",
    "                dtype=dtype,\n",
    "                # groups=out_channels,\n",
    "            )\n",
    "        else:\n",
    "            down_conv = Identity()\n",
    "\n",
    "        self.down_sample = torch.nn.Sequential(\n",
    "            down_conv,\n",
    "            norm_layer(out_channels),\n",
    "        )\n",
    "        self.bn2 = norm_layer(out_channels, dtype=dtype)\n",
    "        # does not change the spatial dimension\n",
    "        self.conv3 = torch.nn.Conv1d(\n",
    "            out_channels,\n",
    "            out_channels,\n",
    "            kernel_size=1,\n",
    "            stride=1,\n",
    "            bias=False,\n",
    "            dtype=dtype,\n",
    "        )\n",
    "        self.bn3 = norm_layer(out_channels, dtype=dtype)\n",
    "        self.activation = activation_function(inplace=True)\n",
    "        self.factor = torch.torch.nn.parameter.Parameter(torch.tensor(0.0, dtype=dtype))\n",
    "\n",
    "    def next_spatial_dim(self, last_spatial_dim):\n",
    "        return math.floor(\n",
    "            (last_spatial_dim + 2 * self.padding - self.kernel_size)\n",
    "            / self.stride + 1\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.activation(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.activation(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        # not really the identity, but kind of\n",
    "        identity = self.down_sample(x)\n",
    "\n",
    "        return self.activation(out * self.factor + identity)\n",
    "\n",
    "\n",
    "class ResNetEncoder(torch.torch.nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        spectrum_size,\n",
    "        cnn_encoder_channel_dims,\n",
    "        activation_function,\n",
    "        kernel_size,\n",
    "        stride,\n",
    "        dtype,\n",
    "        num_blocks,\n",
    "        verbose=False,\n",
    "    ):\n",
    "        super(ResNetEncoder, self).__init__()\n",
    "\n",
    "        self.spatial_dims = [spectrum_size]\n",
    "        layers = []\n",
    "        for in_channels, out_channels in zip(\n",
    "            cnn_encoder_channel_dims[:-1],\n",
    "            cnn_encoder_channel_dims[1:],\n",
    "        ):\n",
    "            block = ReZeroBlock(\n",
    "                in_channels=in_channels,\n",
    "                out_channels=out_channels,\n",
    "                activation_function=activation_function,\n",
    "                kernel_size=kernel_size,\n",
    "                stride=stride,\n",
    "                dtype=dtype,\n",
    "            )\n",
    "            layers.append(block)\n",
    "            self.spatial_dims.append(block.next_spatial_dim(self.spatial_dims[-1]))\n",
    "            for _ in range(num_blocks - 1):\n",
    "                block = ReZeroBlock(\n",
    "                    in_channels=out_channels,\n",
    "                    out_channels=out_channels,\n",
    "                    activation_function=activation_function,\n",
    "                    kernel_size=kernel_size,\n",
    "                    stride=1,\n",
    "                    dtype=dtype,\n",
    "                )\n",
    "                layers.append(block)\n",
    "                self.spatial_dims.append(block.next_spatial_dim(self.spatial_dims[-1]))\n",
    "\n",
    "        self.resnet_layers = torch.torch.nn.Sequential(*layers)\n",
    "        if verbose:\n",
    "            print(\"CNN Encoder Channel Dims: %s\" % (cnn_encoder_channel_dims))\n",
    "            print(\"CNN Encoder Spatial Dims: %s\" % (self.spatial_dims))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.resnet_layers(x)\n",
    "\n",
    "\n",
    "class ReZeroNet(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        spectra_channels,\n",
    "        spectra_size,\n",
    "        initial_cnn_channels,\n",
    "        cnn_channel_factor,\n",
    "        num_cnn_layers,\n",
    "        kernel_size,\n",
    "        stride,\n",
    "        activation_function,\n",
    "        fc_dims,\n",
    "        fc_dropout=0.0,\n",
    "        dtype=None,\n",
    "        verbose=False,\n",
    "        fc_output_channels=1,\n",
    "        num_blocks=1,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.fc_output_channels = fc_output_channels\n",
    "        self.dtype = dtype or torch.float32\n",
    "\n",
    "        activation_function = getattr(torch.nn, activation_function)\n",
    "\n",
    "        # Setup CNN Encoder\n",
    "        cnn_encoder_channel_dims = [spectra_channels] + [\n",
    "            int(initial_cnn_channels * (cnn_channel_factor**idx))\n",
    "            for idx in range(num_cnn_layers)\n",
    "        ]\n",
    "        self.cnn_encoder = ResNetEncoder(\n",
    "            spectrum_size=spectra_size,\n",
    "            cnn_encoder_channel_dims=cnn_encoder_channel_dims,\n",
    "            activation_function=activation_function,\n",
    "            kernel_size=kernel_size,\n",
    "            stride=stride,\n",
    "            num_blocks=num_blocks,\n",
    "            dtype=dtype,\n",
    "            verbose=verbose,\n",
    "        )\n",
    "        self.fc_dims = [\n",
    "            int(\n",
    "                self.cnn_encoder.spatial_dims[-1]\n",
    "            ) * int(cnn_encoder_channel_dims[-1])\n",
    "        ] + fc_dims\n",
    "\n",
    "        if verbose:\n",
    "            print(\"Fc Dims: %s\" % self.fc_dims)\n",
    "        fc_layers = []\n",
    "        for idx, (in_dim, out_dim) in enumerate(\n",
    "                zip(self.fc_dims[:-2], self.fc_dims[1:-1])\n",
    "        ):\n",
    "            fc_layers.append(torch.nn.Linear(in_dim, out_dim))\n",
    "            fc_layers.append(torch.nn.ELU())\n",
    "            fc_layers.append(torch.nn.Dropout(fc_dropout / (2 ** idx)))\n",
    "        fc_layers.append(\n",
    "            torch.nn.Linear(\n",
    "                self.fc_dims[-2],\n",
    "                self.fc_dims[-1] * self.fc_output_channels,\n",
    "            ),\n",
    "        )\n",
    "        self.fc_net = torch.nn.Sequential(*fc_layers)\n",
    "        if verbose:\n",
    "            num_params = sum(p.numel() for p in self.parameters())\n",
    "            print(\"Number of Parameters: %s\" % num_params)\n",
    "\n",
    "    def forward(self, spectra):\n",
    "        embeddings = self.cnn_encoder(spectra)\n",
    "        forecast = self.fc_net(embeddings.view(-1, self.fc_dims[0]))\n",
    "        if self.fc_output_channels > 1:\n",
    "            forecast = forecast.reshape(\n",
    "                -1, self.fc_output_channels, self.fc_dims[-1]\n",
    "            )\n",
    "        return forecast\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b7cf6c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "\n",
    "\n",
    "class ResZeroBlock(torch.nn.Module):\n",
    "    def __init__(self, skip_part, model_part):\n",
    "        super(ResZeroBlock, self).__init__()\n",
    "        self.skip_part = skip_part\n",
    "        self.model_part = model_part\n",
    "        self.factor = torch.nn.parameter.Parameter(torch.tensor(0.))\n",
    "\n",
    "    def forward(self, X):\n",
    "        return self.skip_part(X) + self.factor * self.model_part(X)\n",
    "\n",
    "\n",
    "class Identity(torch.nn.Module):\n",
    "    def forward(self, X):\n",
    "        return X\n",
    "\n",
    "\n",
    "class RamanXception(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        spectra_size,\n",
    "        initial_channels,\n",
    "        entry_channels,\n",
    "        num_mid_blocks,\n",
    "        exit_channels,\n",
    "        num_concentrations,\n",
    "        fc_dims,\n",
    "        fc_dropout,\n",
    "        lower_bounds=None,\n",
    "        dtype=None,\n",
    "        activation_function='ReLU',\n",
    "        classification_idx=None,\n",
    "        verbose=False,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super(RamanXception, self).__init__()\n",
    "\n",
    "        self.classification_idx = classification_idx or num_concentrations\n",
    "\n",
    "        if lower_bounds is None:\n",
    "            self.lower_bounds = torch.nn.parameter.Parameter(\n",
    "                torch.tensor([-1000] * num_concentrations),\n",
    "                requires_grad=False,\n",
    "            )\n",
    "        else:\n",
    "            self.lower_bounds = torch.nn.parameter.Parameter(\n",
    "                lower_bounds,\n",
    "                requires_grad=False,\n",
    "            )\n",
    "        dtype = dtype or torch.float32\n",
    "        activation_function = getattr(torch.nn, activation_function)\n",
    "        self.spatial_dimensions = [spectra_size]\n",
    "\n",
    "        # setup initial layers\n",
    "        initial_layers = torch.nn.Sequential()\n",
    "        for idx, (in_channels, out_channels) in enumerate(\n",
    "            zip(\n",
    "                [1] + initial_channels[:-1],\n",
    "                initial_channels,\n",
    "            ),\n",
    "        ):\n",
    "            initial_layers.add_module(\n",
    "                'initial_%s' % idx,\n",
    "                torch.nn.Conv1d(\n",
    "                    in_channels,\n",
    "                    out_channels,\n",
    "                    kernel_size=3,\n",
    "                    stride=2,\n",
    "                    padding=1,\n",
    "                    dtype=dtype,\n",
    "                    bias=False,\n",
    "                ),\n",
    "            )\n",
    "            self.spatial_dimensions.append(\n",
    "                math.floor((self.spatial_dimensions[-1] - 1) / 2 + 1)\n",
    "            )\n",
    "            initial_layers.add_module(\n",
    "                'initial_batch_%s' % idx,\n",
    "                torch.nn.BatchNorm1d(\n",
    "                    out_channels,\n",
    "                    dtype=dtype,\n",
    "                ),\n",
    "            )\n",
    "            initial_layers.add_module(\n",
    "                'initial_activation_%s' % idx,\n",
    "                activation_function(),\n",
    "            )\n",
    "\n",
    "        # Entry flow\n",
    "        entry_flow = torch.nn.Sequential()\n",
    "        # self.entry_flow_length = len(entry_channels)\n",
    "        for idx, (in_channels, out_channels) in enumerate(\n",
    "            zip(\n",
    "                [initial_channels[-1]] + entry_channels[:-1],\n",
    "                entry_channels,\n",
    "            )\n",
    "        ):\n",
    "            entry_flow.add_module(\n",
    "                name='entry_flow_%s' % idx,\n",
    "                module=ResZeroBlock(\n",
    "                    skip_part=torch.nn.Conv1d(\n",
    "                        in_channels,\n",
    "                        out_channels,\n",
    "                        kernel_size=1,\n",
    "                        stride=2,\n",
    "                        dtype=dtype,\n",
    "                        bias=False,\n",
    "                    ),\n",
    "                    model_part=torch.nn.Sequential(\n",
    "                        activation_function(),\n",
    "                        # spatial dimension stays constant\n",
    "                        torch.nn.Conv1d(\n",
    "                            in_channels,\n",
    "                            in_channels,\n",
    "                            kernel_size=1,\n",
    "                            dtype=dtype,\n",
    "                            bias=False,\n",
    "                        ),\n",
    "                        torch.nn.Conv1d(\n",
    "                            in_channels,\n",
    "                            in_channels,\n",
    "                            kernel_size=3,\n",
    "                            groups=in_channels,\n",
    "                            padding=1,\n",
    "                            dtype=dtype,\n",
    "                            bias=False,\n",
    "                        ),\n",
    "                        # spatial dimension stays constant\n",
    "                        torch.nn.BatchNorm1d(\n",
    "                            in_channels,\n",
    "                            dtype=dtype,\n",
    "                        ),\n",
    "                        activation_function(),\n",
    "                        torch.nn.Conv1d(\n",
    "                            in_channels,\n",
    "                            out_channels,\n",
    "                            kernel_size=1,\n",
    "                            dtype=dtype,\n",
    "                            bias=False,\n",
    "                        ),\n",
    "                        torch.nn.Conv1d(\n",
    "                            out_channels,\n",
    "                            out_channels,\n",
    "                            kernel_size=3,\n",
    "                            groups=out_channels,\n",
    "                            padding=1,\n",
    "                            dtype=dtype,\n",
    "                            bias=False,\n",
    "                        ),\n",
    "                        torch.nn.BatchNorm1d(\n",
    "                            out_channels,\n",
    "                            dtype=dtype,\n",
    "                        ),\n",
    "                        # spatial dimension: in_dim / 2\n",
    "                        torch.nn.MaxPool1d(3, stride=2, padding=1),\n",
    "                    )\n",
    "                ),\n",
    "            )\n",
    "            self.spatial_dimensions.append(\n",
    "                math.floor((self.spatial_dimensions[-1] - 1) / 2 + 1)\n",
    "            )\n",
    "\n",
    "        # Middle flow\n",
    "        num_mid_channels = entry_channels[-1]\n",
    "        middle_flow = torch.nn.Sequential()\n",
    "        for idx in range(num_mid_blocks):\n",
    "            middle_flow.add_module(\n",
    "                name='middle_flow_%s' % idx,\n",
    "                module=ResZeroBlock(\n",
    "                    skip_part=Identity(),\n",
    "                    model_part=torch.nn.Sequential(\n",
    "                        activation_function(),\n",
    "                        torch.nn.Conv1d(\n",
    "                            num_mid_channels,\n",
    "                            num_mid_channels,\n",
    "                            kernel_size=1,\n",
    "                            dtype=dtype,\n",
    "                            bias=False,\n",
    "                        ),\n",
    "                        torch.nn.Conv1d(\n",
    "                            num_mid_channels,\n",
    "                            num_mid_channels,\n",
    "                            kernel_size=3,\n",
    "                            groups=num_mid_channels,\n",
    "                            padding=1,\n",
    "                            dtype=dtype,\n",
    "                            bias=False,\n",
    "                        ),\n",
    "                        torch.nn.BatchNorm1d(\n",
    "                            num_mid_channels,\n",
    "                            dtype=dtype,\n",
    "                        ),\n",
    "                        activation_function(),\n",
    "                        torch.nn.Conv1d(\n",
    "                            num_mid_channels,\n",
    "                            num_mid_channels,\n",
    "                            kernel_size=1,\n",
    "                            dtype=dtype,\n",
    "                            bias=False,\n",
    "                        ),\n",
    "                        torch.nn.Conv1d(\n",
    "                            num_mid_channels,\n",
    "                            num_mid_channels,\n",
    "                            kernel_size=3,\n",
    "                            groups=num_mid_channels,\n",
    "                            padding=1,\n",
    "                            dtype=dtype,\n",
    "                            bias=False,\n",
    "                        ),\n",
    "                        torch.nn.BatchNorm1d(\n",
    "                            num_mid_channels,\n",
    "                            dtype=dtype,\n",
    "                        ),\n",
    "                        activation_function(),\n",
    "                        torch.nn.Conv1d(\n",
    "                            num_mid_channels,\n",
    "                            num_mid_channels,\n",
    "                            kernel_size=1,\n",
    "                            dtype=dtype,\n",
    "                            bias=False,\n",
    "                        ),\n",
    "                        torch.nn.Conv1d(\n",
    "                            num_mid_channels,\n",
    "                            num_mid_channels,\n",
    "                            kernel_size=3,\n",
    "                            groups=num_mid_channels,\n",
    "                            padding=1,\n",
    "                            dtype=dtype,\n",
    "                            bias=False,\n",
    "                        ),\n",
    "                    )\n",
    "                )\n",
    "            )\n",
    "            self.spatial_dimensions.append(self.spatial_dimensions[-1])\n",
    "\n",
    "        exit_flow = torch.nn.Sequential()\n",
    "        for idx, (in_channels, (mid_channels, out_channels)) in enumerate(list(\n",
    "            zip(\n",
    "                [num_mid_channels] + [out for _, out in exit_channels[:-2]],\n",
    "                exit_channels[:-1],\n",
    "            ),\n",
    "        )):\n",
    "            exit_flow.add_module(\n",
    "                name='exit_flow_%s' % idx,\n",
    "                module=ResZeroBlock(\n",
    "                    skip_part=torch.nn.Conv1d(\n",
    "                        in_channels,\n",
    "                        out_channels,\n",
    "                        kernel_size=1,\n",
    "                        stride=2,\n",
    "                        dtype=dtype,\n",
    "                        bias=False,\n",
    "                    ),\n",
    "                    model_part=torch.nn.Sequential(\n",
    "                        torch.nn.Conv1d(\n",
    "                            in_channels,\n",
    "                            mid_channels,\n",
    "                            kernel_size=1,\n",
    "                            dtype=dtype,\n",
    "                            bias=False,\n",
    "                        ),\n",
    "                        torch.nn.Conv1d(\n",
    "                            mid_channels,\n",
    "                            mid_channels,\n",
    "                            kernel_size=3,\n",
    "                            groups=mid_channels,\n",
    "                            padding=1,\n",
    "                            dtype=dtype,\n",
    "                            bias=False,\n",
    "                        ),\n",
    "                        torch.nn.BatchNorm1d(\n",
    "                            mid_channels,\n",
    "                            dtype=dtype,\n",
    "                        ),\n",
    "                        activation_function(),\n",
    "                        torch.nn.Conv1d(\n",
    "                            mid_channels,\n",
    "                            out_channels,\n",
    "                            kernel_size=1,\n",
    "                            dtype=dtype,\n",
    "                            bias=False,\n",
    "                        ),\n",
    "                        torch.nn.Conv1d(\n",
    "                            out_channels,\n",
    "                            out_channels,\n",
    "                            kernel_size=3,\n",
    "                            groups=out_channels,\n",
    "                            padding=1,\n",
    "                            dtype=dtype,\n",
    "                            bias=False,\n",
    "                        ),\n",
    "                        torch.nn.BatchNorm1d(\n",
    "                            out_channels,\n",
    "                            dtype=dtype,\n",
    "                        ),\n",
    "                        activation_function(),\n",
    "                        torch.nn.MaxPool1d(\n",
    "                            kernel_size=3,\n",
    "                            stride=2,\n",
    "                            padding=1,\n",
    "                        ),\n",
    "                    )\n",
    "                )\n",
    "            )\n",
    "            self.spatial_dimensions.append(\n",
    "                math.floor((self.spatial_dimensions[-1] - 1) / 2 + 1)\n",
    "            )\n",
    "\n",
    "        # Last part of the exit flow\n",
    "        in_channels = exit_channels[-2][1]\n",
    "        mid_channels = exit_channels[-1][0]\n",
    "        out_channels = exit_channels[-1][1]\n",
    "        final_flow = torch.nn.Sequential(\n",
    "            torch.nn.Conv1d(\n",
    "                in_channels,\n",
    "                mid_channels,\n",
    "                kernel_size=1,\n",
    "                dtype=dtype,\n",
    "                bias=False,\n",
    "            ),\n",
    "            torch.nn.Conv1d(\n",
    "                mid_channels,\n",
    "                mid_channels,\n",
    "                kernel_size=3,\n",
    "                groups=mid_channels,\n",
    "                padding=1,\n",
    "                dtype=dtype,\n",
    "                bias=False,\n",
    "            ),\n",
    "            torch.nn.BatchNorm1d(\n",
    "                mid_channels,\n",
    "                dtype=dtype,\n",
    "            ),\n",
    "            activation_function(),\n",
    "            torch.nn.Conv1d(\n",
    "                mid_channels,\n",
    "                out_channels,\n",
    "                kernel_size=1,\n",
    "                dtype=dtype,\n",
    "            ),\n",
    "            torch.nn.Conv1d(\n",
    "                out_channels,\n",
    "                out_channels,\n",
    "                kernel_size=3,\n",
    "                groups=out_channels,\n",
    "                padding=1,\n",
    "                dtype=dtype,\n",
    "            ),\n",
    "            torch.nn.BatchNorm1d(\n",
    "                out_channels,\n",
    "                dtype=dtype,\n",
    "            ),\n",
    "            activation_function(),\n",
    "        )\n",
    "        self.conv_net = torch.nn.Sequential(\n",
    "            initial_layers,\n",
    "            entry_flow,\n",
    "            middle_flow,\n",
    "            exit_flow,\n",
    "            final_flow,\n",
    "        )\n",
    "\n",
    "        self.fc_input_dim = int(out_channels * self.spatial_dimensions[-1])\n",
    "        self.fc_net = torch.nn.Sequential()\n",
    "        for idx, (in_dim, out_dim) in enumerate(\n",
    "            zip(\n",
    "                [self.fc_input_dim] + fc_dims[:-1],\n",
    "                fc_dims,\n",
    "            )\n",
    "        ):\n",
    "            self.fc_net.add_module(\n",
    "                'fc_net_%s' % idx,\n",
    "                torch.nn.Linear(\n",
    "                    in_dim,\n",
    "                    out_dim,\n",
    "                    dtype=dtype,\n",
    "                    bias=True,\n",
    "                ),\n",
    "            )\n",
    "            self.fc_net.add_module(\n",
    "                'fc_relu_%s' % idx,\n",
    "                torch.nn.ReLU(),\n",
    "            )\n",
    "            self.fc_net.add_module(\n",
    "                'fc_dropout_%s' % idx,\n",
    "                torch.nn.Dropout(fc_dropout),\n",
    "            )\n",
    "\n",
    "        self.fc_net.add_module(\n",
    "            'output_layer',\n",
    "            torch.nn.Linear(\n",
    "                fc_dims[-1] if fc_dims else out_channels,\n",
    "                num_concentrations,\n",
    "                dtype=dtype,\n",
    "                bias=True,\n",
    "            ),\n",
    "        )\n",
    "        self.softplus = torch.nn.Softplus()\n",
    "        if verbose:\n",
    "            print('Spatial dimensions: %s' % self.spatial_dimensions)\n",
    "            print(\n",
    "                'Fully Connected dimensions %s' % (\n",
    "                        [self.fc_input_dim] + fc_dims\n",
    "                )\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_net(x)\n",
    "\n",
    "        fc_output = self.fc_net(torch.reshape(x, (-1, self.fc_input_dim)))\n",
    "        return torch.concat(\n",
    "            [\n",
    "                fc_output[:, :self.classification_idx],\n",
    "                torch.sigmoid(fc_output[:, self.classification_idx:])\n",
    "            ],\n",
    "            dim=1,\n",
    "        )\n",
    "\n",
    "\n",
    "model_config = {\n",
    "    'initial_channels': 8,\n",
    "    'entry_channels_start': 17,\n",
    "    'channel_factor': 1.5692504144354933,\n",
    "    'entry_exit_length': 3,\n",
    "    'num_mid_blocks': 4,\n",
    "    'fc_dims': 101,\n",
    "    'fc_dropout': 0.11748964300948816,\n",
    "    'learning_rate': 0.001,\n",
    "    'gamma': 0.9921697445978254,\n",
    "    'batch_size': 21,\n",
    "    'entropy_weight': 6.441421425536572,\n",
    "    'uniform_sampling_range': 0.03803705551872033,\n",
    "    'activation_function': 'ELU', \n",
    "    'fake_weight': 0.032878013410751736,\n",
    "    'just_scale_concentrations': True,\n",
    "    'entry_factor': 1.5692504144354933,\n",
    "    'exit_factor': 1.5692504144354933,\n",
    "    'entry_length': 3,\n",
    "    'exit_length': 3,\n",
    "    'spectra_size': 1643,\n",
    "    'dtype': torch.float32}\n",
    "\n",
    "lr = model_config.get('learning_rate')\n",
    "l2_reg = model_config.get('l2_reg', 0.)\n",
    "gamma = model_config.get('gamma', 1.)\n",
    "model_config['initial_channels'] = [\n",
    "    model_config['initial_channels'],\n",
    "    2 * model_config['initial_channels'],\n",
    "]\n",
    "# create entry channel dimensions\n",
    "entry_channels_start = model_config['entry_channels_start']\n",
    "entry_factor = model_config['entry_factor']\n",
    "entry_length = model_config['entry_length']\n",
    "entry_channels = [entry_channels_start]\n",
    "for _ in range(entry_length):\n",
    "    entry_channels.append(int(entry_factor * entry_channels[-1]))\n",
    "model_config['entry_channels'] = entry_channels\n",
    "# create exit channel dimensions\n",
    "exit_channels_start = entry_channels[-1]\n",
    "exit_factor = model_config.get('exit_factor')\n",
    "exit_length = model_config.get('exit_length')\n",
    "exit_channels = [\n",
    "    (\n",
    "        int(exit_channels_start * math.sqrt(exit_factor)),\n",
    "        int(exit_channels_start * exit_factor),\n",
    "    )\n",
    "]\n",
    "for _ in range(1, exit_length):\n",
    "    exit_channels.append(\n",
    "        (\n",
    "            int(exit_channels[-1][0] * math.sqrt(exit_factor)),\n",
    "            int(exit_channels[-1][0] * exit_factor),\n",
    "        )\n",
    "    )\n",
    "model_config['exit_channels'] = exit_channels\n",
    "model_config[\"num_concnetrations\"] = 3\n",
    "model_config['fc_dims'] = [config['fc_dims']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "035dd91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "def train(\n",
    "    model, \n",
    "    optimizer,\n",
    "    device,\n",
    "    amp_dtype,\n",
    "    scheduler,\n",
    "    train_dl,\n",
    "    eval_dl,\n",
    "    loss_fn,\n",
    "    epochs,\n",
    "    checkpoint_name,\n",
    "    score=-float(\"inf\"),\n",
    "    neptune_run=None,\n",
    "    p=True,\n",
    "):  \n",
    "    scaler = torch.amp.GradScaler(device)\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "        all_logits = []\n",
    "        all_targets = []\n",
    "        \n",
    "        for inputs, targets, weights in train_dl:\n",
    "            inputs = inputs.to(device, non_blocking=True)\n",
    "            targets = targets.to(device, non_blocking=True)\n",
    "            weights = weights.to(device, non_blocking=True)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            with torch.amp.autocast(device_type=device, dtype=amp_dtype, cache_enabled=True):\n",
    "                logits = model(inputs)\n",
    "                loss = loss_fn(logits, targets)\n",
    "                  \n",
    "            if amp_dtype == torch.bfloat16:                \n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            else:\n",
    "                scaler.scale(loss).backward()\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "\n",
    "            scheduler.step()\n",
    "            if neptune_run is not None:  neptune_run[\"lr_step\"].append(scheduler.get_last_lr()[0])\n",
    "            \n",
    "            total_loss += loss.detach().cpu()\n",
    "            all_logits.append(logits.detach().cpu())\n",
    "            all_targets.append(targets.detach().cpu())\n",
    "        \n",
    "        all_logits = torch.cat(all_logits)\n",
    "        all_targets = torch.cat(all_targets)\n",
    "\n",
    "        one, two, three, r2 = metric_fn(all_logits, all_targets)\n",
    "        total_loss = total_loss / len(train_dl)\n",
    "        \n",
    "        model.eval()\n",
    "        eval_total_loss = 0.0\n",
    "        eval_all_logits = []\n",
    "        eval_all_targets = []\n",
    "\n",
    "        for inputs, targets, weights in eval_dl:\n",
    "            inputs = inputs.to(device, non_blocking=True)\n",
    "            targets = targets.to(device, non_blocking=True)\n",
    "            weights = weights.to(device, non_blocking=True)\n",
    "\n",
    "            with torch.inference_mode():\n",
    "                with torch.amp.autocast(device_type=device, dtype=amp_dtype, cache_enabled=True):\n",
    "                    logits = model(inputs)\n",
    "                    loss = loss_fn(logits, targets)\n",
    "\n",
    "            eval_total_loss += loss.detach().cpu()\n",
    "            eval_all_logits.append(logits.detach().cpu())\n",
    "            eval_all_targets.append(targets.detach().cpu())\n",
    "        \n",
    "        eval_all_logits = torch.cat(eval_all_logits)\n",
    "        eval_all_targets = torch.cat(eval_all_targets)\n",
    "\n",
    "        eval_one, eval_two, eval_three, eval_r2 = metric_fn(eval_all_logits, eval_all_targets)\n",
    "        eval_total_loss = eval_total_loss / len(eval_dl)\n",
    "        \n",
    "        if eval_r2 > score:\n",
    "            score = eval_r2\n",
    "            data = {\"state_dict\": model.state_dict()}\n",
    "            data[\"epoch\"] = epoch \n",
    "            data[\"score\"] = score\n",
    "            torch.save(data, f\"/kaggle/working/{checkpoint_name}\")\n",
    "        \n",
    "        if neptune_run is not None:\n",
    "            neptune_run[\"train/loss\"].append(total_loss)\n",
    "            neptune_run[\"eval/loss\"].append(eval_total_loss)\n",
    "            neptune_run[\"train/r2\"].append(r2)\n",
    "            neptune_run[\"eval/r2\"].append(eval_r2)\n",
    "            neptune_run[\"train/one\"].append(one)\n",
    "            neptune_run[\"train/two\"].append(two)\n",
    "            neptune_run[\"train/three\"].append(three)\n",
    "            neptune_run[\"eval/one\"].append(eval_one)\n",
    "            neptune_run[\"eval/two\"].append(eval_two)\n",
    "            neptune_run[\"eval/three\"].append(eval_three)\n",
    "            \n",
    "        if p and epoch % 5 == 0:\n",
    "            print(\n",
    "                f\"Epoch: {epoch}, \"\n",
    "                f\"train/loss: {total_loss:.4f}, \"\n",
    "                f\"eval/loss: {eval_total_loss:.4f}, \"\n",
    "                f\"train/r2: {r2:.4f}, \"\n",
    "                f\"eval/r2: {eval_r2:.4f}, \"\n",
    "                f\"train/one: {one:.4f}, \"\n",
    "                f\"train/two: {two:.4f}, \"\n",
    "                f\"train/three: {three:.4f}, \"\n",
    "                f\"eval/one: {eval_one:.4f}, \"\n",
    "                f\"eval/two: {eval_two:.4f}, \"\n",
    "                f\"eval/three: {eval_three:.4f} \"\n",
    "            )\n",
    "            \n",
    "    if neptune_run is not None: neptune_run.stop()\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8dd5d0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 100\n",
    "WD = 1e-3\n",
    "LR = 1e-4\n",
    "\n",
    "DROPOUT = 0.5\n",
    "DROP_PATH_RATE = None\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "RESUME = False\n",
    "\n",
    "if False:\n",
    "    config[\"dtype\"] = torch.float32\n",
    "    config[\"spectra_size\"] = 1643\n",
    "    config[\"spectra_channels\"] = 1\n",
    "    config[\"fc_dims\"] = [\n",
    "        config[\"fc_dims\"],\n",
    "        int(config[\"fc_dims\"] / 2),\n",
    "        3,\n",
    "    ]\n",
    "\n",
    "    #mse_loss_function = MSEIgnoreNans()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54dd678c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.387266\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[neptune] [warning] NeptuneWarning: By default, these monitoring options are disabled in interactive sessions: 'capture_stdout', 'capture_stderr', 'capture_traceback', 'capture_hardware_metrics'. You can set them to 'True' when initializing the run and the monitoring will continue until you call run.stop() or the kernel stops. NOTE: To track the source files, pass their paths to the 'source_code' argument. For help, see: https://docs-legacy.neptune.ai/logging/source_code/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[neptune] [info   ] Neptune initialized. Open in the app: https://app.neptune.ai/arbaaz/kaggle-spect/e/KAG-312\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1775ad92f30c40e1b62c243154124a5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:227: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, train/loss: 2.3302, eval/loss: 3.0766, train/r2: -1.5368, eval/r2: -2.6660, train/one: -3.6786, train/two: -0.5999, train/three: -0.3318, eval/one: -3.9156, eval/two: -2.2408, eval/three: -1.8416 \n",
      "Epoch: 5, train/loss: 0.9565, eval/loss: 1.1033, train/r2: -0.0513, eval/r2: -0.1970, train/one: -0.1301, train/two: 0.0091, train/three: -0.0328, eval/one: 0.0352, eval/two: -0.5632, eval/three: -0.0631 \n",
      "Epoch: 10, train/loss: 0.9050, eval/loss: 0.8658, train/r2: 0.0249, eval/r2: 0.0124, train/one: 0.1203, train/two: -0.0441, train/three: -0.0016, eval/one: 0.1114, eval/two: -0.0580, eval/three: -0.0164 \n",
      "Epoch: 15, train/loss: 0.7501, eval/loss: 0.8563, train/r2: 0.2130, eval/r2: 0.1111, train/one: 0.3027, train/two: 0.2005, train/three: 0.1357, eval/one: 0.2962, eval/two: -0.0632, eval/three: 0.1003 \n",
      "Epoch: 20, train/loss: 0.6047, eval/loss: 0.7669, train/r2: 0.3373, eval/r2: 0.0356, train/one: 0.4473, train/two: 0.1775, train/three: 0.3871, eval/one: 0.4909, eval/two: -0.0280, eval/three: -0.3562 \n",
      "Epoch: 25, train/loss: 0.4196, eval/loss: 0.7743, train/r2: 0.5087, eval/r2: 0.2457, train/one: 0.6920, train/two: 0.2449, train/three: 0.5893, eval/one: 0.7050, eval/two: -0.3491, eval/three: 0.3813 \n",
      "Epoch: 30, train/loss: 0.3988, eval/loss: 0.3480, train/r2: 0.5538, eval/r2: 0.4437, train/one: 0.6608, train/two: 0.2132, train/three: 0.7875, eval/one: 0.3297, eval/two: 0.4028, eval/three: 0.5984 \n",
      "Epoch: 35, train/loss: 0.3225, eval/loss: 0.3792, train/r2: 0.6714, eval/r2: 0.3757, train/one: 0.7309, train/two: 0.4575, train/three: 0.8259, eval/one: 0.6239, eval/two: -0.1989, eval/three: 0.7021 \n",
      "Epoch: 40, train/loss: 0.2601, eval/loss: 0.2904, train/r2: 0.7334, eval/r2: 0.6197, train/one: 0.7110, train/two: 0.6257, train/three: 0.8635, eval/one: 0.7467, eval/two: 0.2660, eval/three: 0.8464 \n",
      "Epoch: 45, train/loss: 0.2759, eval/loss: 0.2652, train/r2: 0.7443, eval/r2: 0.7255, train/one: 0.7650, train/two: 0.6206, train/three: 0.8474, eval/one: 0.7898, eval/two: 0.6233, eval/three: 0.7634 \n",
      "Epoch: 50, train/loss: 0.2477, eval/loss: 0.2718, train/r2: 0.7592, eval/r2: 0.6538, train/one: 0.8062, train/two: 0.6902, train/three: 0.7812, eval/one: 0.6077, eval/two: 0.5268, eval/three: 0.8269 \n",
      "Epoch: 55, train/loss: 0.2147, eval/loss: 0.2418, train/r2: 0.8087, eval/r2: 0.6106, train/one: 0.8113, train/two: 0.7646, train/three: 0.8502, eval/one: 0.8145, eval/two: 0.6618, eval/three: 0.3554 \n",
      "Epoch: 60, train/loss: 0.1824, eval/loss: 0.1974, train/r2: 0.7912, eval/r2: 0.7569, train/one: 0.7720, train/two: 0.7056, train/three: 0.8959, eval/one: 0.7385, eval/two: 0.7597, eval/three: 0.7724 \n",
      "Epoch: 65, train/loss: 0.1572, eval/loss: 0.1535, train/r2: 0.8588, eval/r2: 0.6814, train/one: 0.8318, train/two: 0.8560, train/three: 0.8886, eval/one: 0.8786, eval/two: 0.6709, eval/three: 0.4947 \n",
      "Epoch: 70, train/loss: 0.1392, eval/loss: 0.1676, train/r2: 0.8628, eval/r2: 0.7426, train/one: 0.8519, train/two: 0.8456, train/three: 0.8909, eval/one: 0.6702, eval/two: 0.7644, eval/three: 0.7932 \n",
      "Epoch: 75, train/loss: 0.1269, eval/loss: 0.1714, train/r2: 0.8677, eval/r2: 0.8052, train/one: 0.8287, train/two: 0.8632, train/three: 0.9111, eval/one: 0.8171, eval/two: 0.7768, eval/three: 0.8218 \n",
      "Epoch: 80, train/loss: 0.1212, eval/loss: 0.1426, train/r2: 0.8799, eval/r2: 0.8508, train/one: 0.8688, train/two: 0.8895, train/three: 0.8812, eval/one: 0.8000, eval/two: 0.8439, eval/three: 0.9086 \n",
      "Epoch: 85, train/loss: 0.1702, eval/loss: 0.2274, train/r2: 0.8323, eval/r2: 0.6628, train/one: 0.7942, train/two: 0.8004, train/three: 0.9022, eval/one: 0.8182, eval/two: 0.5189, eval/three: 0.6513 \n",
      "Epoch: 90, train/loss: 0.1345, eval/loss: 0.1229, train/r2: 0.8582, eval/r2: 0.8588, train/one: 0.8175, train/two: 0.8515, train/three: 0.9056, eval/one: 0.8562, eval/two: 0.8776, eval/three: 0.8427 \n",
      "Epoch: 95, train/loss: 0.1262, eval/loss: 0.1560, train/r2: 0.8908, eval/r2: 0.7982, train/one: 0.8609, train/two: 0.9021, train/three: 0.9095, eval/one: 0.8323, eval/two: 0.7342, eval/three: 0.8280 \n",
      "[neptune] [info   ] Shutting down background jobs, please wait a moment...\n",
      "[neptune] [info   ] Done!\n",
      "[neptune] [info   ] Waiting for the remaining 336 operations to synchronize with Neptune. Do not kill this process.\n",
      "[neptune] [info   ] All 336 operations synced, thanks for waiting!\n",
      "[neptune] [info   ] Explore the metadata in the Neptune app: https://app.neptune.ai/arbaaz/kaggle-spect/e/KAG-312/metadata\n",
      "[neptune] [info   ] Neptune initialized. Open in the app: https://app.neptune.ai/arbaaz/kaggle-spect/e/KAG-313\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fe2b87d276d484ea6bc5a06897368d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:227: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, train/loss: 2.7953, eval/loss: 2.7959, train/r2: -1.5585, eval/r2: -2.0534, train/one: -3.8298, train/two: -0.3950, train/three: -0.4507, eval/one: -2.9824, eval/two: -2.4701, eval/three: -0.7079 \n",
      "Epoch: 5, train/loss: 1.1114, eval/loss: 0.9856, train/r2: -0.1442, eval/r2: -0.2581, train/one: -0.3130, train/two: -0.0959, train/three: -0.0236, eval/one: -0.4660, eval/two: -0.1328, eval/three: -0.1754 \n",
      "Epoch: 10, train/loss: 0.8912, eval/loss: 0.8087, train/r2: 0.1094, eval/r2: -0.0637, train/one: 0.1254, train/two: 0.0769, train/three: 0.1260, eval/one: 0.2060, eval/two: 0.0541, eval/three: -0.4513 \n",
      "Epoch: 15, train/loss: 0.8787, eval/loss: 0.6486, train/r2: 0.1466, eval/r2: 0.2044, train/one: 0.1576, train/two: 0.0981, train/three: 0.1840, eval/one: 0.2417, eval/two: 0.1358, eval/three: 0.2358 \n",
      "Epoch: 20, train/loss: 0.6800, eval/loss: 0.8336, train/r2: 0.2844, eval/r2: 0.2100, train/one: 0.3685, train/two: 0.1087, train/three: 0.3758, eval/one: 0.3386, eval/two: -0.0213, eval/three: 0.3128 \n",
      "Epoch: 25, train/loss: 0.5511, eval/loss: 0.5118, train/r2: 0.3978, eval/r2: 0.3274, train/one: 0.5559, train/two: 0.2351, train/three: 0.4025, eval/one: 0.2938, eval/two: 0.1011, eval/three: 0.5873 \n",
      "Epoch: 30, train/loss: 0.3645, eval/loss: 0.4228, train/r2: 0.6399, eval/r2: 0.4730, train/one: 0.7251, train/two: 0.5063, train/three: 0.6882, eval/one: 0.6771, eval/two: 0.1058, eval/three: 0.6362 \n",
      "Epoch: 35, train/loss: 0.3396, eval/loss: 0.3674, train/r2: 0.6597, eval/r2: 0.6715, train/one: 0.6489, train/two: 0.4810, train/three: 0.8494, eval/one: 0.7092, eval/two: 0.4524, eval/three: 0.8530 \n",
      "Epoch: 40, train/loss: 0.2981, eval/loss: 0.3261, train/r2: 0.6803, eval/r2: 0.6577, train/one: 0.6009, train/two: 0.5867, train/three: 0.8534, eval/one: 0.7035, eval/two: 0.4686, eval/three: 0.8010 \n",
      "Epoch: 45, train/loss: 0.2424, eval/loss: 0.2456, train/r2: 0.7424, eval/r2: 0.6741, train/one: 0.6986, train/two: 0.7035, train/three: 0.8250, eval/one: 0.5146, eval/two: 0.7353, eval/three: 0.7725 \n",
      "Epoch: 50, train/loss: 0.2331, eval/loss: 0.2512, train/r2: 0.7617, eval/r2: 0.7549, train/one: 0.6793, train/two: 0.7434, train/three: 0.8624, eval/one: 0.7229, eval/two: 0.6415, eval/three: 0.9003 \n",
      "Epoch: 55, train/loss: 0.1609, eval/loss: 0.2062, train/r2: 0.8317, eval/r2: 0.7178, train/one: 0.8113, train/two: 0.7900, train/three: 0.8939, eval/one: 0.7165, eval/two: 0.6996, eval/three: 0.7373 \n",
      "Epoch: 60, train/loss: 0.1971, eval/loss: 0.1632, train/r2: 0.8105, eval/r2: 0.7995, train/one: 0.7992, train/two: 0.7421, train/three: 0.8903, eval/one: 0.7864, eval/two: 0.8422, eval/three: 0.7698 \n",
      "Epoch: 65, train/loss: 0.1451, eval/loss: 0.1876, train/r2: 0.8576, eval/r2: 0.6828, train/one: 0.8551, train/two: 0.8324, train/three: 0.8855, eval/one: 0.4910, eval/two: 0.7253, eval/three: 0.8322 \n",
      "Epoch: 70, train/loss: 0.1674, eval/loss: 0.1648, train/r2: 0.8354, eval/r2: 0.7978, train/one: 0.8032, train/two: 0.8442, train/three: 0.8588, eval/one: 0.7814, eval/two: 0.8024, eval/three: 0.8096 \n",
      "Epoch: 75, train/loss: 0.1527, eval/loss: 0.1569, train/r2: 0.8567, eval/r2: 0.8197, train/one: 0.8367, train/two: 0.8629, train/three: 0.8704, eval/one: 0.8840, eval/two: 0.7790, eval/three: 0.7959 \n",
      "Epoch: 80, train/loss: 0.1620, eval/loss: 0.1490, train/r2: 0.8178, eval/r2: 0.8366, train/one: 0.7700, train/two: 0.7886, train/three: 0.8948, eval/one: 0.7994, eval/two: 0.7503, eval/three: 0.9601 \n",
      "Epoch: 85, train/loss: 0.1591, eval/loss: 0.1063, train/r2: 0.8266, eval/r2: 0.8456, train/one: 0.8175, train/two: 0.7632, train/three: 0.8992, eval/one: 0.8330, eval/two: 0.8762, eval/three: 0.8276 \n",
      "Epoch: 90, train/loss: 0.1556, eval/loss: 0.1513, train/r2: 0.8435, eval/r2: 0.8155, train/one: 0.8519, train/two: 0.8209, train/three: 0.8577, eval/one: 0.8929, eval/two: 0.7341, eval/three: 0.8194 \n",
      "Epoch: 95, train/loss: 0.1606, eval/loss: 0.0993, train/r2: 0.8375, eval/r2: 0.8652, train/one: 0.8318, train/two: 0.8018, train/three: 0.8790, eval/one: 0.8931, eval/two: 0.8284, eval/three: 0.8742 \n",
      "[neptune] [info   ] Shutting down background jobs, please wait a moment...\n",
      "[neptune] [info   ] Done!\n",
      "[neptune] [info   ] Waiting for the remaining 299 operations to synchronize with Neptune. Do not kill this process.\n",
      "[neptune] [info   ] All 299 operations synced, thanks for waiting!\n",
      "[neptune] [info   ] Explore the metadata in the Neptune app: https://app.neptune.ai/arbaaz/kaggle-spect/e/KAG-313/metadata\n",
      "[neptune] [info   ] Neptune initialized. Open in the app: https://app.neptune.ai/arbaaz/kaggle-spect/e/KAG-314\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b09e3224337643be93627fadcec76915",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:227: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, train/loss: 2.6998, eval/loss: 3.0836, train/r2: -1.9631, eval/r2: -1.3929, train/one: -4.6018, train/two: -1.1673, train/three: -0.1203, eval/one: -2.6100, eval/two: -1.4591, eval/three: -0.1097 \n",
      "Epoch: 5, train/loss: 1.1375, eval/loss: 0.9349, train/r2: -0.2207, eval/r2: -0.2453, train/one: -0.4339, train/two: -0.0646, train/three: -0.1637, eval/one: -0.0839, eval/two: -0.3719, eval/three: -0.2801 \n",
      "Epoch: 10, train/loss: 0.9031, eval/loss: 1.0995, train/r2: 0.0290, eval/r2: -0.0243, train/one: 0.0721, train/two: 0.0580, train/three: -0.0430, eval/one: 0.1146, eval/two: -0.2238, eval/three: 0.0362 \n",
      "Epoch: 15, train/loss: 0.8068, eval/loss: 0.8233, train/r2: 0.1633, eval/r2: 0.0065, train/one: 0.1994, train/two: 0.1389, train/three: 0.1518, eval/one: 0.1944, eval/two: -0.3007, eval/three: 0.1259 \n",
      "Epoch: 20, train/loss: 0.7601, eval/loss: 0.8574, train/r2: 0.2808, eval/r2: 0.1075, train/one: 0.3294, train/two: 0.2225, train/three: 0.2904, eval/one: 0.2692, eval/two: -0.0928, eval/three: 0.1461 \n",
      "Epoch: 25, train/loss: 0.5041, eval/loss: 0.8393, train/r2: 0.4571, eval/r2: 0.1404, train/one: 0.5742, train/two: 0.2917, train/three: 0.5054, eval/one: 0.2905, eval/two: -0.3634, eval/three: 0.4940 \n",
      "Epoch: 30, train/loss: 0.4568, eval/loss: 0.5503, train/r2: 0.5358, eval/r2: 0.2498, train/one: 0.6084, train/two: 0.3502, train/three: 0.6488, eval/one: 0.2620, eval/two: -0.2639, eval/three: 0.7513 \n",
      "Epoch: 35, train/loss: 0.3128, eval/loss: 0.4003, train/r2: 0.6777, eval/r2: 0.4813, train/one: 0.7828, train/two: 0.4404, train/three: 0.8098, eval/one: 0.4487, eval/two: 0.2097, eval/three: 0.7857 \n",
      "Epoch: 40, train/loss: 0.2964, eval/loss: 0.2885, train/r2: 0.7266, eval/r2: 0.7024, train/one: 0.7119, train/two: 0.5760, train/three: 0.8919, eval/one: 0.5707, eval/two: 0.6435, eval/three: 0.8931 \n",
      "Epoch: 45, train/loss: 0.2332, eval/loss: 0.3205, train/r2: 0.7477, eval/r2: 0.5789, train/one: 0.7223, train/two: 0.7245, train/three: 0.7963, eval/one: 0.6559, eval/two: 0.2640, eval/three: 0.8168 \n",
      "Epoch: 50, train/loss: 0.1672, eval/loss: 0.1949, train/r2: 0.8327, eval/r2: 0.7712, train/one: 0.7756, train/two: 0.8211, train/three: 0.9014, eval/one: 0.6454, eval/two: 0.7962, eval/three: 0.8719 \n",
      "Epoch: 55, train/loss: 0.1637, eval/loss: 0.2828, train/r2: 0.8229, eval/r2: 0.6866, train/one: 0.7736, train/two: 0.8351, train/three: 0.8599, eval/one: 0.3736, eval/two: 0.8046, eval/three: 0.8815 \n",
      "Epoch: 60, train/loss: 0.1509, eval/loss: 0.3988, train/r2: 0.8177, eval/r2: 0.4520, train/one: 0.8137, train/two: 0.7813, train/three: 0.8582, eval/one: -0.2784, eval/two: 0.8236, eval/three: 0.8108 \n",
      "Epoch: 65, train/loss: 0.1670, eval/loss: 0.2210, train/r2: 0.8324, eval/r2: 0.7602, train/one: 0.8410, train/two: 0.8049, train/three: 0.8513, eval/one: 0.6940, eval/two: 0.6697, eval/three: 0.9169 \n",
      "Epoch: 70, train/loss: 0.1645, eval/loss: 0.1814, train/r2: 0.8528, eval/r2: 0.7438, train/one: 0.8150, train/two: 0.8398, train/three: 0.9035, eval/one: 0.7666, eval/two: 0.5286, eval/three: 0.9363 \n",
      "Epoch: 75, train/loss: 0.1713, eval/loss: 0.1495, train/r2: 0.8384, eval/r2: 0.8367, train/one: 0.8253, train/two: 0.8178, train/three: 0.8719, eval/one: 0.7988, eval/two: 0.7764, eval/three: 0.9349 \n",
      "Epoch: 80, train/loss: 0.1402, eval/loss: 0.1796, train/r2: 0.8598, eval/r2: 0.8007, train/one: 0.8528, train/two: 0.8219, train/three: 0.9048, eval/one: 0.8066, eval/two: 0.6767, eval/three: 0.9189 \n",
      "Epoch: 85, train/loss: 0.1662, eval/loss: 0.1973, train/r2: 0.8101, eval/r2: 0.7987, train/one: 0.7546, train/two: 0.8716, train/three: 0.8041, eval/one: 0.7381, eval/two: 0.7966, eval/three: 0.8615 \n",
      "Epoch: 90, train/loss: 0.1395, eval/loss: 0.2107, train/r2: 0.8596, eval/r2: 0.7480, train/one: 0.8535, train/two: 0.8636, train/three: 0.8615, eval/one: 0.5709, eval/two: 0.7890, eval/three: 0.8841 \n",
      "Epoch: 95, train/loss: 0.1737, eval/loss: 0.1430, train/r2: 0.8277, eval/r2: 0.8251, train/one: 0.7991, train/two: 0.7945, train/three: 0.8895, eval/one: 0.8297, eval/two: 0.7168, eval/three: 0.9287 \n",
      "[neptune] [info   ] Shutting down background jobs, please wait a moment...\n",
      "[neptune] [info   ] Done!\n",
      "[neptune] [info   ] Waiting for the remaining 285 operations to synchronize with Neptune. Do not kill this process.\n",
      "[neptune] [info   ] All 285 operations synced, thanks for waiting!\n",
      "[neptune] [info   ] Explore the metadata in the Neptune app: https://app.neptune.ai/arbaaz/kaggle-spect/e/KAG-314/metadata\n",
      "[neptune] [info   ] Neptune initialized. Open in the app: https://app.neptune.ai/arbaaz/kaggle-spect/e/KAG-315\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e4e53aa7ab24f8388f693fd0248aad9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:227: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, train/loss: 2.3995, eval/loss: 2.3529, train/r2: -1.5230, eval/r2: -0.7191, train/one: -3.4630, train/two: -0.8923, train/three: -0.2138, eval/one: -1.5425, eval/two: -0.3646, eval/three: -0.2501 \n",
      "Epoch: 5, train/loss: 1.1211, eval/loss: 1.9796, train/r2: -0.2743, eval/r2: -1.3688, train/one: -0.6269, train/two: -0.0657, train/three: -0.1303, eval/one: -0.6926, eval/two: -1.0884, eval/three: -2.3255 \n",
      "Epoch: 10, train/loss: 1.0025, eval/loss: 1.2340, train/r2: 0.0570, eval/r2: -0.2364, train/one: 0.0836, train/two: 0.0463, train/three: 0.0410, eval/one: -0.9048, eval/two: 0.1027, eval/three: 0.0929 \n",
      "Epoch: 15, train/loss: 0.8716, eval/loss: 1.1473, train/r2: 0.1259, eval/r2: 0.1104, train/one: 0.2102, train/two: 0.0296, train/three: 0.1380, eval/one: 0.2359, eval/two: 0.1083, eval/three: -0.0132 \n",
      "Epoch: 20, train/loss: 0.6749, eval/loss: 0.8065, train/r2: 0.2634, eval/r2: 0.1645, train/one: 0.3405, train/two: 0.1561, train/three: 0.2935, eval/one: 0.0286, eval/two: 0.1072, eval/three: 0.3577 \n",
      "Epoch: 25, train/loss: 0.5315, eval/loss: 0.5345, train/r2: 0.4329, eval/r2: 0.4423, train/one: 0.5059, train/two: 0.2025, train/three: 0.5902, eval/one: 0.4723, eval/two: 0.3699, eval/three: 0.4847 \n",
      "Epoch: 30, train/loss: 0.4202, eval/loss: 0.7451, train/r2: 0.5461, eval/r2: 0.5588, train/one: 0.6998, train/two: 0.2842, train/three: 0.6543, eval/one: 0.6104, eval/two: 0.2634, eval/three: 0.8026 \n",
      "Epoch: 35, train/loss: 0.3047, eval/loss: 0.5117, train/r2: 0.7188, eval/r2: 0.6232, train/one: 0.7811, train/two: 0.4993, train/three: 0.8760, eval/one: 0.7431, eval/two: 0.3489, eval/three: 0.7776 \n",
      "Epoch: 40, train/loss: 0.3447, eval/loss: 0.5122, train/r2: 0.6787, eval/r2: 0.5921, train/one: 0.7031, train/two: 0.4987, train/three: 0.8344, eval/one: 0.7285, eval/two: 0.5362, eval/three: 0.5116 \n",
      "Epoch: 45, train/loss: 0.2173, eval/loss: 0.3937, train/r2: 0.7847, eval/r2: 0.6261, train/one: 0.7940, train/two: 0.6730, train/three: 0.8870, eval/one: 0.6452, eval/two: 0.4822, eval/three: 0.7510 \n",
      "Epoch: 50, train/loss: 0.2657, eval/loss: 0.4440, train/r2: 0.7481, eval/r2: 0.6286, train/one: 0.7300, train/two: 0.6163, train/three: 0.8978, eval/one: 0.8106, eval/two: 0.3402, eval/three: 0.7348 \n",
      "Epoch: 55, train/loss: 0.1940, eval/loss: 0.2677, train/r2: 0.8054, eval/r2: 0.8021, train/one: 0.7875, train/two: 0.7814, train/three: 0.8472, eval/one: 0.8687, eval/two: 0.6455, eval/three: 0.8920 \n",
      "Epoch: 60, train/loss: 0.1940, eval/loss: 0.2656, train/r2: 0.8045, eval/r2: 0.7439, train/one: 0.7862, train/two: 0.7806, train/three: 0.8468, eval/one: 0.6470, eval/two: 0.7012, eval/three: 0.8836 \n",
      "Epoch: 65, train/loss: 0.1697, eval/loss: 0.3012, train/r2: 0.8357, eval/r2: 0.7232, train/one: 0.8038, train/two: 0.8041, train/three: 0.8991, eval/one: 0.8251, eval/two: 0.6829, eval/three: 0.6615 \n",
      "Epoch: 70, train/loss: 0.1697, eval/loss: 0.1927, train/r2: 0.8279, eval/r2: 0.8477, train/one: 0.8165, train/two: 0.8110, train/three: 0.8563, eval/one: 0.8908, eval/two: 0.8350, eval/three: 0.8173 \n",
      "Epoch: 75, train/loss: 0.1116, eval/loss: 0.2944, train/r2: 0.8917, eval/r2: 0.7514, train/one: 0.8775, train/two: 0.8979, train/three: 0.8998, eval/one: 0.6784, eval/two: 0.7883, eval/three: 0.7874 \n",
      "Epoch: 80, train/loss: 0.1508, eval/loss: 0.2012, train/r2: 0.8414, eval/r2: 0.8205, train/one: 0.8361, train/two: 0.8286, train/three: 0.8595, eval/one: 0.8182, eval/two: 0.8224, eval/three: 0.8207 \n",
      "Epoch: 85, train/loss: 0.1522, eval/loss: 0.1969, train/r2: 0.8570, eval/r2: 0.7823, train/one: 0.8314, train/two: 0.8514, train/three: 0.8883, eval/one: 0.7848, eval/two: 0.8496, eval/three: 0.7125 \n",
      "Epoch: 90, train/loss: 0.1972, eval/loss: 0.1902, train/r2: 0.8381, eval/r2: 0.7623, train/one: 0.8143, train/two: 0.8407, train/three: 0.8593, eval/one: 0.7926, eval/two: 0.8761, eval/three: 0.6182 \n",
      "Epoch: 95, train/loss: 0.1709, eval/loss: 0.2792, train/r2: 0.8167, eval/r2: 0.7967, train/one: 0.7253, train/two: 0.8309, train/three: 0.8939, eval/one: 0.7591, eval/two: 0.8240, eval/three: 0.8068 \n",
      "[neptune] [info   ] Shutting down background jobs, please wait a moment...\n",
      "[neptune] [info   ] Done!\n",
      "[neptune] [info   ] Waiting for the remaining 286 operations to synchronize with Neptune. Do not kill this process.\n",
      "[neptune] [info   ] All 286 operations synced, thanks for waiting!\n",
      "[neptune] [info   ] Explore the metadata in the Neptune app: https://app.neptune.ai/arbaaz/kaggle-spect/e/KAG-315/metadata\n",
      "[neptune] [info   ] Neptune initialized. Open in the app: https://app.neptune.ai/arbaaz/kaggle-spect/e/KAG-316\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8cb2c0936704f10a4c5ebce43c9d2a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:227: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, train/loss: 2.6479, eval/loss: 3.1371, train/r2: -1.3944, eval/r2: -2.3154, train/one: -3.3117, train/two: -0.7180, train/three: -0.1534, eval/one: -4.3701, eval/two: -1.6845, eval/three: -0.8918 \n",
      "Epoch: 5, train/loss: 1.1597, eval/loss: 0.9949, train/r2: -0.1414, eval/r2: -0.3167, train/one: -0.1774, train/two: -0.1409, train/three: -0.1060, eval/one: -0.1051, eval/two: -0.3928, eval/three: -0.4523 \n",
      "Epoch: 10, train/loss: 0.9023, eval/loss: 0.8721, train/r2: 0.0859, eval/r2: -0.0613, train/one: 0.1111, train/two: 0.0578, train/three: 0.0889, eval/one: 0.0890, eval/two: -0.0793, eval/three: -0.1935 \n",
      "Epoch: 15, train/loss: 0.8085, eval/loss: 0.6531, train/r2: 0.2453, eval/r2: 0.0923, train/one: 0.3152, train/two: 0.1797, train/three: 0.2410, eval/one: 0.1626, eval/two: -0.1136, eval/three: 0.2279 \n",
      "Epoch: 20, train/loss: 0.6574, eval/loss: 0.6764, train/r2: 0.3208, eval/r2: 0.1185, train/one: 0.4356, train/two: 0.1012, train/three: 0.4255, eval/one: 0.2892, eval/two: -0.4331, eval/three: 0.4995 \n",
      "Epoch: 25, train/loss: 0.5066, eval/loss: 0.4717, train/r2: 0.5320, eval/r2: 0.3989, train/one: 0.5428, train/two: 0.3572, train/three: 0.6960, eval/one: 0.3893, eval/two: 0.1049, eval/three: 0.7024 \n",
      "Epoch: 30, train/loss: 0.3976, eval/loss: 0.3575, train/r2: 0.5644, eval/r2: 0.5056, train/one: 0.6011, train/two: 0.3752, train/three: 0.7170, eval/one: 0.5711, eval/two: 0.1674, eval/three: 0.7782 \n",
      "Epoch: 35, train/loss: 0.3122, eval/loss: 0.2466, train/r2: 0.6437, eval/r2: 0.5867, train/one: 0.6686, train/two: 0.4361, train/three: 0.8264, eval/one: 0.7693, eval/two: 0.2582, eval/three: 0.7326 \n",
      "Epoch: 40, train/loss: 0.3364, eval/loss: 0.1798, train/r2: 0.6567, eval/r2: 0.7638, train/one: 0.6811, train/two: 0.4424, train/three: 0.8467, eval/one: 0.8221, eval/two: 0.6549, eval/three: 0.8144 \n",
      "Epoch: 45, train/loss: 0.2146, eval/loss: 0.2163, train/r2: 0.7959, eval/r2: 0.6264, train/one: 0.8203, train/two: 0.7092, train/three: 0.8582, eval/one: 0.7098, eval/two: 0.2617, eval/three: 0.9077 \n",
      "Epoch: 50, train/loss: 0.1321, eval/loss: 0.2238, train/r2: 0.8661, eval/r2: 0.6912, train/one: 0.8627, train/two: 0.8054, train/three: 0.9302, eval/one: 0.5929, eval/two: 0.6195, eval/three: 0.8611 \n",
      "Epoch: 55, train/loss: 0.1580, eval/loss: 0.1189, train/r2: 0.8391, eval/r2: 0.8554, train/one: 0.8607, train/two: 0.7332, train/three: 0.9234, eval/one: 0.7487, eval/two: 0.9094, eval/three: 0.9083 \n",
      "Epoch: 60, train/loss: 0.1353, eval/loss: 0.1759, train/r2: 0.8661, eval/r2: 0.7134, train/one: 0.8720, train/two: 0.8409, train/three: 0.8854, eval/one: 0.5808, eval/two: 0.7378, eval/three: 0.8215 \n",
      "Epoch: 65, train/loss: 0.1643, eval/loss: 0.1152, train/r2: 0.8335, eval/r2: 0.8730, train/one: 0.8182, train/two: 0.7940, train/three: 0.8883, eval/one: 0.8399, eval/two: 0.8693, eval/three: 0.9100 \n",
      "Epoch: 70, train/loss: 0.1338, eval/loss: 0.1741, train/r2: 0.8628, eval/r2: 0.8082, train/one: 0.8363, train/two: 0.8230, train/three: 0.9289, eval/one: 0.6900, eval/two: 0.8761, eval/three: 0.8586 \n",
      "Epoch: 75, train/loss: 0.1557, eval/loss: 0.1243, train/r2: 0.8420, eval/r2: 0.8294, train/one: 0.8233, train/two: 0.8322, train/three: 0.8704, eval/one: 0.7580, eval/two: 0.8855, eval/three: 0.8448 \n",
      "Epoch: 80, train/loss: 0.1176, eval/loss: 0.2286, train/r2: 0.8725, eval/r2: 0.6334, train/one: 0.8856, train/two: 0.8673, train/three: 0.8647, eval/one: 0.3685, eval/two: 0.6498, eval/three: 0.8819 \n",
      "Epoch: 85, train/loss: 0.1155, eval/loss: 0.1671, train/r2: 0.8737, eval/r2: 0.7594, train/one: 0.8652, train/two: 0.8725, train/three: 0.8835, eval/one: 0.5418, eval/two: 0.8344, eval/three: 0.9020 \n",
      "Epoch: 90, train/loss: 0.1033, eval/loss: 0.1979, train/r2: 0.8938, eval/r2: 0.6849, train/one: 0.8943, train/two: 0.8705, train/three: 0.9165, eval/one: 0.5998, eval/two: 0.6307, eval/three: 0.8242 \n",
      "Epoch: 95, train/loss: 0.1915, eval/loss: 0.1906, train/r2: 0.8258, eval/r2: 0.7555, train/one: 0.8275, train/two: 0.7759, train/three: 0.8740, eval/one: 0.5732, eval/two: 0.8469, eval/three: 0.8464 \n",
      "[neptune] [info   ] Shutting down background jobs, please wait a moment...\n",
      "[neptune] [info   ] Done!\n",
      "[neptune] [info   ] Waiting for the remaining 273 operations to synchronize with Neptune. Do not kill this process.\n",
      "[neptune] [info   ] All 273 operations synced, thanks for waiting!\n",
      "[neptune] [info   ] Explore the metadata in the Neptune app: https://app.neptune.ai/arbaaz/kaggle-spect/e/KAG-316/metadata\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "\n",
    "inputs_mean_std = []\n",
    "targets_mean_std = []\n",
    "scores = []\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=SEED)\n",
    "splits = kfold.split(inputs)\n",
    "\n",
    "for fold, (train_idx, eval_idx) in enumerate(splits):\n",
    "    MODEL_NAME = f\"finetune.xception.F{fold}\"\n",
    "    checkpoint_name = f\"finetune.xception.F{fold}.pt\"\n",
    "    \n",
    "    train_inputs = inputs[train_idx]\n",
    "    train_targets = targets[train_idx]\n",
    "    eval_inputs = inputs[eval_idx]\n",
    "    eval_targets = targets[eval_idx]\n",
    "\n",
    "    train_ds = get_dataset(train_inputs, train_targets, config)\n",
    "    \n",
    "    inputs_mean_std.append((fold, train_ds.s_mean, train_ds.s_std))\n",
    "    targets_mean_std.append((fold, train_ds.concentration_means, train_ds.concentration_stds))\n",
    "    \n",
    "    eval_ds = get_dataset(\n",
    "        eval_inputs, \n",
    "        eval_targets, \n",
    "        config,\n",
    "        (train_ds.s_mean, train_ds.s_std), \n",
    "        (train_ds.concentration_means, train_ds.concentration_stds)\n",
    "    )\n",
    "    \n",
    "    BATCH_SIZE = 32\n",
    "    train_dl, eval_dl = return_dls(train_ds, eval_ds, BATCH_SIZE, len(eval_ds))\n",
    "    \n",
    "    #model = convnextv2_atto().to(device)\n",
    "    #model = ReZeroNet(**config).to(device)\n",
    "    #model = ResNet(dropout=DROPOUT).to(device)\n",
    "    model = RamanXception(\n",
    "        **model_config,\n",
    "        classification_idx=3,\n",
    "        num_concentrations=3\n",
    "    ).to(device)\n",
    "    \n",
    "    ckpt = get_ckpt(\"/kaggle/input/baseline/pytorch/default/1/xception.pretrain.0.pt\")[\"state_dict\"]\n",
    "    model.load_state_dict(ckpt)\n",
    "    \n",
    "    if fold == 0: print(get_model_size(model))\n",
    "    \n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=LR, weight_decay=WD, foreach=True)\n",
    "    scheduler = get_scheduler(optimizer, train_dl, EPOCHS)\n",
    "    \n",
    "    score = train(\n",
    "            model, \n",
    "            optimizer, \n",
    "            device,\n",
    "            torch.float16,\n",
    "            scheduler,\n",
    "            train_dl, \n",
    "            eval_dl,\n",
    "            loss_fn,\n",
    "            EPOCHS,\n",
    "            checkpoint_name,\n",
    "            neptune_run=setup_neptune(),\n",
    "        )\n",
    "    \n",
    "    scores.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4925ae75",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpectralTestDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        spectra,\n",
    "        concentrations,\n",
    "        dtype=None,\n",
    "        spectra_mean_std=None,\n",
    "        concentration_mean_std=None,\n",
    "        combine_spectra_range=0.0,\n",
    "        baseline_factor_bound=0.0,\n",
    "        baseline_period_lower_bound=100.0,\n",
    "        baseline_period_upper_bound=200.0,\n",
    "        augment_slope_std=0.0,\n",
    "        augment_intersept_std=0.0,\n",
    "        rolling_bound=0,\n",
    "        spectrum_rolling_sigma=0.0,\n",
    "        augmentation_weight=0.1,\n",
    "        original_datapoint_weight=1.,\n",
    "    ):\n",
    "        self.dtype = dtype or torch.float32\n",
    "        self.combine_spectra_range = combine_spectra_range\n",
    "        self.baseline_factor_bound = baseline_factor_bound\n",
    "        self.augment_slope_std = augment_slope_std\n",
    "        self.augment_intercept_std = augment_intersept_std\n",
    "        self.baseline_period_lower_bound = baseline_period_lower_bound\n",
    "        self.baseline_period_upper_bound = baseline_period_upper_bound\n",
    "        self.rolling_bound = rolling_bound\n",
    "        self.spectrum_rolling_sigma = spectrum_rolling_sigma\n",
    "        self.augmentation_weight = torch.tensor(augmentation_weight, dtype=dtype)\n",
    "        self.original_dp_weight = original_datapoint_weight\n",
    "\n",
    "        # normalize spectra\n",
    "        spectra = torch.tensor(spectra, dtype=dtype)\n",
    "\n",
    "        if spectra_mean_std is None:\n",
    "            self.s_mean = torch.mean(spectra)\n",
    "            self.s_std = torch.std(spectra)\n",
    "        else:\n",
    "            self.s_mean, self.s_std = spectra_mean_std\n",
    "\n",
    "        self.spectra = torch.divide(\n",
    "            torch.subtract(spectra, self.s_mean),\n",
    "            self.s_std,\n",
    "        )\n",
    "\n",
    "        self.dummy_wns = np.tile(\n",
    "            np.arange(\n",
    "                0., 1., 1. / self.spectra.shape[2],\n",
    "                dtype=np_dtype_from_torch[self.dtype]\n",
    "            )[None, :self.spectra.shape[2]],\n",
    "            (self.spectra.shape[1], 1),\n",
    "        )\n",
    "\n",
    "        if False:\n",
    "            # normalize concentrations\n",
    "            concentrations = torch.tensor(concentrations, dtype=dtype)\n",
    "            if concentration_mean_std is None:\n",
    "                self.concentration_means = torch.nanmean(concentrations, dim=0)\n",
    "\n",
    "                self.concentration_stds = torch.maximum(\n",
    "                    torch.tensor(\n",
    "                        [\n",
    "                            torch.std(col[torch.logical_not(torch.isnan(col))])\n",
    "                            for col in concentrations.T\n",
    "                        ]\n",
    "                    ),\n",
    "                    torch.tensor([1e-3] * concentrations.shape[1]),\n",
    "                )\n",
    "            else:\n",
    "                self.concentration_means = concentration_mean_std[0]\n",
    "                self.concentration_stds = concentration_mean_std[1]\n",
    "\n",
    "            self.concentrations = torch.divide(\n",
    "                torch.subtract(\n",
    "                    concentrations,\n",
    "                    self.concentration_means,\n",
    "                ),\n",
    "                self.concentration_stds,\n",
    "            )\n",
    "\n",
    "    def pick_two(self, max_idx=None):\n",
    "        max_idx = max_idx or len(self)\n",
    "        return random.choices(range(max_idx), k=2)\n",
    "\n",
    "    def __len__(self):\n",
    "        return 96\n",
    "\n",
    "    def augment_spectra(self, spectra):\n",
    "        if self.augment_slope_std > 0.0:\n",
    "\n",
    "            def spectrum_approximation(x, slope, intercept):\n",
    "                return (slope * x + intercept).reshape(-1, 1)[:, 0]\n",
    "\n",
    "            slope, inter = scipy.optimize.curve_fit(\n",
    "                spectrum_approximation,\n",
    "                self.dummy_wns,\n",
    "                spectra.reshape(-1, 1)[:, 0],\n",
    "                p0=np.random.rand(2),\n",
    "            )[0]\n",
    "\n",
    "            new_slope = slope * (\n",
    "                    np.random.gamma(\n",
    "                        shape=1. / self.augment_slope_std,\n",
    "                        scale=self.augment_slope_std,\n",
    "                        size=1,\n",
    "                    )\n",
    "            )[0]\n",
    "            new_intercept = inter * (\n",
    "                1.0 + np.random.randn(1) * self.augment_intercept_std\n",
    "            )[0]\n",
    "            spectra += torch.tensor(\n",
    "                (new_slope - slope)\n",
    "            ) * self.dummy_wns + new_intercept - inter\n",
    "\n",
    "        factor = self.baseline_factor_bound * torch.rand(size=(1,))\n",
    "        offset = torch.rand(size=(1,)) * 2.0 * torch.pi\n",
    "        period = self.baseline_period_lower_bound + (\n",
    "            self.baseline_period_upper_bound - self.baseline_period_lower_bound\n",
    "        ) * torch.rand(size=(1,))\n",
    "        permutations = factor * torch.cos(\n",
    "            2.0 * torch.pi / period * self.dummy_wns + offset\n",
    "        )\n",
    "        return self.roll_spectrum(\n",
    "            spectra + permutations * spectra,\n",
    "            delta=random.randint(-self.rolling_bound, self.rolling_bound),\n",
    "        )\n",
    "\n",
    "    def roll_spectrum(self, spectra, delta):\n",
    "        num_spectra = spectra.shape[0]\n",
    "        rolled_spectra = np.roll(spectra, delta, axis=1)\n",
    "        if delta > 0:\n",
    "            rolled_spectra[:, :delta] = (\n",
    "                np.random.rand(num_spectra, delta) * self.spectrum_rolling_sigma + 1\n",
    "            ) * rolled_spectra[:, delta:(delta + 1)]\n",
    "        elif delta < 0:\n",
    "            rolled_spectra[:, delta:] = (\n",
    "                np.random.rand(num_spectra, -delta) * self.spectrum_rolling_sigma + 1\n",
    "            ) * rolled_spectra[:, delta - 1:delta]\n",
    "        return rolled_spectra\n",
    "\n",
    "    def combine_k_items(self, indices, weights):\n",
    "        return (\n",
    "            # spectra\n",
    "            torch.sum(\n",
    "                torch.mul(weights[:, None, None], self.spectra[indices, :, :]),\n",
    "                dim=0,\n",
    "            ),\n",
    "            # concentrations\n",
    "            #torch.sum(\n",
    "            #    torch.mul(weights[:, None], self.concentrations[indices, :]),\n",
    "            #    dim=0,\n",
    "            #)\n",
    "        )\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if True:#self.combine_spectra_range < 1e-12:\n",
    "            spectrum = self.spectra[idx]\n",
    "            #spectrum = self.augment_spectra(spectrum)\n",
    "            return spectrum\n",
    "        else:\n",
    "            if random.random() < self.original_dp_weight:\n",
    "                one_weight = 1.\n",
    "                label_weight = torch.tensor(1.0, dtype=self.dtype)\n",
    "            else:\n",
    "                one_weight = random.uniform(0.0, self.combine_spectra_range)\n",
    "                label_weight = self.augmentation_weight\n",
    "            weights = torch.tensor([one_weight, (1 - one_weight)])\n",
    "            # just pick two random indices\n",
    "            indices = random.choices(range(len(self)), k=2)\n",
    "\n",
    "            mixed_spectra = self.combine_k_items(\n",
    "                indices=indices,\n",
    "                weights=weights,\n",
    "            )\n",
    "            mixed_spectra = self.augment_spectra(mixed_spectra[0])\n",
    "            return mixed_spectra\n",
    "        \n",
    "  \n",
    "def get_test_dataset(inputs, inputs_mean_std, targets_mean_std):\n",
    "    return SpectralTestDataset(\n",
    "        spectra=inputs[:, None, :],\n",
    "        concentrations=None,\n",
    "        dtype=torch.float32,\n",
    "        spectra_mean_std=inputs_mean_std,\n",
    "        concentration_mean_std=targets_mean_std,\n",
    "        combine_spectra_range=1.0,\n",
    "        baseline_factor_bound=config[\"baseline_factor_bound\"],\n",
    "        baseline_period_lower_bound=config[\"baseline_period_lower_bound\"],\n",
    "        baseline_period_upper_bound=(config[\"baseline_period_lower_bound\"] + config[\"baseline_period_span\"]),\n",
    "        augment_slope_std=config[\"augment_slope_std\"],\n",
    "        augment_intersept_std=0.0,\n",
    "        rolling_bound=config[\"rolling_bound\"],\n",
    "        spectrum_rolling_sigma=0.01,\n",
    "        augmentation_weight=0.1,\n",
    "        original_datapoint_weight=1.,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "94caa304",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/finetune.baseline.resnet.F0.pt 92 0.8889310253438752\n",
      "/kaggle/working/finetune.baseline.resnet.F1.pt 83 0.9428886696482195\n",
      "/kaggle/working/finetune.baseline.resnet.F2.pt 62 0.9188509923921502\n",
      "/kaggle/working/finetune.baseline.resnet.F3.pt 94 0.9387695188878328\n",
      "/kaggle/working/finetune.baseline.resnet.F4.pt 65 0.9315321986159409\n",
      "/kaggle/working/finetune.xception.F0.pt 93 0.8760090686615679\n",
      "/kaggle/working/finetune.xception.F1.pt 97 0.8991505598176587\n",
      "/kaggle/working/finetune.xception.F2.pt 81 0.8787869812044655\n",
      "/kaggle/working/finetune.xception.F3.pt 94 0.8667093844091135\n",
      "/kaggle/working/finetune.xception.F4.pt 77 0.8830788332910499\n",
      "/kaggle/working/finetune.xception.resnet.F0.pt 59 0.7940462473673003\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/kaggle/working/finetune.baseline.resnet.F0.pt',\n",
       " '/kaggle/working/finetune.baseline.resnet.F1.pt',\n",
       " '/kaggle/working/finetune.baseline.resnet.F2.pt',\n",
       " '/kaggle/working/finetune.baseline.resnet.F3.pt',\n",
       " '/kaggle/working/finetune.baseline.resnet.F4.pt',\n",
       " '/kaggle/working/finetune.xception.F0.pt',\n",
       " '/kaggle/working/finetune.xception.F1.pt',\n",
       " '/kaggle/working/finetune.xception.F2.pt',\n",
       " '/kaggle/working/finetune.xception.F3.pt',\n",
       " '/kaggle/working/finetune.xception.F4.pt',\n",
       " '/kaggle/working/finetune.xception.resnet.F0.pt']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckpt_paths = get_ckpt_paths(\"/kaggle/working/\", \"finetune\")\n",
    "ckpt_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5b492f13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([6.8227, 1.1995, 1.6005]), tensor([2.9272, 0.5459, 0.6937]))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets_mean_std[1][1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4786020e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.66954874,  0.78885008,  0.66945825],\n",
       "       [ 6.02439293,  1.72374044,  1.86294906],\n",
       "       [ 4.73387718,  0.66746245,  1.11429106],\n",
       "       [ 3.36186427,  0.95707884,  0.60138372],\n",
       "       [10.74335563,  1.08469177,  1.04640487],\n",
       "       [ 7.79149424,  1.85122653,  0.87439316],\n",
       "       [ 6.45080018,  0.73214387,  0.4693115 ],\n",
       "       [ 6.17747787,  2.04762333,  1.14821508],\n",
       "       [ 6.78303218,  1.93231102,  1.18067036],\n",
       "       [ 9.51890954,  0.78413444,  0.33448671],\n",
       "       [ 9.3611771 ,  0.82066024,  1.16067062],\n",
       "       [ 2.83731915,  1.2601258 ,  0.96025776],\n",
       "       [ 4.37750159,  1.13258094,  1.13889522],\n",
       "       [ 4.98539773,  0.97945887,  1.86429871],\n",
       "       [ 4.52354546,  1.22185777,  1.09667284],\n",
       "       [ 8.81121107,  0.7327261 ,  0.87053035],\n",
       "       [ 5.44735984,  0.92049363,  1.02608077],\n",
       "       [ 5.73599372,  1.14094102,  1.15152851],\n",
       "       [ 6.62377178,  1.38141356,  1.19645389],\n",
       "       [ 4.02276778,  0.86357384,  1.19953272],\n",
       "       [ 5.91987985,  0.86746868,  0.87188835],\n",
       "       [ 6.23072515,  1.04093682,  1.27837619],\n",
       "       [ 2.27548483,  1.36251904,  0.6701781 ],\n",
       "       [ 3.36952463,  1.40896094,  1.46113334],\n",
       "       [ 4.35660194,  1.09062162,  1.24284651],\n",
       "       [ 4.0678728 ,  1.19030164,  1.26008976],\n",
       "       [ 6.41420119,  1.10265503,  1.07515615],\n",
       "       [ 6.64488832,  0.66565763,  1.36454735],\n",
       "       [ 7.28255808,  0.98590884,  1.21960453],\n",
       "       [ 5.7797594 ,  0.61516396,  0.26100878],\n",
       "       [ 6.80284762,  0.74100435,  1.50858286],\n",
       "       [ 8.4413549 ,  0.83805174,  0.90912175],\n",
       "       [ 7.08581288,  0.8148997 ,  1.29361626],\n",
       "       [ 7.20843523,  1.11225799,  0.97312958],\n",
       "       [ 6.96795337,  1.3073226 ,  1.04426764],\n",
       "       [ 5.27048529,  0.44163706,  1.06557383],\n",
       "       [ 8.5273497 ,  1.11643885,  0.71140576],\n",
       "       [ 7.23213612,  1.34361054,  0.57213012],\n",
       "       [ 5.076384  ,  1.05093389,  0.64973897],\n",
       "       [ 8.3568009 ,  1.01208006,  1.51671441],\n",
       "       [ 6.56077259,  0.8157452 ,  1.15784603],\n",
       "       [ 4.90170248,  1.26218832,  0.45322051],\n",
       "       [ 7.33159422,  0.47221119,  1.35952758],\n",
       "       [ 3.28231935,  0.8383869 ,  1.09635914],\n",
       "       [ 1.89894918,  1.38253701,  0.86586945],\n",
       "       [ 5.90571814,  0.49436809,  1.50821649],\n",
       "       [ 3.31085529,  0.65060049,  1.61797732],\n",
       "       [ 5.16053794,  0.92536003,  1.37419701],\n",
       "       [ 4.2280646 ,  1.2474649 ,  1.88762671],\n",
       "       [ 6.68069364,  0.74517822,  1.75603237],\n",
       "       [ 2.8213438 ,  1.41421686,  2.02546337],\n",
       "       [ 2.51600981,  1.21545525,  1.83714596],\n",
       "       [ 5.21958187,  0.89847991,  1.20086501],\n",
       "       [ 3.11777273,  1.64198275,  1.19057767],\n",
       "       [ 3.7412815 ,  1.19666455,  1.52508806],\n",
       "       [ 4.07536184,  1.21460103,  1.86411029],\n",
       "       [ 3.74593536,  1.80403784,  1.17945744],\n",
       "       [ 3.29672445,  1.25387274,  1.73533104],\n",
       "       [ 4.45996717,  0.40212638,  1.6127308 ],\n",
       "       [ 7.40388633,  0.39041807,  0.63434369],\n",
       "       [ 3.35361558,  0.67851379,  1.30944732],\n",
       "       [ 2.9437331 ,  1.24516266,  1.49501083],\n",
       "       [ 4.50594402,  1.35762269,  1.02698701],\n",
       "       [ 7.43417894,  0.69670833,  1.77738316],\n",
       "       [ 7.99838337,  1.64438925,  0.58677975],\n",
       "       [ 7.30883949,  0.61449704,  0.6821868 ],\n",
       "       [ 9.62281423,  1.03719273,  1.27297932],\n",
       "       [ 4.91659383,  0.94738234,  0.73893279],\n",
       "       [ 8.58758213,  0.62550856,  0.69232595],\n",
       "       [ 8.07403695,  0.50203139,  0.76735391],\n",
       "       [ 9.3696198 ,  0.49357107,  1.08398637],\n",
       "       [ 8.82024837,  1.07554969,  0.99585534],\n",
       "       [ 5.4850737 ,  0.89435001,  1.85579193],\n",
       "       [ 7.41694443,  0.37691334,  1.06849418],\n",
       "       [ 5.52716873,  0.84713157,  1.82990417],\n",
       "       [ 6.59505193,  0.2957531 ,  1.24741243],\n",
       "       [ 5.49299002,  1.0413761 ,  0.2271854 ],\n",
       "       [ 5.3710888 ,  0.8444807 ,  1.53618015],\n",
       "       [ 3.2479885 ,  1.44709909,  0.78840184],\n",
       "       [ 4.61238065,  0.56893797,  1.38915778],\n",
       "       [ 7.04214169,  0.80986391,  0.64567438],\n",
       "       [ 1.51781654,  1.20123102,  2.04391685],\n",
       "       [ 6.32116767,  0.62523868,  2.06007507],\n",
       "       [ 4.35857784,  0.93362661,  1.28178911],\n",
       "       [ 3.3929611 ,  1.30704472,  1.64523852],\n",
       "       [ 5.83200024,  0.9601309 ,  1.26330962],\n",
       "       [ 7.11210129,  1.34748728,  0.98341237],\n",
       "       [ 4.92746693,  0.89264352,  0.98150134],\n",
       "       [ 6.90660623,  1.27639653,  1.09057343],\n",
       "       [ 5.56521513,  0.91855661,  1.23140786],\n",
       "       [ 7.03081567,  0.83404965,  1.1763767 ],\n",
       "       [ 3.41749745,  0.99606431,  1.41962151],\n",
       "       [ 4.82609487,  0.61734884,  0.97921063],\n",
       "       [ 5.24057504,  0.42609629,  0.91408573],\n",
       "       [ 3.001357  ,  1.15267354,  1.20295891],\n",
       "       [ 3.63538364,  1.99672036,  1.04559315]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "def inference(test_inputs, ckpt_name, i):\n",
    "    ckpt = get_ckpt(ckpt_name)\n",
    "    \n",
    "    test_ds = get_test_dataset(test_inputs, inputs_mean_std[i][1:], targets_mean_std[i][1:]) #[i][1:]\n",
    "    test_dl = DataLoader(test_ds, batch_size=32)\n",
    "\n",
    "    #model = ReZeroNet(**config).to(device)\n",
    "    #model = ResNet(dropout=DROPOUT).to(device)\n",
    "    model = RamanXception(\n",
    "        **model_config,\n",
    "        classification_idx=3,\n",
    "        num_concentrations=3\n",
    "    ).to(device)\n",
    "    \n",
    "    model.load_state_dict(ckpt[\"state_dict\"])\n",
    "    model.eval()\n",
    "    \n",
    "    all_preds = []\n",
    "    for inputs in test_dl:\n",
    "        with torch.inference_mode():\n",
    "            preds = model(inputs.cuda())\n",
    "            preds = preds.double() \n",
    "            all_preds.append(cuda_to_np(preds))\n",
    "            \n",
    "    preds = np.concatenate(all_preds)\n",
    "    mus = targets_mean_std[i][1:][0] #[i][1:][0]\n",
    "    sigmas = targets_mean_std[i][1:][1] #[i][1:][1]\n",
    "\n",
    "    for i in range(3):\n",
    "        preds[:, i] = reverse_zscore(preds[:, i], mus[i].numpy(), sigmas[i].numpy())\n",
    "    \n",
    "    return preds\n",
    "\n",
    "preds = inference(test_inputs, \"/kaggle/working/finetune.xception.F1.pt\", 1) # CAREFUL ABOUT INDEX\n",
    "generate_csv(preds, \"/kaggle/working/finetune.xception.F1.pt.89.csv\")\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "48724221",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min: 0.276526487, Max: 11.88990894, Mean: 3.208722795402778, Std: 3.1291512817697695\n",
      "Min: 0.22718540335807802, Max: 10.743355628477673, Mean: 2.607027186618872, Std: 2.4520468249081184\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_stats(targets, minmax=True), get_stats(preds, minmax=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe51104",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min: 0.276526487, Max: 11.88990894, Mean: 3.208722795402778, Std: 3.1291512817697695\n",
      "Min: 0.21520479832992123, Max: 9.941416729453636, Mean: 2.220094471803795, Std: 1.9768473694491508\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_stats(targets, minmax=True), get_stats(preds, minmax=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b84e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensemble_inference(ckpt_paths):\n",
    "    test_inputs = get_test_data()\n",
    "    all_preds = []\n",
    "\n",
    "    for i, ckpt_path in enumerate(ckpt_paths):\n",
    "        ckpt = get_ckpt(ckpt_path)\n",
    "        \n",
    "        model = ReZeroNet(**config).to(device)\n",
    "        model.load_state_dict(ckpt[\"state_dict\"])\n",
    "        model.eval()\n",
    "\n",
    "        test_ds = get_test_dataset(test_inputs, inputs_mean_std[i][1:], targets_mean_std[i][1:])\n",
    "        test_dl = DataLoader(test_ds, batch_size=32)\n",
    "        \n",
    "        fold_preds = []\n",
    "        for inputs in test_dl:\n",
    "            with torch.inference_mode():\n",
    "                preds = model(inputs.cuda())\n",
    "                preds = cuda_to_np(preds.double())\n",
    "                fold_preds.append(preds)\n",
    "                \n",
    "        fold_preds = np.concatenate(fold_preds)\n",
    "        \n",
    "        means = targets_mean_std[i][1:][0]\n",
    "        stds = targets_mean_std[i][1:][1]\n",
    "        for i in range(3):\n",
    "            fold_preds[:, i] = reverse_zscore(fold_preds[:, i], means[i].numpy(), stds[i].numpy())\n",
    "            \n",
    "        all_preds.append(fold_preds)\n",
    "\n",
    "    return np.mean(all_preds, axis=0)\n",
    "\n",
    "preds = ensemble_inference(ckpt_paths)\n",
    "generate_csv(preds, \"paper.finetune.avg.pretrain.weights.ensemble.csv\")\n",
    "preds"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
