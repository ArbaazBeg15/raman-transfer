{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "314d6601",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34ca4ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def setup_reproducibility(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available(): torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.use_deterministic_algorithms(False, warn_only=True)\n",
    "    torch.set_float32_matmul_precision(\"high\")\n",
    "    \n",
    "SEED = 64364\n",
    "setup_reproducibility(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb8c02b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import OrderedDict\n",
    "from transformers import get_cosine_schedule_with_warmup\n",
    "from scipy import signal\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from huggingface_hub import login, snapshot_download\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "def average_state_dicts(state_dict_list):\n",
    "    n = len(state_dict_list)\n",
    "    # Ensure we don't modify the originals\n",
    "    avg_sd = OrderedDict()\n",
    "\n",
    "    # Iterate over every parameter/buffer key\n",
    "    for k in state_dict_list[0]:\n",
    "        # sum across models â†’ float32 to avoid overflow on int types\n",
    "        avg = sum(sd[k].float() for sd in state_dict_list) / n\n",
    "        # cast back to original dtype if needed\n",
    "        avg_sd[k] = avg.to(dtype=state_dict_list[0][k].dtype)\n",
    "\n",
    "    return avg_sd\n",
    "\n",
    "\n",
    "def get_ckpt_paths(output_dir, keyword):\n",
    "    output_files = sorted(os.listdir(output_dir))\n",
    "\n",
    "    ckpt_paths = []\n",
    "    for f in output_files:\n",
    "        if keyword in f and \"csv\" not in f:\n",
    "            ckpt_path = os.path.join(output_dir, f)\n",
    "            ckpt_paths.append(ckpt_path)\n",
    "            ckpt = torch.load(ckpt_path, weights_only=False)\n",
    "            print(ckpt_path, ckpt[\"epoch\"], ckpt[\"score\"])\n",
    "            \n",
    "    return ckpt_paths\n",
    "\n",
    "\n",
    "def rest(t=4000):\n",
    "    import time\n",
    "    [time.sleep(1) for i in range(t)]\n",
    "        \n",
    "        \n",
    "def generate_csv(preds, name):\n",
    "    column_names = ['Glucose', 'Sodium Acetate', 'Magnesium Sulfate']\n",
    "    preds_df = pd.DataFrame(preds, columns=column_names)\n",
    "    preds_df.insert(0, 'ID', [i+1 for i in range(len(preds_df))])\n",
    "    preds_df.to_csv(name, index=False)\n",
    "    \n",
    "    \n",
    "def get_ckpt(path):\n",
    "    return torch.load(path, weights_only=False)\n",
    "\n",
    "\n",
    "def cuda_to_np(tensor):\n",
    "    return tensor.cpu().detach().numpy()\n",
    "\n",
    "\n",
    "def get_scheduler(optimizer, train_dl, epochs):\n",
    "    total_training_steps = len(train_dl) * epochs\n",
    "    warmup_steps = int(total_training_steps * 0.05)  # e.g. 5% warmup\n",
    "    \n",
    "    return get_cosine_schedule_with_warmup(\n",
    "        optimizer=optimizer,\n",
    "        num_warmup_steps=warmup_steps,\n",
    "        num_training_steps=total_training_steps\n",
    "    )\n",
    "\n",
    "\n",
    "def get_stats(tensor, p=True, r=False, minmax=False):\n",
    "    if minmax:\n",
    "        min, max = tensor.min(), tensor.max()\n",
    "        mean, std = tensor.mean(), tensor.std()\n",
    "        if p: print(f\"Min: {min}, Max: {max}, Mean: {mean}, Std: {std}\")\n",
    "        if r: return min, max, mean, std\n",
    "    else:\n",
    "        mean, std = tensor.mean(), tensor.std()\n",
    "        if p: print(f\"Mean: {mean}, Std: {std}\")\n",
    "        if r: return mean, std\n",
    "    \n",
    "    \n",
    "def zscore(tensor, mean=None, std=None):\n",
    "    if mean is None: mean = tensor.mean()\n",
    "    if std is None: std = tensor.std()\n",
    "    return (tensor - mean) / (std + 1e-8)\n",
    "\n",
    "\n",
    "def reverse_zscore(tensor, mu, sigma):\n",
    "    return (tensor * sigma) + mu\n",
    "\n",
    "\n",
    "def get_model_size(model):\n",
    "    print(sum(p.numel() for p in model.parameters()) / 1e6)\n",
    "    \n",
    "\n",
    "def get_index(iterable):\n",
    "    return random.randint(0, len(iterable) - 1)\n",
    "\n",
    "\n",
    "def get_indices(iterable, n):\n",
    "    return random.sample(range(len(iterable)), n)\n",
    "\n",
    "\n",
    "def split(inputs, targets, seed):\n",
    "    return train_test_split(\n",
    "        inputs,\n",
    "        targets, \n",
    "        test_size=0.2,\n",
    "        shuffle=True, \n",
    "        random_state=seed\n",
    "    ) \n",
    "\n",
    "\n",
    "def show_waves(waves, dpi=100):\n",
    "    \"\"\"\n",
    "    waves: numpy array of shape (3, N)\n",
    "    Creates three separate figures that stretch wide.\n",
    "    \"\"\"\n",
    "    N = waves.shape[1]\n",
    "    t = np.arange(N)\n",
    "\n",
    "    # Wide aspect ratio; height modest so each window fills width\n",
    "    for i in range(waves.shape[0]):\n",
    "        fig = plt.figure(figsize=(14, 4), dpi=dpi)  # wide figure\n",
    "        ax = fig.add_subplot(111)\n",
    "        ax.plot(t, waves[i], linewidth=1)\n",
    "        ax.set_title(f\"Wave {i+1}\")\n",
    "        ax.set_xlabel(\"Sample\")\n",
    "        ax.set_ylabel(\"Amplitude\")\n",
    "        ax.grid(True)\n",
    "        fig.tight_layout()  # reduce margins to use width\n",
    "        \n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "def hf_ds_download(hf_token, repo_id):\n",
    "    login(hf_token[1:])\n",
    "    return snapshot_download(repo_id, repo_type=\"dataset\")\n",
    "\n",
    "\n",
    "def get_spectra_features(X, b=False):\n",
    "    \"\"\"Create multi-channel features from spectra: raw, 1st derivative, 2nd derivative.\"\"\"\n",
    "    X_processed = np.zeros_like(X)\n",
    "    # Baseline correction and SNV\n",
    "    for i in tqdm(range(X.shape[0])):\n",
    "        poly = np.polyfit(np.arange(X.shape[1]), X[i], 3)\n",
    "        baseline = np.polyval(poly, np.arange(X.shape[1]))\n",
    "        corrected_spec = X[i] - baseline\n",
    "        #X_processed[i] = (corrected_spec - corrected_spec.mean()) / (corrected_spec.std() + 1e-8)\n",
    "        X_processed[i] = corrected_spec\n",
    "        \n",
    "    # Calculate derivatives\n",
    "    deriv1 = signal.savgol_filter(X_processed, window_length=11, polyorder=3, deriv=1, axis=1)\n",
    "    deriv2 = signal.savgol_filter(X_processed, window_length=11, polyorder=3, deriv=2, axis=1)\n",
    "\n",
    "    if b: return np.stack([X_processed, deriv1, deriv2], axis=1)\n",
    "    return np.stack([deriv1, deriv2], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2cfbbe45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 'sample_submission.csv')\n",
      "(1, 'timegate.csv')\n",
      "(2, 'mettler_toledo.csv')\n",
      "(3, 'kaiser.csv')\n",
      "(4, 'anton_532.csv')\n",
      "(5, 'transfer_plate.csv')\n",
      "(6, '96_samples.csv')\n",
      "(7, 'tornado.csv')\n",
      "(8, 'tec5.csv')\n",
      "(9, 'metrohm.csv')\n",
      "(10, 'anton_785.csv')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "if True:\n",
    "    path = \"/kaggle/input/dig-4-bio-raman-transfer-learning-challenge\"\n",
    "    files = os.listdir(path)\n",
    "    [print((i, files[i])) for i in range(len(files))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "748ea179-9ff5-4979-b9ce-76c9bec9410e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    hf_token = \"xhf_XURkoNhwOIPtEdHfNeRpVkjEwKSkhtigFi\"\n",
    "    path = hf_ds_download(hf_token, \"ArbaazBeg/kaggle-spectogram\")\n",
    "    files = os.listdir(path)\n",
    "    [(i, files[i]) for i in range(len(files))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "62074de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "def load_comp_data(filepath, is_train=True):\n",
    "    \"\"\"Load and preprocess the Raman spectroscopy data\"\"\"\n",
    "    if is_train:\n",
    "        df = pd.read_csv(filepath)\n",
    "        # Extract target variables\n",
    "        target_cols = ['Glucose (g/L)', 'Sodium Acetate (g/L)', 'Magnesium Acetate (g/L)']\n",
    "        y = df[target_cols].dropna().values\n",
    "        \n",
    "        # Process spectral data\n",
    "        X = df.iloc[:, :-4] # Remove last 4 columns (analyte info and targets)\n",
    "    else:\n",
    "        df = pd.read_csv(filepath, header=None)\n",
    "        X = df\n",
    "        y = None\n",
    "    \n",
    "    # Set column names\n",
    "    X.columns = [\"sample_id\"] + [str(i) for i in range(X.shape[1]-1)]\n",
    "    \n",
    "    # Fill sample_id using forward fill\n",
    "    X['sample_id'] = X['sample_id'].ffill()\n",
    "    \n",
    "    # Clean sample_id\n",
    "    if is_train:\n",
    "        X['sample_id'] = X['sample_id'].str.strip()\n",
    "    else:\n",
    "        X['sample_id'] = X['sample_id'].str.strip().str.replace('sample', '').astype(int)\n",
    "    \n",
    "    # Clean spectral data (remove brackets)\n",
    "    spectral_cols = X.columns[1:]\n",
    "    for col in spectral_cols:\n",
    "        X[col] = X[col].astype(str).str.replace('[', '', regex=False).str.replace(']', '', regex=False)\n",
    "        X[col] = pd.to_numeric(X[col], errors='coerce')\n",
    "\n",
    "    return X, y\n",
    "\n",
    "\n",
    "def fix_val_test_shape(X):\n",
    "    lower_wns = 300\n",
    "    upper_wns = 1942\n",
    "    joint_wns = np.arange(lower_wns, upper_wns + 1)\n",
    "    spectral_values = np.linspace(65, 3350, 2048)\n",
    "\n",
    "    spectra_selection = np.logical_and(\n",
    "        lower_wns <= spectral_values, spectral_values <= upper_wns,\n",
    "    )\n",
    "    wns = spectral_values[spectra_selection]\n",
    "    X = X[:, spectra_selection]\n",
    "    X = np.array([np.interp(joint_wns, xp=wns, fp=spectrum,)for spectrum in X])\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e86f5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs, targets = load_comp_data(os.path.join(path, 'transfer_plate.csv'), is_train=True)\n",
    "test_inputs, _ = load_comp_data(os.path.join(path, '96_samples.csv'), is_train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "824359e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = inputs.drop('sample_id', axis=1).values.reshape(-1, 2, 2048).mean(axis=1)\n",
    "test_inputs = test_inputs.drop('sample_id', axis=1).values.reshape(-1, 2, 2048).mean(axis=1)\n",
    "\n",
    "inputs = fix_val_test_shape(inputs)\n",
    "test_inputs = fix_val_test_shape(test_inputs)\n",
    "\n",
    "# Version 2 Update: Normalise Val and Test data like Train\n",
    "inputs = inputs / np.max(inputs)\n",
    "test_inputs = test_inputs / np.max(test_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e66bd721",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[46 94 50 93  1 44 35 78 71  3 75 40 39 18 45 95  6 55 26 56 42 92 53 76\n",
      " 85 73 82 68 15 23 80 12 38 86 11 19 63 16 14 25 21 37 59 57 90 30 27 47\n",
      " 91 69 89  4 60 33 36  2  5 10 64 54  8 67 87 84 81 17 13 70 66 32 41 49\n",
      " 58 24 34 31 74 61  9 83 48 72 22 51 20 88 52 29 28 62 79 65  0 77  7 43]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((96, 1643), (96, 3), (96, 1643))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = np.random.permutation(inputs.shape[0])\n",
    "print(idx)\n",
    "inputs = inputs[idx]\n",
    "targets = targets[idx]\n",
    "\n",
    "inputs.shape, targets.shape, test_inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4ba2c070",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import scipy.optimize\n",
    "\n",
    "\n",
    "np_dtype_from_torch = {\n",
    "    torch.float32: np.float32,\n",
    "    torch.float64: np.float64,\n",
    "}\n",
    "\n",
    "class SpectralDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        spectra,\n",
    "        concentrations,\n",
    "        dtype=None,\n",
    "        spectra_mean_std=None,\n",
    "        concentration_mean_std=None,\n",
    "        combine_spectra_range=0.0,\n",
    "        baseline_factor_bound=0.0,\n",
    "        baseline_period_lower_bound=100.0,\n",
    "        baseline_period_upper_bound=200.0,\n",
    "        augment_slope_std=0.0,\n",
    "        augment_intersept_std=0.0,\n",
    "        rolling_bound=0,\n",
    "        spectrum_rolling_sigma=0.0,\n",
    "        augmentation_weight=0.1,\n",
    "        original_datapoint_weight=1.,\n",
    "    ):\n",
    "        self.dtype = dtype or torch.float32\n",
    "        self.combine_spectra_range = combine_spectra_range\n",
    "        self.baseline_factor_bound = baseline_factor_bound\n",
    "        self.augment_slope_std = augment_slope_std\n",
    "        self.augment_intercept_std = augment_intersept_std\n",
    "        self.baseline_period_lower_bound = baseline_period_lower_bound\n",
    "        self.baseline_period_upper_bound = baseline_period_upper_bound\n",
    "        self.rolling_bound = rolling_bound\n",
    "        self.spectrum_rolling_sigma = spectrum_rolling_sigma\n",
    "        self.augmentation_weight = torch.tensor(augmentation_weight, dtype=dtype)\n",
    "        self.original_dp_weight = original_datapoint_weight\n",
    "\n",
    "        # normalize spectra\n",
    "        spectra = torch.tensor(spectra, dtype=dtype)\n",
    "\n",
    "        if spectra_mean_std is None:\n",
    "            self.s_mean = torch.mean(spectra)\n",
    "            self.s_std = torch.std(spectra)\n",
    "        else:\n",
    "            self.s_mean, self.s_std = spectra_mean_std\n",
    "\n",
    "        self.spectra = torch.divide(\n",
    "            torch.subtract(spectra, self.s_mean),\n",
    "            self.s_std,\n",
    "        )\n",
    "\n",
    "        self.dummy_wns = np.tile(\n",
    "            np.arange(\n",
    "                0., 1., 1. / self.spectra.shape[2],\n",
    "                dtype=np_dtype_from_torch[self.dtype]\n",
    "            )[None, :self.spectra.shape[2]],\n",
    "            (self.spectra.shape[1], 1),\n",
    "        )\n",
    "\n",
    "        # normalize concentrations\n",
    "        concentrations = torch.tensor(concentrations, dtype=dtype)\n",
    "        if concentration_mean_std is None:\n",
    "            self.concentration_means = torch.nanmean(concentrations, dim=0)\n",
    "\n",
    "            self.concentration_stds = torch.maximum(\n",
    "                torch.tensor(\n",
    "                    [\n",
    "                        torch.std(col[torch.logical_not(torch.isnan(col))])\n",
    "                        for col in concentrations.T\n",
    "                    ]\n",
    "                ),\n",
    "                torch.tensor([1e-3] * concentrations.shape[1]),\n",
    "            )\n",
    "        else:\n",
    "            self.concentration_means = concentration_mean_std[0]\n",
    "            self.concentration_stds = concentration_mean_std[1]\n",
    "\n",
    "        self.concentrations = torch.divide(\n",
    "            torch.subtract(\n",
    "                concentrations,\n",
    "                self.concentration_means,\n",
    "            ),\n",
    "            self.concentration_stds,\n",
    "        )\n",
    "\n",
    "    def pick_two(self, max_idx=None):\n",
    "        max_idx = max_idx or len(self)\n",
    "        return random.choices(range(max_idx), k=2)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.concentrations)\n",
    "\n",
    "    def augment_spectra(self, spectra):\n",
    "        if self.augment_slope_std > 0.0:\n",
    "\n",
    "            def spectrum_approximation(x, slope, intercept):\n",
    "                return (slope * x + intercept).reshape(-1, 1)[:, 0]\n",
    "\n",
    "            slope, inter = scipy.optimize.curve_fit(\n",
    "                spectrum_approximation,\n",
    "                self.dummy_wns,\n",
    "                spectra.reshape(-1, 1)[:, 0],\n",
    "                p0=np.random.rand(2),\n",
    "            )[0]\n",
    "\n",
    "            new_slope = slope * (\n",
    "                    np.random.gamma(\n",
    "                        shape=1. / self.augment_slope_std,\n",
    "                        scale=self.augment_slope_std,\n",
    "                        size=1,\n",
    "                    )\n",
    "            )[0]\n",
    "            new_intercept = inter * (\n",
    "                1.0 + np.random.randn(1) * self.augment_intercept_std\n",
    "            )[0]\n",
    "            spectra += torch.tensor(\n",
    "                (new_slope - slope)\n",
    "            ) * self.dummy_wns + new_intercept - inter\n",
    "\n",
    "        factor = self.baseline_factor_bound * torch.rand(size=(1,))\n",
    "        offset = torch.rand(size=(1,)) * 2.0 * torch.pi\n",
    "        period = self.baseline_period_lower_bound + (\n",
    "            self.baseline_period_upper_bound - self.baseline_period_lower_bound\n",
    "        ) * torch.rand(size=(1,))\n",
    "        permutations = factor * torch.cos(\n",
    "            2.0 * torch.pi / period * self.dummy_wns + offset\n",
    "        )\n",
    "        return self.roll_spectrum(\n",
    "            spectra + permutations * spectra,\n",
    "            delta=random.randint(-self.rolling_bound, self.rolling_bound),\n",
    "        )\n",
    "\n",
    "    def roll_spectrum(self, spectra, delta):\n",
    "        num_spectra = spectra.shape[0]\n",
    "        rolled_spectra = np.roll(spectra, delta, axis=1)\n",
    "        if delta > 0:\n",
    "            rolled_spectra[:, :delta] = (\n",
    "                np.random.rand(num_spectra, delta) * self.spectrum_rolling_sigma + 1\n",
    "            ) * rolled_spectra[:, delta:(delta + 1)]\n",
    "        elif delta < 0:\n",
    "            rolled_spectra[:, delta:] = (\n",
    "                np.random.rand(num_spectra, -delta) * self.spectrum_rolling_sigma + 1\n",
    "            ) * rolled_spectra[:, delta - 1:delta]\n",
    "        return rolled_spectra\n",
    "\n",
    "    def combine_k_items(self, indices, weights):\n",
    "        return (\n",
    "            # spectra\n",
    "            torch.sum(\n",
    "                torch.mul(weights[:, None, None], self.spectra[indices, :, :]),\n",
    "                dim=0,\n",
    "            ),\n",
    "            # concentrations\n",
    "            torch.sum(\n",
    "                torch.mul(weights[:, None], self.concentrations[indices, :]),\n",
    "                dim=0,\n",
    "            )\n",
    "        )\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.combine_spectra_range < 1e-12:\n",
    "            spectrum = self.spectra[idx]\n",
    "            spectrum = self.augment_spectra(spectrum)\n",
    "            return (\n",
    "                spectrum,\n",
    "                self.concentrations[idx],\n",
    "                torch.tensor(1.0, dtype=self.dtype),\n",
    "            )\n",
    "        else:\n",
    "            if random.random() < self.original_dp_weight:\n",
    "                one_weight = 1.\n",
    "                label_weight = torch.tensor(1.0, dtype=self.dtype)\n",
    "            else:\n",
    "                one_weight = random.uniform(0.0, self.combine_spectra_range)\n",
    "                label_weight = self.augmentation_weight\n",
    "            weights = torch.tensor([one_weight, (1 - one_weight)])\n",
    "            # just pick two random indices\n",
    "            indices = random.choices(range(len(self)), k=2)\n",
    "\n",
    "            mixed_spectra, mixed_concentrations = self.combine_k_items(\n",
    "                indices=indices,\n",
    "                weights=weights,\n",
    "            )\n",
    "            mixed_spectra = self.augment_spectra(mixed_spectra)\n",
    "            return mixed_spectra, mixed_concentrations, label_weight\n",
    "\n",
    "\n",
    "config = {\n",
    "    'initial_cnn_channels': 32,\n",
    "    'cnn_channel_factor': 1.279574024454846,\n",
    "    'num_cnn_layers': 8,\n",
    "    'kernel_size': 3,\n",
    "    'stride': 2,\n",
    "    'activation_function': 'ELU',\n",
    "    'fc_dropout': 0.10361700399831791,\n",
    "    'lr': 0.001,\n",
    "    'gamma': 0.9649606352621118,\n",
    "    'baseline_factor_bound': 0.748262317340447,\n",
    "    'baseline_period_lower_bound': 0.9703081695287203,\n",
    "    'baseline_period_span': 19.79744237606427,\n",
    "    'original_datapoint_weight': 0.4335003268130408,\n",
    "    'augment_slope_std': 0.08171025264382692,\n",
    "    'batch_size': 32,\n",
    "    'fc_dims': 226,\n",
    "    'rolling_bound': 2,\n",
    "    'num_blocks': 2,\n",
    "}\n",
    "\n",
    "def get_dataset(inputs, targets, config, inputs_mean_std=None, targets_mean_std=None):\n",
    "    return SpectralDataset(\n",
    "        spectra=inputs[:, None, :],\n",
    "        concentrations=targets,\n",
    "        dtype=torch.float32,\n",
    "        spectra_mean_std=inputs_mean_std,\n",
    "        concentration_mean_std=targets_mean_std,\n",
    "        combine_spectra_range=1.0,\n",
    "        baseline_factor_bound=config[\"baseline_factor_bound\"],\n",
    "        baseline_period_lower_bound=config[\"baseline_period_lower_bound\"],\n",
    "        baseline_period_upper_bound=(config[\"baseline_period_lower_bound\"] + config[\"baseline_period_span\"]),\n",
    "        augment_slope_std=config[\"augment_slope_std\"],\n",
    "        augment_intersept_std=0.0,\n",
    "        rolling_bound=config[\"rolling_bound\"],\n",
    "        spectrum_rolling_sigma=0.01,\n",
    "        augmentation_weight=0.1,\n",
    "        original_datapoint_weight=1.,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9c11034d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "def build_loader(\n",
    "    SEED,\n",
    "    ds,\n",
    "    train=True,\n",
    "    batch_size=1,\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    "    drop_last=True,\n",
    "    pin_memory=True,\n",
    "    persistent_workers=False,\n",
    "):\n",
    "    def seed_worker(worker_id):\n",
    "        worker_seed = torch.initial_seed() % 2**32\n",
    "        np.random.seed(worker_seed)\n",
    "        random.seed(worker_seed)\n",
    "\n",
    "    generator = torch.Generator()\n",
    "    generator.manual_seed(SEED if train else SEED+5232)\n",
    "\n",
    "    return DataLoader(\n",
    "        ds,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=pin_memory,\n",
    "        drop_last=drop_last,\n",
    "        persistent_workers=persistent_workers,\n",
    "        worker_init_fn=seed_worker,\n",
    "        generator=generator,\n",
    "        #sampler=DistributedSampler(\n",
    "        #    train_ds,\n",
    "        #    shuffle=True,\n",
    "        #    drop_last=True,\n",
    "        #    seed=config.seed\n",
    "        #)\n",
    "    )\n",
    "    \n",
    "    \n",
    "def return_dls(train_ds, eval_ds, train_batch_size, eval_batch_size):\n",
    "    train_dl = build_loader(\n",
    "        SEED,\n",
    "        train_ds,\n",
    "        train=True,\n",
    "        batch_size=train_batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=0,\n",
    "        drop_last=False,\n",
    "        pin_memory=True,\n",
    "        persistent_workers=False,\n",
    "    )\n",
    "\n",
    "    eval_dl = build_loader(\n",
    "        SEED,\n",
    "        eval_ds,\n",
    "        train=False,\n",
    "        batch_size=eval_batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=0,\n",
    "        drop_last=False,\n",
    "        pin_memory=True,\n",
    "        persistent_workers=False,\n",
    "    )\n",
    "    \n",
    "    return train_dl, eval_dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e343398b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import neptune\n",
    "\n",
    "\n",
    "def setup_neptune():\n",
    "    if not RESUME:\n",
    "        neptune_run = neptune.init_run(\n",
    "            project=\"arbaaz/kaggle-spect\",\n",
    "            name=MODEL_NAME,\n",
    "            api_token=\"eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiJlOGE2YjNiZS1mZGUyLTRjYjItYTg5Yy1mZWJkZTIzNzE1NmIifQ==\"\n",
    "        )\n",
    "\n",
    "        neptune_run[\"h_parameters\"] = {\n",
    "            \"seed\": SEED,\n",
    "            \"model_name\": MODEL_NAME,\n",
    "            \"optimizer_name\": \"nadam\",\n",
    "            \"learning_rate\": LR,\n",
    "            \"scheduler_name\": \"default\",\n",
    "            \"weight_decay\": WD,\n",
    "            \"num_epochs\": EPOCHS,\n",
    "            \"batch_size\": BATCH_SIZE,\n",
    "        }\n",
    "        if DROPOUT: neptune_run[\"h_parameters\"] = {\"dropout\": DROPOUT}\n",
    "        if DROP_PATH_RATE: neptune_run[\"h_parameters\"] = {\"drop_path_rate\": DROP_PATH_RATE}\n",
    "    else:\n",
    "        neptune_run = neptune.init_run(\n",
    "            project=\"arbaaz/crunchdao-structural-break\",\n",
    "            with_id=config.with_id,\n",
    "            api_token=\"eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiJlOGE2YjNiZS1mZGUyLTRjYjItYTg5Yy1mZWJkZTIzNzE1NmIifQ==\"\n",
    "        )\n",
    "\n",
    "    return neptune_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d4227b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "from torch.nn.modules.loss import _Loss\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "\n",
    "def loss_fn(logits, targets):\n",
    "    logits = logits.view(-1)\n",
    "    targets = targets.view(-1)\n",
    "    return F.mse_loss(logits, targets)\n",
    "\n",
    "\n",
    "def metric_fn(logits, targets):\n",
    "    preds = logits.cpu().detach().float().numpy()\n",
    "    targets = targets.cpu().detach().float().numpy()\n",
    "    \n",
    "    dim1 = r2_score(targets[:, 0], preds[:, 0])\n",
    "    dim2 = r2_score(targets[:, 1], preds[:, 1])\n",
    "    dim3 = r2_score(targets[:, 2], preds[:, 2])\n",
    "    \n",
    "    return dim1, dim2, dim3, r2_score(targets, preds)\n",
    "\n",
    "\n",
    "class MSEIgnoreNans(_Loss):\n",
    "    def forward(\n",
    "        self,\n",
    "        input: torch.Tensor,\n",
    "        target: torch.Tensor,\n",
    "        weights: torch.Tensor,\n",
    "    ) -> torch.Tensor:\n",
    "        mask = torch.isfinite(target)\n",
    "        mse = torch.mean(\n",
    "            torch.mul(\n",
    "                torch.square(input[mask] - target[mask]),\n",
    "                torch.tile(weights[:, None], dims=(1, target.shape[1]))[mask],\n",
    "            )\n",
    "        )\n",
    "        return torch.where(\n",
    "            torch.isfinite(mse),\n",
    "            mse,\n",
    "            torch.tensor(0.).to(target.device),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6ccc0a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "\n",
    "class Identity(torch.torch.nn.Module):\n",
    "    def forward(self, x):\n",
    "        return x\n",
    "\n",
    "\n",
    "# this is not a resnet yet\n",
    "class ReZeroBlock(torch.torch.nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels,\n",
    "        out_channels,\n",
    "        activation_function,\n",
    "        kernel_size,\n",
    "        stride,\n",
    "        dtype,\n",
    "        norm_layer=None,\n",
    "    ):\n",
    "        super(ReZeroBlock, self).__init__()\n",
    "        if norm_layer is None:\n",
    "            norm_layer = torch.torch.nn.BatchNorm1d\n",
    "\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        self.padding = divmod(kernel_size, 2)[0] if stride == 1 else 0\n",
    "\n",
    "        # does not change spatial dimension\n",
    "        self.conv1 = torch.nn.Conv1d(\n",
    "            in_channels,\n",
    "            out_channels,\n",
    "            kernel_size=1,\n",
    "            stride=1,\n",
    "            bias=False,\n",
    "            dtype=dtype,\n",
    "        )\n",
    "        self.bn1 = norm_layer(out_channels, dtype=dtype)\n",
    "        # Both self.conv2 and self.downsample layers\n",
    "        # downsample the input when stride != 1\n",
    "        self.conv2 = torch.nn.Conv1d(\n",
    "            out_channels,\n",
    "            out_channels,\n",
    "            kernel_size=kernel_size,\n",
    "            stride=stride,\n",
    "            groups=out_channels,\n",
    "            bias=False,\n",
    "            dtype=dtype,\n",
    "            padding=self.padding,\n",
    "        )\n",
    "        if stride > 1:\n",
    "            down_conv = torch.nn.Conv1d(\n",
    "                in_channels,\n",
    "                out_channels,\n",
    "                kernel_size=kernel_size,\n",
    "                stride=stride,\n",
    "                bias=False,\n",
    "                dtype=dtype,\n",
    "                # groups=out_channels,\n",
    "            )\n",
    "        else:\n",
    "            down_conv = Identity()\n",
    "\n",
    "        self.down_sample = torch.nn.Sequential(\n",
    "            down_conv,\n",
    "            norm_layer(out_channels),\n",
    "        )\n",
    "        self.bn2 = norm_layer(out_channels, dtype=dtype)\n",
    "        # does not change the spatial dimension\n",
    "        self.conv3 = torch.nn.Conv1d(\n",
    "            out_channels,\n",
    "            out_channels,\n",
    "            kernel_size=1,\n",
    "            stride=1,\n",
    "            bias=False,\n",
    "            dtype=dtype,\n",
    "        )\n",
    "        self.bn3 = norm_layer(out_channels, dtype=dtype)\n",
    "        self.activation = activation_function(inplace=True)\n",
    "        self.factor = torch.torch.nn.parameter.Parameter(torch.tensor(0.0, dtype=dtype))\n",
    "\n",
    "    def next_spatial_dim(self, last_spatial_dim):\n",
    "        return math.floor(\n",
    "            (last_spatial_dim + 2 * self.padding - self.kernel_size)\n",
    "            / self.stride + 1\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.activation(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.activation(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        # not really the identity, but kind of\n",
    "        identity = self.down_sample(x)\n",
    "\n",
    "        return self.activation(out * self.factor + identity)\n",
    "\n",
    "\n",
    "class ResNetEncoder(torch.torch.nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        spectrum_size,\n",
    "        cnn_encoder_channel_dims,\n",
    "        activation_function,\n",
    "        kernel_size,\n",
    "        stride,\n",
    "        dtype,\n",
    "        num_blocks,\n",
    "        verbose=False,\n",
    "    ):\n",
    "        super(ResNetEncoder, self).__init__()\n",
    "\n",
    "        self.spatial_dims = [spectrum_size]\n",
    "        layers = []\n",
    "        for in_channels, out_channels in zip(\n",
    "            cnn_encoder_channel_dims[:-1],\n",
    "            cnn_encoder_channel_dims[1:],\n",
    "        ):\n",
    "            block = ReZeroBlock(\n",
    "                in_channels=in_channels,\n",
    "                out_channels=out_channels,\n",
    "                activation_function=activation_function,\n",
    "                kernel_size=kernel_size,\n",
    "                stride=stride,\n",
    "                dtype=dtype,\n",
    "            )\n",
    "            layers.append(block)\n",
    "            self.spatial_dims.append(block.next_spatial_dim(self.spatial_dims[-1]))\n",
    "            for _ in range(num_blocks - 1):\n",
    "                block = ReZeroBlock(\n",
    "                    in_channels=out_channels,\n",
    "                    out_channels=out_channels,\n",
    "                    activation_function=activation_function,\n",
    "                    kernel_size=kernel_size,\n",
    "                    stride=1,\n",
    "                    dtype=dtype,\n",
    "                )\n",
    "                layers.append(block)\n",
    "                self.spatial_dims.append(block.next_spatial_dim(self.spatial_dims[-1]))\n",
    "\n",
    "        self.resnet_layers = torch.torch.nn.Sequential(*layers)\n",
    "        if verbose:\n",
    "            print(\"CNN Encoder Channel Dims: %s\" % (cnn_encoder_channel_dims))\n",
    "            print(\"CNN Encoder Spatial Dims: %s\" % (self.spatial_dims))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.resnet_layers(x)\n",
    "\n",
    "\n",
    "class ReZeroNet(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        spectra_channels,\n",
    "        spectra_size,\n",
    "        initial_cnn_channels,\n",
    "        cnn_channel_factor,\n",
    "        num_cnn_layers,\n",
    "        kernel_size,\n",
    "        stride,\n",
    "        activation_function,\n",
    "        fc_dims,\n",
    "        fc_dropout=0.0,\n",
    "        dtype=None,\n",
    "        verbose=False,\n",
    "        fc_output_channels=1,\n",
    "        num_blocks=1,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.fc_output_channels = fc_output_channels\n",
    "        self.dtype = dtype or torch.float32\n",
    "\n",
    "        activation_function = getattr(torch.nn, activation_function)\n",
    "\n",
    "        # Setup CNN Encoder\n",
    "        cnn_encoder_channel_dims = [spectra_channels] + [\n",
    "            int(initial_cnn_channels * (cnn_channel_factor**idx))\n",
    "            for idx in range(num_cnn_layers)\n",
    "        ]\n",
    "        self.cnn_encoder = ResNetEncoder(\n",
    "            spectrum_size=spectra_size,\n",
    "            cnn_encoder_channel_dims=cnn_encoder_channel_dims,\n",
    "            activation_function=activation_function,\n",
    "            kernel_size=kernel_size,\n",
    "            stride=stride,\n",
    "            num_blocks=num_blocks,\n",
    "            dtype=dtype,\n",
    "            verbose=verbose,\n",
    "        )\n",
    "        self.fc_dims = [\n",
    "            int(\n",
    "                self.cnn_encoder.spatial_dims[-1]\n",
    "            ) * int(cnn_encoder_channel_dims[-1])\n",
    "        ] + fc_dims\n",
    "\n",
    "        if verbose:\n",
    "            print(\"Fc Dims: %s\" % self.fc_dims)\n",
    "        fc_layers = []\n",
    "        for idx, (in_dim, out_dim) in enumerate(\n",
    "                zip(self.fc_dims[:-2], self.fc_dims[1:-1])\n",
    "        ):\n",
    "            fc_layers.append(torch.nn.Linear(in_dim, out_dim))\n",
    "            fc_layers.append(torch.nn.ELU())\n",
    "            fc_layers.append(torch.nn.Dropout(fc_dropout / (2 ** idx)))\n",
    "        fc_layers.append(\n",
    "            torch.nn.Linear(\n",
    "                self.fc_dims[-2],\n",
    "                self.fc_dims[-1] * self.fc_output_channels,\n",
    "            ),\n",
    "        )\n",
    "        self.fc_net = torch.nn.Sequential(*fc_layers)\n",
    "        if verbose:\n",
    "            num_params = sum(p.numel() for p in self.parameters())\n",
    "            print(\"Number of Parameters: %s\" % num_params)\n",
    "\n",
    "    def forward(self, spectra):\n",
    "        embeddings = self.cnn_encoder(spectra)\n",
    "        forecast = self.fc_net(embeddings.view(-1, self.fc_dims[0]))\n",
    "        if self.fc_output_channels > 1:\n",
    "            forecast = forecast.reshape(\n",
    "                -1, self.fc_output_channels, self.fc_dims[-1]\n",
    "            )\n",
    "        return forecast\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b7cf6c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "\n",
    "\n",
    "class ResZeroBlock(torch.nn.Module):\n",
    "    def __init__(self, skip_part, model_part):\n",
    "        super(ResZeroBlock, self).__init__()\n",
    "        self.skip_part = skip_part\n",
    "        self.model_part = model_part\n",
    "        self.factor = torch.nn.parameter.Parameter(torch.tensor(0.))\n",
    "\n",
    "    def forward(self, X):\n",
    "        return self.skip_part(X) + self.factor * self.model_part(X)\n",
    "\n",
    "\n",
    "class Identity(torch.nn.Module):\n",
    "    def forward(self, X):\n",
    "        return X\n",
    "\n",
    "\n",
    "class RamanXception(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        spectra_size,\n",
    "        initial_channels,\n",
    "        entry_channels,\n",
    "        num_mid_blocks,\n",
    "        exit_channels,\n",
    "        num_concentrations,\n",
    "        fc_dims,\n",
    "        fc_dropout,\n",
    "        lower_bounds=None,\n",
    "        dtype=None,\n",
    "        activation_function='ReLU',\n",
    "        classification_idx=None,\n",
    "        verbose=False,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super(RamanXception, self).__init__()\n",
    "\n",
    "        self.classification_idx = classification_idx or num_concentrations\n",
    "\n",
    "        if lower_bounds is None:\n",
    "            self.lower_bounds = torch.nn.parameter.Parameter(\n",
    "                torch.tensor([-1000] * num_concentrations),\n",
    "                requires_grad=False,\n",
    "            )\n",
    "        else:\n",
    "            self.lower_bounds = torch.nn.parameter.Parameter(\n",
    "                lower_bounds,\n",
    "                requires_grad=False,\n",
    "            )\n",
    "        dtype = dtype or torch.float32\n",
    "        activation_function = getattr(torch.nn, activation_function)\n",
    "        self.spatial_dimensions = [spectra_size]\n",
    "\n",
    "        # setup initial layers\n",
    "        initial_layers = torch.nn.Sequential()\n",
    "        for idx, (in_channels, out_channels) in enumerate(\n",
    "            zip(\n",
    "                [1] + initial_channels[:-1],\n",
    "                initial_channels,\n",
    "            ),\n",
    "        ):\n",
    "            initial_layers.add_module(\n",
    "                'initial_%s' % idx,\n",
    "                torch.nn.Conv1d(\n",
    "                    in_channels,\n",
    "                    out_channels,\n",
    "                    kernel_size=3,\n",
    "                    stride=2,\n",
    "                    padding=1,\n",
    "                    dtype=dtype,\n",
    "                    bias=False,\n",
    "                ),\n",
    "            )\n",
    "            self.spatial_dimensions.append(\n",
    "                math.floor((self.spatial_dimensions[-1] - 1) / 2 + 1)\n",
    "            )\n",
    "            initial_layers.add_module(\n",
    "                'initial_batch_%s' % idx,\n",
    "                torch.nn.BatchNorm1d(\n",
    "                    out_channels,\n",
    "                    dtype=dtype,\n",
    "                ),\n",
    "            )\n",
    "            initial_layers.add_module(\n",
    "                'initial_activation_%s' % idx,\n",
    "                activation_function(),\n",
    "            )\n",
    "\n",
    "        # Entry flow\n",
    "        entry_flow = torch.nn.Sequential()\n",
    "        # self.entry_flow_length = len(entry_channels)\n",
    "        for idx, (in_channels, out_channels) in enumerate(\n",
    "            zip(\n",
    "                [initial_channels[-1]] + entry_channels[:-1],\n",
    "                entry_channels,\n",
    "            )\n",
    "        ):\n",
    "            entry_flow.add_module(\n",
    "                name='entry_flow_%s' % idx,\n",
    "                module=ResZeroBlock(\n",
    "                    skip_part=torch.nn.Conv1d(\n",
    "                        in_channels,\n",
    "                        out_channels,\n",
    "                        kernel_size=1,\n",
    "                        stride=2,\n",
    "                        dtype=dtype,\n",
    "                        bias=False,\n",
    "                    ),\n",
    "                    model_part=torch.nn.Sequential(\n",
    "                        activation_function(),\n",
    "                        # spatial dimension stays constant\n",
    "                        torch.nn.Conv1d(\n",
    "                            in_channels,\n",
    "                            in_channels,\n",
    "                            kernel_size=1,\n",
    "                            dtype=dtype,\n",
    "                            bias=False,\n",
    "                        ),\n",
    "                        torch.nn.Conv1d(\n",
    "                            in_channels,\n",
    "                            in_channels,\n",
    "                            kernel_size=3,\n",
    "                            groups=in_channels,\n",
    "                            padding=1,\n",
    "                            dtype=dtype,\n",
    "                            bias=False,\n",
    "                        ),\n",
    "                        # spatial dimension stays constant\n",
    "                        torch.nn.BatchNorm1d(\n",
    "                            in_channels,\n",
    "                            dtype=dtype,\n",
    "                        ),\n",
    "                        activation_function(),\n",
    "                        torch.nn.Conv1d(\n",
    "                            in_channels,\n",
    "                            out_channels,\n",
    "                            kernel_size=1,\n",
    "                            dtype=dtype,\n",
    "                            bias=False,\n",
    "                        ),\n",
    "                        torch.nn.Conv1d(\n",
    "                            out_channels,\n",
    "                            out_channels,\n",
    "                            kernel_size=3,\n",
    "                            groups=out_channels,\n",
    "                            padding=1,\n",
    "                            dtype=dtype,\n",
    "                            bias=False,\n",
    "                        ),\n",
    "                        torch.nn.BatchNorm1d(\n",
    "                            out_channels,\n",
    "                            dtype=dtype,\n",
    "                        ),\n",
    "                        # spatial dimension: in_dim / 2\n",
    "                        torch.nn.MaxPool1d(3, stride=2, padding=1),\n",
    "                    )\n",
    "                ),\n",
    "            )\n",
    "            self.spatial_dimensions.append(\n",
    "                math.floor((self.spatial_dimensions[-1] - 1) / 2 + 1)\n",
    "            )\n",
    "\n",
    "        # Middle flow\n",
    "        num_mid_channels = entry_channels[-1]\n",
    "        middle_flow = torch.nn.Sequential()\n",
    "        for idx in range(num_mid_blocks):\n",
    "            middle_flow.add_module(\n",
    "                name='middle_flow_%s' % idx,\n",
    "                module=ResZeroBlock(\n",
    "                    skip_part=Identity(),\n",
    "                    model_part=torch.nn.Sequential(\n",
    "                        activation_function(),\n",
    "                        torch.nn.Conv1d(\n",
    "                            num_mid_channels,\n",
    "                            num_mid_channels,\n",
    "                            kernel_size=1,\n",
    "                            dtype=dtype,\n",
    "                            bias=False,\n",
    "                        ),\n",
    "                        torch.nn.Conv1d(\n",
    "                            num_mid_channels,\n",
    "                            num_mid_channels,\n",
    "                            kernel_size=3,\n",
    "                            groups=num_mid_channels,\n",
    "                            padding=1,\n",
    "                            dtype=dtype,\n",
    "                            bias=False,\n",
    "                        ),\n",
    "                        torch.nn.BatchNorm1d(\n",
    "                            num_mid_channels,\n",
    "                            dtype=dtype,\n",
    "                        ),\n",
    "                        activation_function(),\n",
    "                        torch.nn.Conv1d(\n",
    "                            num_mid_channels,\n",
    "                            num_mid_channels,\n",
    "                            kernel_size=1,\n",
    "                            dtype=dtype,\n",
    "                            bias=False,\n",
    "                        ),\n",
    "                        torch.nn.Conv1d(\n",
    "                            num_mid_channels,\n",
    "                            num_mid_channels,\n",
    "                            kernel_size=3,\n",
    "                            groups=num_mid_channels,\n",
    "                            padding=1,\n",
    "                            dtype=dtype,\n",
    "                            bias=False,\n",
    "                        ),\n",
    "                        torch.nn.BatchNorm1d(\n",
    "                            num_mid_channels,\n",
    "                            dtype=dtype,\n",
    "                        ),\n",
    "                        activation_function(),\n",
    "                        torch.nn.Conv1d(\n",
    "                            num_mid_channels,\n",
    "                            num_mid_channels,\n",
    "                            kernel_size=1,\n",
    "                            dtype=dtype,\n",
    "                            bias=False,\n",
    "                        ),\n",
    "                        torch.nn.Conv1d(\n",
    "                            num_mid_channels,\n",
    "                            num_mid_channels,\n",
    "                            kernel_size=3,\n",
    "                            groups=num_mid_channels,\n",
    "                            padding=1,\n",
    "                            dtype=dtype,\n",
    "                            bias=False,\n",
    "                        ),\n",
    "                    )\n",
    "                )\n",
    "            )\n",
    "            self.spatial_dimensions.append(self.spatial_dimensions[-1])\n",
    "\n",
    "        exit_flow = torch.nn.Sequential()\n",
    "        for idx, (in_channels, (mid_channels, out_channels)) in enumerate(list(\n",
    "            zip(\n",
    "                [num_mid_channels] + [out for _, out in exit_channels[:-2]],\n",
    "                exit_channels[:-1],\n",
    "            ),\n",
    "        )):\n",
    "            exit_flow.add_module(\n",
    "                name='exit_flow_%s' % idx,\n",
    "                module=ResZeroBlock(\n",
    "                    skip_part=torch.nn.Conv1d(\n",
    "                        in_channels,\n",
    "                        out_channels,\n",
    "                        kernel_size=1,\n",
    "                        stride=2,\n",
    "                        dtype=dtype,\n",
    "                        bias=False,\n",
    "                    ),\n",
    "                    model_part=torch.nn.Sequential(\n",
    "                        torch.nn.Conv1d(\n",
    "                            in_channels,\n",
    "                            mid_channels,\n",
    "                            kernel_size=1,\n",
    "                            dtype=dtype,\n",
    "                            bias=False,\n",
    "                        ),\n",
    "                        torch.nn.Conv1d(\n",
    "                            mid_channels,\n",
    "                            mid_channels,\n",
    "                            kernel_size=3,\n",
    "                            groups=mid_channels,\n",
    "                            padding=1,\n",
    "                            dtype=dtype,\n",
    "                            bias=False,\n",
    "                        ),\n",
    "                        torch.nn.BatchNorm1d(\n",
    "                            mid_channels,\n",
    "                            dtype=dtype,\n",
    "                        ),\n",
    "                        activation_function(),\n",
    "                        torch.nn.Conv1d(\n",
    "                            mid_channels,\n",
    "                            out_channels,\n",
    "                            kernel_size=1,\n",
    "                            dtype=dtype,\n",
    "                            bias=False,\n",
    "                        ),\n",
    "                        torch.nn.Conv1d(\n",
    "                            out_channels,\n",
    "                            out_channels,\n",
    "                            kernel_size=3,\n",
    "                            groups=out_channels,\n",
    "                            padding=1,\n",
    "                            dtype=dtype,\n",
    "                            bias=False,\n",
    "                        ),\n",
    "                        torch.nn.BatchNorm1d(\n",
    "                            out_channels,\n",
    "                            dtype=dtype,\n",
    "                        ),\n",
    "                        activation_function(),\n",
    "                        torch.nn.MaxPool1d(\n",
    "                            kernel_size=3,\n",
    "                            stride=2,\n",
    "                            padding=1,\n",
    "                        ),\n",
    "                    )\n",
    "                )\n",
    "            )\n",
    "            self.spatial_dimensions.append(\n",
    "                math.floor((self.spatial_dimensions[-1] - 1) / 2 + 1)\n",
    "            )\n",
    "\n",
    "        # Last part of the exit flow\n",
    "        in_channels = exit_channels[-2][1]\n",
    "        mid_channels = exit_channels[-1][0]\n",
    "        out_channels = exit_channels[-1][1]\n",
    "        final_flow = torch.nn.Sequential(\n",
    "            torch.nn.Conv1d(\n",
    "                in_channels,\n",
    "                mid_channels,\n",
    "                kernel_size=1,\n",
    "                dtype=dtype,\n",
    "                bias=False,\n",
    "            ),\n",
    "            torch.nn.Conv1d(\n",
    "                mid_channels,\n",
    "                mid_channels,\n",
    "                kernel_size=3,\n",
    "                groups=mid_channels,\n",
    "                padding=1,\n",
    "                dtype=dtype,\n",
    "                bias=False,\n",
    "            ),\n",
    "            torch.nn.BatchNorm1d(\n",
    "                mid_channels,\n",
    "                dtype=dtype,\n",
    "            ),\n",
    "            activation_function(),\n",
    "            torch.nn.Conv1d(\n",
    "                mid_channels,\n",
    "                out_channels,\n",
    "                kernel_size=1,\n",
    "                dtype=dtype,\n",
    "            ),\n",
    "            torch.nn.Conv1d(\n",
    "                out_channels,\n",
    "                out_channels,\n",
    "                kernel_size=3,\n",
    "                groups=out_channels,\n",
    "                padding=1,\n",
    "                dtype=dtype,\n",
    "            ),\n",
    "            torch.nn.BatchNorm1d(\n",
    "                out_channels,\n",
    "                dtype=dtype,\n",
    "            ),\n",
    "            activation_function(),\n",
    "        )\n",
    "        self.conv_net = torch.nn.Sequential(\n",
    "            initial_layers,\n",
    "            entry_flow,\n",
    "            middle_flow,\n",
    "            exit_flow,\n",
    "            final_flow,\n",
    "        )\n",
    "\n",
    "        self.fc_input_dim = int(out_channels * self.spatial_dimensions[-1])\n",
    "        self.fc_net = torch.nn.Sequential()\n",
    "        for idx, (in_dim, out_dim) in enumerate(\n",
    "            zip(\n",
    "                [self.fc_input_dim] + fc_dims[:-1],\n",
    "                fc_dims,\n",
    "            )\n",
    "        ):\n",
    "            self.fc_net.add_module(\n",
    "                'fc_net_%s' % idx,\n",
    "                torch.nn.Linear(\n",
    "                    in_dim,\n",
    "                    out_dim,\n",
    "                    dtype=dtype,\n",
    "                    bias=True,\n",
    "                ),\n",
    "            )\n",
    "            self.fc_net.add_module(\n",
    "                'fc_relu_%s' % idx,\n",
    "                torch.nn.ReLU(),\n",
    "            )\n",
    "            self.fc_net.add_module(\n",
    "                'fc_dropout_%s' % idx,\n",
    "                torch.nn.Dropout(fc_dropout),\n",
    "            )\n",
    "\n",
    "        self.fc_net.add_module(\n",
    "            'output_layer',\n",
    "            torch.nn.Linear(\n",
    "                fc_dims[-1] if fc_dims else out_channels,\n",
    "                num_concentrations,\n",
    "                dtype=dtype,\n",
    "                bias=True,\n",
    "            ),\n",
    "        )\n",
    "        self.softplus = torch.nn.Softplus()\n",
    "        if verbose:\n",
    "            print('Spatial dimensions: %s' % self.spatial_dimensions)\n",
    "            print(\n",
    "                'Fully Connected dimensions %s' % (\n",
    "                        [self.fc_input_dim] + fc_dims\n",
    "                )\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_net(x)\n",
    "\n",
    "        fc_output = self.fc_net(torch.reshape(x, (-1, self.fc_input_dim)))\n",
    "        return torch.concat(\n",
    "            [\n",
    "                fc_output[:, :self.classification_idx],\n",
    "                torch.sigmoid(fc_output[:, self.classification_idx:])\n",
    "            ],\n",
    "            dim=1,\n",
    "        )\n",
    "\n",
    "\n",
    "model_config = {\n",
    "    'initial_channels': 8,\n",
    "    'entry_channels_start': 17,\n",
    "    'channel_factor': 1.5692504144354933,\n",
    "    'entry_exit_length': 3,\n",
    "    'num_mid_blocks': 4,\n",
    "    'fc_dims': 101,\n",
    "    'fc_dropout': 0.11748964300948816,\n",
    "    'learning_rate': 0.001,\n",
    "    'gamma': 0.9921697445978254,\n",
    "    'batch_size': 21,\n",
    "    'entropy_weight': 6.441421425536572,\n",
    "    'uniform_sampling_range': 0.03803705551872033,\n",
    "    'activation_function': 'ELU', \n",
    "    'fake_weight': 0.032878013410751736,\n",
    "    'just_scale_concentrations': True,\n",
    "    'entry_factor': 1.5692504144354933,\n",
    "    'exit_factor': 1.5692504144354933,\n",
    "    'entry_length': 3,\n",
    "    'exit_length': 3,\n",
    "    'spectra_size': 1643,\n",
    "    'dtype': torch.float32}\n",
    "\n",
    "lr = model_config.get('learning_rate')\n",
    "l2_reg = model_config.get('l2_reg', 0.)\n",
    "gamma = model_config.get('gamma', 1.)\n",
    "model_config['initial_channels'] = [\n",
    "    model_config['initial_channels'],\n",
    "    2 * model_config['initial_channels'],\n",
    "]\n",
    "# create entry channel dimensions\n",
    "entry_channels_start = model_config['entry_channels_start']\n",
    "entry_factor = model_config['entry_factor']\n",
    "entry_length = model_config['entry_length']\n",
    "entry_channels = [entry_channels_start]\n",
    "for _ in range(entry_length):\n",
    "    entry_channels.append(int(entry_factor * entry_channels[-1]))\n",
    "model_config['entry_channels'] = entry_channels\n",
    "# create exit channel dimensions\n",
    "exit_channels_start = entry_channels[-1]\n",
    "exit_factor = model_config.get('exit_factor')\n",
    "exit_length = model_config.get('exit_length')\n",
    "exit_channels = [\n",
    "    (\n",
    "        int(exit_channels_start * math.sqrt(exit_factor)),\n",
    "        int(exit_channels_start * exit_factor),\n",
    "    )\n",
    "]\n",
    "for _ in range(1, exit_length):\n",
    "    exit_channels.append(\n",
    "        (\n",
    "            int(exit_channels[-1][0] * math.sqrt(exit_factor)),\n",
    "            int(exit_channels[-1][0] * exit_factor),\n",
    "        )\n",
    "    )\n",
    "model_config['exit_channels'] = exit_channels\n",
    "model_config[\"num_concnetrations\"] = 3\n",
    "model_config['fc_dims'] = [config['fc_dims']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "035dd91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "def train(\n",
    "    model, \n",
    "    optimizer,\n",
    "    device,\n",
    "    amp_dtype,\n",
    "    scheduler,\n",
    "    train_dl,\n",
    "    eval_dl,\n",
    "    loss_fn,\n",
    "    epochs,\n",
    "    checkpoint_name,\n",
    "    score=-float(\"inf\"),\n",
    "    neptune_run=None,\n",
    "    p=True,\n",
    "):  \n",
    "    scaler = torch.amp.GradScaler(device)\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "        all_logits = []\n",
    "        all_targets = []\n",
    "        \n",
    "        for inputs, targets, weights in train_dl:\n",
    "            inputs = inputs.to(device, non_blocking=True)\n",
    "            targets = targets.to(device, non_blocking=True)\n",
    "            weights = weights.to(device, non_blocking=True)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            with torch.amp.autocast(device_type=device, dtype=amp_dtype, cache_enabled=True):\n",
    "                logits = model(inputs)\n",
    "                loss = loss_fn(logits, targets)\n",
    "                  \n",
    "            if amp_dtype == torch.bfloat16:                \n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            else:\n",
    "                scaler.scale(loss).backward()\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "\n",
    "            scheduler.step()\n",
    "            if neptune_run is not None:  neptune_run[\"lr_step\"].append(scheduler.get_last_lr()[0])\n",
    "            \n",
    "            total_loss += loss.detach().cpu()\n",
    "            all_logits.append(logits.detach().cpu())\n",
    "            all_targets.append(targets.detach().cpu())\n",
    "        \n",
    "        all_logits = torch.cat(all_logits)\n",
    "        all_targets = torch.cat(all_targets)\n",
    "\n",
    "        one, two, three, r2 = metric_fn(all_logits, all_targets)\n",
    "        total_loss = total_loss / len(train_dl)\n",
    "        \n",
    "        model.eval()\n",
    "        eval_total_loss = 0.0\n",
    "        eval_all_logits = []\n",
    "        eval_all_targets = []\n",
    "\n",
    "        for inputs, targets, weights in eval_dl:\n",
    "            inputs = inputs.to(device, non_blocking=True)\n",
    "            targets = targets.to(device, non_blocking=True)\n",
    "            weights = weights.to(device, non_blocking=True)\n",
    "\n",
    "            with torch.inference_mode():\n",
    "                with torch.amp.autocast(device_type=device, dtype=amp_dtype, cache_enabled=True):\n",
    "                    logits = model(inputs)\n",
    "                    loss = loss_fn(logits, targets)\n",
    "\n",
    "            eval_total_loss += loss.detach().cpu()\n",
    "            eval_all_logits.append(logits.detach().cpu())\n",
    "            eval_all_targets.append(targets.detach().cpu())\n",
    "        \n",
    "        eval_all_logits = torch.cat(eval_all_logits)\n",
    "        eval_all_targets = torch.cat(eval_all_targets)\n",
    "\n",
    "        eval_one, eval_two, eval_three, eval_r2 = metric_fn(eval_all_logits, eval_all_targets)\n",
    "        eval_total_loss = eval_total_loss / len(eval_dl)\n",
    "        \n",
    "        if eval_r2 > score:\n",
    "            score = eval_r2\n",
    "            data = {\"state_dict\": model.state_dict()}\n",
    "            data[\"epoch\"] = epoch \n",
    "            data[\"score\"] = score\n",
    "            torch.save(data, f\"/kaggle/working/{checkpoint_name}\")\n",
    "        \n",
    "        if neptune_run is not None:\n",
    "            neptune_run[\"train/loss\"].append(total_loss)\n",
    "            neptune_run[\"eval/loss\"].append(eval_total_loss)\n",
    "            neptune_run[\"train/r2\"].append(r2)\n",
    "            neptune_run[\"eval/r2\"].append(eval_r2)\n",
    "            neptune_run[\"train/one\"].append(one)\n",
    "            neptune_run[\"train/two\"].append(two)\n",
    "            neptune_run[\"train/three\"].append(three)\n",
    "            neptune_run[\"eval/one\"].append(eval_one)\n",
    "            neptune_run[\"eval/two\"].append(eval_two)\n",
    "            neptune_run[\"eval/three\"].append(eval_three)\n",
    "            \n",
    "        if p and epoch % 5 == 0:\n",
    "            print(\n",
    "                f\"Epoch: {epoch}, \"\n",
    "                f\"train/loss: {total_loss:.4f}, \"\n",
    "                f\"eval/loss: {eval_total_loss:.4f}, \"\n",
    "                f\"train/r2: {r2:.4f}, \"\n",
    "                f\"eval/r2: {eval_r2:.4f}, \"\n",
    "                f\"train/one: {one:.4f}, \"\n",
    "                f\"train/two: {two:.4f}, \"\n",
    "                f\"train/three: {three:.4f}, \"\n",
    "                f\"eval/one: {eval_one:.4f}, \"\n",
    "                f\"eval/two: {eval_two:.4f}, \"\n",
    "                f\"eval/three: {eval_three:.4f} \"\n",
    "            )\n",
    "            \n",
    "    if neptune_run is not None: neptune_run.stop()\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8dd5d0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 100\n",
    "WD = 1e-3\n",
    "LR = 1e-4\n",
    "\n",
    "DROPOUT = 0.5\n",
    "DROP_PATH_RATE = None\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "RESUME = False\n",
    "\n",
    "if False:\n",
    "    config[\"dtype\"] = torch.float32\n",
    "    config[\"spectra_size\"] = 1643\n",
    "    config[\"spectra_channels\"] = 1\n",
    "    config[\"fc_dims\"] = [\n",
    "        config[\"fc_dims\"],\n",
    "        int(config[\"fc_dims\"] / 2),\n",
    "        3,\n",
    "    ]\n",
    "\n",
    "    #mse_loss_function = MSEIgnoreNans()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "54dd678c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8677010776545604\n",
      "0.387266\n",
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a77605e902904c16b2a567f3386d80c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:227: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, train/loss: 1.7703, eval/loss: 2.9935, train/r2: -0.7029, eval/r2: -1.5814, train/one: -1.6054, train/two: -0.1867, train/three: -0.3165, eval/one: -4.4234, eval/two: -0.0723, eval/three: -0.2484 \n",
      "Epoch: 5, train/loss: 0.9517, eval/loss: 0.8543, train/r2: -0.0419, eval/r2: 0.0105, train/one: -0.2099, train/two: 0.0502, train/three: 0.0342, eval/one: -0.1065, eval/two: 0.1620, eval/three: -0.0240 \n",
      "Epoch: 10, train/loss: 0.5830, eval/loss: 0.6283, train/r2: 0.2983, eval/r2: 0.3195, train/one: 0.2889, train/two: 0.3026, train/three: 0.3033, eval/one: 0.4313, eval/two: 0.3029, eval/three: 0.2244 \n",
      "Epoch: 15, train/loss: 0.4886, eval/loss: 0.3265, train/r2: 0.4979, eval/r2: 0.6538, train/one: 0.4865, train/two: 0.2753, train/three: 0.7320, eval/one: 0.6146, eval/two: 0.6066, eval/three: 0.7400 \n",
      "Epoch: 20, train/loss: 0.2606, eval/loss: 0.2113, train/r2: 0.7319, eval/r2: 0.7373, train/one: 0.7225, train/two: 0.6749, train/three: 0.7982, eval/one: 0.8166, eval/two: 0.7001, eval/three: 0.6952 \n",
      "Epoch: 25, train/loss: 0.2060, eval/loss: 0.1876, train/r2: 0.7747, eval/r2: 0.8230, train/one: 0.8225, train/two: 0.7079, train/three: 0.7938, eval/one: 0.8305, eval/two: 0.8048, eval/three: 0.8336 \n",
      "Epoch: 30, train/loss: 0.1710, eval/loss: 0.2291, train/r2: 0.8195, eval/r2: 0.6706, train/one: 0.8450, train/two: 0.7795, train/three: 0.8339, eval/one: 0.6602, eval/two: 0.6124, eval/three: 0.7392 \n",
      "Epoch: 35, train/loss: 0.1059, eval/loss: 0.1279, train/r2: 0.9003, eval/r2: 0.8497, train/one: 0.9226, train/two: 0.8906, train/three: 0.8878, eval/one: 0.8868, eval/two: 0.8425, eval/three: 0.8197 \n",
      "Epoch: 40, train/loss: 0.1349, eval/loss: 0.1260, train/r2: 0.8369, eval/r2: 0.7639, train/one: 0.8456, train/two: 0.8490, train/three: 0.8160, eval/one: 0.7249, eval/two: 0.7951, eval/three: 0.7717 \n",
      "Epoch: 45, train/loss: 0.1452, eval/loss: 0.2218, train/r2: 0.8408, eval/r2: 0.7712, train/one: 0.7686, train/two: 0.8732, train/three: 0.8806, eval/one: 0.7349, eval/two: 0.8496, eval/three: 0.7292 \n",
      "Epoch: 50, train/loss: 0.1167, eval/loss: 0.1387, train/r2: 0.8886, eval/r2: 0.8125, train/one: 0.8724, train/two: 0.8957, train/three: 0.8977, eval/one: 0.6462, eval/two: 0.9238, eval/three: 0.8676 \n",
      "Epoch: 55, train/loss: 0.1109, eval/loss: 0.1379, train/r2: 0.8744, eval/r2: 0.8122, train/one: 0.8797, train/two: 0.9177, train/three: 0.8256, eval/one: 0.7877, eval/two: 0.8380, eval/three: 0.8109 \n",
      "Epoch: 60, train/loss: 0.1019, eval/loss: 0.1747, train/r2: 0.8963, eval/r2: 0.8259, train/one: 0.9008, train/two: 0.8954, train/three: 0.8926, eval/one: 0.8060, eval/two: 0.9087, eval/three: 0.7630 \n",
      "Epoch: 65, train/loss: 0.0985, eval/loss: 0.1926, train/r2: 0.8960, eval/r2: 0.7688, train/one: 0.8910, train/two: 0.9170, train/three: 0.8801, eval/one: 0.7833, eval/two: 0.7807, eval/three: 0.7424 \n",
      "Epoch: 70, train/loss: 0.1009, eval/loss: 0.1422, train/r2: 0.8963, eval/r2: 0.8625, train/one: 0.8835, train/two: 0.9055, train/three: 0.8997, eval/one: 0.9278, eval/two: 0.8079, eval/three: 0.8518 \n",
      "Epoch: 75, train/loss: 0.0953, eval/loss: 0.1179, train/r2: 0.9066, eval/r2: 0.8450, train/one: 0.9172, train/two: 0.8913, train/three: 0.9115, eval/one: 0.8679, eval/two: 0.7971, eval/three: 0.8700 \n",
      "Epoch: 80, train/loss: 0.0920, eval/loss: 0.1284, train/r2: 0.9040, eval/r2: 0.8245, train/one: 0.9105, train/two: 0.9131, train/three: 0.8884, eval/one: 0.8432, eval/two: 0.9035, eval/three: 0.7267 \n",
      "Epoch: 85, train/loss: 0.0957, eval/loss: 0.0845, train/r2: 0.9132, eval/r2: 0.8039, train/one: 0.9171, train/two: 0.9115, train/three: 0.9110, eval/one: 0.9194, eval/two: 0.9193, eval/three: 0.5730 \n",
      "Epoch: 90, train/loss: 0.0737, eval/loss: 0.1759, train/r2: 0.9240, eval/r2: 0.8255, train/one: 0.9115, train/two: 0.9326, train/three: 0.9281, eval/one: 0.8007, eval/two: 0.8752, eval/three: 0.8006 \n",
      "Epoch: 95, train/loss: 0.0880, eval/loss: 0.1082, train/r2: 0.9234, eval/r2: 0.8650, train/one: 0.9146, train/two: 0.9283, train/three: 0.9272, eval/one: 0.8994, eval/two: 0.8968, eval/three: 0.7987 \n",
      "0.8677010776545604\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7945f827ab3487bb466a1cb087e3ffa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:227: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, train/loss: 1.8612, eval/loss: 2.6675, train/r2: -0.6327, eval/r2: -1.5498, train/one: -1.2103, train/two: -0.4120, train/three: -0.2758, eval/one: -3.8225, eval/two: -0.4438, eval/three: -0.3830 \n",
      "Epoch: 5, train/loss: 0.9617, eval/loss: 1.0663, train/r2: -0.1122, eval/r2: 0.0337, train/one: -0.3532, train/two: 0.0752, train/three: -0.0586, eval/one: 0.0954, eval/two: -0.0336, eval/three: 0.0394 \n",
      "Epoch: 10, train/loss: 0.6948, eval/loss: 0.8885, train/r2: 0.2531, eval/r2: -0.0048, train/one: 0.2419, train/two: 0.2303, train/three: 0.2872, eval/one: 0.3088, eval/two: -0.2830, eval/three: -0.0403 \n",
      "Epoch: 15, train/loss: 0.4951, eval/loss: 0.4469, train/r2: 0.5505, eval/r2: 0.5411, train/one: 0.5013, train/two: 0.5180, train/three: 0.6323, eval/one: 0.5832, eval/two: 0.4491, eval/three: 0.5909 \n",
      "Epoch: 20, train/loss: 0.2905, eval/loss: 0.2731, train/r2: 0.7006, eval/r2: 0.7260, train/one: 0.6989, train/two: 0.7265, train/three: 0.6764, eval/one: 0.8420, eval/two: 0.5290, eval/three: 0.8069 \n",
      "Epoch: 25, train/loss: 0.2748, eval/loss: 0.2524, train/r2: 0.7166, eval/r2: 0.6806, train/one: 0.7400, train/two: 0.6321, train/three: 0.7777, eval/one: 0.8562, eval/two: 0.4048, eval/three: 0.7808 \n",
      "Epoch: 30, train/loss: 0.2024, eval/loss: 0.1913, train/r2: 0.8104, eval/r2: 0.8070, train/one: 0.7290, train/two: 0.8521, train/three: 0.8501, eval/one: 0.8641, eval/two: 0.6910, eval/three: 0.8660 \n",
      "Epoch: 35, train/loss: 0.1384, eval/loss: 0.1689, train/r2: 0.8489, eval/r2: 0.8058, train/one: 0.8150, train/two: 0.8766, train/three: 0.8552, eval/one: 0.8706, eval/two: 0.6861, eval/three: 0.8608 \n",
      "Epoch: 40, train/loss: 0.1458, eval/loss: 0.1322, train/r2: 0.8584, eval/r2: 0.8367, train/one: 0.8657, train/two: 0.8689, train/three: 0.8405, eval/one: 0.9193, eval/two: 0.6608, eval/three: 0.9299 \n",
      "Epoch: 45, train/loss: 0.1637, eval/loss: 0.1285, train/r2: 0.8547, eval/r2: 0.8619, train/one: 0.8673, train/two: 0.8419, train/three: 0.8549, eval/one: 0.8725, eval/two: 0.7618, eval/three: 0.9514 \n",
      "Epoch: 50, train/loss: 0.1264, eval/loss: 0.1514, train/r2: 0.8645, eval/r2: 0.8299, train/one: 0.8922, train/two: 0.8725, train/three: 0.8289, eval/one: 0.9628, eval/two: 0.9311, eval/three: 0.5958 \n",
      "Epoch: 55, train/loss: 0.1121, eval/loss: 0.0995, train/r2: 0.8666, eval/r2: 0.9165, train/one: 0.8845, train/two: 0.8568, train/three: 0.8586, eval/one: 0.9633, eval/two: 0.8578, eval/three: 0.9283 \n",
      "Epoch: 60, train/loss: 0.1110, eval/loss: 0.0785, train/r2: 0.9000, eval/r2: 0.9251, train/one: 0.8966, train/two: 0.9165, train/three: 0.8868, eval/one: 0.9519, eval/two: 0.9056, eval/three: 0.9179 \n",
      "Epoch: 65, train/loss: 0.1090, eval/loss: 0.0908, train/r2: 0.8721, eval/r2: 0.8978, train/one: 0.9068, train/two: 0.8661, train/three: 0.8434, eval/one: 0.9249, eval/two: 0.9210, eval/three: 0.8475 \n",
      "Epoch: 70, train/loss: 0.0997, eval/loss: 0.1186, train/r2: 0.8977, eval/r2: 0.8961, train/one: 0.8857, train/two: 0.9091, train/three: 0.8982, eval/one: 0.9251, eval/two: 0.8207, eval/three: 0.9427 \n",
      "Epoch: 75, train/loss: 0.0989, eval/loss: 0.0693, train/r2: 0.8945, eval/r2: 0.9252, train/one: 0.8676, train/two: 0.9072, train/three: 0.9088, eval/one: 0.9444, eval/two: 0.9333, eval/three: 0.8980 \n",
      "Epoch: 80, train/loss: 0.1263, eval/loss: 0.0725, train/r2: 0.8646, eval/r2: 0.9302, train/one: 0.8220, train/two: 0.9083, train/three: 0.8634, eval/one: 0.9421, eval/two: 0.9349, eval/three: 0.9137 \n",
      "Epoch: 85, train/loss: 0.0969, eval/loss: 0.0900, train/r2: 0.8999, eval/r2: 0.8870, train/one: 0.8966, train/two: 0.8966, train/three: 0.9067, eval/one: 0.9417, eval/two: 0.8109, eval/three: 0.9082 \n",
      "Epoch: 90, train/loss: 0.1134, eval/loss: 0.0679, train/r2: 0.8876, eval/r2: 0.9237, train/one: 0.8796, train/two: 0.9087, train/three: 0.8746, eval/one: 0.9644, eval/two: 0.8842, eval/three: 0.9226 \n",
      "Epoch: 95, train/loss: 0.1036, eval/loss: 0.0977, train/r2: 0.8983, eval/r2: 0.8868, train/one: 0.9099, train/two: 0.9253, train/three: 0.8597, eval/one: 0.9475, eval/two: 0.8356, eval/three: 0.8773 \n",
      "0.8677010776545604\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53eef9bad95b4da7bfabefd8dced2925",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:227: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, train/loss: 1.8972, eval/loss: 1.6707, train/r2: -0.6862, eval/r2: -2.5519, train/one: -1.3036, train/two: -0.4470, train/three: -0.3081, eval/one: -7.3637, eval/two: -0.2364, eval/three: -0.0555 \n",
      "Epoch: 5, train/loss: 0.9632, eval/loss: 1.2183, train/r2: -0.0705, eval/r2: -0.8829, train/one: -0.2137, train/two: 0.0857, train/three: -0.0836, eval/one: -1.7208, eval/two: -0.8027, eval/three: -0.1254 \n",
      "Epoch: 10, train/loss: 0.7184, eval/loss: 0.7959, train/r2: 0.2567, eval/r2: 0.0682, train/one: 0.2693, train/two: 0.2760, train/three: 0.2248, eval/one: 0.2332, eval/two: -0.1583, eval/three: 0.1296 \n",
      "Epoch: 15, train/loss: 0.5323, eval/loss: 0.5001, train/r2: 0.4757, eval/r2: 0.4309, train/one: 0.4311, train/two: 0.4466, train/three: 0.5494, eval/one: 0.3217, eval/two: 0.4645, eval/three: 0.5063 \n",
      "Epoch: 20, train/loss: 0.3334, eval/loss: 0.3865, train/r2: 0.6777, eval/r2: 0.5514, train/one: 0.6154, train/two: 0.7020, train/three: 0.7157, eval/one: 0.6399, eval/two: 0.4936, eval/three: 0.5207 \n",
      "Epoch: 25, train/loss: 0.2658, eval/loss: 0.2168, train/r2: 0.7341, eval/r2: 0.7452, train/one: 0.7939, train/two: 0.6768, train/three: 0.7317, eval/one: 0.9140, eval/two: 0.5999, eval/three: 0.7216 \n",
      "Epoch: 30, train/loss: 0.2015, eval/loss: 0.2282, train/r2: 0.8153, eval/r2: 0.7785, train/one: 0.8209, train/two: 0.8664, train/three: 0.7585, eval/one: 0.8794, eval/two: 0.5578, eval/three: 0.8982 \n",
      "Epoch: 35, train/loss: 0.1935, eval/loss: 0.3086, train/r2: 0.8224, eval/r2: 0.5661, train/one: 0.8520, train/two: 0.8203, train/three: 0.7948, eval/one: 0.3339, eval/two: 0.7371, eval/three: 0.6274 \n",
      "Epoch: 40, train/loss: 0.1333, eval/loss: 0.1889, train/r2: 0.8540, eval/r2: 0.8260, train/one: 0.8522, train/two: 0.8244, train/three: 0.8854, eval/one: 0.9066, eval/two: 0.7228, eval/three: 0.8487 \n",
      "Epoch: 45, train/loss: 0.1175, eval/loss: 0.1159, train/r2: 0.8602, eval/r2: 0.8549, train/one: 0.8603, train/two: 0.8540, train/three: 0.8662, eval/one: 0.8371, eval/two: 0.8962, eval/three: 0.8313 \n",
      "Epoch: 50, train/loss: 0.1281, eval/loss: 0.1500, train/r2: 0.8701, eval/r2: 0.8006, train/one: 0.8694, train/two: 0.9071, train/three: 0.8338, eval/one: 0.7186, eval/two: 0.8640, eval/three: 0.8192 \n",
      "Epoch: 55, train/loss: 0.1274, eval/loss: 0.1791, train/r2: 0.8440, eval/r2: 0.7362, train/one: 0.9042, train/two: 0.8097, train/three: 0.8182, eval/one: 0.5644, eval/two: 0.8734, eval/three: 0.7710 \n",
      "Epoch: 60, train/loss: 0.1141, eval/loss: 0.1340, train/r2: 0.8811, eval/r2: 0.8141, train/one: 0.8707, train/two: 0.8658, train/three: 0.9068, eval/one: 0.9050, eval/two: 0.6927, eval/three: 0.8446 \n",
      "Epoch: 65, train/loss: 0.1276, eval/loss: 0.1494, train/r2: 0.8658, eval/r2: 0.8451, train/one: 0.8992, train/two: 0.8734, train/three: 0.8248, eval/one: 0.8768, eval/two: 0.8913, eval/three: 0.7672 \n",
      "Epoch: 70, train/loss: 0.0945, eval/loss: 0.1465, train/r2: 0.8919, eval/r2: 0.8278, train/one: 0.8992, train/two: 0.9028, train/three: 0.8737, eval/one: 0.7618, eval/two: 0.7955, eval/three: 0.9261 \n",
      "Epoch: 75, train/loss: 0.0840, eval/loss: 0.1392, train/r2: 0.9082, eval/r2: 0.8327, train/one: 0.8950, train/two: 0.9353, train/three: 0.8943, eval/one: 0.8179, eval/two: 0.8939, eval/three: 0.7864 \n",
      "Epoch: 80, train/loss: 0.1036, eval/loss: 0.1455, train/r2: 0.8910, eval/r2: 0.8428, train/one: 0.9094, train/two: 0.8924, train/three: 0.8710, eval/one: 0.8580, eval/two: 0.8669, eval/three: 0.8035 \n",
      "Epoch: 85, train/loss: 0.0943, eval/loss: 0.0899, train/r2: 0.9122, eval/r2: 0.8747, train/one: 0.9203, train/two: 0.9069, train/three: 0.9094, eval/one: 0.7701, eval/two: 0.9279, eval/three: 0.9261 \n",
      "Epoch: 90, train/loss: 0.0859, eval/loss: 0.1370, train/r2: 0.9122, eval/r2: 0.8564, train/one: 0.9270, train/two: 0.8843, train/three: 0.9251, eval/one: 0.8265, eval/two: 0.8173, eval/three: 0.9253 \n",
      "Epoch: 95, train/loss: 0.0893, eval/loss: 0.0934, train/r2: 0.9153, eval/r2: 0.8720, train/one: 0.9127, train/two: 0.9272, train/three: 0.9060, eval/one: 0.9254, eval/two: 0.9158, eval/three: 0.7750 \n",
      "0.8677010776545604\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7edcb749d65e4488b42139b593c7ccb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:227: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, train/loss: 1.6995, eval/loss: 2.1554, train/r2: -0.7637, eval/r2: -1.0256, train/one: -1.6945, train/two: -0.3533, train/three: -0.2433, eval/one: -2.6626, eval/two: -0.0313, eval/three: -0.3830 \n",
      "Epoch: 5, train/loss: 1.0303, eval/loss: 1.1282, train/r2: -0.1196, eval/r2: -0.1614, train/one: -0.5024, train/two: 0.1082, train/three: 0.0355, eval/one: -0.3951, eval/two: -0.1840, eval/three: 0.0948 \n",
      "Epoch: 10, train/loss: 0.6554, eval/loss: 0.6008, train/r2: 0.3110, eval/r2: 0.2188, train/one: 0.2353, train/two: 0.3478, train/three: 0.3498, eval/one: 0.0945, eval/two: 0.2583, eval/three: 0.3036 \n",
      "Epoch: 15, train/loss: 0.3738, eval/loss: 0.6078, train/r2: 0.5808, eval/r2: 0.4767, train/one: 0.5337, train/two: 0.5926, train/three: 0.6161, eval/one: 0.4930, eval/two: 0.3199, eval/three: 0.6172 \n",
      "Epoch: 20, train/loss: 0.2654, eval/loss: 0.2446, train/r2: 0.7336, eval/r2: 0.6166, train/one: 0.6793, train/two: 0.7672, train/three: 0.7545, eval/one: 0.3734, eval/two: 0.7499, eval/three: 0.7264 \n",
      "Epoch: 25, train/loss: 0.2316, eval/loss: 0.2725, train/r2: 0.7535, eval/r2: 0.7190, train/one: 0.7594, train/two: 0.7225, train/three: 0.7786, eval/one: 0.6185, eval/two: 0.6974, eval/three: 0.8409 \n",
      "Epoch: 30, train/loss: 0.1700, eval/loss: 0.1895, train/r2: 0.8080, eval/r2: 0.8149, train/one: 0.7962, train/two: 0.8083, train/three: 0.8194, eval/one: 0.6995, eval/two: 0.8971, eval/three: 0.8480 \n",
      "Epoch: 35, train/loss: 0.1570, eval/loss: 0.1368, train/r2: 0.8412, eval/r2: 0.8730, train/one: 0.8095, train/two: 0.8568, train/three: 0.8574, eval/one: 0.8179, eval/two: 0.8821, eval/three: 0.9190 \n",
      "Epoch: 40, train/loss: 0.1481, eval/loss: 0.1818, train/r2: 0.8596, eval/r2: 0.8444, train/one: 0.8520, train/two: 0.8508, train/three: 0.8760, eval/one: 0.7330, eval/two: 0.9199, eval/three: 0.8804 \n",
      "Epoch: 45, train/loss: 0.1346, eval/loss: 0.1696, train/r2: 0.8618, eval/r2: 0.8186, train/one: 0.8660, train/two: 0.8626, train/three: 0.8568, eval/one: 0.7405, eval/two: 0.8514, eval/three: 0.8641 \n",
      "Epoch: 50, train/loss: 0.1195, eval/loss: 0.1457, train/r2: 0.8773, eval/r2: 0.8826, train/one: 0.8838, train/two: 0.8572, train/three: 0.8908, eval/one: 0.8885, eval/two: 0.9334, eval/three: 0.8257 \n",
      "Epoch: 55, train/loss: 0.1207, eval/loss: 0.1161, train/r2: 0.8838, eval/r2: 0.8994, train/one: 0.9300, train/two: 0.8648, train/three: 0.8565, eval/one: 0.8310, eval/two: 0.9455, eval/three: 0.9217 \n",
      "Epoch: 60, train/loss: 0.1270, eval/loss: 0.0990, train/r2: 0.8846, eval/r2: 0.9006, train/one: 0.8688, train/two: 0.8770, train/three: 0.9080, eval/one: 0.8745, eval/two: 0.9171, eval/three: 0.9100 \n",
      "Epoch: 65, train/loss: 0.1296, eval/loss: 0.0808, train/r2: 0.8578, eval/r2: 0.9111, train/one: 0.8970, train/two: 0.8284, train/three: 0.8478, eval/one: 0.8586, eval/two: 0.9441, eval/three: 0.9307 \n",
      "Epoch: 70, train/loss: 0.0996, eval/loss: 0.1575, train/r2: 0.9112, eval/r2: 0.8650, train/one: 0.9211, train/two: 0.9099, train/three: 0.9026, eval/one: 0.7770, eval/two: 0.9432, eval/three: 0.8749 \n",
      "Epoch: 75, train/loss: 0.0952, eval/loss: 0.0952, train/r2: 0.9066, eval/r2: 0.9075, train/one: 0.8993, train/two: 0.9044, train/three: 0.9162, eval/one: 0.8807, eval/two: 0.9143, eval/three: 0.9274 \n",
      "Epoch: 80, train/loss: 0.0952, eval/loss: 0.1044, train/r2: 0.9031, eval/r2: 0.9092, train/one: 0.8981, train/two: 0.8884, train/three: 0.9227, eval/one: 0.9035, eval/two: 0.9047, eval/three: 0.9194 \n",
      "Epoch: 85, train/loss: 0.1177, eval/loss: 0.0879, train/r2: 0.8619, eval/r2: 0.9074, train/one: 0.8562, train/two: 0.8726, train/three: 0.8569, eval/one: 0.9264, eval/two: 0.8723, eval/three: 0.9234 \n",
      "Epoch: 90, train/loss: 0.1135, eval/loss: 0.1070, train/r2: 0.9060, eval/r2: 0.8970, train/one: 0.8979, train/two: 0.9143, train/three: 0.9058, eval/one: 0.8836, eval/two: 0.9185, eval/three: 0.8889 \n",
      "Epoch: 95, train/loss: 0.1196, eval/loss: 0.1540, train/r2: 0.8778, eval/r2: 0.8831, train/one: 0.8876, train/two: 0.8409, train/three: 0.9050, eval/one: 0.7988, eval/two: 0.9344, eval/three: 0.9161 \n",
      "0.8677010776545604\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8fb4fe2ee87445780c419accfeea4dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:227: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, train/loss: 1.8601, eval/loss: 2.8769, train/r2: -0.8884, eval/r2: -2.4564, train/one: -1.8338, train/two: -0.5886, train/three: -0.2428, eval/one: -3.3452, eval/two: -3.8927, eval/three: -0.1313 \n",
      "Epoch: 5, train/loss: 0.9643, eval/loss: 0.9405, train/r2: 0.0293, eval/r2: -0.1875, train/one: -0.1276, train/two: 0.1693, train/three: 0.0461, eval/one: -0.0072, eval/two: -0.1930, eval/three: -0.3623 \n",
      "Epoch: 10, train/loss: 0.6148, eval/loss: 0.9453, train/r2: 0.3772, eval/r2: -0.2252, train/one: 0.3948, train/two: 0.4265, train/three: 0.3103, eval/one: -0.0033, eval/two: -0.9131, eval/three: 0.2407 \n",
      "Epoch: 15, train/loss: 0.3795, eval/loss: 0.4057, train/r2: 0.6341, eval/r2: 0.3728, train/one: 0.6689, train/two: 0.6303, train/three: 0.6032, eval/one: 0.5684, eval/two: -0.1815, eval/three: 0.7316 \n",
      "Epoch: 20, train/loss: 0.2682, eval/loss: 0.2783, train/r2: 0.7292, eval/r2: 0.5316, train/one: 0.7202, train/two: 0.7163, train/three: 0.7512, eval/one: 0.6839, eval/two: 0.5294, eval/three: 0.3816 \n",
      "Epoch: 25, train/loss: 0.2174, eval/loss: 0.2326, train/r2: 0.8015, eval/r2: 0.6532, train/one: 0.7708, train/two: 0.7882, train/three: 0.8454, eval/one: 0.7547, eval/two: 0.4147, eval/three: 0.7901 \n",
      "Epoch: 30, train/loss: 0.1441, eval/loss: 0.2096, train/r2: 0.8500, eval/r2: 0.7047, train/one: 0.8631, train/two: 0.8306, train/three: 0.8563, eval/one: 0.6941, eval/two: 0.5423, eval/three: 0.8778 \n",
      "Epoch: 35, train/loss: 0.1344, eval/loss: 0.2482, train/r2: 0.8531, eval/r2: 0.6777, train/one: 0.8900, train/two: 0.8046, train/three: 0.8647, eval/one: 0.9117, eval/two: 0.3368, eval/three: 0.7846 \n",
      "Epoch: 40, train/loss: 0.1305, eval/loss: 0.1499, train/r2: 0.8648, eval/r2: 0.7556, train/one: 0.8957, train/two: 0.8294, train/three: 0.8694, eval/one: 0.7230, eval/two: 0.7202, eval/three: 0.8235 \n",
      "Epoch: 45, train/loss: 0.1221, eval/loss: 0.1557, train/r2: 0.8676, eval/r2: 0.8286, train/one: 0.8966, train/two: 0.8332, train/three: 0.8731, eval/one: 0.8399, eval/two: 0.8261, eval/three: 0.8198 \n",
      "Epoch: 50, train/loss: 0.1214, eval/loss: 0.1432, train/r2: 0.8912, eval/r2: 0.7917, train/one: 0.9038, train/two: 0.9048, train/three: 0.8650, eval/one: 0.8382, eval/two: 0.7724, eval/three: 0.7646 \n",
      "Epoch: 55, train/loss: 0.1229, eval/loss: 0.1846, train/r2: 0.8706, eval/r2: 0.6195, train/one: 0.8458, train/two: 0.9006, train/three: 0.8656, eval/one: 0.7294, eval/two: 0.7753, eval/three: 0.3538 \n",
      "Epoch: 60, train/loss: 0.1056, eval/loss: 0.1186, train/r2: 0.8961, eval/r2: 0.8516, train/one: 0.9011, train/two: 0.8972, train/three: 0.8899, eval/one: 0.7986, eval/two: 0.9418, eval/three: 0.8144 \n",
      "Epoch: 65, train/loss: 0.1032, eval/loss: 0.1194, train/r2: 0.9070, eval/r2: 0.8377, train/one: 0.8757, train/two: 0.9242, train/three: 0.9210, eval/one: 0.7898, eval/two: 0.8848, eval/three: 0.8386 \n",
      "Epoch: 70, train/loss: 0.1154, eval/loss: 0.1343, train/r2: 0.8971, eval/r2: 0.8216, train/one: 0.8811, train/two: 0.8967, train/three: 0.9135, eval/one: 0.8313, eval/two: 0.7766, eval/three: 0.8567 \n",
      "Epoch: 75, train/loss: 0.0966, eval/loss: 0.1070, train/r2: 0.8962, eval/r2: 0.8441, train/one: 0.9116, train/two: 0.8863, train/three: 0.8908, eval/one: 0.8557, eval/two: 0.7866, eval/three: 0.8901 \n",
      "Epoch: 80, train/loss: 0.1051, eval/loss: 0.1000, train/r2: 0.8843, eval/r2: 0.8717, train/one: 0.8859, train/two: 0.9016, train/three: 0.8653, eval/one: 0.8833, eval/two: 0.8814, eval/three: 0.8503 \n",
      "Epoch: 85, train/loss: 0.1028, eval/loss: 0.0835, train/r2: 0.9034, eval/r2: 0.8639, train/one: 0.9084, train/two: 0.9101, train/three: 0.8918, eval/one: 0.9317, eval/two: 0.8137, eval/three: 0.8463 \n",
      "Epoch: 90, train/loss: 0.1058, eval/loss: 0.1382, train/r2: 0.8976, eval/r2: 0.7875, train/one: 0.8793, train/two: 0.9027, train/three: 0.9109, eval/one: 0.8454, eval/two: 0.8319, eval/three: 0.6851 \n",
      "Epoch: 95, train/loss: 0.0966, eval/loss: 0.0941, train/r2: 0.9015, eval/r2: 0.8813, train/one: 0.8895, train/two: 0.9114, train/three: 0.9036, eval/one: 0.9205, eval/two: 0.9184, eval/three: 0.8049 \n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "\n",
    "inputs_mean_std = []\n",
    "targets_mean_std = []\n",
    "scores = []\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=SEED)\n",
    "splits = kfold.split(inputs)\n",
    "\n",
    "for fold, (train_idx, eval_idx) in enumerate(splits):\n",
    "    MODEL_NAME = f\"ensemble2.finetune.xception.F{fold}\"\n",
    "    checkpoint_name = f\"ensemble2.finetune.xception.F{fold}.pt\"\n",
    "    \n",
    "    train_inputs = inputs[train_idx]\n",
    "    train_targets = targets[train_idx]\n",
    "    eval_inputs = inputs[eval_idx]\n",
    "    eval_targets = targets[eval_idx]\n",
    "\n",
    "    train_ds = get_dataset(train_inputs, train_targets, config)\n",
    "    \n",
    "    inputs_mean_std.append((fold, train_ds.s_mean, train_ds.s_std))\n",
    "    targets_mean_std.append((fold, train_ds.concentration_means, train_ds.concentration_stds))\n",
    "    \n",
    "    eval_ds = get_dataset(\n",
    "        eval_inputs, \n",
    "        eval_targets, \n",
    "        config,\n",
    "        (train_ds.s_mean, train_ds.s_std), \n",
    "        (train_ds.concentration_means, train_ds.concentration_stds)\n",
    "    )\n",
    "    \n",
    "    BATCH_SIZE = 32\n",
    "    train_dl, eval_dl = return_dls(train_ds, eval_ds, BATCH_SIZE, len(eval_ds))\n",
    "    \n",
    "    #model = convnextv2_atto().to(device)\n",
    "    #model = ReZeroNet(**config).to(device)\n",
    "    #model = ResNet(dropout=DROPOUT).to(device)\n",
    "    model = RamanXception(\n",
    "        **model_config,\n",
    "        classification_idx=3,\n",
    "        num_concentrations=3\n",
    "    ).to(device)\n",
    "    \n",
    "    ckpt = get_ckpt(\"/kaggle/working/ensemble.pretrain.xception.2.pt\")\n",
    "    print(ckpt[\"score\"])\n",
    "    model.load_state_dict(ckpt[\"state_dict\"])\n",
    "    \n",
    "    if fold == 0: print(get_model_size(model))\n",
    "    \n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=LR, weight_decay=WD, foreach=True)\n",
    "    scheduler = get_scheduler(optimizer, train_dl, EPOCHS)\n",
    "    \n",
    "    score = train(\n",
    "            model, \n",
    "            optimizer, \n",
    "            device,\n",
    "            torch.float16,\n",
    "            scheduler,\n",
    "            train_dl, \n",
    "            eval_dl,\n",
    "            loss_fn,\n",
    "            EPOCHS,\n",
    "            checkpoint_name,\n",
    "            neptune_run=None#setup_neptune(),\n",
    "        )\n",
    "    \n",
    "    scores.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4925ae75",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpectralTestDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        spectra,\n",
    "        concentrations,\n",
    "        dtype=None,\n",
    "        spectra_mean_std=None,\n",
    "        concentration_mean_std=None,\n",
    "        combine_spectra_range=0.0,\n",
    "        baseline_factor_bound=0.0,\n",
    "        baseline_period_lower_bound=100.0,\n",
    "        baseline_period_upper_bound=200.0,\n",
    "        augment_slope_std=0.0,\n",
    "        augment_intersept_std=0.0,\n",
    "        rolling_bound=0,\n",
    "        spectrum_rolling_sigma=0.0,\n",
    "        augmentation_weight=0.1,\n",
    "        original_datapoint_weight=1.,\n",
    "    ):\n",
    "        self.dtype = dtype or torch.float32\n",
    "        self.combine_spectra_range = combine_spectra_range\n",
    "        self.baseline_factor_bound = baseline_factor_bound\n",
    "        self.augment_slope_std = augment_slope_std\n",
    "        self.augment_intercept_std = augment_intersept_std\n",
    "        self.baseline_period_lower_bound = baseline_period_lower_bound\n",
    "        self.baseline_period_upper_bound = baseline_period_upper_bound\n",
    "        self.rolling_bound = rolling_bound\n",
    "        self.spectrum_rolling_sigma = spectrum_rolling_sigma\n",
    "        self.augmentation_weight = torch.tensor(augmentation_weight, dtype=dtype)\n",
    "        self.original_dp_weight = original_datapoint_weight\n",
    "\n",
    "        # normalize spectra\n",
    "        spectra = torch.tensor(spectra, dtype=dtype)\n",
    "\n",
    "        if spectra_mean_std is None:\n",
    "            self.s_mean = torch.mean(spectra)\n",
    "            self.s_std = torch.std(spectra)\n",
    "        else:\n",
    "            self.s_mean, self.s_std = spectra_mean_std\n",
    "\n",
    "        self.spectra = torch.divide(\n",
    "            torch.subtract(spectra, self.s_mean),\n",
    "            self.s_std,\n",
    "        )\n",
    "\n",
    "        self.dummy_wns = np.tile(\n",
    "            np.arange(\n",
    "                0., 1., 1. / self.spectra.shape[2],\n",
    "                dtype=np_dtype_from_torch[self.dtype]\n",
    "            )[None, :self.spectra.shape[2]],\n",
    "            (self.spectra.shape[1], 1),\n",
    "        )\n",
    "\n",
    "        if False:\n",
    "            # normalize concentrations\n",
    "            concentrations = torch.tensor(concentrations, dtype=dtype)\n",
    "            if concentration_mean_std is None:\n",
    "                self.concentration_means = torch.nanmean(concentrations, dim=0)\n",
    "\n",
    "                self.concentration_stds = torch.maximum(\n",
    "                    torch.tensor(\n",
    "                        [\n",
    "                            torch.std(col[torch.logical_not(torch.isnan(col))])\n",
    "                            for col in concentrations.T\n",
    "                        ]\n",
    "                    ),\n",
    "                    torch.tensor([1e-3] * concentrations.shape[1]),\n",
    "                )\n",
    "            else:\n",
    "                self.concentration_means = concentration_mean_std[0]\n",
    "                self.concentration_stds = concentration_mean_std[1]\n",
    "\n",
    "            self.concentrations = torch.divide(\n",
    "                torch.subtract(\n",
    "                    concentrations,\n",
    "                    self.concentration_means,\n",
    "                ),\n",
    "                self.concentration_stds,\n",
    "            )\n",
    "\n",
    "    def pick_two(self, max_idx=None):\n",
    "        max_idx = max_idx or len(self)\n",
    "        return random.choices(range(max_idx), k=2)\n",
    "\n",
    "    def __len__(self):\n",
    "        return 96\n",
    "\n",
    "    def augment_spectra(self, spectra):\n",
    "        if self.augment_slope_std > 0.0:\n",
    "\n",
    "            def spectrum_approximation(x, slope, intercept):\n",
    "                return (slope * x + intercept).reshape(-1, 1)[:, 0]\n",
    "\n",
    "            slope, inter = scipy.optimize.curve_fit(\n",
    "                spectrum_approximation,\n",
    "                self.dummy_wns,\n",
    "                spectra.reshape(-1, 1)[:, 0],\n",
    "                p0=np.random.rand(2),\n",
    "            )[0]\n",
    "\n",
    "            new_slope = slope * (\n",
    "                    np.random.gamma(\n",
    "                        shape=1. / self.augment_slope_std,\n",
    "                        scale=self.augment_slope_std,\n",
    "                        size=1,\n",
    "                    )\n",
    "            )[0]\n",
    "            new_intercept = inter * (\n",
    "                1.0 + np.random.randn(1) * self.augment_intercept_std\n",
    "            )[0]\n",
    "            spectra += torch.tensor(\n",
    "                (new_slope - slope)\n",
    "            ) * self.dummy_wns + new_intercept - inter\n",
    "\n",
    "        factor = self.baseline_factor_bound * torch.rand(size=(1,))\n",
    "        offset = torch.rand(size=(1,)) * 2.0 * torch.pi\n",
    "        period = self.baseline_period_lower_bound + (\n",
    "            self.baseline_period_upper_bound - self.baseline_period_lower_bound\n",
    "        ) * torch.rand(size=(1,))\n",
    "        permutations = factor * torch.cos(\n",
    "            2.0 * torch.pi / period * self.dummy_wns + offset\n",
    "        )\n",
    "        return self.roll_spectrum(\n",
    "            spectra + permutations * spectra,\n",
    "            delta=random.randint(-self.rolling_bound, self.rolling_bound),\n",
    "        )\n",
    "\n",
    "    def roll_spectrum(self, spectra, delta):\n",
    "        num_spectra = spectra.shape[0]\n",
    "        rolled_spectra = np.roll(spectra, delta, axis=1)\n",
    "        if delta > 0:\n",
    "            rolled_spectra[:, :delta] = (\n",
    "                np.random.rand(num_spectra, delta) * self.spectrum_rolling_sigma + 1\n",
    "            ) * rolled_spectra[:, delta:(delta + 1)]\n",
    "        elif delta < 0:\n",
    "            rolled_spectra[:, delta:] = (\n",
    "                np.random.rand(num_spectra, -delta) * self.spectrum_rolling_sigma + 1\n",
    "            ) * rolled_spectra[:, delta - 1:delta]\n",
    "        return rolled_spectra\n",
    "\n",
    "    def combine_k_items(self, indices, weights):\n",
    "        return (\n",
    "            # spectra\n",
    "            torch.sum(\n",
    "                torch.mul(weights[:, None, None], self.spectra[indices, :, :]),\n",
    "                dim=0,\n",
    "            ),\n",
    "            # concentrations\n",
    "            #torch.sum(\n",
    "            #    torch.mul(weights[:, None], self.concentrations[indices, :]),\n",
    "            #    dim=0,\n",
    "            #)\n",
    "        )\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if True:#self.combine_spectra_range < 1e-12:\n",
    "            spectrum = self.spectra[idx]\n",
    "            #spectrum = self.augment_spectra(spectrum)\n",
    "            return spectrum\n",
    "        else:\n",
    "            if random.random() < self.original_dp_weight:\n",
    "                one_weight = 1.\n",
    "                label_weight = torch.tensor(1.0, dtype=self.dtype)\n",
    "            else:\n",
    "                one_weight = random.uniform(0.0, self.combine_spectra_range)\n",
    "                label_weight = self.augmentation_weight\n",
    "            weights = torch.tensor([one_weight, (1 - one_weight)])\n",
    "            # just pick two random indices\n",
    "            indices = random.choices(range(len(self)), k=2)\n",
    "\n",
    "            mixed_spectra = self.combine_k_items(\n",
    "                indices=indices,\n",
    "                weights=weights,\n",
    "            )\n",
    "            mixed_spectra = self.augment_spectra(mixed_spectra[0])\n",
    "            return mixed_spectra\n",
    "        \n",
    "  \n",
    "def get_test_dataset(inputs, inputs_mean_std, targets_mean_std):\n",
    "    return SpectralTestDataset(\n",
    "        spectra=inputs[:, None, :],\n",
    "        concentrations=None,\n",
    "        dtype=torch.float32,\n",
    "        spectra_mean_std=inputs_mean_std,\n",
    "        concentration_mean_std=targets_mean_std,\n",
    "        combine_spectra_range=1.0,\n",
    "        baseline_factor_bound=config[\"baseline_factor_bound\"],\n",
    "        baseline_period_lower_bound=config[\"baseline_period_lower_bound\"],\n",
    "        baseline_period_upper_bound=(config[\"baseline_period_lower_bound\"] + config[\"baseline_period_span\"]),\n",
    "        augment_slope_std=config[\"augment_slope_std\"],\n",
    "        augment_intersept_std=0.0,\n",
    "        rolling_bound=config[\"rolling_bound\"],\n",
    "        spectrum_rolling_sigma=0.01,\n",
    "        augmentation_weight=0.1,\n",
    "        original_datapoint_weight=1.,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "94caa304",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/ensemble2.finetune.xception.F0.pt 78 0.898994394393961\n",
      "/kaggle/working/ensemble2.finetune.xception.F1.pt 83 0.9380567703767388\n",
      "/kaggle/working/ensemble2.finetune.xception.F2.pt 98 0.9148076559305819\n",
      "/kaggle/working/ensemble2.finetune.xception.F3.pt 53 0.9426619849538058\n",
      "/kaggle/working/ensemble2.finetune.xception.F4.pt 96 0.8836769129542378\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/kaggle/working/ensemble2.finetune.xception.F0.pt',\n",
       " '/kaggle/working/ensemble2.finetune.xception.F1.pt',\n",
       " '/kaggle/working/ensemble2.finetune.xception.F2.pt',\n",
       " '/kaggle/working/ensemble2.finetune.xception.F3.pt',\n",
       " '/kaggle/working/ensemble2.finetune.xception.F4.pt']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckpt_paths = get_ckpt_paths(\"/kaggle/working/\", \"ensemble2\")\n",
    "ckpt_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5b492f13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([6.9872, 1.1800, 1.6035]), tensor([2.8131, 0.5574, 0.6539]))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets_mean_std[1][1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4786020e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.58606339,  0.75891245,  0.42661883],\n",
       "       [ 6.25517408,  2.01518144,  1.46033086],\n",
       "       [ 4.63505232,  0.56403658,  1.02985228],\n",
       "       [ 2.44505992,  1.55903949,  0.43248095],\n",
       "       [11.08343304,  0.91598526,  0.92062097],\n",
       "       [ 8.69974262,  1.91590026,  0.79920837],\n",
       "       [ 6.50978055,  0.64628472,  0.42474924],\n",
       "       [ 7.27071856,  1.94725528,  1.20118055],\n",
       "       [ 5.94930382,  1.86546728,  0.87630055],\n",
       "       [ 8.16056469,  1.01667554,  0.31071675],\n",
       "       [ 7.58837385,  1.03123432,  0.99114782],\n",
       "       [ 4.2994806 ,  0.6622994 ,  0.97279431],\n",
       "       [ 3.82550342,  1.08284377,  0.99600972],\n",
       "       [ 5.16439506,  1.11320403,  1.56788008],\n",
       "       [ 4.9056996 ,  0.90954496,  0.99029765],\n",
       "       [ 7.96030053,  0.68337803,  0.95676336],\n",
       "       [ 4.99033944,  0.98771026,  0.99445161],\n",
       "       [ 5.3374776 ,  0.86117655,  1.11675056],\n",
       "       [ 4.67244148,  1.41751159,  1.10603694],\n",
       "       [ 3.1764085 ,  1.02720739,  1.18472305],\n",
       "       [ 5.06787312,  0.82981459,  1.09145541],\n",
       "       [ 6.04232431,  0.90353469,  1.07477974],\n",
       "       [ 2.41222979,  1.49684435,  0.44340736],\n",
       "       [ 2.05910598,  1.43833805,  1.412535  ],\n",
       "       [ 3.72770104,  1.01932245,  1.0708307 ],\n",
       "       [ 5.39043162,  0.70476757,  1.22664768],\n",
       "       [ 5.743444  ,  1.12591173,  1.09740554],\n",
       "       [ 4.83746441,  0.68993865,  1.24242503],\n",
       "       [ 6.38623759,  0.95843523,  1.01936069],\n",
       "       [ 4.44491573,  0.48318631,  0.20740544],\n",
       "       [ 6.8238485 ,  0.83087475,  1.42544959],\n",
       "       [ 6.4963039 ,  1.05181235,  0.74681244],\n",
       "       [ 7.79915843,  1.18202596,  1.16659209],\n",
       "       [ 6.89309599,  1.19853319,  0.74866074],\n",
       "       [ 7.03671725,  1.67192983,  1.09493962],\n",
       "       [ 4.75819556,  0.45336897,  0.68019844],\n",
       "       [ 7.96359616,  0.8913026 ,  0.73942607],\n",
       "       [ 5.80140205,  1.73377063,  0.53220418],\n",
       "       [ 3.5547049 ,  1.38194945,  0.62110528],\n",
       "       [ 7.72947167,  1.26191247,  1.41198037],\n",
       "       [ 6.67734834,  0.4465013 ,  1.00560945],\n",
       "       [ 3.16324961,  1.40327454,  0.37964007],\n",
       "       [ 7.53776175,  0.30920273,  1.41151233],\n",
       "       [ 2.98950462,  0.6254211 ,  1.14112292],\n",
       "       [ 2.14436065,  1.54158975,  0.72730066],\n",
       "       [ 7.93598596,  0.41050075,  1.49909898],\n",
       "       [ 4.44142315,  0.27569239,  1.41904654],\n",
       "       [ 4.22906697,  0.94853557,  1.02657484],\n",
       "       [ 4.61444258,  0.99652273,  1.47979806],\n",
       "       [ 7.8673945 ,  1.02301659,  1.61491459],\n",
       "       [ 2.53907594,  1.2611766 ,  1.83349194],\n",
       "       [ 2.41030202,  1.19893953,  1.47242351],\n",
       "       [ 3.74094754,  0.82793035,  1.52158047],\n",
       "       [ 4.22924497,  1.63013489,  1.17734114],\n",
       "       [ 3.44433814,  1.11715071,  1.45631577],\n",
       "       [ 3.20248084,  1.31929928,  1.74881223],\n",
       "       [ 3.85541008,  1.70868569,  1.5103253 ],\n",
       "       [ 4.46239776,  1.40269388,  1.6959724 ],\n",
       "       [ 5.19884024,  0.33730364,  1.53604678],\n",
       "       [ 6.04742395,  0.12509598,  0.63431465],\n",
       "       [ 3.38061642,  0.40404317,  1.29809573],\n",
       "       [ 2.68187824,  1.38462895,  1.59081353],\n",
       "       [ 4.09011082,  1.11637564,  0.7825425 ],\n",
       "       [ 8.10868989,  0.65110027,  1.76276621],\n",
       "       [ 7.2986788 ,  1.64732345,  0.46408866],\n",
       "       [ 5.521401  ,  0.8975483 ,  0.31362765],\n",
       "       [ 7.04463381,  1.46509323,  1.02874695],\n",
       "       [ 4.09510563,  1.19303881,  0.73599889],\n",
       "       [ 6.43133574,  0.69037641,  0.77523686],\n",
       "       [ 8.52865913,  0.63734312,  0.9272271 ],\n",
       "       [ 9.02304041,  0.77377873,  0.9966389 ],\n",
       "       [ 8.70221552,  1.15039727,  1.06153996],\n",
       "       [ 4.13369056,  1.42510379,  1.83905381],\n",
       "       [ 7.62038394,  0.36174063,  0.89271058],\n",
       "       [ 4.5714316 ,  1.11692524,  1.5049567 ],\n",
       "       [ 6.87612841,  0.17222087,  1.0319094 ],\n",
       "       [ 4.58375055,  0.98995677,  0.25557058],\n",
       "       [ 4.76728388,  0.62811643,  1.41294938],\n",
       "       [ 3.52634671,  1.46878351,  1.01674918],\n",
       "       [ 4.33875355,  0.50608319,  1.3752819 ],\n",
       "       [ 7.99620901,  0.75871942,  0.44162734],\n",
       "       [ 2.57286317,  1.01073342,  1.86997632],\n",
       "       [ 7.43546999,  0.94428082,  1.83165318],\n",
       "       [ 6.44133997,  1.07609747,  1.34663408],\n",
       "       [ 3.69316599,  1.25563951,  1.44581776],\n",
       "       [ 4.68289558,  1.08703975,  1.23826665],\n",
       "       [ 4.83253321,  0.74263664,  0.89854515],\n",
       "       [ 3.85098508,  0.84912456,  1.09062292],\n",
       "       [ 6.13774488,  1.1130799 ,  1.0818805 ],\n",
       "       [ 4.45556278,  0.95478846,  1.22890791],\n",
       "       [ 5.7946931 ,  1.1311385 ,  1.2047824 ],\n",
       "       [ 4.43725506,  1.02403892,  1.44921533],\n",
       "       [ 5.22160791,  0.25151926,  0.9871258 ],\n",
       "       [ 6.04056777,  0.25877809,  0.85650987],\n",
       "       [ 3.08271998,  1.86003926,  1.17531993],\n",
       "       [ 3.99384162,  1.85001114,  1.06828623]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "def inference(test_inputs, ckpt_name, i):\n",
    "    ckpt = get_ckpt(ckpt_name)\n",
    "    \n",
    "    test_ds = get_test_dataset(test_inputs, inputs_mean_std[i][1:], targets_mean_std[i][1:]) #[i][1:]\n",
    "    test_dl = DataLoader(test_ds, batch_size=32)\n",
    "\n",
    "    #model = ReZeroNet(**config).to(device)\n",
    "    #model = ResNet(dropout=DROPOUT).to(device)\n",
    "    model = RamanXception(\n",
    "        **model_config,\n",
    "        classification_idx=3,\n",
    "        num_concentrations=3\n",
    "    ).to(device)\n",
    "    \n",
    "    model.load_state_dict(ckpt[\"state_dict\"])\n",
    "    model.eval()\n",
    "    \n",
    "    all_preds = []\n",
    "    for inputs in test_dl:\n",
    "        with torch.inference_mode():\n",
    "            preds = model(inputs.cuda())\n",
    "            preds = preds.double() \n",
    "            all_preds.append(cuda_to_np(preds))\n",
    "            \n",
    "    preds = np.concatenate(all_preds)\n",
    "    mus = targets_mean_std[i][1:][0] #[i][1:][0]\n",
    "    sigmas = targets_mean_std[i][1:][1] #[i][1:][1]\n",
    "\n",
    "    for i in range(3):\n",
    "        preds[:, i] = reverse_zscore(preds[:, i], mus[i].numpy(), sigmas[i].numpy())\n",
    "    \n",
    "    return preds\n",
    "\n",
    "preds = inference(test_inputs, \"/kaggle/working/finetune.xception.F1.pt\", 1) # CAREFUL ABOUT INDEX\n",
    "generate_csv(preds, \"/kaggle/working/finetune.xception.seed.change.F1.pt.9268.csv\")\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "64b84e1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/kaggle/working/ensemble2.finetune.xception.F0.pt', '/kaggle/working/ensemble2.finetune.xception.F1.pt', '/kaggle/working/ensemble2.finetune.xception.F2.pt', '/kaggle/working/ensemble2.finetune.xception.F3.pt', '/kaggle/working/ensemble2.finetune.xception.F4.pt']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 3.37769083,  0.50667116,  0.48112236],\n",
       "       [ 5.42142497,  2.04052496,  1.61334092],\n",
       "       [ 4.75719179,  0.27889624,  0.98159921],\n",
       "       [ 2.75481858,  1.08613276,  0.55975065],\n",
       "       [10.13435922,  0.74811225,  1.05197833],\n",
       "       [ 8.13995074,  1.80065596,  0.86503619],\n",
       "       [ 5.17045363,  0.55028919,  0.42860752],\n",
       "       [ 8.02543031,  2.03716417,  1.223674  ],\n",
       "       [ 8.29707297,  1.38649234,  0.92116488],\n",
       "       [ 8.59365566,  0.75635087,  0.40266944],\n",
       "       [ 9.14544336,  0.98223214,  0.93680561],\n",
       "       [ 2.66947178,  0.71237141,  1.04065033],\n",
       "       [ 3.57817271,  1.21566165,  1.01968179],\n",
       "       [ 3.57235347,  1.08491614,  1.57248638],\n",
       "       [ 3.26736602,  1.02732502,  1.07106481],\n",
       "       [ 8.53122118,  0.95985219,  0.84415817],\n",
       "       [ 4.08658702,  0.98502203,  1.07137845],\n",
       "       [ 6.69133356,  0.82452608,  1.02112331],\n",
       "       [ 6.9395492 ,  1.49281648,  1.0275752 ],\n",
       "       [ 2.11989975,  0.88603122,  1.29005514],\n",
       "       [ 4.57947189,  1.06723338,  1.08698156],\n",
       "       [ 6.40549839,  1.08622827,  1.05110477],\n",
       "       [ 2.13488276,  1.16720996,  0.57081032],\n",
       "       [ 3.01632211,  1.39853228,  1.32129657],\n",
       "       [ 3.67466953,  1.26853813,  1.21994225],\n",
       "       [ 5.22713722,  1.05697842,  1.12518613],\n",
       "       [ 6.26176616,  1.41059947,  1.07046448],\n",
       "       [ 5.92432309,  0.97367951,  1.31542874],\n",
       "       [ 8.66668575,  1.13851474,  1.26150473],\n",
       "       [ 4.42395404,  0.15157316,  0.49473645],\n",
       "       [ 8.41717813,  0.86580301,  0.99649212],\n",
       "       [ 7.07655445,  0.55691989,  0.83765567],\n",
       "       [ 7.60217967,  1.13668865,  1.08003585],\n",
       "       [ 7.05959257,  1.26388774,  0.7586111 ],\n",
       "       [ 8.10022585,  1.65984561,  0.88539083],\n",
       "       [ 4.50853124,  0.4796081 ,  0.74957825],\n",
       "       [ 7.83819602,  0.80236497,  0.69830071],\n",
       "       [ 6.91098803,  1.3917948 ,  0.58096774],\n",
       "       [ 3.28472954,  1.02670609,  0.63543619],\n",
       "       [ 8.9711289 ,  1.17778041,  1.14409196],\n",
       "       [ 6.34510754,  0.4724808 ,  1.12093725],\n",
       "       [ 3.95020554,  1.26756371,  0.64133515],\n",
       "       [ 6.81983293,  0.13494954,  1.33388737],\n",
       "       [ 2.80062275,  0.54623317,  0.86227179],\n",
       "       [ 1.80279614,  1.1328601 ,  0.70339686],\n",
       "       [ 6.43143414,  0.23419433,  1.50293848],\n",
       "       [ 3.01453157,  0.25705031,  1.34280687],\n",
       "       [ 3.97903296,  0.94283367,  1.02998948],\n",
       "       [ 5.32692155,  1.02261039,  1.29352758],\n",
       "       [ 6.71919067,  0.86946205,  1.69793014],\n",
       "       [ 1.44047973,  1.26654716,  1.61036096],\n",
       "       [ 2.37826574,  1.03739829,  1.42372786],\n",
       "       [ 4.28558765,  0.78321566,  1.42110888],\n",
       "       [ 4.11301992,  1.64351243,  0.9871565 ],\n",
       "       [ 3.32687382,  1.2476173 ,  1.43253759],\n",
       "       [ 3.4020043 ,  1.26792243,  1.66042949],\n",
       "       [ 3.82076439,  1.7176185 ,  1.37374398],\n",
       "       [ 3.8157934 ,  1.14562069,  1.7960597 ],\n",
       "       [ 5.08358051,  0.18946031,  1.4967869 ],\n",
       "       [ 5.8205304 ,  0.18526349,  0.66526886],\n",
       "       [ 2.2171494 ,  0.39824125,  1.08872506],\n",
       "       [ 2.07344456,  0.89831269,  1.34315824],\n",
       "       [ 3.04401304,  1.38817153,  0.7720373 ],\n",
       "       [ 8.71209932,  0.66434165,  1.58161083],\n",
       "       [ 7.81897822,  1.50915982,  0.53502479],\n",
       "       [ 4.43975906,  0.8482815 ,  0.53548937],\n",
       "       [ 9.18762582,  1.47846437,  1.08055924],\n",
       "       [ 3.06886376,  1.36053339,  0.85336482],\n",
       "       [ 6.23987444,  0.64874044,  0.84301396],\n",
       "       [ 7.39452634,  0.35707029,  1.03058225],\n",
       "       [10.21985638,  0.7329887 ,  0.938022  ],\n",
       "       [ 9.57411099,  1.1158479 ,  0.98066225],\n",
       "       [ 5.88717595,  1.08289142,  1.67402614],\n",
       "       [ 8.80788603,  0.42608112,  0.94819292],\n",
       "       [ 5.48754896,  0.92335009,  1.55261012],\n",
       "       [ 7.48238219,  0.1652859 ,  1.07445789],\n",
       "       [ 3.4461701 ,  0.37915036,  0.3795273 ],\n",
       "       [ 4.90131898,  0.86132019,  1.4424989 ],\n",
       "       [ 2.21812077,  1.31231715,  0.71643541],\n",
       "       [ 3.4240378 ,  0.34367569,  1.45857759],\n",
       "       [ 7.11296497,  0.60788414,  0.5073139 ],\n",
       "       [ 1.80666224,  0.73250928,  1.72583764],\n",
       "       [ 7.01430098,  0.50370337,  1.87963134],\n",
       "       [ 6.11625374,  1.0265722 ,  1.48462698],\n",
       "       [ 3.4766737 ,  1.00346456,  1.34724341],\n",
       "       [ 4.22264149,  1.136589  ,  1.12792786],\n",
       "       [ 5.9832265 ,  1.04161083,  0.83655487],\n",
       "       [ 3.45796963,  0.89083954,  1.00864836],\n",
       "       [ 6.93546119,  1.05308851,  0.86060855],\n",
       "       [ 5.23086688,  1.04027665,  1.06702464],\n",
       "       [ 7.70406221,  1.01917194,  1.2817401 ],\n",
       "       [ 2.92649269,  1.06418134,  1.33562006],\n",
       "       [ 5.14038078,  0.13435247,  0.80635521],\n",
       "       [ 5.98178151,  0.09146801,  0.94150351],\n",
       "       [ 2.6532406 ,  1.45168105,  1.01424631],\n",
       "       [ 4.48789577,  1.72626992,  0.84102343]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def ensemble_inference(test_inputs, ckpt_paths):\n",
    "    print(ckpt_paths)\n",
    "    all_preds = []\n",
    "\n",
    "    for i, ckpt_path in enumerate(ckpt_paths):\n",
    "        ckpt = get_ckpt(ckpt_path)\n",
    "        \n",
    "        #model = ReZeroNet(**config).to(device)\n",
    "        model = RamanXception(\n",
    "            **model_config,\n",
    "            classification_idx=3,\n",
    "            num_concentrations=3\n",
    "        ).to(device)\n",
    "        \n",
    "        model.load_state_dict(ckpt[\"state_dict\"])\n",
    "        model.eval()\n",
    "\n",
    "        test_ds = get_test_dataset(test_inputs, inputs_mean_std[i][1:], targets_mean_std[i][1:])\n",
    "        test_dl = DataLoader(test_ds, batch_size=32)\n",
    "        \n",
    "        fold_preds = []\n",
    "        for inputs in test_dl:\n",
    "            with torch.inference_mode():\n",
    "                preds = model(inputs.cuda())\n",
    "                preds = cuda_to_np(preds.double())\n",
    "                fold_preds.append(preds)\n",
    "                \n",
    "        fold_preds = np.concatenate(fold_preds)\n",
    "        \n",
    "        means = targets_mean_std[i][1:][0]\n",
    "        stds = targets_mean_std[i][1:][1]\n",
    "        for i in range(3):\n",
    "            fold_preds[:, i] = reverse_zscore(fold_preds[:, i], means[i].numpy(), stds[i].numpy())\n",
    "            \n",
    "        all_preds.append(fold_preds)\n",
    "\n",
    "    return np.mean(all_preds, axis=0)\n",
    "\n",
    "preds = ensemble_inference(test_inputs, ckpt_paths)\n",
    "generate_csv(preds, \"ensemble2.finetune.xception.csv\")\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "47757d7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min: 0.276526487, Max: 11.88990894, Mean: 3.2087227954027777, Std: 3.1291512817697695\n"
     ]
    }
   ],
   "source": [
    "get_stats(targets, minmax=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "eb123d90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min: 0.1601953788441101, Max: 10.275419730372358, Mean: 2.5201870082594056, Std: 2.500594045055393\n"
     ]
    }
   ],
   "source": [
    "get_stats(preds2, minmax=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe1fc251",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds1 = pd.read_csv(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "966d1477",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds1 = pd.read_csv(\"/kaggle/working/ensemble.finetune.xception.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f25e55ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds1 = preds1.drop(columns=\"ID\").to_numpy()\n",
    "#preds2 = preds2.drop(columns=\"ID\").to_numpy()\n",
    "preds2 = np.stack([preds1, preds]).mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0b9c90c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_csv(preds2, \"ensemble.combined.1.3.finetune.xception.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d9eab2f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.69724078,  0.62571933,  0.58767392],\n",
       "       [ 5.82543866,  2.00827409,  1.50867673],\n",
       "       [ 5.24602463,  0.34695376,  0.97963756],\n",
       "       [ 2.70941937,  1.08957237,  0.57803972],\n",
       "       [10.21591767,  0.76222972,  0.90962506],\n",
       "       [ 7.7754118 ,  1.78192065,  0.8381941 ],\n",
       "       [ 5.10610932,  0.62070606,  0.49511448],\n",
       "       [ 7.89470412,  2.01653113,  1.2738571 ],\n",
       "       [ 8.09159227,  1.56797358,  0.89525379],\n",
       "       [ 9.11870557,  0.88221053,  0.39647066],\n",
       "       [ 9.40201648,  0.99201456,  0.95559302],\n",
       "       [ 3.28862222,  0.72036677,  0.9330797 ],\n",
       "       [ 3.65196612,  1.22054596,  1.00523889],\n",
       "       [ 4.83309233,  0.97421456,  1.44752873],\n",
       "       [ 4.11890237,  0.97278191,  0.99262141],\n",
       "       [ 8.8080836 ,  0.8837792 ,  0.82487738],\n",
       "       [ 5.19730267,  0.92124824,  0.99400793],\n",
       "       [ 6.39044431,  0.81881538,  0.93835391],\n",
       "       [ 7.10412457,  1.48144382,  0.98597225],\n",
       "       [ 3.1084413 ,  0.88911189,  1.09061111],\n",
       "       [ 5.63293774,  1.0640557 ,  0.89318355],\n",
       "       [ 7.20044195,  1.11855771,  0.93451452],\n",
       "       [ 2.07425987,  1.25452372,  0.66831214],\n",
       "       [ 3.24206761,  1.37604436,  1.171883  ],\n",
       "       [ 4.05095962,  1.15927498,  1.0638274 ],\n",
       "       [ 5.08693588,  1.08291746,  1.10387404],\n",
       "       [ 7.02242425,  1.40549401,  0.9386767 ],\n",
       "       [ 6.49820585,  0.93845243,  1.30664019],\n",
       "       [ 9.38369023,  1.01787571,  1.10297987],\n",
       "       [ 4.39235555,  0.29470898,  0.50423201],\n",
       "       [ 7.97541514,  0.84310838,  1.07970443],\n",
       "       [ 7.35555728,  0.66874446,  0.82102928],\n",
       "       [ 6.81347637,  1.06779045,  1.03912678],\n",
       "       [ 7.55387828,  1.15115083,  0.70794051],\n",
       "       [ 8.44809553,  1.4719646 ,  0.92705643],\n",
       "       [ 4.48297332,  0.49048108,  0.7885816 ],\n",
       "       [ 7.58801157,  0.88065361,  0.68179938],\n",
       "       [ 6.919854  ,  1.39831364,  0.50686948],\n",
       "       [ 3.24927264,  1.08482977,  0.61225767],\n",
       "       [ 8.79440593,  1.11665462,  1.15566417],\n",
       "       [ 7.14406251,  0.49386534,  1.10797987],\n",
       "       [ 3.94908176,  1.35116899,  0.60143704],\n",
       "       [ 6.49522308,  0.2000748 ,  1.33156125],\n",
       "       [ 3.09221821,  0.55275896,  0.95686001],\n",
       "       [ 1.76610379,  1.26606656,  0.73491395],\n",
       "       [ 6.62387109,  0.28567177,  1.40192047],\n",
       "       [ 3.12216551,  0.26195195,  1.28978748],\n",
       "       [ 4.27326896,  0.95188994,  1.01082743],\n",
       "       [ 5.44513717,  1.05961538,  1.23463526],\n",
       "       [ 6.63579959,  0.7970225 ,  1.66964334],\n",
       "       [ 1.72746947,  1.21320439,  1.70381372],\n",
       "       [ 2.61746123,  1.09262184,  1.34038723],\n",
       "       [ 4.53392528,  0.80350689,  1.24292518],\n",
       "       [ 4.58547354,  1.65993335,  1.14816195],\n",
       "       [ 3.79705136,  1.23784843,  1.32935664],\n",
       "       [ 3.54339753,  1.2830594 ,  1.69972835],\n",
       "       [ 3.89613944,  1.65803558,  1.35538401],\n",
       "       [ 3.90180897,  1.21901733,  1.7777429 ],\n",
       "       [ 5.21970771,  0.24815709,  1.41661937],\n",
       "       [ 6.19906329,  0.23441713,  0.62447229],\n",
       "       [ 2.3992663 ,  0.39064433,  1.06600399],\n",
       "       [ 2.25566786,  0.90614971,  1.26341636],\n",
       "       [ 4.14759956,  1.27279551,  0.65304142],\n",
       "       [ 8.90770611,  0.61025552,  1.50500312],\n",
       "       [ 7.73980316,  1.57825967,  0.52621865],\n",
       "       [ 4.98709468,  0.81899135,  0.56409101],\n",
       "       [ 8.63011392,  1.4817559 ,  1.15100044],\n",
       "       [ 3.78076393,  1.2591896 ,  0.69942767],\n",
       "       [ 7.0326852 ,  0.76225727,  0.6990828 ],\n",
       "       [ 7.4879716 ,  0.42660912,  0.85182468],\n",
       "       [10.27541973,  0.68591057,  0.88954915],\n",
       "       [ 9.03298725,  1.19840299,  0.97010734],\n",
       "       [ 5.48475255,  1.08946386,  1.64176491],\n",
       "       [ 7.5944372 ,  0.39146883,  0.91087494],\n",
       "       [ 5.60369057,  0.96847529,  1.45256197],\n",
       "       [ 7.31658961,  0.19165083,  1.09208082],\n",
       "       [ 3.69136301,  0.58101652,  0.36004477],\n",
       "       [ 5.54832873,  0.76305993,  1.34511559],\n",
       "       [ 2.30793418,  1.39557359,  0.76492732],\n",
       "       [ 3.52192059,  0.40167972,  1.37603739],\n",
       "       [ 6.54109777,  0.61317537,  0.55640362],\n",
       "       [ 2.09261564,  0.75573563,  1.74061087],\n",
       "       [ 7.154011  ,  0.54147678,  1.76778049],\n",
       "       [ 6.34483844,  1.00672127,  1.39837466],\n",
       "       [ 3.50160727,  1.08287389,  1.46928564],\n",
       "       [ 5.19192737,  1.17439719,  1.05430868],\n",
       "       [ 6.31021752,  0.97327601,  0.76148525],\n",
       "       [ 4.14051403,  0.7870643 ,  0.9496864 ],\n",
       "       [ 7.05416609,  1.03349301,  0.87708369],\n",
       "       [ 5.49781704,  1.01155617,  1.10720294],\n",
       "       [ 7.82330236,  0.98448106,  1.13541112],\n",
       "       [ 3.67824414,  1.04650469,  1.23406402],\n",
       "       [ 5.31384881,  0.25120041,  0.84448437],\n",
       "       [ 5.8237384 ,  0.16019538,  1.02536455],\n",
       "       [ 2.741745  ,  1.46237442,  1.00696802],\n",
       "       [ 4.55479965,  1.74540554,  0.92319798]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce49ee80",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
