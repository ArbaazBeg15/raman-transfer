{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b7e06e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.9/63.9 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m487.9/487.9 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Building wheel for bravado-core (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
     ]
    }
   ],
   "source": [
    "#!pip3 install -q neptune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "627d3e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os; os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def setup_reproducibility(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available(): torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.use_deterministic_algorithms(False, warn_only=True)\n",
    "    torch.set_float32_matmul_precision(\"high\")\n",
    "    \n",
    "SEED = 1000\n",
    "setup_reproducibility(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1bc8cc7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "from transformers import get_cosine_schedule_with_warmup\n",
    "from scipy import signal\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from huggingface_hub import login, snapshot_download\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "def rest(t=4000):\n",
    "    import time\n",
    "    for i in range(4000):\n",
    "        time.sleep(i)\n",
    "        \n",
    "\n",
    "def average_state_dicts(state_dict_list):\n",
    "    n = len(state_dict_list)\n",
    "    # Ensure we don't modify the originals\n",
    "    avg_sd = OrderedDict()\n",
    "\n",
    "    # Iterate over every parameter/buffer key\n",
    "    for k in state_dict_list[0]:\n",
    "        # sum across models → float32 to avoid overflow on int types\n",
    "        avg = sum(sd[k].float() for sd in state_dict_list) / n\n",
    "        # cast back to original dtype if needed\n",
    "        avg_sd[k] = avg.to(dtype=state_dict_list[0][k].dtype)\n",
    "\n",
    "    return avg_sd\n",
    "\n",
    "\n",
    "def cuda_to_np(tensor):\n",
    "    return tensor.cpu().detach().numpy()\n",
    "\n",
    "\n",
    "def get_scheduler(optimizer, train_dl, epochs):\n",
    "    total_training_steps = len(train_dl) * epochs\n",
    "    warmup_steps = int(total_training_steps * 0.05)  # e.g. 5% warmup\n",
    "    \n",
    "    return get_cosine_schedule_with_warmup(\n",
    "        optimizer=optimizer,\n",
    "        num_warmup_steps=warmup_steps,\n",
    "        num_training_steps=total_training_steps\n",
    "    )\n",
    "\n",
    "\n",
    "def get_stats(tensor, p=True, r=False, minmax=False):\n",
    "    if minmax:\n",
    "        min, max = tensor.min(), tensor.max()\n",
    "        mean, std = tensor.mean(), tensor.std()\n",
    "        if p: print(f\"Min: {min}, Max: {max} ,Mean: {mean}, Std: {std}\")\n",
    "        if r: return min, max, mean, std\n",
    "    else:\n",
    "        mean, std = tensor.mean(), tensor.std()\n",
    "        if p: print(f\"Mean: {mean}, Std: {std}\")\n",
    "        if r: return mean, std\n",
    "    \n",
    "    \n",
    "def zscore(tensor, mean=None, std=None):\n",
    "    if mean is None: mean = tensor.mean()\n",
    "    if std is None: std = tensor.std()\n",
    "    return (tensor - mean) / (std + 1e-8)\n",
    "\n",
    "\n",
    "def get_model_size(model):\n",
    "    print(sum(p.numel() for p in model.parameters()) / 1e6)\n",
    "    \n",
    "\n",
    "def get_index(iterable):\n",
    "    return random.randint(0, len(iterable) - 1)\n",
    "\n",
    "\n",
    "def get_indices(iterable, n):\n",
    "    return random.sample(range(len(iterable)), n)\n",
    "\n",
    "\n",
    "def split(inputs, targets, seed):\n",
    "    return train_test_split(\n",
    "        inputs,\n",
    "        targets, \n",
    "        test_size=0.2,\n",
    "        shuffle=True, \n",
    "        random_state=seed\n",
    "    ) \n",
    "\n",
    "\n",
    "def show_waves(waves, dpi=100):\n",
    "    \"\"\"\n",
    "    waves: numpy array of shape (3, N)\n",
    "    Creates three separate figures that stretch wide.\n",
    "    \"\"\"\n",
    "    N = waves.shape[1]\n",
    "    t = np.arange(N)\n",
    "\n",
    "    # Wide aspect ratio; height modest so each window fills width\n",
    "    for i in range(waves.shape[0]):\n",
    "        fig = plt.figure(figsize=(14, 4), dpi=dpi)  # wide figure\n",
    "        ax = fig.add_subplot(111)\n",
    "        ax.plot(t, waves[i], linewidth=1)\n",
    "        ax.set_title(f\"Wave {i+1}\")\n",
    "        ax.set_xlabel(\"Sample\")\n",
    "        ax.set_ylabel(\"Amplitude\")\n",
    "        ax.grid(True)\n",
    "        fig.tight_layout()  # reduce margins to use width\n",
    "        \n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "def hf_ds_download(hf_token, repo_id):\n",
    "    login(hf_token[1:])\n",
    "    return snapshot_download(repo_id, repo_type=\"dataset\")\n",
    "\n",
    "\n",
    "def get_spectra_features(X, b=False):\n",
    "    \"\"\"Create multi-channel features from spectra: raw, 1st derivative, 2nd derivative.\"\"\"\n",
    "    X_processed = np.zeros_like(X)\n",
    "    # Baseline correction and SNV\n",
    "    for i in tqdm(range(X.shape[0])):\n",
    "        poly = np.polyfit(np.arange(X.shape[1]), X[i], 3)\n",
    "        baseline = np.polyval(poly, np.arange(X.shape[1]))\n",
    "        corrected_spec = X[i] - baseline\n",
    "        #X_processed[i] = (corrected_spec - corrected_spec.mean()) / (corrected_spec.std() + 1e-8)\n",
    "        X_processed[i] = corrected_spec\n",
    "        \n",
    "    # Calculate derivatives\n",
    "    deriv1 = signal.savgol_filter(X_processed, window_length=11, polyorder=3, deriv=1, axis=1)\n",
    "    deriv2 = signal.savgol_filter(X_processed, window_length=11, polyorder=3, deriv=2, axis=1)\n",
    "\n",
    "    if b: return np.stack([X_processed, deriv1, deriv2], axis=1)\n",
    "    return np.stack([deriv1, deriv2], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c619231b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if True:\n",
    "    path = \"/kaggle/input/dig-4-bio-raman-transfer-learning-challenge\"\n",
    "    files = os.listdir(path)\n",
    "    [(i, files[i]) for i in range(len(files))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d6bf968",
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    hf_token = \"xhf_XURkoNhwOIPtEdHfNeRpVkjEwKSkhtigFi\"\n",
    "    path = hf_ds_download(hf_token, \"ArbaazBeg/kaggle-spectogram\")\n",
    "    files = os.listdir(path)\n",
    "    [(i, files[i]) for i in range(len(files))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1eac0b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "dataset_names = ['anton_532', 'anton_785', 'kaiser', 'mettler_toledo', 'metrohm', 'tec5', 'timegate', 'tornado']\n",
    "\n",
    "lower_bounds = {\n",
    "    'anton_532': 200,\n",
    "    'anton_785': 100,\n",
    "    'kaiser': -37,\n",
    "    'mettler_toledo': 300,\n",
    "    'metrohm': 200,\n",
    "    'tec5': 85,\n",
    "    'timegate': 200,\n",
    "    'tornado': 300,\n",
    "}\n",
    "\n",
    "\n",
    "upper_bounds = {\n",
    "    'anton_532': 3500,\n",
    "    'anton_785': 2300,\n",
    "    'kaiser': 1942,\n",
    "    'mettler_toledo': 3350,\n",
    "    'metrohm': 3350,\n",
    "    'tec5': 3210,\n",
    "    'timegate': 2000,\n",
    "    'tornado': 3300,\n",
    "}\n",
    "\n",
    "def get_csv_dataset(\n",
    "    dataset_name,\n",
    "    lower_wn=-1000,\n",
    "    upper_wn=10000,\n",
    "    dtype=None,\n",
    "):\n",
    "    lower_wn = max(lower_wn, lower_bounds[dataset_name])\n",
    "    upper_wn = min(upper_wn, upper_bounds[dataset_name])\n",
    "    dtype = dtype or np.float64\n",
    "\n",
    "    df = pd.read_csv(\n",
    "        os.path.join(\n",
    "            DATA_PATH,\n",
    "            '%s.csv' % dataset_name,\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    spectra_selection = np.logical_and(\n",
    "        lower_wn <= np.array([float(one) for one in df.columns[:-5]]),\n",
    "        np.array([float(one) for one in df.columns[:-5]]) <= upper_wn,\n",
    "    )\n",
    "\n",
    "    spectra = df.iloc[:, :-5].iloc[:, spectra_selection].values\n",
    "    label = df.iloc[:, -5:-1].values\n",
    "    cv_indices = df.iloc[:, -1].values\n",
    "    all_indices = np.array(range(len(cv_indices)))\n",
    "\n",
    "    cv_folds = [\n",
    "        (\n",
    "            # trainings indices\n",
    "            all_indices[cv_indices != fold_idx],\n",
    "            # validation indices\n",
    "            all_indices[cv_indices == fold_idx],\n",
    "        )\n",
    "        for fold_idx in range(len(set(cv_indices)))\n",
    "    ]\n",
    "    \n",
    "    wavenumbers = np.array([\n",
    "        float(one) for one in df.columns[:-5]\n",
    "    ])[spectra_selection]\n",
    "\n",
    "    return (\n",
    "        spectra.astype(dtype),\n",
    "        label.astype(dtype),\n",
    "        None,\n",
    "        cv_folds,\n",
    "        wavenumbers.astype(dtype)\n",
    "    )\n",
    "\n",
    "def load_joint_dataset(\n",
    "    dataset_names,\n",
    "    lower_wn=-1000,\n",
    "    upper_wn=10000,\n",
    "    dtype=None,\n",
    "    leave_out_one_device=False,\n",
    "):\n",
    "\n",
    "    dtype = dtype or np.float64\n",
    "\n",
    "    lower_wn = max(\n",
    "        lower_wn,\n",
    "        *[lower_bounds[name] for name in dataset_names])\n",
    "    upper_wn = min(\n",
    "        upper_wn,\n",
    "        *[upper_bounds[name] for name in dataset_names]\n",
    "    )\n",
    "\n",
    "    print(\"Lower WN: \", lower_wn)\n",
    "    print(\"Upper WN: \", upper_wn)\n",
    "\n",
    "    datasets = [\n",
    "        get_csv_dataset(\n",
    "            dataset_name,\n",
    "            lower_wn=lower_wn,\n",
    "            upper_wn=upper_wn,\n",
    "            dtype=dtype,\n",
    "        )\n",
    "        for dataset_name in dataset_names\n",
    "    ]\n",
    "\n",
    "    joint_wns = np.arange(lower_wn, upper_wn + 1)\n",
    "    print(\"Joint WNS: \", joint_wns)\n",
    "    \n",
    "    interpolated_data = [\n",
    "        np.array([\n",
    "            np.interp(\n",
    "                joint_wns,\n",
    "                xp=wns,\n",
    "                fp=spectrum,\n",
    "            )\n",
    "            for spectrum in spectra\n",
    "        ])\n",
    "        for spectra, _, _, _, wns in datasets\n",
    "    ]\n",
    "    \n",
    "    normed_spectra = np.concatenate(\n",
    "        [\n",
    "            spectra / np.max(spectra)\n",
    "            for spectra in interpolated_data\n",
    "        ],\n",
    "        axis=0,\n",
    "    )\n",
    "    \n",
    "    dataset_offsets = np.concatenate(\n",
    "        [\n",
    "            [0],\n",
    "            np.cumsum([len(one[0]) for one in datasets])[:-1]\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    num_items = sum((len(one[0]) for one in datasets))\n",
    "    if leave_out_one_device:\n",
    "        val_indices = [\n",
    "            np.arange(start, end, 1)\n",
    "            for start, end in zip(\n",
    "                dataset_offsets,\n",
    "                np.concatenate([dataset_offsets[1:], np.array([num_items])])\n",
    "            )\n",
    "        ]\n",
    "    else:\n",
    "        val_indices = [\n",
    "            val_idxs + offset\n",
    "            for one, offset in zip(datasets, dataset_offsets)\n",
    "            for train_idxs, val_idxs in one[3]\n",
    "        ]\n",
    "\n",
    "    all_indices = set(range(num_items))\n",
    "\n",
    "    cv_folds = [\n",
    "        (np.array(list(all_indices - set(val_idxs))), val_idxs)\n",
    "        for val_idxs in val_indices\n",
    "    ]\n",
    "    return (\n",
    "        normed_spectra,\n",
    "        np.concatenate([one[1] for one in datasets])[:, :3],\n",
    "        cv_folds,\n",
    "        np.concatenate(\n",
    "            [\n",
    "                [0],\n",
    "                np.cumsum([len(one[0]) for one in datasets])\n",
    "            ]\n",
    "        ),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "19dbf4fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lower WN:  300\n",
      "Upper WN:  1942\n",
      "Joint WNS:  [ 300  301  302 ... 1940 1941 1942]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((2261, 1643), (2261, 3))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_PATH = path\n",
    "inputs, targets, cv_folds, dataset_offsets = load_joint_dataset(dataset_names)\n",
    "inputs.shape, targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c76ebc5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2194 1024  359 ... 2119  599 1459]\n"
     ]
    }
   ],
   "source": [
    "idx = np.random.permutation(inputs.shape[0])\n",
    "print(idx)\n",
    "inputs = inputs[idx]\n",
    "targets = targets[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9b83eb02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import scipy.optimize\n",
    "\n",
    "\n",
    "np_dtype_from_torch = {\n",
    "    torch.float32: np.float32,\n",
    "    torch.float64: np.float64,\n",
    "}\n",
    "\n",
    "class SpectralDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        spectra,\n",
    "        concentrations,\n",
    "        dtype=None,\n",
    "        spectra_mean_std=None,\n",
    "        concentration_mean_std=None,\n",
    "        combine_spectra_range=0.0,\n",
    "        baseline_factor_bound=0.0,\n",
    "        baseline_period_lower_bound=100.0,\n",
    "        baseline_period_upper_bound=200.0,\n",
    "        augment_slope_std=0.0,\n",
    "        augment_intersept_std=0.0,\n",
    "        rolling_bound=0,\n",
    "        spectrum_rolling_sigma=0.0,\n",
    "        augmentation_weight=0.1,\n",
    "        original_datapoint_weight=1.,\n",
    "    ):\n",
    "        self.dtype = dtype or torch.float32\n",
    "        self.combine_spectra_range = combine_spectra_range\n",
    "        self.baseline_factor_bound = baseline_factor_bound\n",
    "        self.augment_slope_std = augment_slope_std\n",
    "        self.augment_intercept_std = augment_intersept_std\n",
    "        self.baseline_period_lower_bound = baseline_period_lower_bound\n",
    "        self.baseline_period_upper_bound = baseline_period_upper_bound\n",
    "        self.rolling_bound = rolling_bound\n",
    "        self.spectrum_rolling_sigma = spectrum_rolling_sigma\n",
    "        self.augmentation_weight = torch.tensor(augmentation_weight, dtype=dtype)\n",
    "        self.original_dp_weight = original_datapoint_weight\n",
    "\n",
    "        # normalize spectra\n",
    "        spectra = torch.tensor(spectra, dtype=dtype)\n",
    "\n",
    "        if spectra_mean_std is None:\n",
    "            self.s_mean = torch.mean(spectra)\n",
    "            self.s_std = torch.std(spectra)\n",
    "        else:\n",
    "            self.s_mean, self.s_std = spectra_mean_std\n",
    "\n",
    "        self.spectra = torch.divide(\n",
    "            torch.subtract(spectra, self.s_mean),\n",
    "            self.s_std,\n",
    "        )\n",
    "\n",
    "        self.dummy_wns = np.tile(\n",
    "            np.arange(\n",
    "                0., 1., 1. / self.spectra.shape[2],\n",
    "                dtype=np_dtype_from_torch[self.dtype]\n",
    "            )[None, :self.spectra.shape[2]],\n",
    "            (self.spectra.shape[1], 1),\n",
    "        )\n",
    "\n",
    "        # normalize concentrations\n",
    "        concentrations = torch.tensor(concentrations, dtype=dtype)\n",
    "        if concentration_mean_std is None:\n",
    "            self.concentration_means = torch.nanmean(concentrations, dim=0)\n",
    "\n",
    "            self.concentration_stds = torch.maximum(\n",
    "                torch.tensor(\n",
    "                    [\n",
    "                        torch.std(col[torch.logical_not(torch.isnan(col))])\n",
    "                        for col in concentrations.T\n",
    "                    ]\n",
    "                ),\n",
    "                torch.tensor([1e-3] * concentrations.shape[1]),\n",
    "            )\n",
    "        else:\n",
    "            self.concentration_means = concentration_mean_std[0]\n",
    "            self.concentration_stds = concentration_mean_std[1]\n",
    "\n",
    "        self.concentrations = torch.divide(\n",
    "            torch.subtract(\n",
    "                concentrations,\n",
    "                self.concentration_means,\n",
    "            ),\n",
    "            self.concentration_stds,\n",
    "        )\n",
    "\n",
    "    def pick_two(self, max_idx=None):\n",
    "        max_idx = max_idx or len(self)\n",
    "        return random.choices(range(max_idx), k=2)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.concentrations)\n",
    "\n",
    "    def augment_spectra(self, spectra):\n",
    "        if self.augment_slope_std > 0.0:\n",
    "\n",
    "            def spectrum_approximation(x, slope, intercept):\n",
    "                return (slope * x + intercept).reshape(-1, 1)[:, 0]\n",
    "\n",
    "            slope, inter = scipy.optimize.curve_fit(\n",
    "                spectrum_approximation,\n",
    "                self.dummy_wns,\n",
    "                spectra.reshape(-1, 1)[:, 0],\n",
    "                p0=np.random.rand(2),\n",
    "            )[0]\n",
    "\n",
    "            new_slope = slope * (\n",
    "                    np.random.gamma(\n",
    "                        shape=1. / self.augment_slope_std,\n",
    "                        scale=self.augment_slope_std,\n",
    "                        size=1,\n",
    "                    )\n",
    "            )[0]\n",
    "            new_intercept = inter * (\n",
    "                1.0 + np.random.randn(1) * self.augment_intercept_std\n",
    "            )[0]\n",
    "            spectra += torch.tensor(\n",
    "                (new_slope - slope)\n",
    "            ) * self.dummy_wns + new_intercept - inter\n",
    "\n",
    "        factor = self.baseline_factor_bound * torch.rand(size=(1,))\n",
    "        offset = torch.rand(size=(1,)) * 2.0 * torch.pi\n",
    "        period = self.baseline_period_lower_bound + (\n",
    "            self.baseline_period_upper_bound - self.baseline_period_lower_bound\n",
    "        ) * torch.rand(size=(1,))\n",
    "        permutations = factor * torch.cos(\n",
    "            2.0 * torch.pi / period * self.dummy_wns + offset\n",
    "        )\n",
    "        return self.roll_spectrum(\n",
    "            spectra + permutations * spectra,\n",
    "            delta=random.randint(-self.rolling_bound, self.rolling_bound),\n",
    "        )\n",
    "\n",
    "    def roll_spectrum(self, spectra, delta):\n",
    "        num_spectra = spectra.shape[0]\n",
    "        rolled_spectra = np.roll(spectra, delta, axis=1)\n",
    "        if delta > 0:\n",
    "            rolled_spectra[:, :delta] = (\n",
    "                np.random.rand(num_spectra, delta) * self.spectrum_rolling_sigma + 1\n",
    "            ) * rolled_spectra[:, delta:(delta + 1)]\n",
    "        elif delta < 0:\n",
    "            rolled_spectra[:, delta:] = (\n",
    "                np.random.rand(num_spectra, -delta) * self.spectrum_rolling_sigma + 1\n",
    "            ) * rolled_spectra[:, delta - 1:delta]\n",
    "        return rolled_spectra\n",
    "\n",
    "    def combine_k_items(self, indices, weights):\n",
    "        return (\n",
    "            # spectra\n",
    "            torch.sum(\n",
    "                torch.mul(weights[:, None, None], self.spectra[indices, :, :]),\n",
    "                dim=0,\n",
    "            ),\n",
    "            # concentrations\n",
    "            torch.sum(\n",
    "                torch.mul(weights[:, None], self.concentrations[indices, :]),\n",
    "                dim=0,\n",
    "            )\n",
    "        )\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.combine_spectra_range < 1e-12:\n",
    "            spectrum = self.spectra[idx]\n",
    "            spectrum = self.augment_spectra(spectrum)\n",
    "            return (\n",
    "                spectrum,\n",
    "                self.concentrations[idx],\n",
    "                torch.tensor(1.0, dtype=self.dtype),\n",
    "            )\n",
    "          \n",
    "        else:\n",
    "            if random.random() < self.original_dp_weight:\n",
    "                one_weight = 1.\n",
    "                label_weight = torch.tensor(1.0, dtype=self.dtype)\n",
    "            else:\n",
    "                one_weight = random.uniform(0.0, self.combine_spectra_range)\n",
    "                label_weight = self.augmentation_weight\n",
    "            weights = torch.tensor([one_weight, (1 - one_weight)])\n",
    "            # just pick two random indices\n",
    "            indices = random.choices(range(len(self)), k=2)\n",
    "\n",
    "            mixed_spectra, mixed_concentrations = self.combine_k_items(\n",
    "                indices=indices,\n",
    "                weights=weights,\n",
    "            )\n",
    "            mixed_spectra = self.augment_spectra(mixed_spectra)\n",
    "            return mixed_spectra, mixed_concentrations, label_weight\n",
    "\n",
    "\n",
    "config = {\n",
    "    'initial_cnn_channels': 32,\n",
    "    'cnn_channel_factor': 1.279574024454846,\n",
    "    'num_cnn_layers': 8,\n",
    "    'kernel_size': 3,\n",
    "    'stride': 2,\n",
    "    'activation_function': 'ELU',\n",
    "    'fc_dropout': 0.10361700399831791,\n",
    "    'lr': 0.001,\n",
    "    'gamma': 0.9649606352621118,\n",
    "    'baseline_factor_bound': 0.748262317340447,\n",
    "    'baseline_period_lower_bound': 0.9703081695287203,\n",
    "    'baseline_period_span': 19.79744237606427,\n",
    "    'original_datapoint_weight': 0.4335003268130408,\n",
    "    'augment_slope_std': 0.08171025264382692,\n",
    "    'batch_size': 32,\n",
    "    'fc_dims': 226,\n",
    "    'rolling_bound': 2,\n",
    "    'num_blocks': 2,\n",
    "}\n",
    "\n",
    "def get_dataset(inputs, targets, config, inputs_mean_std=None, targets_mean_std=None):\n",
    "    return SpectralDataset(\n",
    "        spectra=inputs[:, None, :],\n",
    "        concentrations=targets,\n",
    "        dtype=torch.float32,\n",
    "        spectra_mean_std=inputs_mean_std,\n",
    "        concentration_mean_std=targets_mean_std,\n",
    "        combine_spectra_range=1.0,\n",
    "        baseline_factor_bound=config[\"baseline_factor_bound\"],\n",
    "        baseline_period_lower_bound=config[\"baseline_period_lower_bound\"],\n",
    "        baseline_period_upper_bound=(config[\"baseline_period_lower_bound\"] + config[\"baseline_period_span\"]),\n",
    "        augment_slope_std=config[\"augment_slope_std\"],\n",
    "        augment_intersept_std=0.0,\n",
    "        rolling_bound=config[\"rolling_bound\"],\n",
    "        spectrum_rolling_sigma=0.01,\n",
    "        augmentation_weight=0.1,\n",
    "        original_datapoint_weight=1.,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eb8f5695",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "def build_loader(\n",
    "    SEED,\n",
    "    ds,\n",
    "    train=True,\n",
    "    batch_size=1,\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    "    drop_last=True,\n",
    "    pin_memory=True,\n",
    "    persistent_workers=False,\n",
    "):\n",
    "    def seed_worker(worker_id):\n",
    "        worker_seed = torch.initial_seed() % 2**32\n",
    "        np.random.seed(worker_seed)\n",
    "        random.seed(worker_seed)\n",
    "\n",
    "    generator = torch.Generator()\n",
    "    generator.manual_seed(SEED if train else SEED+5232)\n",
    "\n",
    "    return DataLoader(\n",
    "        ds,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=pin_memory,\n",
    "        drop_last=drop_last,\n",
    "        persistent_workers=persistent_workers,\n",
    "        worker_init_fn=seed_worker,\n",
    "        generator=generator,\n",
    "        #sampler=DistributedSampler(\n",
    "        #    train_ds,\n",
    "        #    shuffle=True,\n",
    "        #    drop_last=True,\n",
    "        #    seed=config.seed\n",
    "        #)\n",
    "    )\n",
    "    \n",
    "    \n",
    "def return_dls(train_ds, eval_ds, train_batch_size, eval_batch_size):\n",
    "    train_dl = build_loader(\n",
    "        SEED,\n",
    "        train_ds,\n",
    "        train=True,\n",
    "        batch_size=train_batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=0,\n",
    "        drop_last=False,\n",
    "        pin_memory=True,\n",
    "        persistent_workers=False,\n",
    "    )\n",
    "\n",
    "    eval_dl = build_loader(\n",
    "        SEED,\n",
    "        eval_ds,\n",
    "        train=False,\n",
    "        batch_size=eval_batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=0,\n",
    "        drop_last=False,\n",
    "        pin_memory=True,\n",
    "        persistent_workers=False,\n",
    "    )\n",
    "    \n",
    "    return train_dl, eval_dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1e76b4ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import neptune\n",
    "\n",
    "\n",
    "def setup_neptune():\n",
    "    if not RESUME:\n",
    "        neptune_run = neptune.init_run(\n",
    "            project=\"arbaaz/kaggle-spect\",\n",
    "            name=MODEL_NAME,\n",
    "            api_token=\"eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiJlOGE2YjNiZS1mZGUyLTRjYjItYTg5Yy1mZWJkZTIzNzE1NmIifQ==\"\n",
    "        )\n",
    "\n",
    "        neptune_run[\"h_parameters\"] = {\n",
    "            \"seed\": SEED,\n",
    "            \"model_name\": MODEL_NAME,\n",
    "            \"optimizer_name\": \"nadam\",\n",
    "            \"learning_rate\": LR,\n",
    "            \"scheduler_name\": \"default\",\n",
    "            \"weight_decay\": WD,\n",
    "            \"num_epochs\": EPOCHS,\n",
    "            \"batch_size\": BATCH_SIZE,\n",
    "        }\n",
    "        if DROPOUT: neptune_run[\"h_parameters\"] = {\"dropout\": DROPOUT}\n",
    "        if DROP_PATH_RATE: neptune_run[\"h_parameters\"] = {\"drop_path_rate\": DROP_PATH_RATE}\n",
    "    else:\n",
    "        neptune_run = neptune.init_run(\n",
    "            project=\"arbaaz/crunchdao-structural-break\",\n",
    "            with_id=config.with_id,\n",
    "            api_token=\"eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiJlOGE2YjNiZS1mZGUyLTRjYjItYTg5Yy1mZWJkZTIzNzE1NmIifQ==\"\n",
    "        )\n",
    "\n",
    "    return neptune_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3484e5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "from torch.nn.modules.loss import _Loss\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "\n",
    "def loss_fn(logits, targets):\n",
    "    logits = logits.view(-1)\n",
    "    targets = targets.view(-1)\n",
    "    return F.mse_loss(logits, targets)\n",
    "\n",
    "\n",
    "def metric_fn(logits, targets):\n",
    "    preds = logits.cpu().detach().float().numpy()\n",
    "    targets = targets.cpu().detach().float().numpy()\n",
    "    \n",
    "    dim1 = r2_score(targets[:, 0], preds[:, 0])\n",
    "    dim2 = r2_score(targets[:, 1], preds[:, 1])\n",
    "    dim3 = r2_score(targets[:, 2], preds[:, 2])\n",
    "    \n",
    "    return dim1, dim2, dim3, r2_score(targets, preds)\n",
    "\n",
    "\n",
    "class MSEIgnoreNans(_Loss):\n",
    "    def forward(\n",
    "        self,\n",
    "        input: torch.Tensor,\n",
    "        target: torch.Tensor,\n",
    "        weights: torch.Tensor,\n",
    "    ) -> torch.Tensor:\n",
    "        mask = torch.isfinite(target)\n",
    "        mse = torch.mean(\n",
    "            torch.mul(\n",
    "                torch.square(input[mask] - target[mask]),\n",
    "                torch.tile(weights[:, None], dims=(1, target.shape[1]))[mask],\n",
    "            )\n",
    "        )\n",
    "        return torch.where(\n",
    "            torch.isfinite(mse),\n",
    "            mse,\n",
    "            torch.tensor(0.).to(target.device),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b9bd69df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "\n",
    "class Identity(torch.torch.nn.Module):\n",
    "    def forward(self, x):\n",
    "        return x\n",
    "\n",
    "\n",
    "# this is not a resnet yet\n",
    "class ReZeroBlock(torch.torch.nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels,\n",
    "        out_channels,\n",
    "        activation_function,\n",
    "        kernel_size,\n",
    "        stride,\n",
    "        dtype,\n",
    "        norm_layer=None,\n",
    "    ):\n",
    "        super(ReZeroBlock, self).__init__()\n",
    "        if norm_layer is None:\n",
    "            norm_layer = torch.torch.nn.BatchNorm1d\n",
    "\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        self.padding = divmod(kernel_size, 2)[0] if stride == 1 else 0\n",
    "\n",
    "        # does not change spatial dimension\n",
    "        self.conv1 = torch.nn.Conv1d(\n",
    "            in_channels,\n",
    "            out_channels,\n",
    "            kernel_size=1,\n",
    "            stride=1,\n",
    "            bias=False,\n",
    "            dtype=dtype,\n",
    "        )\n",
    "        self.bn1 = norm_layer(out_channels, dtype=dtype)\n",
    "        # Both self.conv2 and self.downsample layers\n",
    "        # downsample the input when stride != 1\n",
    "        self.conv2 = torch.nn.Conv1d(\n",
    "            out_channels,\n",
    "            out_channels,\n",
    "            kernel_size=kernel_size,\n",
    "            stride=stride,\n",
    "            groups=out_channels,\n",
    "            bias=False,\n",
    "            dtype=dtype,\n",
    "            padding=self.padding,\n",
    "        )\n",
    "        if stride > 1:\n",
    "            down_conv = torch.nn.Conv1d(\n",
    "                in_channels,\n",
    "                out_channels,\n",
    "                kernel_size=kernel_size,\n",
    "                stride=stride,\n",
    "                bias=False,\n",
    "                dtype=dtype,\n",
    "                # groups=out_channels,\n",
    "            )\n",
    "        else:\n",
    "            down_conv = Identity()\n",
    "\n",
    "        self.down_sample = torch.nn.Sequential(\n",
    "            down_conv,\n",
    "            norm_layer(out_channels),\n",
    "        )\n",
    "        self.bn2 = norm_layer(out_channels, dtype=dtype)\n",
    "        # does not change the spatial dimension\n",
    "        self.conv3 = torch.nn.Conv1d(\n",
    "            out_channels,\n",
    "            out_channels,\n",
    "            kernel_size=1,\n",
    "            stride=1,\n",
    "            bias=False,\n",
    "            dtype=dtype,\n",
    "        )\n",
    "        self.bn3 = norm_layer(out_channels, dtype=dtype)\n",
    "        self.activation = activation_function(inplace=True)\n",
    "        self.factor = torch.torch.nn.parameter.Parameter(torch.tensor(0.0, dtype=dtype))\n",
    "\n",
    "    def next_spatial_dim(self, last_spatial_dim):\n",
    "        return math.floor(\n",
    "            (last_spatial_dim + 2 * self.padding - self.kernel_size)\n",
    "            / self.stride + 1\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.activation(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.activation(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        # not really the identity, but kind of\n",
    "        identity = self.down_sample(x)\n",
    "\n",
    "        return self.activation(out * self.factor + identity)\n",
    "\n",
    "\n",
    "class ResNetEncoder(torch.torch.nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        spectrum_size,\n",
    "        cnn_encoder_channel_dims,\n",
    "        activation_function,\n",
    "        kernel_size,\n",
    "        stride,\n",
    "        dtype,\n",
    "        num_blocks,\n",
    "        verbose=False,\n",
    "    ):\n",
    "        super(ResNetEncoder, self).__init__()\n",
    "\n",
    "        self.spatial_dims = [spectrum_size]\n",
    "        layers = []\n",
    "        for in_channels, out_channels in zip(\n",
    "            cnn_encoder_channel_dims[:-1],\n",
    "            cnn_encoder_channel_dims[1:],\n",
    "        ):\n",
    "            block = ReZeroBlock(\n",
    "                in_channels=in_channels,\n",
    "                out_channels=out_channels,\n",
    "                activation_function=activation_function,\n",
    "                kernel_size=kernel_size,\n",
    "                stride=stride,\n",
    "                dtype=dtype,\n",
    "            )\n",
    "            layers.append(block)\n",
    "            self.spatial_dims.append(block.next_spatial_dim(self.spatial_dims[-1]))\n",
    "            for _ in range(num_blocks - 1):\n",
    "                block = ReZeroBlock(\n",
    "                    in_channels=out_channels,\n",
    "                    out_channels=out_channels,\n",
    "                    activation_function=activation_function,\n",
    "                    kernel_size=kernel_size,\n",
    "                    stride=1,\n",
    "                    dtype=dtype,\n",
    "                )\n",
    "                layers.append(block)\n",
    "                self.spatial_dims.append(block.next_spatial_dim(self.spatial_dims[-1]))\n",
    "\n",
    "        self.resnet_layers = torch.torch.nn.Sequential(*layers)\n",
    "        if verbose:\n",
    "            print(\"CNN Encoder Channel Dims: %s\" % (cnn_encoder_channel_dims))\n",
    "            print(\"CNN Encoder Spatial Dims: %s\" % (self.spatial_dims))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.resnet_layers(x)\n",
    "\n",
    "\n",
    "class ReZeroNet(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        spectra_channels,\n",
    "        spectra_size,\n",
    "        initial_cnn_channels,\n",
    "        cnn_channel_factor,\n",
    "        num_cnn_layers,\n",
    "        kernel_size,\n",
    "        stride,\n",
    "        activation_function,\n",
    "        fc_dims,\n",
    "        fc_dropout=0.0,\n",
    "        dtype=None,\n",
    "        verbose=False,\n",
    "        fc_output_channels=1,\n",
    "        num_blocks=1,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.fc_output_channels = fc_output_channels\n",
    "        self.dtype = dtype or torch.float32\n",
    "\n",
    "        activation_function = getattr(torch.nn, activation_function)\n",
    "\n",
    "        # Setup CNN Encoder\n",
    "        cnn_encoder_channel_dims = [spectra_channels] + [\n",
    "            int(initial_cnn_channels * (cnn_channel_factor**idx))\n",
    "            for idx in range(num_cnn_layers)\n",
    "        ]\n",
    "        self.cnn_encoder = ResNetEncoder(\n",
    "            spectrum_size=spectra_size,\n",
    "            cnn_encoder_channel_dims=cnn_encoder_channel_dims,\n",
    "            activation_function=activation_function,\n",
    "            kernel_size=kernel_size,\n",
    "            stride=stride,\n",
    "            num_blocks=num_blocks,\n",
    "            dtype=dtype,\n",
    "            verbose=verbose,\n",
    "        )\n",
    "        self.fc_dims = [\n",
    "            int(\n",
    "                self.cnn_encoder.spatial_dims[-1]\n",
    "            ) * int(cnn_encoder_channel_dims[-1])\n",
    "        ] + fc_dims\n",
    "\n",
    "        if verbose:\n",
    "            print(\"Fc Dims: %s\" % self.fc_dims)\n",
    "        fc_layers = []\n",
    "        for idx, (in_dim, out_dim) in enumerate(\n",
    "                zip(self.fc_dims[:-2], self.fc_dims[1:-1])\n",
    "        ):\n",
    "            fc_layers.append(torch.nn.Linear(in_dim, out_dim))\n",
    "            fc_layers.append(torch.nn.ELU())\n",
    "            fc_layers.append(torch.nn.Dropout(fc_dropout / (2 ** idx)))\n",
    "        fc_layers.append(\n",
    "            torch.nn.Linear(\n",
    "                self.fc_dims[-2],\n",
    "                self.fc_dims[-1] * self.fc_output_channels,\n",
    "            ),\n",
    "        )\n",
    "        self.fc_net = torch.nn.Sequential(*fc_layers)\n",
    "        if verbose:\n",
    "            num_params = sum(p.numel() for p in self.parameters())\n",
    "            print(\"Number of Parameters: %s\" % num_params)\n",
    "\n",
    "    def forward(self, spectra):\n",
    "        embeddings = self.cnn_encoder(spectra)\n",
    "        forecast = self.fc_net(embeddings.view(-1, self.fc_dims[0]))\n",
    "        if self.fc_output_channels > 1:\n",
    "            forecast = forecast.reshape(\n",
    "                -1, self.fc_output_channels, self.fc_dims[-1]\n",
    "            )\n",
    "        return forecast\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cf964c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "\n",
    "\n",
    "class ResZeroBlock(torch.nn.Module):\n",
    "    def __init__(self, skip_part, model_part):\n",
    "        super(ResZeroBlock, self).__init__()\n",
    "        self.skip_part = skip_part\n",
    "        self.model_part = model_part\n",
    "        self.factor = torch.nn.parameter.Parameter(torch.tensor(0.))\n",
    "\n",
    "    def forward(self, X):\n",
    "        return self.skip_part(X) + self.factor * self.model_part(X)\n",
    "\n",
    "\n",
    "class Identity(torch.nn.Module):\n",
    "    def forward(self, X):\n",
    "        return X\n",
    "\n",
    "\n",
    "class RamanXception(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        spectra_size,\n",
    "        initial_channels,\n",
    "        entry_channels,\n",
    "        num_mid_blocks,\n",
    "        exit_channels,\n",
    "        num_concentrations,\n",
    "        fc_dims,\n",
    "        fc_dropout,\n",
    "        lower_bounds=None,\n",
    "        dtype=None,\n",
    "        activation_function='ReLU',\n",
    "        classification_idx=None,\n",
    "        verbose=False,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super(RamanXception, self).__init__()\n",
    "\n",
    "        self.classification_idx = classification_idx or num_concentrations\n",
    "\n",
    "        if lower_bounds is None:\n",
    "            self.lower_bounds = torch.nn.parameter.Parameter(\n",
    "                torch.tensor([-1000] * num_concentrations),\n",
    "                requires_grad=False,\n",
    "            )\n",
    "        else:\n",
    "            self.lower_bounds = torch.nn.parameter.Parameter(\n",
    "                lower_bounds,\n",
    "                requires_grad=False,\n",
    "            )\n",
    "        dtype = dtype or torch.float32\n",
    "        activation_function = getattr(torch.nn, activation_function)\n",
    "        self.spatial_dimensions = [spectra_size]\n",
    "\n",
    "        # setup initial layers\n",
    "        initial_layers = torch.nn.Sequential()\n",
    "        for idx, (in_channels, out_channels) in enumerate(\n",
    "            zip(\n",
    "                [1] + initial_channels[:-1],\n",
    "                initial_channels,\n",
    "            ),\n",
    "        ):\n",
    "            initial_layers.add_module(\n",
    "                'initial_%s' % idx,\n",
    "                torch.nn.Conv1d(\n",
    "                    in_channels,\n",
    "                    out_channels,\n",
    "                    kernel_size=3,\n",
    "                    stride=2,\n",
    "                    padding=1,\n",
    "                    dtype=dtype,\n",
    "                    bias=False,\n",
    "                ),\n",
    "            )\n",
    "            self.spatial_dimensions.append(\n",
    "                math.floor((self.spatial_dimensions[-1] - 1) / 2 + 1)\n",
    "            )\n",
    "            initial_layers.add_module(\n",
    "                'initial_batch_%s' % idx,\n",
    "                torch.nn.BatchNorm1d(\n",
    "                    out_channels,\n",
    "                    dtype=dtype,\n",
    "                ),\n",
    "            )\n",
    "            initial_layers.add_module(\n",
    "                'initial_activation_%s' % idx,\n",
    "                activation_function(),\n",
    "            )\n",
    "\n",
    "        # Entry flow\n",
    "        entry_flow = torch.nn.Sequential()\n",
    "        # self.entry_flow_length = len(entry_channels)\n",
    "        for idx, (in_channels, out_channels) in enumerate(\n",
    "            zip(\n",
    "                [initial_channels[-1]] + entry_channels[:-1],\n",
    "                entry_channels,\n",
    "            )\n",
    "        ):\n",
    "            entry_flow.add_module(\n",
    "                name='entry_flow_%s' % idx,\n",
    "                module=ResZeroBlock(\n",
    "                    skip_part=torch.nn.Conv1d(\n",
    "                        in_channels,\n",
    "                        out_channels,\n",
    "                        kernel_size=1,\n",
    "                        stride=2,\n",
    "                        dtype=dtype,\n",
    "                        bias=False,\n",
    "                    ),\n",
    "                    model_part=torch.nn.Sequential(\n",
    "                        activation_function(),\n",
    "                        # spatial dimension stays constant\n",
    "                        torch.nn.Conv1d(\n",
    "                            in_channels,\n",
    "                            in_channels,\n",
    "                            kernel_size=1,\n",
    "                            dtype=dtype,\n",
    "                            bias=False,\n",
    "                        ),\n",
    "                        torch.nn.Conv1d(\n",
    "                            in_channels,\n",
    "                            in_channels,\n",
    "                            kernel_size=3,\n",
    "                            groups=in_channels,\n",
    "                            padding=1,\n",
    "                            dtype=dtype,\n",
    "                            bias=False,\n",
    "                        ),\n",
    "                        # spatial dimension stays constant\n",
    "                        torch.nn.BatchNorm1d(\n",
    "                            in_channels,\n",
    "                            dtype=dtype,\n",
    "                        ),\n",
    "                        activation_function(),\n",
    "                        torch.nn.Conv1d(\n",
    "                            in_channels,\n",
    "                            out_channels,\n",
    "                            kernel_size=1,\n",
    "                            dtype=dtype,\n",
    "                            bias=False,\n",
    "                        ),\n",
    "                        torch.nn.Conv1d(\n",
    "                            out_channels,\n",
    "                            out_channels,\n",
    "                            kernel_size=3,\n",
    "                            groups=out_channels,\n",
    "                            padding=1,\n",
    "                            dtype=dtype,\n",
    "                            bias=False,\n",
    "                        ),\n",
    "                        torch.nn.BatchNorm1d(\n",
    "                            out_channels,\n",
    "                            dtype=dtype,\n",
    "                        ),\n",
    "                        # spatial dimension: in_dim / 2\n",
    "                        torch.nn.MaxPool1d(3, stride=2, padding=1),\n",
    "                    )\n",
    "                ),\n",
    "            )\n",
    "            self.spatial_dimensions.append(\n",
    "                math.floor((self.spatial_dimensions[-1] - 1) / 2 + 1)\n",
    "            )\n",
    "\n",
    "        # Middle flow\n",
    "        num_mid_channels = entry_channels[-1]\n",
    "        middle_flow = torch.nn.Sequential()\n",
    "        for idx in range(num_mid_blocks):\n",
    "            middle_flow.add_module(\n",
    "                name='middle_flow_%s' % idx,\n",
    "                module=ResZeroBlock(\n",
    "                    skip_part=Identity(),\n",
    "                    model_part=torch.nn.Sequential(\n",
    "                        activation_function(),\n",
    "                        torch.nn.Conv1d(\n",
    "                            num_mid_channels,\n",
    "                            num_mid_channels,\n",
    "                            kernel_size=1,\n",
    "                            dtype=dtype,\n",
    "                            bias=False,\n",
    "                        ),\n",
    "                        torch.nn.Conv1d(\n",
    "                            num_mid_channels,\n",
    "                            num_mid_channels,\n",
    "                            kernel_size=3,\n",
    "                            groups=num_mid_channels,\n",
    "                            padding=1,\n",
    "                            dtype=dtype,\n",
    "                            bias=False,\n",
    "                        ),\n",
    "                        torch.nn.BatchNorm1d(\n",
    "                            num_mid_channels,\n",
    "                            dtype=dtype,\n",
    "                        ),\n",
    "                        activation_function(),\n",
    "                        torch.nn.Conv1d(\n",
    "                            num_mid_channels,\n",
    "                            num_mid_channels,\n",
    "                            kernel_size=1,\n",
    "                            dtype=dtype,\n",
    "                            bias=False,\n",
    "                        ),\n",
    "                        torch.nn.Conv1d(\n",
    "                            num_mid_channels,\n",
    "                            num_mid_channels,\n",
    "                            kernel_size=3,\n",
    "                            groups=num_mid_channels,\n",
    "                            padding=1,\n",
    "                            dtype=dtype,\n",
    "                            bias=False,\n",
    "                        ),\n",
    "                        torch.nn.BatchNorm1d(\n",
    "                            num_mid_channels,\n",
    "                            dtype=dtype,\n",
    "                        ),\n",
    "                        activation_function(),\n",
    "                        torch.nn.Conv1d(\n",
    "                            num_mid_channels,\n",
    "                            num_mid_channels,\n",
    "                            kernel_size=1,\n",
    "                            dtype=dtype,\n",
    "                            bias=False,\n",
    "                        ),\n",
    "                        torch.nn.Conv1d(\n",
    "                            num_mid_channels,\n",
    "                            num_mid_channels,\n",
    "                            kernel_size=3,\n",
    "                            groups=num_mid_channels,\n",
    "                            padding=1,\n",
    "                            dtype=dtype,\n",
    "                            bias=False,\n",
    "                        ),\n",
    "                    )\n",
    "                )\n",
    "            )\n",
    "            self.spatial_dimensions.append(self.spatial_dimensions[-1])\n",
    "\n",
    "        exit_flow = torch.nn.Sequential()\n",
    "        for idx, (in_channels, (mid_channels, out_channels)) in enumerate(list(\n",
    "            zip(\n",
    "                [num_mid_channels] + [out for _, out in exit_channels[:-2]],\n",
    "                exit_channels[:-1],\n",
    "            ),\n",
    "        )):\n",
    "            exit_flow.add_module(\n",
    "                name='exit_flow_%s' % idx,\n",
    "                module=ResZeroBlock(\n",
    "                    skip_part=torch.nn.Conv1d(\n",
    "                        in_channels,\n",
    "                        out_channels,\n",
    "                        kernel_size=1,\n",
    "                        stride=2,\n",
    "                        dtype=dtype,\n",
    "                        bias=False,\n",
    "                    ),\n",
    "                    model_part=torch.nn.Sequential(\n",
    "                        torch.nn.Conv1d(\n",
    "                            in_channels,\n",
    "                            mid_channels,\n",
    "                            kernel_size=1,\n",
    "                            dtype=dtype,\n",
    "                            bias=False,\n",
    "                        ),\n",
    "                        torch.nn.Conv1d(\n",
    "                            mid_channels,\n",
    "                            mid_channels,\n",
    "                            kernel_size=3,\n",
    "                            groups=mid_channels,\n",
    "                            padding=1,\n",
    "                            dtype=dtype,\n",
    "                            bias=False,\n",
    "                        ),\n",
    "                        torch.nn.BatchNorm1d(\n",
    "                            mid_channels,\n",
    "                            dtype=dtype,\n",
    "                        ),\n",
    "                        activation_function(),\n",
    "                        torch.nn.Conv1d(\n",
    "                            mid_channels,\n",
    "                            out_channels,\n",
    "                            kernel_size=1,\n",
    "                            dtype=dtype,\n",
    "                            bias=False,\n",
    "                        ),\n",
    "                        torch.nn.Conv1d(\n",
    "                            out_channels,\n",
    "                            out_channels,\n",
    "                            kernel_size=3,\n",
    "                            groups=out_channels,\n",
    "                            padding=1,\n",
    "                            dtype=dtype,\n",
    "                            bias=False,\n",
    "                        ),\n",
    "                        torch.nn.BatchNorm1d(\n",
    "                            out_channels,\n",
    "                            dtype=dtype,\n",
    "                        ),\n",
    "                        activation_function(),\n",
    "                        torch.nn.MaxPool1d(\n",
    "                            kernel_size=3,\n",
    "                            stride=2,\n",
    "                            padding=1,\n",
    "                        ),\n",
    "                    )\n",
    "                )\n",
    "            )\n",
    "            self.spatial_dimensions.append(\n",
    "                math.floor((self.spatial_dimensions[-1] - 1) / 2 + 1)\n",
    "            )\n",
    "\n",
    "        # Last part of the exit flow\n",
    "        in_channels = exit_channels[-2][1]\n",
    "        mid_channels = exit_channels[-1][0]\n",
    "        out_channels = exit_channels[-1][1]\n",
    "        final_flow = torch.nn.Sequential(\n",
    "            torch.nn.Conv1d(\n",
    "                in_channels,\n",
    "                mid_channels,\n",
    "                kernel_size=1,\n",
    "                dtype=dtype,\n",
    "                bias=False,\n",
    "            ),\n",
    "            torch.nn.Conv1d(\n",
    "                mid_channels,\n",
    "                mid_channels,\n",
    "                kernel_size=3,\n",
    "                groups=mid_channels,\n",
    "                padding=1,\n",
    "                dtype=dtype,\n",
    "                bias=False,\n",
    "            ),\n",
    "            torch.nn.BatchNorm1d(\n",
    "                mid_channels,\n",
    "                dtype=dtype,\n",
    "            ),\n",
    "            activation_function(),\n",
    "            torch.nn.Conv1d(\n",
    "                mid_channels,\n",
    "                out_channels,\n",
    "                kernel_size=1,\n",
    "                dtype=dtype,\n",
    "            ),\n",
    "            torch.nn.Conv1d(\n",
    "                out_channels,\n",
    "                out_channels,\n",
    "                kernel_size=3,\n",
    "                groups=out_channels,\n",
    "                padding=1,\n",
    "                dtype=dtype,\n",
    "            ),\n",
    "            torch.nn.BatchNorm1d(\n",
    "                out_channels,\n",
    "                dtype=dtype,\n",
    "            ),\n",
    "            activation_function(),\n",
    "        )\n",
    "        self.conv_net = torch.nn.Sequential(\n",
    "            initial_layers,\n",
    "            entry_flow,\n",
    "            middle_flow,\n",
    "            exit_flow,\n",
    "            final_flow,\n",
    "        )\n",
    "\n",
    "        self.fc_input_dim = int(out_channels * self.spatial_dimensions[-1])\n",
    "        self.fc_net = torch.nn.Sequential()\n",
    "        for idx, (in_dim, out_dim) in enumerate(\n",
    "            zip(\n",
    "                [self.fc_input_dim] + fc_dims[:-1],\n",
    "                fc_dims,\n",
    "            )\n",
    "        ):\n",
    "            self.fc_net.add_module(\n",
    "                'fc_net_%s' % idx,\n",
    "                torch.nn.Linear(\n",
    "                    in_dim,\n",
    "                    out_dim,\n",
    "                    dtype=dtype,\n",
    "                    bias=True,\n",
    "                ),\n",
    "            )\n",
    "            self.fc_net.add_module(\n",
    "                'fc_relu_%s' % idx,\n",
    "                torch.nn.ReLU(),\n",
    "            )\n",
    "            self.fc_net.add_module(\n",
    "                'fc_dropout_%s' % idx,\n",
    "                torch.nn.Dropout(fc_dropout),\n",
    "            )\n",
    "\n",
    "        self.fc_net.add_module(\n",
    "            'output_layer',\n",
    "            torch.nn.Linear(\n",
    "                fc_dims[-1] if fc_dims else out_channels,\n",
    "                num_concentrations,\n",
    "                dtype=dtype,\n",
    "                bias=True,\n",
    "            ),\n",
    "        )\n",
    "        self.softplus = torch.nn.Softplus()\n",
    "        if verbose:\n",
    "            print('Spatial dimensions: %s' % self.spatial_dimensions)\n",
    "            print(\n",
    "                'Fully Connected dimensions %s' % (\n",
    "                        [self.fc_input_dim] + fc_dims\n",
    "                )\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_net(x)\n",
    "\n",
    "        fc_output = self.fc_net(torch.reshape(x, (-1, self.fc_input_dim)))\n",
    "        return torch.concat(\n",
    "            [\n",
    "                fc_output[:, :self.classification_idx],\n",
    "                torch.sigmoid(fc_output[:, self.classification_idx:])\n",
    "            ],\n",
    "            dim=1,\n",
    "        )\n",
    "\n",
    "\n",
    "model_config = {\n",
    "    'initial_channels': 8,\n",
    "    'entry_channels_start': 17,\n",
    "    'channel_factor': 1.5692504144354933,\n",
    "    'entry_exit_length': 3,\n",
    "    'num_mid_blocks': 4,\n",
    "    'fc_dims': 101,\n",
    "    'fc_dropout': 0.11748964300948816,\n",
    "    'learning_rate': 0.001,\n",
    "    'gamma': 0.9921697445978254,\n",
    "    'batch_size': 21,\n",
    "    'entropy_weight': 6.441421425536572,\n",
    "    'uniform_sampling_range': 0.03803705551872033,\n",
    "    'activation_function': 'ELU', \n",
    "    'fake_weight': 0.032878013410751736,\n",
    "    'just_scale_concentrations': True,\n",
    "    'entry_factor': 1.5692504144354933,\n",
    "    'exit_factor': 1.5692504144354933,\n",
    "    'entry_length': 3,\n",
    "    'exit_length': 3,\n",
    "    'spectra_size': 1643,\n",
    "    'dtype': torch.float32}\n",
    "\n",
    "lr = model_config.get('learning_rate')\n",
    "l2_reg = model_config.get('l2_reg', 0.)\n",
    "gamma = model_config.get('gamma', 1.)\n",
    "model_config['initial_channels'] = [\n",
    "    model_config['initial_channels'],\n",
    "    2 * model_config['initial_channels'],\n",
    "]\n",
    "# create entry channel dimensions\n",
    "entry_channels_start = model_config['entry_channels_start']\n",
    "entry_factor = model_config['entry_factor']\n",
    "entry_length = model_config['entry_length']\n",
    "entry_channels = [entry_channels_start]\n",
    "for _ in range(entry_length):\n",
    "    entry_channels.append(int(entry_factor * entry_channels[-1]))\n",
    "model_config['entry_channels'] = entry_channels\n",
    "# create exit channel dimensions\n",
    "exit_channels_start = entry_channels[-1]\n",
    "exit_factor = model_config.get('exit_factor')\n",
    "exit_length = model_config.get('exit_length')\n",
    "exit_channels = [\n",
    "    (\n",
    "        int(exit_channels_start * math.sqrt(exit_factor)),\n",
    "        int(exit_channels_start * exit_factor),\n",
    "    )\n",
    "]\n",
    "for _ in range(1, exit_length):\n",
    "    exit_channels.append(\n",
    "        (\n",
    "            int(exit_channels[-1][0] * math.sqrt(exit_factor)),\n",
    "            int(exit_channels[-1][0] * exit_factor),\n",
    "        )\n",
    "    )\n",
    "model_config['exit_channels'] = exit_channels\n",
    "model_config[\"num_concnetrations\"] = 3\n",
    "model_config['fc_dims'] = [config['fc_dims']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "111b3364",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "def train(\n",
    "    model, \n",
    "    optimizer,\n",
    "    device,\n",
    "    amp_dtype,\n",
    "    scheduler,\n",
    "    train_dl,\n",
    "    eval_dl,\n",
    "    loss_fn,\n",
    "    epochs,\n",
    "    checkpoint_name,\n",
    "    score=-float(\"inf\"),\n",
    "    neptune_run=None,\n",
    "    p=True,\n",
    "):  \n",
    "    scaler = torch.amp.GradScaler(device)\n",
    "    for epoch in tqdm(range(epochs), leave=False):\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "        all_logits = []\n",
    "        all_targets = []\n",
    "        \n",
    "        for inputs, targets, weights in train_dl:\n",
    "            inputs = inputs.to(device, non_blocking=True)\n",
    "            targets = targets.to(device, non_blocking=True)\n",
    "            weights = weights.to(device, non_blocking=True)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            with torch.amp.autocast(device_type=device, dtype=amp_dtype, cache_enabled=True):\n",
    "                logits = model(inputs)\n",
    "                loss = loss_fn(logits, targets, weights)\n",
    "                  \n",
    "            if amp_dtype == torch.bfloat16:                \n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            else:\n",
    "                scaler.scale(loss).backward()\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "\n",
    "            scheduler.step()\n",
    "            if neptune_run is not None:  neptune_run[\"lr_step\"].append(scheduler.get_last_lr()[0])\n",
    "            \n",
    "            total_loss += loss.detach().cpu()\n",
    "            all_logits.append(logits.detach().cpu())\n",
    "            all_targets.append(targets.detach().cpu())\n",
    "        \n",
    "        all_logits = torch.cat(all_logits)\n",
    "        all_targets = torch.cat(all_targets)\n",
    "\n",
    "        one, two, three, r2 = metric_fn(all_logits, all_targets)\n",
    "        total_loss = total_loss / len(train_dl)\n",
    "        \n",
    "        model.eval()\n",
    "        eval_total_loss = 0.0\n",
    "        eval_all_logits = []\n",
    "        eval_all_targets = []\n",
    "\n",
    "        for inputs, targets, weights in eval_dl:\n",
    "            inputs = inputs.to(device, non_blocking=True)\n",
    "            targets = targets.to(device, non_blocking=True)\n",
    "            weights = weights.to(device, non_blocking=True)\n",
    "\n",
    "            with torch.inference_mode():\n",
    "                with torch.amp.autocast(device_type=device, dtype=amp_dtype, cache_enabled=True):\n",
    "                    logits = model(inputs)\n",
    "                    loss = loss_fn(logits, targets, weights)\n",
    "\n",
    "            eval_total_loss += loss.detach().cpu()\n",
    "            eval_all_logits.append(logits.detach().cpu())\n",
    "            eval_all_targets.append(targets.detach().cpu())\n",
    "        \n",
    "        eval_all_logits = torch.cat(eval_all_logits)\n",
    "        eval_all_targets = torch.cat(eval_all_targets)\n",
    "\n",
    "        eval_one, eval_two, eval_three, eval_r2 = metric_fn(eval_all_logits, eval_all_targets)\n",
    "        eval_total_loss = eval_total_loss / len(eval_dl)\n",
    "        \n",
    "        if eval_r2 > score:\n",
    "            score = eval_r2\n",
    "            data = {\"state_dict\": model.state_dict()}\n",
    "            data[\"epoch\"] = epoch \n",
    "            data[\"score\"] = score\n",
    "            torch.save(data, f\"/kaggle/working/{checkpoint_name}\")\n",
    "        \n",
    "        if neptune_run is not None:\n",
    "            neptune_run[\"train/loss\"].append(total_loss)\n",
    "            neptune_run[\"eval/loss\"].append(eval_total_loss)\n",
    "            neptune_run[\"train/r2\"].append(r2)\n",
    "            neptune_run[\"eval/r2\"].append(eval_r2)\n",
    "            neptune_run[\"train/one\"].append(one)\n",
    "            neptune_run[\"train/two\"].append(two)\n",
    "            neptune_run[\"train/three\"].append(three)\n",
    "            neptune_run[\"eval/one\"].append(eval_one)\n",
    "            neptune_run[\"eval/two\"].append(eval_two)\n",
    "            neptune_run[\"eval/three\"].append(eval_three)\n",
    "            \n",
    "        if p and epoch % 5 == 0:\n",
    "            print(\n",
    "                f\"Epoch: {epoch}, \"\n",
    "                f\"train/loss: {total_loss:.4f}, \"\n",
    "                f\"eval/loss: {eval_total_loss:.4f}, \"\n",
    "                f\"train/r2: {r2:.4f}, \"\n",
    "                f\"eval/r2: {eval_r2:.4f}, \"\n",
    "                f\"train/one: {one:.4f}, \"\n",
    "                f\"train/two: {two:.4f}, \"\n",
    "                f\"train/three: {three:.4f}, \"\n",
    "                f\"eval/one: {eval_one:.4f}, \"\n",
    "                f\"eval/two: {eval_two:.4f}, \"\n",
    "                f\"eval/three: {eval_three:.4f} \"\n",
    "            )\n",
    "            \n",
    "    if neptune_run is not None: neptune_run.stop()\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a63a6ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 100\n",
    "WD = 1e-3\n",
    "LR = 1e-4\n",
    "\n",
    "DROPOUT = 0.5\n",
    "DROP_PATH_RATE = 0.2\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "RESUME = False\n",
    "\n",
    "if False:\n",
    "    config[\"dtype\"] = torch.float32\n",
    "    config[\"spectra_size\"] = 1643\n",
    "    config[\"spectra_channels\"] = 1\n",
    "    config[\"fc_dims\"] = [\n",
    "        config[\"fc_dims\"],\n",
    "        int(config[\"fc_dims\"] / 2),\n",
    "        3,\n",
    "    ]\n",
    "\n",
    "mse_loss_function = MSEIgnoreNans()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "45cf8cfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.387266\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[neptune] [warning] NeptuneWarning: By default, these monitoring options are disabled in interactive sessions: 'capture_stdout', 'capture_stderr', 'capture_traceback', 'capture_hardware_metrics'. You can set them to 'True' when initializing the run and the monitoring will continue until you call run.stop() or the kernel stops. NOTE: To track the source files, pass their paths to the 'source_code' argument. For help, see: https://docs-legacy.neptune.ai/logging/source_code/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[neptune] [info   ] Neptune initialized. Open in the app: https://app.neptune.ai/arbaaz/kaggle-spect/e/KAG-327\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23ed7c2632554b468c30d8922c68f430",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:227: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, train/loss: 0.9875, eval/loss: 1.0896, train/r2: -0.0118, eval/r2: -0.0001, train/one: -0.0168, train/two: -0.0193, train/three: 0.0006, eval/one: 0.0016, eval/two: 0.0020, eval/three: -0.0038 \n",
      "Epoch: 5, train/loss: 0.9332, eval/loss: 0.9164, train/r2: 0.0473, eval/r2: 0.0967, train/one: 0.0202, train/two: -0.0052, train/three: 0.1270, eval/one: 0.0577, eval/two: 0.0030, eval/three: 0.2293 \n",
      "Epoch: 10, train/loss: 0.7181, eval/loss: 0.6851, train/r2: 0.3051, eval/r2: 0.3196, train/one: 0.1423, train/two: 0.0374, train/three: 0.7356, eval/one: 0.1502, eval/two: 0.0417, eval/three: 0.7667 \n",
      "Epoch: 15, train/loss: 0.4861, eval/loss: 0.5404, train/r2: 0.5246, eval/r2: 0.5069, train/one: 0.4408, train/two: 0.2949, train/three: 0.8381, eval/one: 0.4836, eval/two: 0.2061, eval/three: 0.8310 \n",
      "Epoch: 20, train/loss: 0.3454, eval/loss: 0.3667, train/r2: 0.6422, eval/r2: 0.6484, train/one: 0.6254, train/two: 0.4184, train/three: 0.8829, eval/one: 0.6206, eval/two: 0.4301, eval/three: 0.8945 \n",
      "Epoch: 25, train/loss: 0.2774, eval/loss: 0.3148, train/r2: 0.7217, eval/r2: 0.6961, train/one: 0.7196, train/two: 0.5618, train/three: 0.8838, eval/one: 0.6840, eval/two: 0.4993, eval/three: 0.9050 \n",
      "Epoch: 30, train/loss: 0.2476, eval/loss: 0.2562, train/r2: 0.7541, eval/r2: 0.7331, train/one: 0.7471, train/two: 0.6065, train/three: 0.9088, eval/one: 0.7054, eval/two: 0.5760, eval/three: 0.9180 \n",
      "Epoch: 35, train/loss: 0.2194, eval/loss: 0.2438, train/r2: 0.7829, eval/r2: 0.7572, train/one: 0.7834, train/two: 0.6433, train/three: 0.9219, eval/one: 0.7524, eval/two: 0.5850, eval/three: 0.9342 \n",
      "Epoch: 40, train/loss: 0.1976, eval/loss: 0.2225, train/r2: 0.8054, eval/r2: 0.7946, train/one: 0.8129, train/two: 0.6757, train/three: 0.9276, eval/one: 0.8370, eval/two: 0.6303, eval/three: 0.9163 \n",
      "Epoch: 45, train/loss: 0.1845, eval/loss: 0.1798, train/r2: 0.8185, eval/r2: 0.8215, train/one: 0.8267, train/two: 0.6988, train/three: 0.9299, eval/one: 0.8475, eval/two: 0.6862, eval/three: 0.9309 \n",
      "Epoch: 50, train/loss: 0.1787, eval/loss: 0.1960, train/r2: 0.8145, eval/r2: 0.8108, train/one: 0.8222, train/two: 0.6912, train/three: 0.9301, eval/one: 0.8385, eval/two: 0.6562, eval/three: 0.9375 \n",
      "Epoch: 55, train/loss: 0.1580, eval/loss: 0.1780, train/r2: 0.8465, eval/r2: 0.8277, train/one: 0.8703, train/two: 0.7348, train/three: 0.9344, eval/one: 0.8595, eval/two: 0.6943, eval/three: 0.9295 \n",
      "Epoch: 60, train/loss: 0.1564, eval/loss: 0.1674, train/r2: 0.8484, eval/r2: 0.8323, train/one: 0.8626, train/two: 0.7367, train/three: 0.9458, eval/one: 0.8809, eval/two: 0.6675, eval/three: 0.9486 \n",
      "Epoch: 65, train/loss: 0.1400, eval/loss: 0.1612, train/r2: 0.8645, eval/r2: 0.8414, train/one: 0.8813, train/two: 0.7641, train/three: 0.9480, eval/one: 0.8634, eval/two: 0.7106, eval/three: 0.9502 \n",
      "Epoch: 70, train/loss: 0.1432, eval/loss: 0.1837, train/r2: 0.8587, eval/r2: 0.8184, train/one: 0.8677, train/two: 0.7633, train/three: 0.9452, eval/one: 0.8590, eval/two: 0.6464, eval/three: 0.9497 \n",
      "Epoch: 75, train/loss: 0.1384, eval/loss: 0.1415, train/r2: 0.8640, eval/r2: 0.8601, train/one: 0.8772, train/two: 0.7599, train/three: 0.9550, eval/one: 0.8794, eval/two: 0.7451, eval/three: 0.9557 \n",
      "Epoch: 80, train/loss: 0.1339, eval/loss: 0.1801, train/r2: 0.8679, eval/r2: 0.8257, train/one: 0.8875, train/two: 0.7608, train/three: 0.9555, eval/one: 0.8022, eval/two: 0.7192, eval/three: 0.9557 \n",
      "Epoch: 85, train/loss: 0.1317, eval/loss: 0.1694, train/r2: 0.8700, eval/r2: 0.8423, train/one: 0.8846, train/two: 0.7731, train/three: 0.9522, eval/one: 0.8669, eval/two: 0.6953, eval/three: 0.9647 \n",
      "Epoch: 90, train/loss: 0.1313, eval/loss: 0.1413, train/r2: 0.8680, eval/r2: 0.8553, train/one: 0.8824, train/two: 0.7692, train/three: 0.9525, eval/one: 0.8511, eval/two: 0.7620, eval/three: 0.9526 \n",
      "Epoch: 95, train/loss: 0.1469, eval/loss: 0.1520, train/r2: 0.8463, eval/r2: 0.8471, train/one: 0.8472, train/two: 0.7522, train/three: 0.9396, eval/one: 0.8836, eval/two: 0.7073, eval/three: 0.9504 \n",
      "[neptune] [info   ] Shutting down background jobs, please wait a moment...\n",
      "[neptune] [info   ] Done!\n",
      "[neptune] [info   ] Waiting for the remaining 77 operations to synchronize with Neptune. Do not kill this process.\n",
      "[neptune] [info   ] All 77 operations synced, thanks for waiting!\n",
      "[neptune] [info   ] Explore the metadata in the Neptune app: https://app.neptune.ai/arbaaz/kaggle-spect/e/KAG-327/metadata\n",
      "[neptune] [info   ] Neptune initialized. Open in the app: https://app.neptune.ai/arbaaz/kaggle-spect/e/KAG-328\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e68f73b1400419d8ee370ae0cda78f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:227: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, train/loss: 0.9783, eval/loss: 1.0065, train/r2: -0.0173, eval/r2: -0.0053, train/one: -0.0156, train/two: -0.0190, train/three: -0.0175, eval/one: -0.0041, eval/two: -0.0007, eval/three: -0.0111 \n",
      "Epoch: 5, train/loss: 0.8435, eval/loss: 0.8118, train/r2: 0.1125, eval/r2: 0.1607, train/one: 0.0416, train/two: 0.0149, train/three: 0.2810, eval/one: 0.0898, eval/two: -0.0576, eval/three: 0.4499 \n",
      "Epoch: 10, train/loss: 0.7172, eval/loss: 0.6771, train/r2: 0.2882, eval/r2: 0.3046, train/one: 0.1217, train/two: 0.0617, train/three: 0.6811, eval/one: 0.1478, eval/two: 0.0130, eval/three: 0.7529 \n",
      "Epoch: 15, train/loss: 0.5272, eval/loss: 0.5238, train/r2: 0.4745, eval/r2: 0.4490, train/one: 0.4752, train/two: 0.1220, train/three: 0.8263, eval/one: 0.4514, eval/two: 0.0308, eval/three: 0.8648 \n",
      "Epoch: 20, train/loss: 0.4026, eval/loss: 0.3930, train/r2: 0.5991, eval/r2: 0.6026, train/one: 0.6252, train/two: 0.2831, train/three: 0.8889, eval/one: 0.6322, eval/two: 0.2796, eval/three: 0.8961 \n",
      "Epoch: 25, train/loss: 0.3208, eval/loss: 0.2968, train/r2: 0.6701, eval/r2: 0.6926, train/one: 0.6914, train/two: 0.4235, train/three: 0.8954, eval/one: 0.6905, eval/two: 0.4655, eval/three: 0.9217 \n",
      "Epoch: 30, train/loss: 0.2719, eval/loss: 0.2803, train/r2: 0.7360, eval/r2: 0.7131, train/one: 0.7761, train/two: 0.5336, train/three: 0.8982, eval/one: 0.6979, eval/two: 0.5354, eval/three: 0.9060 \n",
      "Epoch: 35, train/loss: 0.2510, eval/loss: 0.2346, train/r2: 0.7516, eval/r2: 0.7490, train/one: 0.7826, train/two: 0.5554, train/three: 0.9169, eval/one: 0.7866, eval/two: 0.5389, eval/three: 0.9213 \n",
      "Epoch: 40, train/loss: 0.2291, eval/loss: 0.2251, train/r2: 0.7698, eval/r2: 0.7558, train/one: 0.8023, train/two: 0.5911, train/three: 0.9159, eval/one: 0.7429, eval/two: 0.5983, eval/three: 0.9261 \n",
      "Epoch: 45, train/loss: 0.2150, eval/loss: 0.2169, train/r2: 0.7908, eval/r2: 0.7764, train/one: 0.8229, train/two: 0.6167, train/three: 0.9328, eval/one: 0.7788, eval/two: 0.6254, eval/three: 0.9251 \n",
      "Epoch: 50, train/loss: 0.2002, eval/loss: 0.2074, train/r2: 0.8008, eval/r2: 0.7793, train/one: 0.8332, train/two: 0.6372, train/three: 0.9320, eval/one: 0.7855, eval/two: 0.6032, eval/three: 0.9494 \n",
      "Epoch: 55, train/loss: 0.1879, eval/loss: 0.1736, train/r2: 0.8125, eval/r2: 0.8209, train/one: 0.8403, train/two: 0.6599, train/three: 0.9373, eval/one: 0.8579, eval/two: 0.6550, eval/three: 0.9498 \n",
      "Epoch: 60, train/loss: 0.1692, eval/loss: 0.1568, train/r2: 0.8303, eval/r2: 0.8385, train/one: 0.8437, train/two: 0.7005, train/three: 0.9468, eval/one: 0.8628, eval/two: 0.6920, eval/three: 0.9606 \n",
      "Epoch: 65, train/loss: 0.1635, eval/loss: 0.1806, train/r2: 0.8336, eval/r2: 0.8181, train/one: 0.8503, train/two: 0.6988, train/three: 0.9518, eval/one: 0.8365, eval/two: 0.6749, eval/three: 0.9431 \n",
      "Epoch: 70, train/loss: 0.1566, eval/loss: 0.1957, train/r2: 0.8429, eval/r2: 0.8060, train/one: 0.8705, train/two: 0.7071, train/three: 0.9512, eval/one: 0.8288, eval/two: 0.6474, eval/three: 0.9417 \n",
      "Epoch: 75, train/loss: 0.1545, eval/loss: 0.1561, train/r2: 0.8469, eval/r2: 0.8343, train/one: 0.8783, train/two: 0.7154, train/three: 0.9469, eval/one: 0.8379, eval/two: 0.6966, eval/three: 0.9682 \n",
      "Epoch: 80, train/loss: 0.1610, eval/loss: 0.1549, train/r2: 0.8366, eval/r2: 0.8405, train/one: 0.8559, train/two: 0.7080, train/three: 0.9459, eval/one: 0.8422, eval/two: 0.7220, eval/three: 0.9573 \n",
      "Epoch: 85, train/loss: 0.1498, eval/loss: 0.1407, train/r2: 0.8495, eval/r2: 0.8490, train/one: 0.8610, train/two: 0.7314, train/three: 0.9561, eval/one: 0.8634, eval/two: 0.7168, eval/three: 0.9669 \n",
      "Epoch: 90, train/loss: 0.1441, eval/loss: 0.1400, train/r2: 0.8519, eval/r2: 0.8581, train/one: 0.8733, train/two: 0.7283, train/three: 0.9541, eval/one: 0.8627, eval/two: 0.7629, eval/three: 0.9488 \n",
      "Epoch: 95, train/loss: 0.1417, eval/loss: 0.1484, train/r2: 0.8558, eval/r2: 0.8312, train/one: 0.8864, train/two: 0.7246, train/three: 0.9565, eval/one: 0.8436, eval/two: 0.6936, eval/three: 0.9565 \n",
      "[neptune] [info   ] Shutting down background jobs, please wait a moment...\n",
      "[neptune] [info   ] Done!\n",
      "[neptune] [info   ] Waiting for the remaining 77 operations to synchronize with Neptune. Do not kill this process.\n",
      "[neptune] [info   ] All 77 operations synced, thanks for waiting!\n",
      "[neptune] [info   ] Explore the metadata in the Neptune app: https://app.neptune.ai/arbaaz/kaggle-spect/e/KAG-328/metadata\n",
      "[neptune] [info   ] Neptune initialized. Open in the app: https://app.neptune.ai/arbaaz/kaggle-spect/e/KAG-329\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72594b70fb9040ab8da51e01749a6ed9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:227: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, train/loss: 1.0180, eval/loss: 1.0218, train/r2: -0.0062, eval/r2: -0.0039, train/one: -0.0187, train/two: -0.0143, train/three: 0.0145, eval/one: -0.0128, eval/two: -0.0049, eval/three: 0.0062 \n",
      "Epoch: 5, train/loss: 0.9701, eval/loss: 0.9431, train/r2: 0.0463, eval/r2: 0.0417, train/one: 0.0226, train/two: 0.0195, train/three: 0.0969, eval/one: -0.0069, eval/two: 0.0368, eval/three: 0.0951 \n",
      "Epoch: 10, train/loss: 0.7293, eval/loss: 0.7375, train/r2: 0.2666, eval/r2: 0.2796, train/one: 0.0899, train/two: 0.0395, train/three: 0.6705, eval/one: 0.1109, eval/two: 0.0534, eval/three: 0.6744 \n",
      "Epoch: 15, train/loss: 0.6064, eval/loss: 0.5788, train/r2: 0.4105, eval/r2: 0.4232, train/one: 0.3570, train/two: 0.0726, train/three: 0.8020, eval/one: 0.3643, eval/two: 0.0891, eval/three: 0.8164 \n",
      "Epoch: 20, train/loss: 0.4418, eval/loss: 0.4371, train/r2: 0.5597, eval/r2: 0.5577, train/one: 0.6014, train/two: 0.2003, train/three: 0.8775, eval/one: 0.5762, eval/two: 0.2289, eval/three: 0.8679 \n",
      "Epoch: 25, train/loss: 0.3202, eval/loss: 0.2951, train/r2: 0.6725, eval/r2: 0.7120, train/one: 0.6731, train/two: 0.4572, train/three: 0.8872, eval/one: 0.7320, eval/two: 0.4850, eval/three: 0.9190 \n",
      "Epoch: 30, train/loss: 0.2730, eval/loss: 0.2373, train/r2: 0.7184, eval/r2: 0.7493, train/one: 0.7208, train/two: 0.5133, train/three: 0.9212, eval/one: 0.7588, eval/two: 0.5707, eval/three: 0.9185 \n",
      "Epoch: 35, train/loss: 0.2362, eval/loss: 0.2228, train/r2: 0.7704, eval/r2: 0.7467, train/one: 0.7963, train/two: 0.5977, train/three: 0.9173, eval/one: 0.6862, eval/two: 0.6226, eval/three: 0.9312 \n",
      "Epoch: 40, train/loss: 0.2257, eval/loss: 0.2231, train/r2: 0.7731, eval/r2: 0.7752, train/one: 0.7927, train/two: 0.5993, train/three: 0.9271, eval/one: 0.7320, eval/two: 0.6409, eval/three: 0.9527 \n",
      "Epoch: 45, train/loss: 0.2077, eval/loss: 0.1993, train/r2: 0.7911, eval/r2: 0.7959, train/one: 0.8163, train/two: 0.6253, train/three: 0.9318, eval/one: 0.8051, eval/two: 0.6422, eval/three: 0.9405 \n",
      "Epoch: 50, train/loss: 0.1910, eval/loss: 0.1701, train/r2: 0.8107, eval/r2: 0.8321, train/one: 0.8387, train/two: 0.6574, train/three: 0.9360, eval/one: 0.8551, eval/two: 0.6974, eval/three: 0.9436 \n",
      "Epoch: 55, train/loss: 0.1788, eval/loss: 0.1931, train/r2: 0.8194, eval/r2: 0.8038, train/one: 0.8382, train/two: 0.6783, train/three: 0.9418, eval/one: 0.7794, eval/two: 0.6759, eval/three: 0.9559 \n",
      "Epoch: 60, train/loss: 0.1644, eval/loss: 0.1631, train/r2: 0.8321, eval/r2: 0.8207, train/one: 0.8491, train/two: 0.7008, train/three: 0.9465, eval/one: 0.8217, eval/two: 0.6768, eval/three: 0.9637 \n",
      "Epoch: 65, train/loss: 0.1591, eval/loss: 0.1405, train/r2: 0.8380, eval/r2: 0.8508, train/one: 0.8645, train/two: 0.7049, train/three: 0.9446, eval/one: 0.8297, eval/two: 0.7601, eval/three: 0.9626 \n",
      "Epoch: 70, train/loss: 0.1528, eval/loss: 0.1603, train/r2: 0.8464, eval/r2: 0.8352, train/one: 0.8609, train/two: 0.7245, train/three: 0.9537, eval/one: 0.8730, eval/two: 0.6783, eval/three: 0.9543 \n",
      "Epoch: 75, train/loss: 0.1571, eval/loss: 0.1640, train/r2: 0.8475, eval/r2: 0.8386, train/one: 0.8616, train/two: 0.7269, train/three: 0.9539, eval/one: 0.8370, eval/two: 0.7117, eval/three: 0.9672 \n",
      "Epoch: 80, train/loss: 0.1441, eval/loss: 0.1282, train/r2: 0.8533, eval/r2: 0.8621, train/one: 0.8568, train/two: 0.7527, train/three: 0.9504, eval/one: 0.8769, eval/two: 0.7454, eval/three: 0.9639 \n",
      "Epoch: 85, train/loss: 0.1520, eval/loss: 0.1411, train/r2: 0.8473, eval/r2: 0.8541, train/one: 0.8653, train/two: 0.7224, train/three: 0.9543, eval/one: 0.8571, eval/two: 0.7377, eval/three: 0.9676 \n",
      "Epoch: 90, train/loss: 0.1450, eval/loss: 0.1351, train/r2: 0.8580, eval/r2: 0.8613, train/one: 0.8858, train/two: 0.7382, train/three: 0.9499, eval/one: 0.8637, eval/two: 0.7545, eval/three: 0.9658 \n",
      "Epoch: 95, train/loss: 0.1311, eval/loss: 0.1524, train/r2: 0.8694, eval/r2: 0.8465, train/one: 0.8880, train/two: 0.7616, train/three: 0.9585, eval/one: 0.8523, eval/two: 0.7263, eval/three: 0.9609 \n",
      "[neptune] [info   ] Shutting down background jobs, please wait a moment...\n",
      "[neptune] [info   ] Done!\n",
      "[neptune] [info   ] Waiting for the remaining 79 operations to synchronize with Neptune. Do not kill this process.\n",
      "[neptune] [info   ] All 79 operations synced, thanks for waiting!\n",
      "[neptune] [info   ] Explore the metadata in the Neptune app: https://app.neptune.ai/arbaaz/kaggle-spect/e/KAG-329/metadata\n",
      "[neptune] [info   ] Neptune initialized. Open in the app: https://app.neptune.ai/arbaaz/kaggle-spect/e/KAG-330\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ad1f6661d784eccbfb2e35e744ff9b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:227: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, train/loss: 0.9983, eval/loss: 1.0124, train/r2: -0.0340, eval/r2: -0.0012, train/one: -0.0992, train/two: -0.0044, train/three: 0.0015, eval/one: -0.0063, eval/two: -0.0047, eval/three: 0.0075 \n",
      "Epoch: 5, train/loss: 0.9350, eval/loss: 0.9790, train/r2: 0.0434, eval/r2: 0.0671, train/one: 0.0458, train/two: 0.0132, train/three: 0.0711, eval/one: 0.0923, eval/two: 0.0032, eval/three: 0.1057 \n",
      "Epoch: 10, train/loss: 0.7190, eval/loss: 0.7748, train/r2: 0.2694, eval/r2: 0.3239, train/one: 0.1185, train/two: 0.0082, train/three: 0.6816, eval/one: 0.1630, eval/two: 0.0647, eval/three: 0.7439 \n",
      "Epoch: 15, train/loss: 0.5392, eval/loss: 0.5372, train/r2: 0.4692, eval/r2: 0.4851, train/one: 0.5221, train/two: 0.0685, train/three: 0.8169, eval/one: 0.5056, eval/two: 0.1416, eval/three: 0.8080 \n",
      "Epoch: 20, train/loss: 0.4225, eval/loss: 0.4177, train/r2: 0.5790, eval/r2: 0.6096, train/one: 0.5934, train/two: 0.2642, train/three: 0.8795, eval/one: 0.5375, eval/two: 0.4188, eval/three: 0.8725 \n",
      "Epoch: 25, train/loss: 0.3520, eval/loss: 0.4170, train/r2: 0.6584, eval/r2: 0.6266, train/one: 0.6845, train/two: 0.3976, train/three: 0.8929, eval/one: 0.5902, eval/two: 0.3839, eval/three: 0.9056 \n",
      "Epoch: 30, train/loss: 0.2856, eval/loss: 0.2847, train/r2: 0.7172, eval/r2: 0.7213, train/one: 0.7399, train/two: 0.5028, train/three: 0.9089, eval/one: 0.7440, eval/two: 0.5102, eval/three: 0.9095 \n",
      "Epoch: 35, train/loss: 0.2873, eval/loss: 0.2474, train/r2: 0.7159, eval/r2: 0.7779, train/one: 0.7350, train/two: 0.4967, train/three: 0.9160, eval/one: 0.8139, eval/two: 0.5882, eval/three: 0.9317 \n",
      "Epoch: 40, train/loss: 0.2337, eval/loss: 0.2750, train/r2: 0.7612, eval/r2: 0.7382, train/one: 0.7679, train/two: 0.5866, train/three: 0.9290, eval/one: 0.7580, eval/two: 0.5341, eval/three: 0.9224 \n",
      "Epoch: 45, train/loss: 0.2180, eval/loss: 0.2431, train/r2: 0.7802, eval/r2: 0.7832, train/one: 0.8045, train/two: 0.6025, train/three: 0.9335, eval/one: 0.8033, eval/two: 0.6115, eval/three: 0.9349 \n",
      "Epoch: 50, train/loss: 0.2028, eval/loss: 0.2279, train/r2: 0.7990, eval/r2: 0.7976, train/one: 0.8255, train/two: 0.6273, train/three: 0.9441, eval/one: 0.8068, eval/two: 0.6583, eval/three: 0.9277 \n",
      "Epoch: 55, train/loss: 0.2023, eval/loss: 0.2190, train/r2: 0.7994, eval/r2: 0.7901, train/one: 0.8306, train/two: 0.6232, train/three: 0.9443, eval/one: 0.7930, eval/two: 0.6580, eval/three: 0.9193 \n",
      "Epoch: 60, train/loss: 0.1895, eval/loss: 0.2283, train/r2: 0.8028, eval/r2: 0.7942, train/one: 0.8203, train/two: 0.6458, train/three: 0.9422, eval/one: 0.8092, eval/two: 0.6573, eval/three: 0.9160 \n",
      "Epoch: 65, train/loss: 0.1718, eval/loss: 0.2190, train/r2: 0.8291, eval/r2: 0.8004, train/one: 0.8470, train/two: 0.6927, train/three: 0.9477, eval/one: 0.8110, eval/two: 0.6555, eval/three: 0.9347 \n",
      "Epoch: 70, train/loss: 0.1642, eval/loss: 0.1889, train/r2: 0.8348, eval/r2: 0.8010, train/one: 0.8663, train/two: 0.6904, train/three: 0.9476, eval/one: 0.8631, eval/two: 0.6105, eval/three: 0.9295 \n",
      "Epoch: 75, train/loss: 0.1737, eval/loss: 0.1851, train/r2: 0.8228, eval/r2: 0.8172, train/one: 0.8501, train/two: 0.6672, train/three: 0.9511, eval/one: 0.8575, eval/two: 0.6576, eval/three: 0.9364 \n",
      "Epoch: 80, train/loss: 0.1558, eval/loss: 0.2046, train/r2: 0.8442, eval/r2: 0.8158, train/one: 0.8670, train/two: 0.7186, train/three: 0.9470, eval/one: 0.8052, eval/two: 0.7023, eval/three: 0.9399 \n",
      "Epoch: 85, train/loss: 0.1642, eval/loss: 0.1736, train/r2: 0.8336, eval/r2: 0.8502, train/one: 0.8561, train/two: 0.6973, train/three: 0.9475, eval/one: 0.8633, eval/two: 0.7426, eval/three: 0.9446 \n",
      "Epoch: 90, train/loss: 0.1542, eval/loss: 0.1635, train/r2: 0.8466, eval/r2: 0.8538, train/one: 0.8807, train/two: 0.7111, train/three: 0.9480, eval/one: 0.8856, eval/two: 0.7404, eval/three: 0.9352 \n",
      "Epoch: 95, train/loss: 0.1573, eval/loss: 0.1864, train/r2: 0.8460, eval/r2: 0.8361, train/one: 0.8717, train/two: 0.7086, train/three: 0.9577, eval/one: 0.8648, eval/two: 0.6963, eval/three: 0.9472 \n",
      "[neptune] [info   ] Shutting down background jobs, please wait a moment...\n",
      "[neptune] [info   ] Done!\n",
      "[neptune] [info   ] Waiting for the remaining 79 operations to synchronize with Neptune. Do not kill this process.\n",
      "[neptune] [info   ] All 79 operations synced, thanks for waiting!\n",
      "[neptune] [info   ] Explore the metadata in the Neptune app: https://app.neptune.ai/arbaaz/kaggle-spect/e/KAG-330/metadata\n",
      "[neptune] [info   ] Neptune initialized. Open in the app: https://app.neptune.ai/arbaaz/kaggle-spect/e/KAG-331\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c32290c20964996990cfb5330d36710",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:227: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, train/loss: 1.0365, eval/loss: 0.9220, train/r2: -0.0231, eval/r2: 0.0000, train/one: -0.0127, train/two: -0.0370, train/three: -0.0198, eval/one: -0.0012, eval/two: -0.0041, eval/three: 0.0054 \n",
      "Epoch: 5, train/loss: 0.9244, eval/loss: 0.9010, train/r2: 0.0435, eval/r2: 0.0473, train/one: 0.0338, train/two: 0.0047, train/three: 0.0921, eval/one: 0.0277, eval/two: 0.0069, eval/three: 0.1074 \n",
      "Epoch: 10, train/loss: 0.7184, eval/loss: 0.6286, train/r2: 0.2809, eval/r2: 0.3037, train/one: 0.1154, train/two: 0.0455, train/three: 0.6819, eval/one: 0.1839, eval/two: 0.0335, eval/three: 0.6936 \n",
      "Epoch: 15, train/loss: 0.5414, eval/loss: 0.4674, train/r2: 0.4654, eval/r2: 0.4773, train/one: 0.4802, train/two: 0.1597, train/three: 0.7564, eval/one: 0.5505, eval/two: 0.1162, eval/three: 0.7651 \n",
      "Epoch: 20, train/loss: 0.3796, eval/loss: 0.3215, train/r2: 0.6163, eval/r2: 0.6419, train/one: 0.6256, train/two: 0.3752, train/three: 0.8480, eval/one: 0.7114, eval/two: 0.3696, eval/three: 0.8448 \n",
      "Epoch: 25, train/loss: 0.3078, eval/loss: 0.2721, train/r2: 0.6893, eval/r2: 0.7072, train/one: 0.6852, train/two: 0.4891, train/three: 0.8937, eval/one: 0.7474, eval/two: 0.4694, eval/three: 0.9049 \n",
      "Epoch: 30, train/loss: 0.2575, eval/loss: 0.3276, train/r2: 0.7348, eval/r2: 0.6498, train/one: 0.7241, train/two: 0.5698, train/three: 0.9103, eval/one: 0.7190, eval/two: 0.3235, eval/three: 0.9069 \n",
      "Epoch: 35, train/loss: 0.2339, eval/loss: 0.2177, train/r2: 0.7682, eval/r2: 0.7471, train/one: 0.7818, train/two: 0.6002, train/three: 0.9225, eval/one: 0.7818, eval/two: 0.5299, eval/three: 0.9296 \n",
      "Epoch: 40, train/loss: 0.2147, eval/loss: 0.2176, train/r2: 0.7856, eval/r2: 0.7693, train/one: 0.7926, train/two: 0.6359, train/three: 0.9284, eval/one: 0.7908, eval/two: 0.6052, eval/three: 0.9119 \n",
      "Epoch: 45, train/loss: 0.1920, eval/loss: 0.1732, train/r2: 0.8064, eval/r2: 0.8153, train/one: 0.8269, train/two: 0.6606, train/three: 0.9317, eval/one: 0.8465, eval/two: 0.6688, eval/three: 0.9306 \n",
      "Epoch: 50, train/loss: 0.1938, eval/loss: 0.1657, train/r2: 0.8151, eval/r2: 0.8165, train/one: 0.8177, train/two: 0.6921, train/three: 0.9355, eval/one: 0.8561, eval/two: 0.6490, eval/three: 0.9444 \n",
      "Epoch: 55, train/loss: 0.1869, eval/loss: 0.1550, train/r2: 0.8161, eval/r2: 0.8351, train/one: 0.8274, train/two: 0.6870, train/three: 0.9340, eval/one: 0.8727, eval/two: 0.6844, eval/three: 0.9482 \n",
      "Epoch: 60, train/loss: 0.1731, eval/loss: 0.1555, train/r2: 0.8227, eval/r2: 0.8328, train/one: 0.8470, train/two: 0.6738, train/three: 0.9472, eval/one: 0.8856, eval/two: 0.6618, eval/three: 0.9510 \n",
      "Epoch: 65, train/loss: 0.1646, eval/loss: 0.1497, train/r2: 0.8368, eval/r2: 0.8411, train/one: 0.8496, train/two: 0.7160, train/three: 0.9449, eval/one: 0.8911, eval/two: 0.6733, eval/three: 0.9588 \n",
      "Epoch: 70, train/loss: 0.1599, eval/loss: 0.1378, train/r2: 0.8444, eval/r2: 0.8503, train/one: 0.8566, train/two: 0.7299, train/three: 0.9469, eval/one: 0.9000, eval/two: 0.6973, eval/three: 0.9536 \n",
      "Epoch: 75, train/loss: 0.1542, eval/loss: 0.1663, train/r2: 0.8415, eval/r2: 0.8198, train/one: 0.8531, train/two: 0.7232, train/three: 0.9482, eval/one: 0.8891, eval/two: 0.6155, eval/three: 0.9547 \n",
      "Epoch: 80, train/loss: 0.1467, eval/loss: 0.1406, train/r2: 0.8564, eval/r2: 0.8582, train/one: 0.8663, train/two: 0.7507, train/three: 0.9521, eval/one: 0.9113, eval/two: 0.7133, eval/three: 0.9498 \n",
      "Epoch: 85, train/loss: 0.1491, eval/loss: 0.1431, train/r2: 0.8516, eval/r2: 0.8430, train/one: 0.8557, train/two: 0.7480, train/three: 0.9512, eval/one: 0.9153, eval/two: 0.6546, eval/three: 0.9592 \n",
      "Epoch: 90, train/loss: 0.1435, eval/loss: 0.1244, train/r2: 0.8584, eval/r2: 0.8586, train/one: 0.8753, train/two: 0.7519, train/three: 0.9479, eval/one: 0.8892, eval/two: 0.7199, eval/three: 0.9666 \n",
      "Epoch: 95, train/loss: 0.1467, eval/loss: 0.1473, train/r2: 0.8484, eval/r2: 0.8329, train/one: 0.8616, train/two: 0.7396, train/three: 0.9441, eval/one: 0.9160, eval/two: 0.6209, eval/three: 0.9616 \n",
      "[neptune] [info   ] Shutting down background jobs, please wait a moment...\n",
      "[neptune] [info   ] Done!\n",
      "[neptune] [info   ] Waiting for the remaining 32 operations to synchronize with Neptune. Do not kill this process.\n",
      "[neptune] [info   ] All 32 operations synced, thanks for waiting!\n",
      "[neptune] [info   ] Explore the metadata in the Neptune app: https://app.neptune.ai/arbaaz/kaggle-spect/e/KAG-331/metadata\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "\n",
    "inputs_mean_std = []\n",
    "targets_mean_std = []\n",
    "scores = []\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=SEED)\n",
    "splits = kfold.split(inputs)\n",
    "\n",
    "for fold, (train_idx, eval_idx) in enumerate(splits):\n",
    "    MODEL_NAME = f\"ensemble.pretrain.xception.fold.{fold}\"\n",
    "    checkpoint_name = f\"ensemble.pretrain.xception.{fold}.pt\"\n",
    "    \n",
    "    train_inputs = inputs[train_idx]\n",
    "    train_targets = targets[train_idx]\n",
    "    eval_inputs = inputs[eval_idx]\n",
    "    eval_targets = targets[eval_idx]\n",
    "\n",
    "    train_ds = get_dataset(train_inputs, train_targets, config)\n",
    "    \n",
    "    inputs_mean_std.append((fold, train_ds.s_mean, train_ds.s_std))\n",
    "    targets_mean_std.append((fold, train_ds.concentration_means, train_ds.concentration_stds))\n",
    "    \n",
    "    eval_ds = get_dataset(\n",
    "        eval_inputs, \n",
    "        eval_targets, \n",
    "        config, \n",
    "        (train_ds.s_mean, train_ds.s_std), \n",
    "        (train_ds.concentration_means, train_ds.concentration_stds)\n",
    "    )\n",
    "    \n",
    "    BATCH_SIZE = 32\n",
    "    train_dl, eval_dl = return_dls(train_ds, eval_ds, BATCH_SIZE, len(eval_ds))\n",
    "    \n",
    "    #model = ResNet(dropout=DROPOUT).to(device)\n",
    "    #model = ReZeroNet(**config).to(device)\n",
    "    #model = convnextv2_atto().to(device)\n",
    "    #model = SAINT(**model_config, classification_idx=3).to(device)\n",
    "    model = RamanXception(\n",
    "        **model_config,\n",
    "        classification_idx=3,\n",
    "        num_concentrations=3\n",
    "    ).to(device)\n",
    "    \n",
    "    if fold == 0: print(get_model_size(model))\n",
    "    #print(model)    \n",
    "    \n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=LR, weight_decay=WD, foreach=True)\n",
    "    scheduler = get_scheduler(optimizer, train_dl, EPOCHS)\n",
    "    \n",
    "    score = train(\n",
    "            model, \n",
    "            optimizer, \n",
    "            device,\n",
    "            torch.float16,\n",
    "            scheduler,\n",
    "            train_dl, \n",
    "            eval_dl,\n",
    "            mse_loss_function,\n",
    "            EPOCHS,\n",
    "            checkpoint_name,\n",
    "            neptune_run=setup_neptune(),\n",
    "        )\n",
    "    \n",
    "    scores.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "53ec5d48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/ensemble.pretrain.xception.0.pt 93 0.8736222170043484\n",
      "/kaggle/working/ensemble.pretrain.xception.1.pt 81 0.8587845615883181\n",
      "/kaggle/working/ensemble.pretrain.xception.2.pt 79 0.8677010776545604\n",
      "/kaggle/working/ensemble.pretrain.xception.3.pt 99 0.859623472427773\n",
      "/kaggle/working/ensemble.pretrain.xception.4.pt 87 0.8738793832256998\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/kaggle/working/ensemble.pretrain.xception.0.pt',\n",
       " '/kaggle/working/ensemble.pretrain.xception.1.pt',\n",
       " '/kaggle/working/ensemble.pretrain.xception.2.pt',\n",
       " '/kaggle/working/ensemble.pretrain.xception.3.pt',\n",
       " '/kaggle/working/ensemble.pretrain.xception.4.pt']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os \n",
    "import torch\n",
    "\n",
    "\n",
    "def get_ckpt(path):\n",
    "    return torch.load(path, weights_only=False)\n",
    "\n",
    "\n",
    "def get_ckpt_paths(keyword):\n",
    "    output_dir = \"/kaggle/working\"\n",
    "    output_files = sorted(os.listdir(output_dir))\n",
    "\n",
    "    ckpt_paths = []\n",
    "    for f in output_files:\n",
    "        if keyword in f and \"csv\" not in f:\n",
    "            ckpt_path = os.path.join(output_dir, f)\n",
    "            ckpt_paths.append(ckpt_path)\n",
    "            ckpt = torch.load(ckpt_path, weights_only=False)\n",
    "            print(ckpt_path, ckpt[\"epoch\"], ckpt[\"score\"])\n",
    "            \n",
    "    return ckpt_paths\n",
    "\n",
    "ckpt_paths = get_ckpt_paths(\"xception\")\n",
    "ckpt_paths\n",
    "#state_dicts = [get_ckpt(p)[\"state_dict\"] for p in ckpt_paths]\n",
    "\n",
    "#avg_weights = average_state_dicts(state_dicts)\n",
    "#torch.save(avg_weights, \"/kaggle/working/avg_weights_data_fixed.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f78194fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
