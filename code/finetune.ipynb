{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc6442c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def setup_reproducibility(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available(): torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.use_deterministic_algorithms(False, warn_only=True)\n",
    "    torch.set_float32_matmul_precision(\"high\")\n",
    "    \n",
    "SEED = 1000\n",
    "setup_reproducibility(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3fb896b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import get_cosine_schedule_with_warmup\n",
    "from scipy import signal\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from huggingface_hub import login, snapshot_download\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "def get_scheduler(optimizer, train_dl, epochs):\n",
    "    total_training_steps = len(train_dl) * epochs\n",
    "    warmup_steps = int(total_training_steps * 0.05)  # e.g. 5% warmup\n",
    "    \n",
    "    return get_cosine_schedule_with_warmup(\n",
    "        optimizer=optimizer,\n",
    "        num_warmup_steps=warmup_steps,\n",
    "        num_training_steps=total_training_steps\n",
    "    )\n",
    "\n",
    "\n",
    "def get_stats(tensor, p=True, r=False):\n",
    "    mean, std = tensor.mean(), tensor.std()\n",
    "    min, max =  tensor.min(), tensor.max()\n",
    "    \n",
    "    #if p: print(f\"Min: {min}, Max: {max}, Mean: {mean}, Std: {std}\")\n",
    "    if p: print(f\"Mean: {mean}, Std: {std}\")\n",
    "    if r: return mean, std\n",
    "    \n",
    "    \n",
    "def zscore(tensor, mean=None, std=None):\n",
    "    if mean is None: mean = tensor.mean()\n",
    "    if std is None: std = tensor.std()\n",
    "    return (tensor - mean) / (std + 1e-8)\n",
    "\n",
    "\n",
    "def get_model_size(model):\n",
    "    print(sum(p.numel() for p in model.parameters()) / 1e6)\n",
    "    \n",
    "\n",
    "def get_index(iterable):\n",
    "    return random.randint(0, len(iterable) - 1)\n",
    "\n",
    "\n",
    "def get_indices(iterable, n):\n",
    "    return random.sample(range(len(iterable)), n)\n",
    "\n",
    "\n",
    "def split(inputs, targets, seed):\n",
    "    return train_test_split(\n",
    "        inputs,\n",
    "        targets, \n",
    "        test_size=0.2,\n",
    "        shuffle=True, \n",
    "        random_state=seed\n",
    "    ) \n",
    "\n",
    "\n",
    "def show_waves(waves, dpi=100):\n",
    "    \"\"\"\n",
    "    waves: numpy array of shape (3, N)\n",
    "    Creates three separate figures that stretch wide.\n",
    "    \"\"\"\n",
    "    N = waves.shape[1]\n",
    "    t = np.arange(N)\n",
    "\n",
    "    # Wide aspect ratio; height modest so each window fills width\n",
    "    for i in range(waves.shape[0]):\n",
    "        fig = plt.figure(figsize=(14, 4), dpi=dpi)  # wide figure\n",
    "        ax = fig.add_subplot(111)\n",
    "        ax.plot(t, waves[i], linewidth=1)\n",
    "        ax.set_title(f\"Wave {i+1}\")\n",
    "        ax.set_xlabel(\"Sample\")\n",
    "        ax.set_ylabel(\"Amplitude\")\n",
    "        ax.grid(True)\n",
    "        fig.tight_layout()  # reduce margins to use width\n",
    "        \n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "def hf_ds_download(hf_token, repo_id):\n",
    "    login(hf_token[1:])\n",
    "    return snapshot_download(repo_id, repo_type=\"dataset\")\n",
    "\n",
    "\n",
    "def get_spectra_features(X, b=False):\n",
    "    \"\"\"Create multi-channel features from spectra: raw, 1st derivative, 2nd derivative.\"\"\"\n",
    "    X_processed = np.zeros_like(X)\n",
    "    # Baseline correction and SNV\n",
    "    for i in tqdm(range(X.shape[0])):\n",
    "        poly = np.polyfit(np.arange(X.shape[1]), X[i], 3)\n",
    "        baseline = np.polyval(poly, np.arange(X.shape[1]))\n",
    "        corrected_spec = X[i] - baseline\n",
    "        #X_processed[i] = (corrected_spec - corrected_spec.mean()) / (corrected_spec.std() + 1e-8)\n",
    "        X_processed[i] = corrected_spec\n",
    "        \n",
    "    # Calculate derivatives\n",
    "    deriv1 = signal.savgol_filter(X_processed, window_length=11, polyorder=3, deriv=1, axis=1)\n",
    "    deriv2 = signal.savgol_filter(X_processed, window_length=11, polyorder=3, deriv=2, axis=1)\n",
    "\n",
    "    if b: return np.stack([X_processed, deriv1, deriv2], axis=1)\n",
    "    return np.stack([deriv1, deriv2], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc57c619",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 'sample_submission.csv'),\n",
       " (1, 'timegate.csv'),\n",
       " (2, 'mettler_toledo.csv'),\n",
       " (3, 'kaiser.csv'),\n",
       " (4, 'anton_532.csv'),\n",
       " (5, 'transfer_plate.csv'),\n",
       " (6, '96_samples.csv'),\n",
       " (7, 'tornado.csv'),\n",
       " (8, 'tec5.csv'),\n",
       " (9, 'metrohm.csv'),\n",
       " (10, 'anton_785.csv')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "path = \"/kaggle/input/dig-4-bio-raman-transfer-learning-challenge\"\n",
    "files = os.listdir(path)\n",
    "[(i, files[i]) for i in range(len(files))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c3d530d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "def load_transfer_data():\n",
    "    csv_path = os.path.join(path, files[5])\n",
    "    df = pd.read_csv(csv_path)\n",
    "\n",
    "    input_cols = df.columns[1:2049]\n",
    "    target_cols = df.columns[2050:]\n",
    "\n",
    "    targets  = df[target_cols].dropna().to_numpy()\n",
    "\n",
    "    df = df[input_cols]\n",
    "    df['Unnamed: 1'] = df['Unnamed: 1'].str.replace(\"[\\[\\]]\", \"\", regex=True).astype('int64')\n",
    "    df['Unnamed: 2048'] = df['Unnamed: 2048'].str.replace(\"[\\[\\]]\", \"\", regex=True).astype('int64')\n",
    "\n",
    "    inputs = df.to_numpy().reshape(-1, 2, 2048)\n",
    "    inputs = inputs.mean(axis=1)\n",
    "\n",
    "    return inputs, targets\n",
    "\n",
    "\n",
    "def load_test_data(path):\n",
    "    test = pd.read_csv(os.path.join(path, files[6]))\n",
    "\n",
    "    row1 = test.columns[1:].to_numpy().copy()\n",
    "    row1[-1] = \"5611\"\n",
    "    row1 = row1.astype(np.float64)\n",
    "\n",
    "\n",
    "    cols = test.columns[1:]\n",
    "    test = test[cols]\n",
    "    test[\" 5611]\"] = test[\" 5611]\"].str.replace('[\\[\\]]', '', regex=True).astype('int64')\n",
    "    test = test.to_numpy()\n",
    "\n",
    "    test = np.insert(test, 0, row1, axis=0)\n",
    "    return test.reshape(-1, 2, 2048).mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78b26650",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d33ccb80bd6a4230a91f334a7c53fe55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/96 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "inputs, targets = load_transfer_data()\n",
    "inputs = get_spectra_features(inputs)\n",
    "inputs = torch.tensor(inputs)\n",
    "targets = torch.tensor(targets)\n",
    "#train_inputs, eval_inputs, train_targets, eval_targets = split(inputs, targets, SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "361b66c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    train_inputs = torch.tensor(train_inputs)\n",
    "    eval_inputs = torch.tensor(eval_inputs)\n",
    "    train_targets = torch.tensor(train_targets)\n",
    "    eval_targets = torch.tensor(eval_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e53ebd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    min, max, mu, sigma = get_stats(train_inputs, r=True)\n",
    "    train_inputs = zscore(train_inputs)\n",
    "    eval_inputs = zscore(eval_inputs)\n",
    "    get_stats(train_inputs), get_stats(eval_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bfe55238",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "if False:\n",
    "    train_ds = TensorDataset(train_inputs.float(), train_targets.float())\n",
    "    eval_ds = TensorDataset(eval_inputs.float(), eval_targets.float())\n",
    "    len(train_ds), len(eval_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a9dcceb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "def build_loader(\n",
    "    SEED,\n",
    "    ds,\n",
    "    train=True,\n",
    "    batch_size=1,\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    "    drop_last=True,\n",
    "    pin_memory=True,\n",
    "    persistent_workers=False,\n",
    "):\n",
    "    def seed_worker(worker_id):\n",
    "        worker_seed = torch.initial_seed() % 2**32\n",
    "        np.random.seed(worker_seed)\n",
    "        random.seed(worker_seed)\n",
    "\n",
    "    generator = torch.Generator()\n",
    "    generator.manual_seed(SEED if train else SEED+5232)\n",
    "\n",
    "    return DataLoader(\n",
    "        ds,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=pin_memory,\n",
    "        drop_last=drop_last,\n",
    "        persistent_workers=persistent_workers,\n",
    "        worker_init_fn=seed_worker,\n",
    "        generator=generator,\n",
    "        #sampler=DistributedSampler(\n",
    "        #    train_ds,\n",
    "        #    shuffle=True,\n",
    "        #    drop_last=True,\n",
    "        #    seed=config.seed\n",
    "        #)\n",
    "    )\n",
    "    \n",
    "    \n",
    "def return_dls(train_ds, eval_ds, train_batch_size, eval_batch_size):\n",
    "    train_dl = build_loader(\n",
    "        SEED,\n",
    "        train_ds,\n",
    "        train=True,\n",
    "        batch_size=train_batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=0,\n",
    "        drop_last=False,\n",
    "        pin_memory=True,\n",
    "        persistent_workers=False,\n",
    "    )\n",
    "\n",
    "    eval_dl = build_loader(\n",
    "        SEED,\n",
    "        eval_ds,\n",
    "        train=False,\n",
    "        batch_size=eval_batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=0,\n",
    "        drop_last=False,\n",
    "        pin_memory=True,\n",
    "        persistent_workers=False,\n",
    "    )\n",
    "    \n",
    "    return train_dl, eval_dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "437ed80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import neptune\n",
    "\n",
    "\n",
    "def setup_neptune():\n",
    "    if not RESUME:\n",
    "        neptune_run = neptune.init_run(\n",
    "            project=\"arbaaz/kaggle-spect\",\n",
    "            name=MODEL_NAME,\n",
    "            api_token=\"eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiJlOGE2YjNiZS1mZGUyLTRjYjItYTg5Yy1mZWJkZTIzNzE1NmIifQ==\"\n",
    "        )\n",
    "\n",
    "        neptune_run[\"h_parameters\"] = {\n",
    "            \"seed\": SEED,\n",
    "            \"model_name\": MODEL_NAME,\n",
    "            \"optimizer_name\": \"nadam\",\n",
    "            \"learning_rate\": LR,\n",
    "            \"scheduler_name\": \"default\",\n",
    "            \"weight_decay\": WD,\n",
    "            \"num_epochs\": EPOCHS,\n",
    "            \"batch_size\": BATCH_SIZE,\n",
    "        }\n",
    "        if DROPOUT: neptune_run[\"h_parameters\"] = {\"dropout\": DROPOUT}\n",
    "        if DROP_PATH_RATE: neptune_run[\"h_parameters\"] = {\"drop_path_rate\": DROP_PATH_RATE}\n",
    "    else:\n",
    "        neptune_run = neptune.init_run(\n",
    "            project=\"arbaaz/crunchdao-structural-break\",\n",
    "            with_id=config.with_id,\n",
    "            api_token=\"eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiJlOGE2YjNiZS1mZGUyLTRjYjItYTg5Yy1mZWJkZTIzNzE1NmIifQ==\"\n",
    "        )\n",
    "\n",
    "    return neptune_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9e978702",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "\n",
    "def loss_fn(logits, targets):\n",
    "    logits = logits.view(-1)\n",
    "    targets = targets.view(-1)\n",
    "    return F.mse_loss(logits, targets)\n",
    "\n",
    "\n",
    "def metric_fn(logits, targets):\n",
    "    preds = logits.cpu().detach().numpy()\n",
    "    targets = targets.cpu().detach().numpy()\n",
    "    \n",
    "    dim1 = r2_score(targets[:, 0], preds[:, 0])\n",
    "    dim2 = r2_score(targets[:, 1], preds[:, 1])\n",
    "    dim3 = r2_score(targets[:, 2], preds[:, 2])\n",
    "    \n",
    "    mean_r2 = (dim1 + dim2 + dim3) / 3\n",
    "    \n",
    "    return dim1, dim2, dim3, mean_r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5e882d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    \"\"\"A residual block with two 1D convolutional layers.\"\"\"\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels, out_channels, kernel_size, stride, padding=kernel_size//2)\n",
    "        self.bn1 = nn.BatchNorm1d(out_channels)\n",
    "        self.elu = nn.ELU()\n",
    "        self.conv2 = nn.Conv1d(out_channels, out_channels, kernel_size, padding=kernel_size//2)\n",
    "        self.bn2 = nn.BatchNorm1d(out_channels)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv1d(in_channels, out_channels, kernel_size=1, stride=stride),\n",
    "                nn.BatchNorm1d(out_channels)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.elu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = self.elu(out)\n",
    "        return out\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    \"\"\"A deeper ResNet-style 1D CNN for Raman spectra.\"\"\"\n",
    "    def __init__(self, dropout, input_channels=3, num_classes=3):\n",
    "        super().__init__()\n",
    "        self.in_channels = 64\n",
    "        self.conv1 = nn.Conv1d(input_channels, 64, kernel_size=7, stride=2, padding=3)\n",
    "        self.bn1 = nn.BatchNorm1d(64)\n",
    "        self.elu = nn.GELU()\n",
    "        self.maxpool = nn.MaxPool1d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        self.layer1 = self._make_layer(64, 2, stride=1)\n",
    "        self.layer2 = self._make_layer(128, 2, stride=2)\n",
    "        self.layer3 = self._make_layer(256, 2, stride=2)\n",
    "        self.layer4 = self._make_layer(512, 2, stride=2)\n",
    "\n",
    "        self.avgpool = nn.AdaptiveAvgPool1d(1)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ELU(),\n",
    "            nn.Dropout(dropout), # Increased dropout for better regularization\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "\n",
    "    def _make_layer(self, out_channels, num_blocks, stride):\n",
    "        strides = [stride] + [1] * (num_blocks - 1)\n",
    "        layers = []\n",
    "        for s in strides:\n",
    "            layers.append(ResidualBlock(self.in_channels, out_channels, stride=s))\n",
    "            self.in_channels = out_channels\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.elu(self.bn1(self.conv1(x)))\n",
    "        x = self.maxpool(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "44fca775",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "def train(\n",
    "    model, \n",
    "    optimizer,\n",
    "    device,\n",
    "    scaler, \n",
    "    scheduler,\n",
    "    train_dl,\n",
    "    eval_dl,\n",
    "    epochs,\n",
    "    checkpoint_name,\n",
    "    score=-float(\"inf\"),\n",
    "    neptune_run=None,\n",
    "    p=True,\n",
    "):  \n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "        all_logits = []\n",
    "        all_targets = []\n",
    "        \n",
    "        for inputs, targets in train_dl:\n",
    "            inputs = inputs.to(device, non_blocking=True)\n",
    "            targets = targets.to(device, non_blocking=True)\n",
    "            \n",
    "            with torch.amp.autocast(device_type=device, dtype=torch.float16, cache_enabled=True):\n",
    "                logits = model(inputs)\n",
    "                loss = loss_fn(logits, targets)\n",
    "            \n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            optimizer.zero_grad()\n",
    "            scheduler.step()\n",
    "            if neptune_run is not None:  neptune_run[\"lr_step\"].append(scheduler.get_last_lr()[0])\n",
    "            \n",
    "            total_loss += loss.detach().cpu()\n",
    "            all_logits.append(logits.detach().cpu())\n",
    "            all_targets.append(targets.detach().cpu())\n",
    "        \n",
    "        all_logits = torch.cat(all_logits)\n",
    "        all_targets = torch.cat(all_targets)\n",
    "\n",
    "        one, two, three, r2 = metric_fn(all_logits, all_targets)\n",
    "        total_loss = total_loss / len(train_dl)\n",
    "        \n",
    "        model.eval()\n",
    "        eval_total_loss = 0.0\n",
    "        eval_all_logits = []\n",
    "        eval_all_targets = []\n",
    "\n",
    "        for inputs, targets in eval_dl:\n",
    "            inputs = inputs.to(device, non_blocking=True)\n",
    "            targets = targets.to(device, non_blocking=True)\n",
    "\n",
    "            with torch.inference_mode():\n",
    "                #with torch.amp.autocast(device_type=device, dtype=torch.float16, cache_enabled=True):\n",
    "                logits = model(inputs)\n",
    "                loss = loss_fn(logits, targets)\n",
    "\n",
    "            eval_total_loss += loss.detach().cpu()\n",
    "            eval_all_logits.append(logits.detach().cpu())\n",
    "            eval_all_targets.append(targets.detach().cpu())\n",
    "        \n",
    "        eval_all_logits = torch.cat(eval_all_logits)\n",
    "        eval_all_targets = torch.cat(eval_all_targets)\n",
    "\n",
    "        eval_one, eval_two, eval_three, eval_r2 = metric_fn(eval_all_logits, eval_all_targets)\n",
    "        eval_total_loss = eval_total_loss / len(eval_dl)\n",
    "        \n",
    "        if eval_r2 > score:\n",
    "            score = eval_r2\n",
    "            data = {\"state_dict\": model.state_dict()}\n",
    "            data[\"epoch\"] = epoch \n",
    "            data[\"score\"] = score\n",
    "            torch.save(data, f\"/kaggle/working/{checkpoint_name}\")\n",
    "        \n",
    "        if neptune_run is not None:\n",
    "            neptune_run[\"train/loss\"].append(total_loss)\n",
    "            neptune_run[\"eval/loss\"].append(eval_total_loss)\n",
    "            neptune_run[\"train/r2\"].append(r2)\n",
    "            neptune_run[\"eval/r2\"].append(eval_r2)\n",
    "            neptune_run[\"train/one\"].append(one)\n",
    "            neptune_run[\"train/two\"].append(two)\n",
    "            neptune_run[\"train/three\"].append(three)\n",
    "            neptune_run[\"eval/one\"].append(eval_one)\n",
    "            neptune_run[\"eval/two\"].append(eval_two)\n",
    "            neptune_run[\"eval/three\"].append(eval_three)\n",
    "            \n",
    "        if p and epoch % 5 == 0:\n",
    "            print(\n",
    "                f\"Epoch: {epoch}, \"\n",
    "                f\"train/loss: {total_loss:.4f}, \"\n",
    "                f\"eval/loss: {eval_total_loss:.4f}, \"\n",
    "                f\"train/r2: {r2:.4f}, \"\n",
    "                f\"eval/r2: {eval_r2:.4f}, \"\n",
    "                f\"train/one: {one:.4f}, \"\n",
    "                f\"train/two: {two:.4f}, \"\n",
    "                f\"train/three: {three:.4f}, \"\n",
    "                f\"eval/one: {eval_one:.4f}, \"\n",
    "                f\"eval/two: {eval_two:.4f}, \"\n",
    "                f\"eval/three: {eval_three:.4f} \"\n",
    "            )\n",
    "            \n",
    "    if neptune_run is not None: neptune_run.stop()\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6326238b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings#; warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "EPOCHS = 500\n",
    "WD = 1e-3\n",
    "LR = 1e-4\n",
    "\n",
    "DROPOUT = 0.5\n",
    "DROP_PATH_RATE = None\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "RESUME = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e80c4df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "\n",
    "mus = [0.5431315108096543,\n",
    " 0.5373212199292232,\n",
    " 0.5625938858971476,\n",
    " 0.5611233230776563,\n",
    " 0.5471325694126035]\n",
    "\n",
    "sigmas = [249.05215723502948,\n",
    " 248.6726517269414,\n",
    " 247.84789229685813,\n",
    " 247.65868506084584,\n",
    " 248.16012425733976]\n",
    "\n",
    "mus, sigmas = [], []\n",
    "scores = []\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=SEED)\n",
    "splits = kfold.split(range(96))\n",
    "\n",
    "for fold, (train_idx, eval_idx) in enumerate(splits):\n",
    "    MODEL_NAME = f\"resnet.finetune.fold.{fold}\"\n",
    "    checkpoint_name = f\"finetune.fold.{fold}.pt\"\n",
    "    \n",
    "    train_inputs = inputs[train_idx]\n",
    "    train_targets = targets[train_idx]\n",
    "    eval_inputs = inputs[eval_idx]\n",
    "    eval_targets = targets[eval_idx]\n",
    "    \n",
    "    mu, sigma = get_stats(train_inputs, p=False, r=True)\n",
    "    train_inputs = zscore(train_inputs, mu, sigma)\n",
    "    eval_inputs = zscore(eval_inputs, mu, sigma)\n",
    "    mus.append(mu)\n",
    "    sigmas.append(sigma)\n",
    "    continue\n",
    "    train_ds = TensorDataset(train_inputs.float(), train_targets.float())\n",
    "    eval_ds = TensorDataset(eval_inputs.float(), eval_targets.float())\n",
    "    \n",
    "    BATCH_SIZE = len(train_ds)\n",
    "    train_dl, eval_dl = return_dls(train_ds, eval_ds, BATCH_SIZE, len(eval_ds))\n",
    "    \n",
    "    model = ResNet(input_channels=2, dropout=DROPOUT).to(device)\n",
    "    if fold == 0: print(get_model_size(model))\n",
    "    \n",
    "    ckpt = torch.load(f\"pretrain.fold.{fold}.pt\", weights_only=False)\n",
    "    print(ckpt[\"score\"])\n",
    "    model.load_state_dict(ckpt[\"state_dict\"])\n",
    "    \n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=LR, weight_decay=WD, foreach=True)\n",
    "    scaler = torch.amp.GradScaler(device)\n",
    "    scheduler = get_scheduler(optimizer, train_dl, EPOCHS)\n",
    "    score = train(\n",
    "            model, \n",
    "            optimizer, \n",
    "            device,\n",
    "            scaler,\n",
    "            scheduler,\n",
    "            train_dl, \n",
    "            eval_dl,\n",
    "            EPOCHS,\n",
    "            checkpoint_name,\n",
    "            neptune_run=setup_neptune(),\n",
    "        )\n",
    "    \n",
    "    scores.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9b68badb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.neptune',\n",
       " '.virtual_documents',\n",
       " 'finetune.fold.0.pt',\n",
       " 'finetune.fold.1.pt',\n",
       " 'finetune.fold.2.pt',\n",
       " 'finetune.fold.3.pt',\n",
       " 'finetune.fold.4.pt',\n",
       " 'pretrain.fold.0.pt',\n",
       " 'pretrain.fold.1.pt',\n",
       " 'pretrain.fold.2.pt',\n",
       " 'pretrain.fold.3.pt',\n",
       " 'pretrain.fold.4.pt',\n",
       " 'resnet.finetune.8823.fold1.csv',\n",
       " 'resnet.pretrain.4882.fold1.csv']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "32e55b49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d7253c529c445d592199df1bd3aadcb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/96 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cc0f2b47edb481d9155d836bce74867",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/96 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fadff6f59ae64657b22ba88e24ef42d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/96 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f0ad262cfc54259b9a8680000f89d39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/96 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94362342c57e425ea0da1c78c9703cf0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/96 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "\n",
    "core_path = \"/kaggle/working\"\n",
    "files_ = sorted(os.listdir(core_path))\n",
    "i = 0\n",
    "all_preds = []\n",
    "for f in files_:\n",
    "    if \"finetune.fold\" in f:\n",
    "        ckpt_path = os.path.join(core_path, f)\n",
    "        ckpt = torch.load(ckpt_path, weights_only=False)\n",
    "\n",
    "        test = load_test_data(path)\n",
    "        test = get_spectra_features(test)\n",
    "        test = torch.tensor(test)\n",
    "        test = zscore(test, mus[i], sigmas[i]).float()\n",
    "        i += 1\n",
    "\n",
    "        model = ResNet(input_channels=2, dropout=0.5).to(device)\n",
    "        model.load_state_dict(ckpt[\"state_dict\"])\n",
    "        model.eval()\n",
    "\n",
    "        with torch.inference_mode():\n",
    "            preds = model(test.cuda())\n",
    "\n",
    "        preds = preds.cpu().detach().double()\n",
    "        all_preds.append(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d198d595",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = torch.stack(all_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "91e08df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = preds.mean(0).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "68de9b93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.48822867684523436"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckpt = torch.load(\"/kaggle/working/pretrain.fold.1.pt\", weights_only=False)\n",
    "ckpt[\"score\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "176d5a17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 3623.216623942057, Std: 6772.114021862655\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3973e7bf1e7f4cef920abe298c13ebf8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/96 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 0.02771512232720852, Std: 2.6981143951416016\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([96, 2, 2048]), torch.float32, None)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = load_test_data()\n",
    "get_stats(test)\n",
    "test = get_spectra_features(test)\n",
    "test = torch.tensor(test)\n",
    "test = zscore(test, 0.5373212199292232, 248.6726517269414).float()\n",
    "test.shape, test.dtype, get_stats(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "58b4472a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 2.440112045396947, Std: 2.335613724637091\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((96, 3), None)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ResNet(input_channels=2, dropout=0.5).to(device)\n",
    "model.load_state_dict(ckpt[\"state_dict\"])\n",
    "model.eval()\n",
    "\n",
    "with torch.inference_mode():\n",
    "    preds = model(test.cuda())\n",
    "\n",
    "preds = preds.cpu().detach().double().numpy()\n",
    "preds.shape, get_stats(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "106352ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 2.2413799092406403, Std: 1.9773549545086004\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.3601879395544529, 9.246828269958495, None)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.min(), preds.max(), get_stats(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5dce6794",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>Sodium Acetate</th>\n",
       "      <th>Magnesium Sulfate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2.679680</td>\n",
       "      <td>0.783572</td>\n",
       "      <td>0.458006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>6.443715</td>\n",
       "      <td>1.512056</td>\n",
       "      <td>1.462726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>4.334267</td>\n",
       "      <td>0.498753</td>\n",
       "      <td>1.138379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>3.869976</td>\n",
       "      <td>0.856771</td>\n",
       "      <td>0.403803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>9.246828</td>\n",
       "      <td>0.846140</td>\n",
       "      <td>1.014109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>92</td>\n",
       "      <td>3.329243</td>\n",
       "      <td>0.795816</td>\n",
       "      <td>1.240150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>93</td>\n",
       "      <td>3.728871</td>\n",
       "      <td>0.473928</td>\n",
       "      <td>0.961597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>94</td>\n",
       "      <td>4.097541</td>\n",
       "      <td>0.600958</td>\n",
       "      <td>0.902222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>95</td>\n",
       "      <td>3.378495</td>\n",
       "      <td>1.356923</td>\n",
       "      <td>0.916949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>96</td>\n",
       "      <td>5.128580</td>\n",
       "      <td>1.564433</td>\n",
       "      <td>1.023243</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>96 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    ID   Glucose  Sodium Acetate  Magnesium Sulfate\n",
       "0    1  2.679680        0.783572           0.458006\n",
       "1    2  6.443715        1.512056           1.462726\n",
       "2    3  4.334267        0.498753           1.138379\n",
       "3    4  3.869976        0.856771           0.403803\n",
       "4    5  9.246828        0.846140           1.014109\n",
       "..  ..       ...             ...                ...\n",
       "91  92  3.329243        0.795816           1.240150\n",
       "92  93  3.728871        0.473928           0.961597\n",
       "93  94  4.097541        0.600958           0.902222\n",
       "94  95  3.378495        1.356923           0.916949\n",
       "95  96  5.128580        1.564433           1.023243\n",
       "\n",
       "[96 rows x 4 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_names = ['Glucose', 'Sodium Acetate', 'Magnesium Sulfate']\n",
    "preds_df = pd.DataFrame(preds, columns=column_names)\n",
    "preds_df.insert(0, 'ID', [i+1 for i in range(len(preds_df))])\n",
    "preds_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "dad1cd9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('resnet.finetune.fold.4', 0.48822867684523436)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODEL_NAME, ckpt[\"score\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "71b8e5e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>Sodium Acetate</th>\n",
       "      <th>Magnesium Sulfate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2.679680</td>\n",
       "      <td>0.783572</td>\n",
       "      <td>0.458006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>6.443715</td>\n",
       "      <td>1.512056</td>\n",
       "      <td>1.462726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>4.334267</td>\n",
       "      <td>0.498753</td>\n",
       "      <td>1.138379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>3.869976</td>\n",
       "      <td>0.856771</td>\n",
       "      <td>0.403803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>9.246828</td>\n",
       "      <td>0.846140</td>\n",
       "      <td>1.014109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>92</td>\n",
       "      <td>3.329243</td>\n",
       "      <td>0.795816</td>\n",
       "      <td>1.240150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>93</td>\n",
       "      <td>3.728871</td>\n",
       "      <td>0.473928</td>\n",
       "      <td>0.961597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>94</td>\n",
       "      <td>4.097541</td>\n",
       "      <td>0.600958</td>\n",
       "      <td>0.902222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>95</td>\n",
       "      <td>3.378495</td>\n",
       "      <td>1.356923</td>\n",
       "      <td>0.916949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>96</td>\n",
       "      <td>5.128580</td>\n",
       "      <td>1.564433</td>\n",
       "      <td>1.023243</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>96 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    ID   Glucose  Sodium Acetate  Magnesium Sulfate\n",
       "0    1  2.679680        0.783572           0.458006\n",
       "1    2  6.443715        1.512056           1.462726\n",
       "2    3  4.334267        0.498753           1.138379\n",
       "3    4  3.869976        0.856771           0.403803\n",
       "4    5  9.246828        0.846140           1.014109\n",
       "..  ..       ...             ...                ...\n",
       "91  92  3.329243        0.795816           1.240150\n",
       "92  93  3.728871        0.473928           0.961597\n",
       "93  94  4.097541        0.600958           0.902222\n",
       "94  95  3.378495        1.356923           0.916949\n",
       "95  96  5.128580        1.564433           1.023243\n",
       "\n",
       "[96 rows x 4 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name = \"resnet.finetune.all.folds.csv\"\n",
    "preds_df.to_csv(name, index=False)\n",
    "f = pd.read_csv(f\"/kaggle/working/{name}\")\n",
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "235a2294",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.67967954, 0.78357179, 0.45800613],\n",
       "       [6.44371519, 1.51205604, 1.46272559],\n",
       "       [4.33426738, 0.4987534 , 1.13837928],\n",
       "       [3.86997619, 0.856771  , 0.40380331],\n",
       "       [9.24682827, 0.84614031, 1.01410854],\n",
       "       [7.95932093, 1.74550412, 1.12293968],\n",
       "       [4.92644253, 0.6653578 , 0.36018794],\n",
       "       [8.07706261, 1.68925283, 1.35848229],\n",
       "       [6.14031515, 1.24895676, 1.24107531],\n",
       "       [8.34203043, 1.0242914 , 0.49165687],\n",
       "       [7.09966297, 1.09119189, 1.17774593],\n",
       "       [3.86741662, 0.67115462, 1.05267402],\n",
       "       [3.2626493 , 0.88938384, 1.09069486],\n",
       "       [3.85280752, 0.70643659, 1.44978414],\n",
       "       [3.14084277, 0.75801558, 1.07351474],\n",
       "       [6.3768589 , 0.97297016, 0.99683253],\n",
       "       [3.77613826, 0.76518672, 1.10728935],\n",
       "       [5.3258625 , 0.97261331, 1.16698685],\n",
       "       [5.0781498 , 1.08894435, 1.17013738],\n",
       "       [2.64447912, 0.72874848, 1.14038044],\n",
       "       [3.38296123, 0.85824862, 1.00850284],\n",
       "       [4.64680042, 0.84010615, 1.06851076],\n",
       "       [2.42269611, 1.08527687, 0.45194251],\n",
       "       [3.62635102, 1.12087879, 1.36699071],\n",
       "       [3.6552259 , 0.79133885, 1.0816269 ],\n",
       "       [3.78233294, 0.84190735, 1.29789624],\n",
       "       [4.71769986, 1.04963965, 1.08558166],\n",
       "       [4.50758152, 0.8219874 , 1.28204621],\n",
       "       [4.64715652, 0.94682038, 1.0764215 ],\n",
       "       [4.22339907, 0.45079558, 0.37145627],\n",
       "       [4.30216441, 0.77038836, 1.40438765],\n",
       "       [8.19778929, 0.98718158, 1.15704992],\n",
       "       [4.69452715, 0.78869734, 1.3113983 ],\n",
       "       [5.25115891, 1.06841384, 0.94651141],\n",
       "       [6.88286953, 1.42520804, 1.10144662],\n",
       "       [5.91269999, 0.59404509, 0.73712721],\n",
       "       [7.18095465, 0.89720352, 0.83499638],\n",
       "       [4.6943079 , 1.09259636, 0.81618348],\n",
       "       [3.56409383, 1.04834352, 0.83143277],\n",
       "       [7.30635691, 1.196351  , 1.44142096],\n",
       "       [4.10316687, 0.5861431 , 1.08197105],\n",
       "       [3.62104702, 1.27378383, 0.36405517],\n",
       "       [6.42275734, 0.40303165, 1.396963  ],\n",
       "       [3.00005445, 0.74230148, 1.04368896],\n",
       "       [2.51345477, 0.97367489, 0.82864047],\n",
       "       [5.27691574, 0.60316626, 1.69589071],\n",
       "       [2.93626781, 0.42834747, 1.34851744],\n",
       "       [2.905655  , 0.89521633, 1.11391294],\n",
       "       [4.28844886, 0.82174344, 1.30614299],\n",
       "       [6.33632212, 0.85123684, 1.74914308],\n",
       "       [2.4377506 , 0.95603898, 1.93759696],\n",
       "       [2.60849037, 0.77287904, 1.49021733],\n",
       "       [3.51922531, 0.60433527, 1.17223035],\n",
       "       [3.6746232 , 1.45942471, 1.29591664],\n",
       "       [3.23407843, 0.99541453, 1.16686076],\n",
       "       [5.34310064, 1.19831374, 1.8687211 ],\n",
       "       [5.84233284, 1.45134223, 1.5588172 ],\n",
       "       [4.26538348, 1.21579788, 1.87674632],\n",
       "       [4.28838935, 0.4431278 , 1.38921328],\n",
       "       [4.49870358, 0.6307989 , 0.90540375],\n",
       "       [2.18999264, 0.5425288 , 1.36522365],\n",
       "       [2.58839016, 0.87878591, 1.58863447],\n",
       "       [2.91992486, 0.9111812 , 1.09062197],\n",
       "       [5.37026711, 0.79044318, 1.72188647],\n",
       "       [8.49375687, 1.49225025, 0.71044986],\n",
       "       [6.40917416, 0.89920336, 0.49813167],\n",
       "       [6.33153534, 1.41649017, 1.31849972],\n",
       "       [3.34034879, 0.88564045, 0.98946474],\n",
       "       [4.1283021 , 0.85376198, 1.05603421],\n",
       "       [5.74451237, 0.78007137, 1.17077616],\n",
       "       [6.33008699, 0.841216  , 1.08601059],\n",
       "       [5.11279974, 0.88792835, 1.25087099],\n",
       "       [4.56869769, 1.07537067, 1.50758598],\n",
       "       [6.93904686, 0.60562828, 1.22003726],\n",
       "       [3.90111074, 0.69026843, 1.39388167],\n",
       "       [7.01350908, 0.68287029, 1.39744864],\n",
       "       [3.37632768, 0.83991863, 0.43740637],\n",
       "       [4.49571037, 0.62000669, 1.32312115],\n",
       "       [1.95752461, 1.13623021, 0.90050389],\n",
       "       [2.91524   , 0.59732502, 1.52086875],\n",
       "       [6.56491966, 0.81445408, 0.83717629],\n",
       "       [3.5295332 , 0.79100285, 1.98996642],\n",
       "       [6.56142626, 0.89078383, 1.92766345],\n",
       "       [5.43028164, 0.85130572, 1.47893643],\n",
       "       [3.55092678, 0.99773648, 1.6350971 ],\n",
       "       [3.34345112, 0.70798653, 1.11572652],\n",
       "       [3.78477392, 0.78037195, 1.15384164],\n",
       "       [2.58378825, 0.75202547, 1.27589023],\n",
       "       [6.07085638, 0.97571561, 1.13970753],\n",
       "       [1.9561013 , 0.81342762, 1.21465067],\n",
       "       [4.74480519, 1.11487154, 1.14079375],\n",
       "       [3.32924273, 0.79581617, 1.24014992],\n",
       "       [3.72887115, 0.473928  , 0.96159736],\n",
       "       [4.09754138, 0.60095797, 0.90222223],\n",
       "       [3.37849498, 1.35692272, 0.91694937],\n",
       "       [5.12857981, 1.56443274, 1.02324278]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38dd61bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
