{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ecea469",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install -qU xgboost optuna pandas scipy scikit-learn matplotlib tqdm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1468113e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "SEED = 1000\n",
    "\n",
    "def setup_reproducibility():\n",
    "    random.seed(SEED)\n",
    "    np.random.seed(SEED)\n",
    "    torch.manual_seed(SEED)\n",
    "    if torch.cuda.is_available(): torch.cuda.manual_seed_all(SEED)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.use_deterministic_algorithms(False, warn_only=True)\n",
    "    torch.set_float32_matmul_precision(\"high\")\n",
    "\n",
    "setup_reproducibility()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ecaa449",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "def get_stats(tensor, p=True, r=False):\n",
    "    mean, std = tensor.mean(), tensor.std()\n",
    "    min, max =  tensor.min(), tensor.max()\n",
    "    \n",
    "    if p: print(f\"Min: {min}, Max: {max}, Mean: {mean}, Std: {std}\")\n",
    "    \n",
    "    if r: return min, max, mean, std\n",
    "    \n",
    "    \n",
    "def zscore(tensor, mean=None, std=None):\n",
    "    if mean is None: mean = tensor.mean()\n",
    "    if std is None: std = tensor.std()\n",
    "    return (tensor - mean) / (std + 1e-6)\n",
    "\n",
    "\n",
    "def get_model_size(model):\n",
    "    print(sum(p.numel() for p in model.parameters()) / 1e6)\n",
    "    \n",
    "\n",
    "def get_index(iterable):\n",
    "    return random.randint(0, len(iterable) - 1)\n",
    "\n",
    "\n",
    "def split(inputs, targets, seed):\n",
    "    return train_test_split(\n",
    "        inputs,\n",
    "        targets, \n",
    "        test_size=0.2,\n",
    "        shuffle=True, \n",
    "        random_state=seed\n",
    "    ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb2962fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def show_waves(waves, dpi=100):\n",
    "    \"\"\"\n",
    "    waves: numpy array of shape (3, N)\n",
    "    Creates three separate figures that stretch wide.\n",
    "    \"\"\"\n",
    "\n",
    "    N = waves.shape[1]\n",
    "    t = np.arange(N)\n",
    "\n",
    "    # Wide aspect ratio; height modest so each window fills width\n",
    "    for i in range(waves.shape[0]):\n",
    "        fig = plt.figure(figsize=(14, 4), dpi=dpi)  # wide figure\n",
    "        ax = fig.add_subplot(111)\n",
    "        ax.plot(t, waves[i], linewidth=1)\n",
    "        ax.set_title(f\"Wave {i+1}\")\n",
    "        ax.set_xlabel(\"Sample\")\n",
    "        ax.set_ylabel(\"Amplitude\")\n",
    "        ax.grid(True)\n",
    "        fig.tight_layout()  # reduce margins to use width\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b5aab7a-f5ae-450f-b72a-982922fd9342",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login, snapshot_download\n",
    "\n",
    "if False:\n",
    "    hf_token = \"xhf_uOkImkbEroqtIuyvGJrttTzaebfeIdPZID\"\n",
    "    login(hf_token)\n",
    "    repo_id = \"ArbaazBeg/kaggle-spectogram\"\n",
    "    dataset_path = snapshot_download(repo_id, repo_type=\"dataset\")\n",
    "    dataset_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f753ce1-8254-4d5a-b287-340d341f5b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b81644e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, '.gitattributes'),\n",
       " (1, '96_samples.csv'),\n",
       " (2, 'anton_532.csv'),\n",
       " (3, 'anton_785.csv'),\n",
       " (4, 'kaiser.csv'),\n",
       " (5, 'metrohm.csv'),\n",
       " (6, 'mettler_toledo.csv'),\n",
       " (7, 'sample_submission.csv'),\n",
       " (8, 'tec5.csv'),\n",
       " (9, 'timegate.csv'),\n",
       " (10, 'tornado.csv'),\n",
       " (11, 'transfer_plate.csv')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "path = \"/root/.cache/huggingface/hub/datasets--ArbaazBeg--kaggle-spectogram/snapshots/b61d17629d4886fcc89e5bd9ca022af4da493d73\"\n",
    "files = sorted(os.listdir(path))\n",
    "[(i, files[i]) for i in range(len(files))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca6588a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:13: SyntaxWarning: invalid escape sequence '\\['\n",
      "<>:14: SyntaxWarning: invalid escape sequence '\\['\n",
      "<>:13: SyntaxWarning: invalid escape sequence '\\['\n",
      "<>:14: SyntaxWarning: invalid escape sequence '\\['\n",
      "/tmp/ipykernel_3540/3793664017.py:13: SyntaxWarning: invalid escape sequence '\\['\n",
      "  df['Unnamed: 1'] = df['Unnamed: 1'].str.replace(\"[\\[\\]]\", \"\", regex=True).astype('int64')\n",
      "/tmp/ipykernel_3540/3793664017.py:14: SyntaxWarning: invalid escape sequence '\\['\n",
      "  df['Unnamed: 2048'] = df['Unnamed: 2048'].str.replace(\"[\\[\\]]\", \"\", regex=True).astype('int64')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((96, 2048), (96, 3))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "csv_path = os.path.join(path, files[11])\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "input_cols = df.columns[1:2049]\n",
    "target_cols = df.columns[2050:]\n",
    "\n",
    "targets  = df[target_cols].dropna().to_numpy()\n",
    "\n",
    "df = df[input_cols]\n",
    "df['Unnamed: 1'] = df['Unnamed: 1'].str.replace(\"[\\[\\]]\", \"\", regex=True).astype('int64')\n",
    "df['Unnamed: 2048'] = df['Unnamed: 2048'].str.replace(\"[\\[\\]]\", \"\", regex=True).astype('int64')\n",
    "\n",
    "inputs = df.to_numpy().reshape(-1, 2, 2048)\n",
    "inputs = inputs.mean(axis=1)\n",
    "\n",
    "inputs.shape, targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "494edfe7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06ef8d4f14dc49d388a4a9cad77aa1ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/96 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(96, 3, 2048)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy import signal\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "def get_advanced_spectra_features(X):\n",
    "    \"\"\"Create multi-channel features from spectra: raw, 1st derivative, 2nd derivative.\"\"\"\n",
    "    X_processed = np.zeros_like(X)\n",
    "    # Baseline correction and SNV\n",
    "    for i in tqdm(range(X.shape[0])):\n",
    "        poly = np.polyfit(np.arange(X.shape[1]), X[i], 3)\n",
    "        baseline = np.polyval(poly, np.arange(X.shape[1]))\n",
    "        corrected_spec = X[i] - baseline\n",
    "        X_processed[i] = (corrected_spec - corrected_spec.mean()) / (corrected_spec.std() + 1e-8)\n",
    "\n",
    "    # Calculate derivatives\n",
    "    deriv1 = signal.savgol_filter(X_processed, window_length=11, polyorder=3, deriv=1, axis=1)\n",
    "    deriv2 = signal.savgol_filter(X_processed, window_length=11, polyorder=3, deriv=2, axis=1)\n",
    "\n",
    "    # Stack as channels\n",
    "    return np.stack([X_processed, deriv1, deriv2], axis=1)\n",
    "\n",
    "inputs = get_advanced_spectra_features(inputs)\n",
    "inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ec04c142",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = inputs.reshape(-1, 3 * 2048).astype(np.float32)\n",
    "targets = targets.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a80358db",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inputs, eval_inputs, train_targets, eval_targets = split(inputs, targets, SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e0e99d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, _, mean, std = get_stats(train_inputs, p=False, r=True)\n",
    "train_inputs = zscore(train_inputs, mean, std)\n",
    "eval_inputs = zscore(eval_inputs, mean, std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d95c6425",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-21 10:15:13,717] A new study created in memory with name: no-name-d49d2e0e-77be-4bc5-b638-c10b76e4553a\n",
      "[I 2025-08-21 10:15:25,310] Trial 0 finished with value: 0.8887209892272949 and parameters: {'n_estimators': 588, 'max_depth': 9, 'learning_rate': 0.03845930070451266}. Best is trial 0 with value: 0.8887209892272949.\n",
      "[I 2025-08-21 10:15:37,635] Trial 1 finished with value: 0.9089828133583069 and parameters: {'n_estimators': 536, 'max_depth': 9, 'learning_rate': 0.005896263859985883}. Best is trial 1 with value: 0.9089828133583069.\n",
      "[I 2025-08-21 10:15:49,727] Trial 2 finished with value: 0.5599100589752197 and parameters: {'n_estimators': 599, 'max_depth': 8, 'learning_rate': 0.0025285768710404223}. Best is trial 1 with value: 0.9089828133583069.\n",
      "[I 2025-08-21 10:15:56,265] Trial 3 finished with value: 0.8731076717376709 and parameters: {'n_estimators': 940, 'max_depth': 4, 'learning_rate': 0.23118046311115328}. Best is trial 1 with value: 0.9089828133583069.\n",
      "[I 2025-08-21 10:16:04,089] Trial 4 finished with value: 0.8612363934516907 and parameters: {'n_estimators': 885, 'max_depth': 11, 'learning_rate': 0.22790753595721525}. Best is trial 1 with value: 0.9089828133583069.\n",
      "[I 2025-08-21 10:16:08,799] Trial 5 finished with value: 0.8653249144554138 and parameters: {'n_estimators': 296, 'max_depth': 17, 'learning_rate': 0.18246211971758233}. Best is trial 1 with value: 0.9089828133583069.\n",
      "[I 2025-08-21 10:16:17,808] Trial 6 finished with value: 0.8961255550384521 and parameters: {'n_estimators': 702, 'max_depth': 14, 'learning_rate': 0.08504649622584726}. Best is trial 1 with value: 0.9089828133583069.\n",
      "[I 2025-08-21 10:16:35,406] Trial 7 finished with value: 0.6475886106491089 and parameters: {'n_estimators': 999, 'max_depth': 5, 'learning_rate': 0.001653552456598548}. Best is trial 1 with value: 0.9089828133583069.\n",
      "[I 2025-08-21 10:16:39,917] Trial 8 finished with value: 0.7756417393684387 and parameters: {'n_estimators': 544, 'max_depth': 6, 'learning_rate': 0.4784284415781621}. Best is trial 1 with value: 0.9089828133583069.\n",
      "[I 2025-08-21 10:16:48,918] Trial 9 finished with value: 0.899152934551239 and parameters: {'n_estimators': 764, 'max_depth': 3, 'learning_rate': 0.013900264305951673}. Best is trial 1 with value: 0.9089828133583069.\n",
      "[I 2025-08-21 10:16:55,954] Trial 10 finished with value: -6.027576923370361 and parameters: {'n_estimators': 399, 'max_depth': 20, 'learning_rate': 0.00010313909143490669}. Best is trial 1 with value: 0.9089828133583069.\n",
      "[I 2025-08-21 10:17:05,528] Trial 11 finished with value: 0.9074194431304932 and parameters: {'n_estimators': 769, 'max_depth': 3, 'learning_rate': 0.009885727141611305}. Best is trial 1 with value: 0.9089828133583069.\n",
      "[I 2025-08-21 10:17:14,060] Trial 12 finished with value: -0.8533666729927063 and parameters: {'n_estimators': 451, 'max_depth': 12, 'learning_rate': 0.001622661085744067}. Best is trial 1 with value: 0.9089828133583069.\n",
      "[I 2025-08-21 10:17:34,005] Trial 13 finished with value: 0.9074957370758057 and parameters: {'n_estimators': 754, 'max_depth': 7, 'learning_rate': 0.007627800992873079}. Best is trial 1 with value: 0.9089828133583069.\n",
      "[I 2025-08-21 10:17:47,240] Trial 14 finished with value: -3.6575727462768555 and parameters: {'n_estimators': 712, 'max_depth': 8, 'learning_rate': 0.0003546410423005344}. Best is trial 1 with value: 0.9089828133583069.\n",
      "[I 2025-08-21 10:17:57,479] Trial 15 finished with value: 0.8017668128013611 and parameters: {'n_estimators': 488, 'max_depth': 11, 'learning_rate': 0.004168016461702811}. Best is trial 1 with value: 0.9089828133583069.\n",
      "[I 2025-08-21 10:18:03,808] Trial 16 finished with value: 0.9040505290031433 and parameters: {'n_estimators': 222, 'max_depth': 7, 'learning_rate': 0.02937684359544682}. Best is trial 1 with value: 0.9089828133583069.\n",
      "[I 2025-08-21 10:18:19,776] Trial 17 finished with value: -1.661150336265564 and parameters: {'n_estimators': 851, 'max_depth': 14, 'learning_rate': 0.00063686621222962}. Best is trial 1 with value: 0.9089828133583069.\n",
      "[I 2025-08-21 10:18:27,170] Trial 18 finished with value: 0.8321425318717957 and parameters: {'n_estimators': 334, 'max_depth': 10, 'learning_rate': 0.006468411382739131}. Best is trial 1 with value: 0.9089828133583069.\n",
      "[I 2025-08-21 10:18:42,972] Trial 19 finished with value: 0.904062032699585 and parameters: {'n_estimators': 666, 'max_depth': 14, 'learning_rate': 0.02812417169333193}. Best is trial 1 with value: 0.9089828133583069.\n",
      "[I 2025-08-21 10:18:57,388] Trial 20 finished with value: -2.215719223022461 and parameters: {'n_estimators': 821, 'max_depth': 6, 'learning_rate': 0.0005402362198121669}. Best is trial 1 with value: 0.9089828133583069.\n",
      "[I 2025-08-21 10:19:06,001] Trial 21 finished with value: 0.9007013440132141 and parameters: {'n_estimators': 652, 'max_depth': 3, 'learning_rate': 0.011725668216638773}. Best is trial 1 with value: 0.9089828133583069.\n",
      "[I 2025-08-21 10:19:26,246] Trial 22 finished with value: 0.9084423184394836 and parameters: {'n_estimators': 814, 'max_depth': 6, 'learning_rate': 0.00725365602029671}. Best is trial 1 with value: 0.9089828133583069.\n",
      "[I 2025-08-21 10:19:43,795] Trial 23 finished with value: 0.9070865511894226 and parameters: {'n_estimators': 762, 'max_depth': 7, 'learning_rate': 0.004154632257646358}. Best is trial 1 with value: 0.9089828133583069.\n",
      "[I 2025-08-21 10:19:51,437] Trial 24 finished with value: 0.9037651419639587 and parameters: {'n_estimators': 542, 'max_depth': 5, 'learning_rate': 0.06804480877681515}. Best is trial 1 with value: 0.9089828133583069.\n",
      "[I 2025-08-21 10:20:15,262] Trial 25 finished with value: 0.9032575488090515 and parameters: {'n_estimators': 920, 'max_depth': 8, 'learning_rate': 0.01726470003181381}. Best is trial 1 with value: 0.9089828133583069.\n",
      "[I 2025-08-21 10:20:37,269] Trial 26 finished with value: 0.9120898842811584 and parameters: {'n_estimators': 821, 'max_depth': 9, 'learning_rate': 0.005195649919447416}. Best is trial 26 with value: 0.9120898842811584.\n",
      "[I 2025-08-21 10:20:54,419] Trial 27 finished with value: -0.555659830570221 and parameters: {'n_estimators': 817, 'max_depth': 12, 'learning_rate': 0.0010068638710841234}. Best is trial 26 with value: 0.9120898842811584.\n",
      "[I 2025-08-21 10:21:18,713] Trial 28 finished with value: 0.9100354313850403 and parameters: {'n_estimators': 992, 'max_depth': 10, 'learning_rate': 0.003628910598254976}. Best is trial 26 with value: 0.9120898842811584.\n",
      "[I 2025-08-21 10:21:40,415] Trial 29 finished with value: 0.892070472240448 and parameters: {'n_estimators': 999, 'max_depth': 9, 'learning_rate': 0.002739989102163744}. Best is trial 26 with value: 0.9120898842811584.\n",
      "[I 2025-08-21 10:21:57,230] Trial 30 finished with value: -3.9190785884857178 and parameters: {'n_estimators': 935, 'max_depth': 9, 'learning_rate': 0.0002398220575839866}. Best is trial 26 with value: 0.9120898842811584.\n",
      "[I 2025-08-21 10:22:11,102] Trial 31 finished with value: 0.8969672322273254 and parameters: {'n_estimators': 628, 'max_depth': 10, 'learning_rate': 0.004469243170713662}. Best is trial 26 with value: 0.9120898842811584.\n",
      "[I 2025-08-21 10:22:21,673] Trial 32 finished with value: 0.061921376734972 and parameters: {'n_estimators': 568, 'max_depth': 9, 'learning_rate': 0.0019230621612259253}. Best is trial 26 with value: 0.9120898842811584.\n",
      "[I 2025-08-21 10:22:40,550] Trial 33 finished with value: 0.9028385281562805 and parameters: {'n_estimators': 875, 'max_depth': 13, 'learning_rate': 0.023091035603008573}. Best is trial 26 with value: 0.9120898842811584.\n",
      "[I 2025-08-21 10:22:53,450] Trial 34 finished with value: 0.8974886536598206 and parameters: {'n_estimators': 953, 'max_depth': 10, 'learning_rate': 0.048442673372452026}. Best is trial 26 with value: 0.9120898842811584.\n",
      "[I 2025-08-21 10:23:12,617] Trial 35 finished with value: 0.913203239440918 and parameters: {'n_estimators': 812, 'max_depth': 16, 'learning_rate': 0.004818998967370429}. Best is trial 35 with value: 0.913203239440918.\n",
      "[I 2025-08-21 10:23:32,112] Trial 36 finished with value: 0.901806652545929 and parameters: {'n_estimators': 892, 'max_depth': 16, 'learning_rate': 0.003326188837978236}. Best is trial 35 with value: 0.913203239440918.\n",
      "[I 2025-08-21 10:23:45,143] Trial 37 finished with value: -0.9028887152671814 and parameters: {'n_estimators': 699, 'max_depth': 20, 'learning_rate': 0.0010262844451597946}. Best is trial 35 with value: 0.913203239440918.\n",
      "[I 2025-08-21 10:23:56,174] Trial 38 finished with value: -1.0290874242782593 and parameters: {'n_estimators': 605, 'max_depth': 17, 'learning_rate': 0.0011292621757510901}. Best is trial 35 with value: 0.913203239440918.\n",
      "[I 2025-08-21 10:24:22,214] Trial 39 finished with value: 0.9095868468284607 and parameters: {'n_estimators': 952, 'max_depth': 16, 'learning_rate': 0.0058133729829549135}. Best is trial 35 with value: 0.913203239440918.\n",
      "[I 2025-08-21 10:24:46,876] Trial 40 finished with value: 0.9096598625183105 and parameters: {'n_estimators': 958, 'max_depth': 16, 'learning_rate': 0.005535032753383874}. Best is trial 35 with value: 0.913203239440918.\n",
      "[I 2025-08-21 10:25:07,088] Trial 41 finished with value: 0.8192245364189148 and parameters: {'n_estimators': 963, 'max_depth': 16, 'learning_rate': 0.002192023740936054}. Best is trial 35 with value: 0.913203239440918.\n",
      "[I 2025-08-21 10:25:34,533] Trial 42 finished with value: 0.9100568294525146 and parameters: {'n_estimators': 1000, 'max_depth': 18, 'learning_rate': 0.005609361591823472}. Best is trial 35 with value: 0.913203239440918.\n",
      "[I 2025-08-21 10:26:00,652] Trial 43 finished with value: 0.9031611084938049 and parameters: {'n_estimators': 902, 'max_depth': 18, 'learning_rate': 0.01358960317347959}. Best is trial 35 with value: 0.913203239440918.\n",
      "[I 2025-08-21 10:26:22,050] Trial 44 finished with value: 0.8814951777458191 and parameters: {'n_estimators': 991, 'max_depth': 19, 'learning_rate': 0.0026037681375452476}. Best is trial 35 with value: 0.913203239440918.\n",
      "[I 2025-08-21 10:26:48,268] Trial 45 finished with value: 0.9042429327964783 and parameters: {'n_estimators': 851, 'max_depth': 15, 'learning_rate': 0.009787144002774277}. Best is trial 35 with value: 0.913203239440918.\n",
      "[I 2025-08-21 10:27:13,854] Trial 46 finished with value: 0.9111077189445496 and parameters: {'n_estimators': 975, 'max_depth': 18, 'learning_rate': 0.0051016875659094935}. Best is trial 35 with value: 0.913203239440918.\n",
      "[I 2025-08-21 10:27:35,683] Trial 47 finished with value: 0.9070267081260681 and parameters: {'n_estimators': 851, 'max_depth': 18, 'learning_rate': 0.019059802809665724}. Best is trial 35 with value: 0.913203239440918.\n",
      "[I 2025-08-21 10:27:53,073] Trial 48 finished with value: 0.35710763931274414 and parameters: {'n_estimators': 913, 'max_depth': 18, 'learning_rate': 0.0014238861838852142}. Best is trial 35 with value: 0.913203239440918.\n",
      "[I 2025-08-21 10:28:15,678] Trial 49 finished with value: 0.9070761203765869 and parameters: {'n_estimators': 982, 'max_depth': 19, 'learning_rate': 0.0032727269505267416}. Best is trial 35 with value: 0.913203239440918.\n",
      "[I 2025-08-21 10:28:24,296] Trial 50 finished with value: 0.8710885047912598 and parameters: {'n_estimators': 790, 'max_depth': 19, 'learning_rate': 0.12682105217321257}. Best is trial 35 with value: 0.913203239440918.\n",
      "[I 2025-08-21 10:28:48,693] Trial 51 finished with value: 0.9115233421325684 and parameters: {'n_estimators': 956, 'max_depth': 17, 'learning_rate': 0.005032723338497363}. Best is trial 35 with value: 0.913203239440918.\n",
      "[I 2025-08-21 10:29:15,202] Trial 52 finished with value: 0.9061183929443359 and parameters: {'n_estimators': 880, 'max_depth': 17, 'learning_rate': 0.008392797168749844}. Best is trial 35 with value: 0.913203239440918.\n",
      "[I 2025-08-21 10:29:37,566] Trial 53 finished with value: 0.9116776585578918 and parameters: {'n_estimators': 929, 'max_depth': 11, 'learning_rate': 0.004551211118624411}. Best is trial 35 with value: 0.913203239440918.\n",
      "[I 2025-08-21 10:30:01,104] Trial 54 finished with value: 0.9110569357872009 and parameters: {'n_estimators': 924, 'max_depth': 17, 'learning_rate': 0.005188825440058001}. Best is trial 35 with value: 0.913203239440918.\n",
      "[I 2025-08-21 10:30:23,332] Trial 55 finished with value: 0.9065383076667786 and parameters: {'n_estimators': 729, 'max_depth': 15, 'learning_rate': 0.010988293909924979}. Best is trial 35 with value: 0.913203239440918.\n",
      "[I 2025-08-21 10:30:41,820] Trial 56 finished with value: 0.788928747177124 and parameters: {'n_estimators': 923, 'max_depth': 13, 'learning_rate': 0.0021542464897233004}. Best is trial 35 with value: 0.913203239440918.\n",
      "[I 2025-08-21 10:31:07,046] Trial 57 finished with value: 0.906590461730957 and parameters: {'n_estimators': 869, 'max_depth': 17, 'learning_rate': 0.007902944020481762}. Best is trial 35 with value: 0.913203239440918.\n",
      "[I 2025-08-21 10:31:13,622] Trial 58 finished with value: 0.7583577036857605 and parameters: {'n_estimators': 822, 'max_depth': 11, 'learning_rate': 0.5258556425530961}. Best is trial 35 with value: 0.913203239440918.\n",
      "[I 2025-08-21 10:31:39,449] Trial 59 finished with value: 0.9029410481452942 and parameters: {'n_estimators': 933, 'max_depth': 15, 'learning_rate': 0.01438316712779991}. Best is trial 35 with value: 0.913203239440918.\n",
      "[I 2025-08-21 10:31:57,488] Trial 60 finished with value: 0.910986602306366 and parameters: {'n_estimators': 797, 'max_depth': 13, 'learning_rate': 0.004422373385980156}. Best is trial 35 with value: 0.913203239440918.\n",
      "[I 2025-08-21 10:32:16,610] Trial 61 finished with value: 0.9128019213676453 and parameters: {'n_estimators': 790, 'max_depth': 17, 'learning_rate': 0.0050630570207782}. Best is trial 35 with value: 0.913203239440918.\n",
      "[I 2025-08-21 10:32:38,298] Trial 62 finished with value: 0.9109869003295898 and parameters: {'n_estimators': 845, 'max_depth': 19, 'learning_rate': 0.005515469912364086}. Best is trial 35 with value: 0.913203239440918.\n",
      "[I 2025-08-21 10:32:53,094] Trial 63 finished with value: 0.8048295974731445 and parameters: {'n_estimators': 731, 'max_depth': 17, 'learning_rate': 0.0028115091905395267}. Best is trial 35 with value: 0.913203239440918.\n",
      "[I 2025-08-21 10:33:19,069] Trial 64 finished with value: 0.9066147804260254 and parameters: {'n_estimators': 902, 'max_depth': 12, 'learning_rate': 0.006957314197990333}. Best is trial 35 with value: 0.913203239440918.\n",
      "[I 2025-08-21 10:33:34,306] Trial 65 finished with value: 0.23887686431407928 and parameters: {'n_estimators': 793, 'max_depth': 20, 'learning_rate': 0.0015224675042787169}. Best is trial 35 with value: 0.913203239440918.\n",
      "[I 2025-08-21 10:33:49,490] Trial 66 finished with value: -1.339279294013977 and parameters: {'n_estimators': 871, 'max_depth': 17, 'learning_rate': 0.0006991582871255659}. Best is trial 35 with value: 0.913203239440918.\n",
      "[I 2025-08-21 10:33:57,133] Trial 67 finished with value: 0.6048144102096558 and parameters: {'n_estimators': 964, 'max_depth': 15, 'learning_rate': 0.781932605988883}. Best is trial 35 with value: 0.913203239440918.\n",
      "[I 2025-08-21 10:34:19,162] Trial 68 finished with value: 0.910965621471405 and parameters: {'n_estimators': 938, 'max_depth': 18, 'learning_rate': 0.004193594826928613}. Best is trial 35 with value: 0.913203239440918.\n",
      "[I 2025-08-21 10:34:44,046] Trial 69 finished with value: 0.9059274792671204 and parameters: {'n_estimators': 833, 'max_depth': 16, 'learning_rate': 0.009326021707329409}. Best is trial 35 with value: 0.913203239440918.\n",
      "[I 2025-08-21 10:34:53,367] Trial 70 finished with value: 0.5794471502304077 and parameters: {'n_estimators': 477, 'max_depth': 14, 'learning_rate': 0.0032242217093305897}. Best is trial 35 with value: 0.913203239440918.\n",
      "[I 2025-08-21 10:35:07,896] Trial 71 finished with value: 0.9129304885864258 and parameters: {'n_estimators': 750, 'max_depth': 19, 'learning_rate': 0.005576018252296708}. Best is trial 35 with value: 0.913203239440918.\n",
      "[I 2025-08-21 10:35:22,342] Trial 72 finished with value: 0.9133613109588623 and parameters: {'n_estimators': 778, 'max_depth': 20, 'learning_rate': 0.0051061527465020035}. Best is trial 72 with value: 0.9133613109588623.\n",
      "[I 2025-08-21 10:35:38,866] Trial 73 finished with value: 0.910993754863739 and parameters: {'n_estimators': 750, 'max_depth': 20, 'learning_rate': 0.0067963505263978164}. Best is trial 72 with value: 0.9133613109588623.\n",
      "[I 2025-08-21 10:35:58,088] Trial 74 finished with value: 0.9039974808692932 and parameters: {'n_estimators': 677, 'max_depth': 19, 'learning_rate': 0.011481075056464353}. Best is trial 72 with value: 0.9133613109588623.\n",
      "[I 2025-08-21 10:36:13,368] Trial 75 finished with value: 0.5106931328773499 and parameters: {'n_estimators': 781, 'max_depth': 20, 'learning_rate': 0.0018604708978646777}. Best is trial 72 with value: 0.9133613109588623.\n",
      "[I 2025-08-21 10:36:28,966] Trial 76 finished with value: 0.8925714492797852 and parameters: {'n_estimators': 745, 'max_depth': 18, 'learning_rate': 0.003717771926061302}. Best is trial 72 with value: 0.9133613109588623.\n",
      "[I 2025-08-21 10:36:45,251] Trial 77 finished with value: 0.7993869781494141 and parameters: {'n_estimators': 807, 'max_depth': 19, 'learning_rate': 0.0025176292897829936}. Best is trial 72 with value: 0.9133613109588623.\n",
      "[I 2025-08-21 10:37:04,488] Trial 78 finished with value: 0.9034704566001892 and parameters: {'n_estimators': 699, 'max_depth': 8, 'learning_rate': 0.01758909275600645}. Best is trial 72 with value: 0.9133613109588623.\n",
      "[I 2025-08-21 10:37:21,784] Trial 79 finished with value: 0.9121594429016113 and parameters: {'n_estimators': 768, 'max_depth': 10, 'learning_rate': 0.004691276906284712}. Best is trial 72 with value: 0.9133613109588623.\n",
      "[I 2025-08-21 10:37:37,040] Trial 80 finished with value: 0.901075541973114 and parameters: {'n_estimators': 719, 'max_depth': 11, 'learning_rate': 0.029538950689298776}. Best is trial 72 with value: 0.9133613109588623.\n",
      "[I 2025-08-21 10:37:54,779] Trial 81 finished with value: 0.9133011698722839 and parameters: {'n_estimators': 775, 'max_depth': 10, 'learning_rate': 0.004828303490541515}. Best is trial 72 with value: 0.9133613109588623.\n",
      "[I 2025-08-21 10:38:15,762] Trial 82 finished with value: 0.9072191119194031 and parameters: {'n_estimators': 770, 'max_depth': 9, 'learning_rate': 0.008155010245319087}. Best is trial 72 with value: 0.9133613109588623.\n",
      "[I 2025-08-21 10:38:30,570] Trial 83 finished with value: 0.9012934565544128 and parameters: {'n_estimators': 684, 'max_depth': 10, 'learning_rate': 0.004299522333267886}. Best is trial 72 with value: 0.9133613109588623.\n",
      "[I 2025-08-21 10:38:50,303] Trial 84 finished with value: 0.9108726382255554 and parameters: {'n_estimators': 769, 'max_depth': 11, 'learning_rate': 0.006431905430885803}. Best is trial 72 with value: 0.9133613109588623.\n",
      "[I 2025-08-21 10:39:05,944] Trial 85 finished with value: 0.8397291302680969 and parameters: {'n_estimators': 752, 'max_depth': 10, 'learning_rate': 0.002959570106052369}. Best is trial 72 with value: 0.9133613109588623.\n",
      "[I 2025-08-21 10:39:25,672] Trial 86 finished with value: 0.9010547995567322 and parameters: {'n_estimators': 657, 'max_depth': 12, 'learning_rate': 0.013164192591174581}. Best is trial 72 with value: 0.9133613109588623.\n",
      "[I 2025-08-21 10:39:42,083] Trial 87 finished with value: 0.7714411616325378 and parameters: {'n_estimators': 823, 'max_depth': 8, 'learning_rate': 0.0023485517737985725}. Best is trial 72 with value: 0.9133613109588623.\n",
      "[I 2025-08-21 10:39:59,351] Trial 88 finished with value: 0.8984279036521912 and parameters: {'n_estimators': 803, 'max_depth': 9, 'learning_rate': 0.0035684946460902743}. Best is trial 72 with value: 0.9133613109588623.\n",
      "[I 2025-08-21 10:40:17,607] Trial 89 finished with value: 0.9143344759941101 and parameters: {'n_estimators': 782, 'max_depth': 10, 'learning_rate': 0.004917825707513201}. Best is trial 89 with value: 0.9143344759941101.\n",
      "[I 2025-08-21 10:40:38,456] Trial 90 finished with value: 0.9039685130119324 and parameters: {'n_estimators': 734, 'max_depth': 10, 'learning_rate': 0.008922400935964615}. Best is trial 89 with value: 0.9143344759941101.\n",
      "[I 2025-08-21 10:40:51,855] Trial 91 finished with value: 0.9039050936698914 and parameters: {'n_estimators': 632, 'max_depth': 11, 'learning_rate': 0.004709825154276698}. Best is trial 89 with value: 0.9143344759941101.\n",
      "[I 2025-08-21 10:41:13,246] Trial 92 finished with value: 0.9104577898979187 and parameters: {'n_estimators': 836, 'max_depth': 7, 'learning_rate': 0.006395367673461333}. Best is trial 89 with value: 0.9143344759941101.\n",
      "[I 2025-08-21 10:41:30,171] Trial 93 finished with value: 0.898918092250824 and parameters: {'n_estimators': 778, 'max_depth': 9, 'learning_rate': 0.003748796136488179}. Best is trial 89 with value: 0.9143344759941101.\n",
      "[I 2025-08-21 10:41:51,263] Trial 94 finished with value: 0.9112204909324646 and parameters: {'n_estimators': 856, 'max_depth': 10, 'learning_rate': 0.005302119265827212}. Best is trial 89 with value: 0.9143344759941101.\n",
      "[I 2025-08-21 10:41:54,919] Trial 95 finished with value: -3.513993501663208 and parameters: {'n_estimators': 204, 'max_depth': 12, 'learning_rate': 0.0013159774356192337}. Best is trial 89 with value: 0.9143344759941101.\n",
      "[I 2025-08-21 10:42:09,302] Trial 96 finished with value: 0.6216849684715271 and parameters: {'n_estimators': 759, 'max_depth': 9, 'learning_rate': 0.0021130741647928833}. Best is trial 89 with value: 0.9143344759941101.\n",
      "[I 2025-08-21 10:42:16,903] Trial 97 finished with value: 0.8948955535888672 and parameters: {'n_estimators': 360, 'max_depth': 10, 'learning_rate': 0.007691654405211868}. Best is trial 89 with value: 0.9143344759941101.\n",
      "[I 2025-08-21 10:42:30,205] Trial 98 finished with value: 0.3638986349105835 and parameters: {'n_estimators': 718, 'max_depth': 8, 'learning_rate': 0.0018174391171464424}. Best is trial 89 with value: 0.9143344759941101.\n",
      "[I 2025-08-21 10:42:53,955] Trial 99 finished with value: 0.9071242213249207 and parameters: {'n_estimators': 783, 'max_depth': 11, 'learning_rate': 0.01066226520940434}. Best is trial 89 with value: 0.9143344759941101.\n",
      "[I 2025-08-21 10:43:12,377] Trial 100 finished with value: 0.8858518004417419 and parameters: {'n_estimators': 889, 'max_depth': 19, 'learning_rate': 0.0029881737855113667}. Best is trial 89 with value: 0.9143344759941101.\n",
      "[I 2025-08-21 10:43:33,313] Trial 101 finished with value: 0.9127209782600403 and parameters: {'n_estimators': 855, 'max_depth': 10, 'learning_rate': 0.004977586824131474}. Best is trial 89 with value: 0.9143344759941101.\n",
      "[I 2025-08-21 10:43:52,165] Trial 102 finished with value: 0.9134286046028137 and parameters: {'n_estimators': 811, 'max_depth': 11, 'learning_rate': 0.004812775055215291}. Best is trial 89 with value: 0.9143344759941101.\n",
      "[I 2025-08-21 10:44:13,245] Trial 103 finished with value: 0.9100329875946045 and parameters: {'n_estimators': 814, 'max_depth': 11, 'learning_rate': 0.006273960251914426}. Best is trial 89 with value: 0.9143344759941101.\n",
      "[I 2025-08-21 10:44:32,408] Trial 104 finished with value: 0.9088490605354309 and parameters: {'n_estimators': 829, 'max_depth': 10, 'learning_rate': 0.004027529822066791}. Best is trial 89 with value: 0.9143344759941101.\n",
      "[I 2025-08-21 10:44:52,780] Trial 105 finished with value: 0.912273108959198 and parameters: {'n_estimators': 867, 'max_depth': 11, 'learning_rate': 0.0047076244492951684}. Best is trial 89 with value: 0.9143344759941101.\n",
      "[I 2025-08-21 10:45:15,933] Trial 106 finished with value: 0.9080737233161926 and parameters: {'n_estimators': 797, 'max_depth': 9, 'learning_rate': 0.009341309696073368}. Best is trial 89 with value: 0.9143344759941101.\n",
      "[I 2025-08-21 10:45:38,071] Trial 107 finished with value: 0.9101665616035461 and parameters: {'n_estimators': 871, 'max_depth': 12, 'learning_rate': 0.005817472832062211}. Best is trial 89 with value: 0.9143344759941101.\n",
      "[I 2025-08-21 10:46:01,742] Trial 108 finished with value: 0.9067477583885193 and parameters: {'n_estimators': 857, 'max_depth': 11, 'learning_rate': 0.007128283293167975}. Best is trial 89 with value: 0.9143344759941101.\n",
      "[I 2025-08-21 10:46:19,573] Trial 109 finished with value: 0.8924081325531006 and parameters: {'n_estimators': 834, 'max_depth': 13, 'learning_rate': 0.003283586621702962}. Best is trial 89 with value: 0.9143344759941101.\n",
      "[I 2025-08-21 10:46:38,685] Trial 110 finished with value: 0.9129509925842285 and parameters: {'n_estimators': 810, 'max_depth': 10, 'learning_rate': 0.004820621640163975}. Best is trial 89 with value: 0.9143344759941101.\n",
      "[I 2025-08-21 10:46:58,139] Trial 111 finished with value: 0.9135201573371887 and parameters: {'n_estimators': 808, 'max_depth': 10, 'learning_rate': 0.004940307420696477}. Best is trial 89 with value: 0.9143344759941101.\n",
      "[I 2025-08-21 10:47:13,586] Trial 112 finished with value: 0.9130355715751648 and parameters: {'n_estimators': 810, 'max_depth': 10, 'learning_rate': 0.004817208815989473}. Best is trial 89 with value: 0.9143344759941101.\n",
      "[I 2025-08-21 10:47:27,325] Trial 113 finished with value: 0.9034706950187683 and parameters: {'n_estimators': 809, 'max_depth': 10, 'learning_rate': 0.0037897733344581163}. Best is trial 89 with value: 0.9143344759941101.\n",
      "[I 2025-08-21 10:47:40,652] Trial 114 finished with value: 0.8208818435668945 and parameters: {'n_estimators': 793, 'max_depth': 12, 'learning_rate': 0.0026793441500515373}. Best is trial 89 with value: 0.9143344759941101.\n",
      "[I 2025-08-21 10:48:03,286] Trial 115 finished with value: 0.9032084941864014 and parameters: {'n_estimators': 847, 'max_depth': 11, 'learning_rate': 0.014844184069511478}. Best is trial 89 with value: 0.9143344759941101.\n",
      "[I 2025-08-21 10:48:27,311] Trial 116 finished with value: 0.9059057235717773 and parameters: {'n_estimators': 863, 'max_depth': 20, 'learning_rate': 0.007767867617406136}. Best is trial 89 with value: 0.9143344759941101.\n",
      "[I 2025-08-21 10:48:44,907] Trial 117 finished with value: 0.9135634303092957 and parameters: {'n_estimators': 746, 'max_depth': 10, 'learning_rate': 0.00562215283356653}. Best is trial 89 with value: 0.9143344759941101.\n",
      "[I 2025-08-21 10:48:57,006] Trial 118 finished with value: -5.261781215667725 and parameters: {'n_estimators': 743, 'max_depth': 10, 'learning_rate': 0.000134529121763368}. Best is trial 89 with value: 0.9143344759941101.\n",
      "[I 2025-08-21 10:49:16,141] Trial 119 finished with value: 0.9109959602355957 and parameters: {'n_estimators': 779, 'max_depth': 9, 'learning_rate': 0.006263349005674381}. Best is trial 89 with value: 0.9143344759941101.\n",
      "[I 2025-08-21 10:49:39,685] Trial 120 finished with value: 0.906808078289032 and parameters: {'n_estimators': 806, 'max_depth': 9, 'learning_rate': 0.01020112583604748}. Best is trial 89 with value: 0.9143344759941101.\n",
      "[I 2025-08-21 10:49:58,467] Trial 121 finished with value: 0.9133615493774414 and parameters: {'n_estimators': 824, 'max_depth': 10, 'learning_rate': 0.0046630338644036255}. Best is trial 89 with value: 0.9143344759941101.\n",
      "[I 2025-08-21 10:50:16,547] Trial 122 finished with value: 0.9107198119163513 and parameters: {'n_estimators': 762, 'max_depth': 10, 'learning_rate': 0.005341125829502326}. Best is trial 89 with value: 0.9143344759941101.\n",
      "[I 2025-08-21 10:50:34,711] Trial 123 finished with value: 0.9018511176109314 and parameters: {'n_estimators': 840, 'max_depth': 10, 'learning_rate': 0.0035227434838013758}. Best is trial 89 with value: 0.9143344759941101.\n",
      "[I 2025-08-21 10:50:53,330] Trial 124 finished with value: 0.9103851318359375 and parameters: {'n_estimators': 823, 'max_depth': 10, 'learning_rate': 0.0043098230005784}. Best is trial 89 with value: 0.9143344759941101.\n",
      "[I 2025-08-21 10:51:09,008] Trial 125 finished with value: 0.771216869354248 and parameters: {'n_estimators': 790, 'max_depth': 11, 'learning_rate': 0.0024505793697023543}. Best is trial 89 with value: 0.9143344759941101.\n",
      "[I 2025-08-21 10:51:28,172] Trial 126 finished with value: 0.9089463353157043 and parameters: {'n_estimators': 742, 'max_depth': 8, 'learning_rate': 0.007358029829575581}. Best is trial 89 with value: 0.9143344759941101.\n",
      "[I 2025-08-21 10:51:42,191] Trial 127 finished with value: 0.8148948550224304 and parameters: {'n_estimators': 702, 'max_depth': 9, 'learning_rate': 0.002994896903578558}. Best is trial 89 with value: 0.9143344759941101.\n",
      "[I 2025-08-21 10:52:02,034] Trial 128 finished with value: 0.9116155505180359 and parameters: {'n_estimators': 814, 'max_depth': 11, 'learning_rate': 0.005682532748981338}. Best is trial 89 with value: 0.9143344759941101.\n",
      "[I 2025-08-21 10:52:19,230] Trial 129 finished with value: 0.9133206009864807 and parameters: {'n_estimators': 758, 'max_depth': 9, 'learning_rate': 0.004787617186533027}. Best is trial 89 with value: 0.9143344759941101.\n",
      "[I 2025-08-21 10:52:24,732] Trial 130 finished with value: 0.8510319590568542 and parameters: {'n_estimators': 265, 'max_depth': 9, 'learning_rate': 0.008677021331115132}. Best is trial 89 with value: 0.9143344759941101.\n",
      "[I 2025-08-21 10:52:41,445] Trial 131 finished with value: 0.9049311280250549 and parameters: {'n_estimators': 758, 'max_depth': 10, 'learning_rate': 0.004080201434242012}. Best is trial 89 with value: 0.9143344759941101.\n",
      "[I 2025-08-21 10:53:00,061] Trial 132 finished with value: 0.9125571846961975 and parameters: {'n_estimators': 779, 'max_depth': 9, 'learning_rate': 0.00543343447382882}. Best is trial 89 with value: 0.9143344759941101.\n",
      "[I 2025-08-21 10:53:18,909] Trial 133 finished with value: 0.9133538603782654 and parameters: {'n_estimators': 801, 'max_depth': 10, 'learning_rate': 0.004753515264959535}. Best is trial 89 with value: 0.9143344759941101.\n",
      "[I 2025-08-21 10:53:37,472] Trial 134 finished with value: 0.9112216830253601 and parameters: {'n_estimators': 727, 'max_depth': 10, 'learning_rate': 0.0067424771921817984}. Best is trial 89 with value: 0.9143344759941101.\n",
      "[I 2025-08-21 10:53:53,839] Trial 135 finished with value: 0.8778612613677979 and parameters: {'n_estimators': 799, 'max_depth': 8, 'learning_rate': 0.003168160853947411}. Best is trial 89 with value: 0.9143344759941101.\n",
      "[I 2025-08-21 10:54:10,313] Trial 136 finished with value: 0.8991601467132568 and parameters: {'n_estimators': 770, 'max_depth': 20, 'learning_rate': 0.0037993533222533626}. Best is trial 89 with value: 0.9143344759941101.\n",
      "[I 2025-08-21 10:54:25,718] Trial 137 finished with value: 0.9087470173835754 and parameters: {'n_estimators': 707, 'max_depth': 9, 'learning_rate': 0.004541145523973249}. Best is trial 89 with value: 0.9143344759941101.\n",
      "[I 2025-08-21 10:54:49,193] Trial 138 finished with value: 0.9026443362236023 and parameters: {'n_estimators': 753, 'max_depth': 11, 'learning_rate': 0.012343146349705016}. Best is trial 89 with value: 0.9143344759941101.\n",
      "[I 2025-08-21 10:55:09,090] Trial 139 finished with value: 0.9114537239074707 and parameters: {'n_estimators': 789, 'max_depth': 10, 'learning_rate': 0.006181108531891723}. Best is trial 89 with value: 0.9143344759941101.\n",
      "[I 2025-08-21 10:55:25,863] Trial 140 finished with value: 0.8288576602935791 and parameters: {'n_estimators': 827, 'max_depth': 10, 'learning_rate': 0.0026174470074047914}. Best is trial 89 with value: 0.9143344759941101.\n",
      "[I 2025-08-21 10:55:45,116] Trial 141 finished with value: 0.9142523407936096 and parameters: {'n_estimators': 806, 'max_depth': 10, 'learning_rate': 0.00484700679359537}. Best is trial 89 with value: 0.9143344759941101.\n",
      "[I 2025-08-21 10:56:04,486] Trial 142 finished with value: 0.9128955006599426 and parameters: {'n_estimators': 815, 'max_depth': 9, 'learning_rate': 0.004974412977671147}. Best is trial 89 with value: 0.9143344759941101.\n",
      "[I 2025-08-21 10:56:22,187] Trial 143 finished with value: 0.8999732136726379 and parameters: {'n_estimators': 806, 'max_depth': 9, 'learning_rate': 0.00362511339564678}. Best is trial 89 with value: 0.9143344759941101.\n",
      "[I 2025-08-21 10:56:46,128] Trial 144 finished with value: 0.9062392711639404 and parameters: {'n_estimators': 840, 'max_depth': 10, 'learning_rate': 0.007772634973168312}. Best is trial 89 with value: 0.9143344759941101.\n",
      "[I 2025-08-21 10:57:04,674] Trial 145 finished with value: 0.9112128615379333 and parameters: {'n_estimators': 821, 'max_depth': 9, 'learning_rate': 0.004463873625197168}. Best is trial 89 with value: 0.9143344759941101.\n",
      "[I 2025-08-21 10:57:24,678] Trial 146 finished with value: 0.9113877415657043 and parameters: {'n_estimators': 782, 'max_depth': 11, 'learning_rate': 0.006074193031041527}. Best is trial 89 with value: 0.9143344759941101.\n",
      "[I 2025-08-21 10:57:42,634] Trial 147 finished with value: 0.9126367568969727 and parameters: {'n_estimators': 762, 'max_depth': 10, 'learning_rate': 0.005018879750102546}. Best is trial 89 with value: 0.9143344759941101.\n",
      "[I 2025-08-21 10:58:05,712] Trial 148 finished with value: 0.9042971730232239 and parameters: {'n_estimators': 810, 'max_depth': 8, 'learning_rate': 0.008955945115792034}. Best is trial 89 with value: 0.9143344759941101.\n",
      "[I 2025-08-21 10:58:17,639] Trial 149 finished with value: 0.7579018473625183 and parameters: {'n_estimators': 571, 'max_depth': 9, 'learning_rate': 0.003307030167813538}. Best is trial 89 with value: 0.9143344759941101.\n",
      "[I 2025-08-21 10:58:37,071] Trial 150 finished with value: 0.909680187702179 and parameters: {'n_estimators': 736, 'max_depth': 7, 'learning_rate': 0.006989533865824703}. Best is trial 89 with value: 0.9143344759941101.\n",
      "[I 2025-08-21 10:58:56,080] Trial 151 finished with value: 0.914280116558075 and parameters: {'n_estimators': 796, 'max_depth': 10, 'learning_rate': 0.004931622895203752}. Best is trial 89 with value: 0.9143344759941101.\n",
      "[I 2025-08-21 10:59:13,355] Trial 152 finished with value: 0.9069156050682068 and parameters: {'n_estimators': 776, 'max_depth': 10, 'learning_rate': 0.0041383947678086935}. Best is trial 89 with value: 0.9143344759941101.\n",
      "[I 2025-08-21 10:59:33,572] Trial 153 finished with value: 0.911939799785614 and parameters: {'n_estimators': 798, 'max_depth': 11, 'learning_rate': 0.005570662415265522}. Best is trial 89 with value: 0.9143344759941101.\n",
      "[I 2025-08-21 10:59:53,940] Trial 154 finished with value: 0.9143840670585632 and parameters: {'n_estimators': 834, 'max_depth': 10, 'learning_rate': 0.004921367727649843}. Best is trial 154 with value: 0.9143840670585632.\n",
      "[I 2025-08-21 11:00:12,766] Trial 155 finished with value: 0.9058743119239807 and parameters: {'n_estimators': 836, 'max_depth': 10, 'learning_rate': 0.0038104139596932094}. Best is trial 154 with value: 0.9143840670585632.\n",
      "[I 2025-08-21 11:00:29,216] Trial 156 finished with value: 0.8337118029594421 and parameters: {'n_estimators': 770, 'max_depth': 11, 'learning_rate': 0.0028439064629061203}. Best is trial 154 with value: 0.9143840670585632.\n",
      "[I 2025-08-21 11:00:43,624] Trial 157 finished with value: 0.6006357073783875 and parameters: {'n_estimators': 747, 'max_depth': 10, 'learning_rate': 0.0021036536786757333}. Best is trial 154 with value: 0.9143840670585632.\n",
      "[I 2025-08-21 11:01:04,846] Trial 158 finished with value: 0.9093227386474609 and parameters: {'n_estimators': 795, 'max_depth': 12, 'learning_rate': 0.006530781547605092}. Best is trial 154 with value: 0.9143840670585632.\n",
      "[I 2025-08-21 11:01:26,295] Trial 159 finished with value: 0.9111785888671875 and parameters: {'n_estimators': 879, 'max_depth': 10, 'learning_rate': 0.004482525584888256}. Best is trial 154 with value: 0.9143840670585632.\n",
      "[I 2025-08-21 11:01:50,162] Trial 160 finished with value: 0.9063153266906738 and parameters: {'n_estimators': 833, 'max_depth': 11, 'learning_rate': 0.00782033535156195}. Best is trial 154 with value: 0.9143840670585632.\n",
      "[I 2025-08-21 11:02:01,442] Trial 161 finished with value: 0.8891032338142395 and parameters: {'n_estimators': 519, 'max_depth': 9, 'learning_rate': 0.005079372073632125}. Best is trial 154 with value: 0.9143840670585632.\n",
      "[I 2025-08-21 11:02:15,331] Trial 162 finished with value: 0.911726176738739 and parameters: {'n_estimators': 815, 'max_depth': 4, 'learning_rate': 0.005233701431934249}. Best is trial 154 with value: 0.9143840670585632.\n",
      "[I 2025-08-21 11:02:33,995] Trial 163 finished with value: 0.9055965542793274 and parameters: {'n_estimators': 847, 'max_depth': 9, 'learning_rate': 0.0037013626468285488}. Best is trial 154 with value: 0.9143840670585632.\n",
      "[I 2025-08-21 11:02:55,781] Trial 164 finished with value: 0.9098861813545227 and parameters: {'n_estimators': 823, 'max_depth': 10, 'learning_rate': 0.006274016305378188}. Best is trial 154 with value: 0.9143840670585632.\n",
      "[I 2025-08-21 11:03:13,856] Trial 165 finished with value: 0.9111934304237366 and parameters: {'n_estimators': 800, 'max_depth': 9, 'learning_rate': 0.004430870999456666}. Best is trial 154 with value: 0.9143840670585632.\n",
      "[I 2025-08-21 11:03:30,047] Trial 166 finished with value: 0.8632515072822571 and parameters: {'n_estimators': 784, 'max_depth': 10, 'learning_rate': 0.0030505822828560936}. Best is trial 154 with value: 0.9143840670585632.\n",
      "[I 2025-08-21 11:03:50,573] Trial 167 finished with value: 0.9124853014945984 and parameters: {'n_estimators': 812, 'max_depth': 10, 'learning_rate': 0.005697718507315435}. Best is trial 154 with value: 0.9143840670585632.\n",
      "[I 2025-08-21 11:04:00,820] Trial 168 finished with value: 0.908674418926239 and parameters: {'n_estimators': 420, 'max_depth': 11, 'learning_rate': 0.009885393369068017}. Best is trial 154 with value: 0.9143840670585632.\n",
      "[I 2025-08-21 11:04:21,014] Trial 169 finished with value: 0.9079670906066895 and parameters: {'n_estimators': 758, 'max_depth': 11, 'learning_rate': 0.0073795568532636895}. Best is trial 154 with value: 0.9143840670585632.\n",
      "[I 2025-08-21 11:04:37,310] Trial 170 finished with value: 0.9094664454460144 and parameters: {'n_estimators': 723, 'max_depth': 10, 'learning_rate': 0.004642016177641478}. Best is trial 154 with value: 0.9143840670585632.\n",
      "[I 2025-08-21 11:04:56,397] Trial 171 finished with value: 0.9128120541572571 and parameters: {'n_estimators': 786, 'max_depth': 14, 'learning_rate': 0.005095406789453521}. Best is trial 154 with value: 0.9143840670585632.\n",
      "[I 2025-08-21 11:05:13,746] Trial 172 finished with value: 0.9043851494789124 and parameters: {'n_estimators': 791, 'max_depth': 14, 'learning_rate': 0.003934663526093264}. Best is trial 154 with value: 0.9143840670585632.\n",
      "[I 2025-08-21 11:05:32,731] Trial 173 finished with value: 0.9132497906684875 and parameters: {'n_estimators': 771, 'max_depth': 10, 'learning_rate': 0.005773182779427013}. Best is trial 154 with value: 0.9143840670585632.\n",
      "[I 2025-08-21 11:05:52,048] Trial 174 finished with value: 0.9104390144348145 and parameters: {'n_estimators': 773, 'max_depth': 10, 'learning_rate': 0.006361014675798085}. Best is trial 154 with value: 0.9143840670585632.\n",
      "[I 2025-08-21 11:06:09,041] Trial 175 finished with value: 0.8908947110176086 and parameters: {'n_estimators': 811, 'max_depth': 9, 'learning_rate': 0.0033297551905957412}. Best is trial 154 with value: 0.9143840670585632.\n",
      "[I 2025-08-21 11:06:29,732] Trial 176 finished with value: 0.9118011593818665 and parameters: {'n_estimators': 828, 'max_depth': 10, 'learning_rate': 0.005670303679171654}. Best is trial 154 with value: 0.9143840670585632.\n",
      "[I 2025-08-21 11:06:46,054] Trial 177 finished with value: 0.9057237505912781 and parameters: {'n_estimators': 743, 'max_depth': 9, 'learning_rate': 0.00420903048179526}. Best is trial 154 with value: 0.9143840670585632.\n",
      "[I 2025-08-21 11:07:10,419] Trial 178 finished with value: 0.9046749472618103 and parameters: {'n_estimators': 848, 'max_depth': 11, 'learning_rate': 0.008570169907980459}. Best is trial 154 with value: 0.9143840670585632.\n",
      "[I 2025-08-21 11:07:30,459] Trial 179 finished with value: 0.9085052013397217 and parameters: {'n_estimators': 768, 'max_depth': 10, 'learning_rate': 0.007234282293772505}. Best is trial 154 with value: 0.9143840670585632.\n",
      "[I 2025-08-21 11:07:49,223] Trial 180 finished with value: 0.9129068851470947 and parameters: {'n_estimators': 803, 'max_depth': 9, 'learning_rate': 0.004832903193731234}. Best is trial 154 with value: 0.9143840670585632.\n",
      "[I 2025-08-21 11:08:07,699] Trial 181 finished with value: 0.9132838845252991 and parameters: {'n_estimators': 803, 'max_depth': 9, 'learning_rate': 0.00480405483411859}. Best is trial 154 with value: 0.9143840670585632.\n",
      "[I 2025-08-21 11:08:24,689] Trial 182 finished with value: 0.8958780169487 and parameters: {'n_estimators': 799, 'max_depth': 9, 'learning_rate': 0.0035039451842053017}. Best is trial 154 with value: 0.9143840670585632.\n",
      "[I 2025-08-21 11:08:41,738] Trial 183 finished with value: 0.9092455506324768 and parameters: {'n_estimators': 779, 'max_depth': 8, 'learning_rate': 0.004280466205390468}. Best is trial 154 with value: 0.9143840670585632.\n",
      "[I 2025-08-21 11:09:00,391] Trial 184 finished with value: 0.9116423726081848 and parameters: {'n_estimators': 753, 'max_depth': 10, 'learning_rate': 0.00595336272498353}. Best is trial 154 with value: 0.9143840670585632.\n",
      "[I 2025-08-21 11:09:19,525] Trial 185 finished with value: 0.9135231375694275 and parameters: {'n_estimators': 803, 'max_depth': 20, 'learning_rate': 0.0049685808260700685}. Best is trial 154 with value: 0.9143840670585632.\n",
      "[I 2025-08-21 11:09:38,260] Trial 186 finished with value: 0.9057278633117676 and parameters: {'n_estimators': 829, 'max_depth': 20, 'learning_rate': 0.003806733809262364}. Best is trial 154 with value: 0.9143840670585632.\n",
      "[I 2025-08-21 11:09:58,662] Trial 187 finished with value: 0.9089804291725159 and parameters: {'n_estimators': 787, 'max_depth': 20, 'learning_rate': 0.006914136401058654}. Best is trial 154 with value: 0.9143840670585632.\n",
      "[I 2025-08-21 11:10:16,718] Trial 188 finished with value: 0.8770298361778259 and parameters: {'n_estimators': 861, 'max_depth': 19, 'learning_rate': 0.002938590278419212}. Best is trial 154 with value: 0.9143840670585632.\n",
      "[I 2025-08-21 11:10:35,245] Trial 189 finished with value: 0.911189079284668 and parameters: {'n_estimators': 767, 'max_depth': 20, 'learning_rate': 0.005361914579911326}. Best is trial 154 with value: 0.9143840670585632.\n",
      "[I 2025-08-21 11:10:51,934] Trial 190 finished with value: 0.7728694081306458 and parameters: {'n_estimators': 815, 'max_depth': 19, 'learning_rate': 0.002377646187024278}. Best is trial 154 with value: 0.9143840670585632.\n",
      "[I 2025-08-21 11:11:11,067] Trial 191 finished with value: 0.912787139415741 and parameters: {'n_estimators': 800, 'max_depth': 10, 'learning_rate': 0.00500280179747415}. Best is trial 154 with value: 0.9143840670585632.\n",
      "[I 2025-08-21 11:11:29,831] Trial 192 finished with value: 0.9111793637275696 and parameters: {'n_estimators': 805, 'max_depth': 9, 'learning_rate': 0.004532732663974044}. Best is trial 154 with value: 0.9143840670585632.\n",
      "[I 2025-08-21 11:11:51,499] Trial 193 finished with value: 0.9101899266242981 and parameters: {'n_estimators': 835, 'max_depth': 10, 'learning_rate': 0.006098413372964496}. Best is trial 154 with value: 0.9143840670585632.\n",
      "[I 2025-08-21 11:12:09,059] Trial 194 finished with value: 0.9047386050224304 and parameters: {'n_estimators': 792, 'max_depth': 10, 'learning_rate': 0.003930226398483262}. Best is trial 154 with value: 0.9143840670585632.\n",
      "[I 2025-08-21 11:12:28,427] Trial 195 finished with value: 0.9129638671875 and parameters: {'n_estimators': 815, 'max_depth': 11, 'learning_rate': 0.004807712117174856}. Best is trial 154 with value: 0.9143840670585632.\n",
      "[I 2025-08-21 11:12:45,451] Trial 196 finished with value: 0.8943528532981873 and parameters: {'n_estimators': 822, 'max_depth': 11, 'learning_rate': 0.0033782290861684543}. Best is trial 154 with value: 0.9143840670585632.\n",
      "[I 2025-08-21 11:13:06,844] Trial 197 finished with value: 0.9074063301086426 and parameters: {'n_estimators': 760, 'max_depth': 11, 'learning_rate': 0.008315224218560633}. Best is trial 154 with value: 0.9143840670585632.\n",
      "[I 2025-08-21 11:13:28,688] Trial 198 finished with value: 0.910105288028717 and parameters: {'n_estimators': 841, 'max_depth': 20, 'learning_rate': 0.006015592157291746}. Best is trial 154 with value: 0.9143840670585632.\n",
      "[I 2025-08-21 11:13:36,073] Trial 199 finished with value: 0.8578408360481262 and parameters: {'n_estimators': 776, 'max_depth': 12, 'learning_rate': 0.1702340613187616}. Best is trial 154 with value: 0.9143840670585632.\n",
      "[I 2025-08-21 11:13:55,073] Trial 200 finished with value: 0.9131154417991638 and parameters: {'n_estimators': 821, 'max_depth': 11, 'learning_rate': 0.0045752272901695345}. Best is trial 154 with value: 0.9143840670585632.\n",
      "[I 2025-08-21 11:14:14,027] Trial 201 finished with value: 0.9121213555335999 and parameters: {'n_estimators': 813, 'max_depth': 11, 'learning_rate': 0.004545855619347687}. Best is trial 154 with value: 0.9143840670585632.\n",
      "[I 2025-08-21 11:14:35,256] Trial 202 finished with value: 0.9114882349967957 and parameters: {'n_estimators': 851, 'max_depth': 11, 'learning_rate': 0.005242556030460599}. Best is trial 154 with value: 0.9143840670585632.\n",
      "[I 2025-08-21 11:14:52,879] Trial 203 finished with value: 0.9062013626098633 and parameters: {'n_estimators': 785, 'max_depth': 10, 'learning_rate': 0.004057692840313093}. Best is trial 154 with value: 0.9143840670585632.\n",
      "[I 2025-08-21 11:15:14,830] Trial 204 finished with value: 0.9098625779151917 and parameters: {'n_estimators': 829, 'max_depth': 12, 'learning_rate': 0.006728514948962077}. Best is trial 154 with value: 0.9143840670585632.\n",
      "[W 2025-08-21 11:15:22,853] Trial 205 failed with parameters: {'n_estimators': 803, 'max_depth': 11, 'learning_rate': 0.00559224423132004} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"/venv/main/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 201, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_3540/2626715101.py\", line 27, in objective\n",
      "    model.fit(\n",
      "  File \"/venv/main/lib/python3.12/site-packages/xgboost/core.py\", line 729, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/venv/main/lib/python3.12/site-packages/xgboost/sklearn.py\", line 1247, in fit\n",
      "    self._Booster = train(\n",
      "                    ^^^^^^\n",
      "  File \"/venv/main/lib/python3.12/site-packages/xgboost/core.py\", line 729, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/venv/main/lib/python3.12/site-packages/xgboost/training.py\", line 183, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/venv/main/lib/python3.12/site-packages/xgboost/core.py\", line 2247, in update\n",
      "    _LIB.XGBoosterUpdateOneIter(\n",
      "KeyboardInterrupt\n",
      "[W 2025-08-21 11:15:22,859] Trial 205 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 37\u001b[39m\n\u001b[32m     34\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m r2_score(eval_targets, preds)\n\u001b[32m     36\u001b[39m study = optuna.create_study(direction=\u001b[33m\"\u001b[39m\u001b[33mmaximize\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m37\u001b[39m \u001b[43mstudy\u001b[49m\u001b[43m.\u001b[49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m500\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/venv/main/lib/python3.12/site-packages/optuna/study/study.py:490\u001b[39m, in \u001b[36mStudy.optimize\u001b[39m\u001b[34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m    388\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34moptimize\u001b[39m(\n\u001b[32m    389\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    390\u001b[39m     func: ObjectiveFuncType,\n\u001b[32m   (...)\u001b[39m\u001b[32m    397\u001b[39m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    398\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    399\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[32m    400\u001b[39m \n\u001b[32m    401\u001b[39m \u001b[33;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    488\u001b[39m \u001b[33;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[32m    489\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m490\u001b[39m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    491\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    492\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    493\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    494\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    495\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    496\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    497\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    498\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    499\u001b[39m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    500\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/venv/main/lib/python3.12/site-packages/optuna/study/_optimize.py:63\u001b[39m, in \u001b[36m_optimize\u001b[39m\u001b[34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m     61\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     62\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs == \u001b[32m1\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m63\u001b[39m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     64\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     65\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     66\u001b[39m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     67\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     68\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     69\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     70\u001b[39m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     71\u001b[39m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     72\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     73\u001b[39m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     74\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     75\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     76\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs == -\u001b[32m1\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/venv/main/lib/python3.12/site-packages/optuna/study/_optimize.py:160\u001b[39m, in \u001b[36m_optimize_sequential\u001b[39m\u001b[34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[39m\n\u001b[32m    157\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m    159\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m160\u001b[39m     frozen_trial_id = \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    161\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    162\u001b[39m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[32m    163\u001b[39m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[32m    164\u001b[39m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[32m    165\u001b[39m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[32m    166\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/venv/main/lib/python3.12/site-packages/optuna/study/_optimize.py:258\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    251\u001b[39m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mShould not reach.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    253\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    254\u001b[39m     updated_state == TrialState.FAIL\n\u001b[32m    255\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    256\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[32m    257\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m258\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[32m    259\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m trial._trial_id\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/venv/main/lib/python3.12/site-packages/optuna/study/_optimize.py:201\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    199\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial._trial_id, study._storage):\n\u001b[32m    200\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m201\u001b[39m         value_or_values = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    202\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions.TrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    203\u001b[39m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[32m    204\u001b[39m         state = TrialState.PRUNED\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 27\u001b[39m, in \u001b[36mobjective\u001b[39m\u001b[34m(trial)\u001b[39m\n\u001b[32m     10\u001b[39m learning_rate = trial.suggest_float(\u001b[33m\"\u001b[39m\u001b[33mlearning_rate\u001b[39m\u001b[33m\"\u001b[39m, \u001b[32m0.0001\u001b[39m, \u001b[32m0.8\u001b[39m, log=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     12\u001b[39m model = XGBRegressor(\n\u001b[32m     13\u001b[39m     n_estimators=n_estimators,\n\u001b[32m     14\u001b[39m     learning_rate=learning_rate,\n\u001b[32m   (...)\u001b[39m\u001b[32m     24\u001b[39m     device=\u001b[33m\"\u001b[39m\u001b[33mcuda\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     25\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     28\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_targets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     29\u001b[39m \u001b[43m    \u001b[49m\u001b[43meval_set\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43meval_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_targets\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     30\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     31\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     33\u001b[39m preds = model.predict(eval_inputs)\n\u001b[32m     34\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m r2_score(eval_targets, preds)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/venv/main/lib/python3.12/site-packages/xgboost/core.py:729\u001b[39m, in \u001b[36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    727\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig.parameters, args):\n\u001b[32m    728\u001b[39m     kwargs[k] = arg\n\u001b[32m--> \u001b[39m\u001b[32m729\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/venv/main/lib/python3.12/site-packages/xgboost/sklearn.py:1247\u001b[39m, in \u001b[36mXGBModel.fit\u001b[39m\u001b[34m(self, X, y, sample_weight, base_margin, eval_set, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights)\u001b[39m\n\u001b[32m   1244\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1245\u001b[39m     obj = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1247\u001b[39m \u001b[38;5;28mself\u001b[39m._Booster = \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1248\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1249\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_dmatrix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1250\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_num_boosting_rounds\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1251\u001b[39m \u001b[43m    \u001b[49m\u001b[43mevals\u001b[49m\u001b[43m=\u001b[49m\u001b[43mevals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1252\u001b[39m \u001b[43m    \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1253\u001b[39m \u001b[43m    \u001b[49m\u001b[43mevals_result\u001b[49m\u001b[43m=\u001b[49m\u001b[43mevals_result\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1254\u001b[39m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m=\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1255\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcustom_metric\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1256\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1257\u001b[39m \u001b[43m    \u001b[49m\u001b[43mxgb_model\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1258\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1259\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1261\u001b[39m \u001b[38;5;28mself\u001b[39m._set_evaluation_result(evals_result)\n\u001b[32m   1262\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/venv/main/lib/python3.12/site-packages/xgboost/core.py:729\u001b[39m, in \u001b[36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    727\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig.parameters, args):\n\u001b[32m    728\u001b[39m     kwargs[k] = arg\n\u001b[32m--> \u001b[39m\u001b[32m729\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/venv/main/lib/python3.12/site-packages/xgboost/training.py:183\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m(params, dtrain, num_boost_round, evals, obj, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[39m\n\u001b[32m    181\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cb_container.before_iteration(bst, i, dtrain, evals):\n\u001b[32m    182\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m183\u001b[39m \u001b[43mbst\u001b[49m\u001b[43m.\u001b[49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miteration\u001b[49m\u001b[43m=\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfobj\u001b[49m\u001b[43m=\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    184\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cb_container.after_iteration(bst, i, dtrain, evals):\n\u001b[32m    185\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/venv/main/lib/python3.12/site-packages/xgboost/core.py:2247\u001b[39m, in \u001b[36mBooster.update\u001b[39m\u001b[34m(self, dtrain, iteration, fobj)\u001b[39m\n\u001b[32m   2243\u001b[39m \u001b[38;5;28mself\u001b[39m._assign_dmatrix_features(dtrain)\n\u001b[32m   2245\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m fobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   2246\u001b[39m     _check_call(\n\u001b[32m-> \u001b[39m\u001b[32m2247\u001b[39m         \u001b[43m_LIB\u001b[49m\u001b[43m.\u001b[49m\u001b[43mXGBoosterUpdateOneIter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2248\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctypes\u001b[49m\u001b[43m.\u001b[49m\u001b[43mc_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43miteration\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle\u001b[49m\n\u001b[32m   2249\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2250\u001b[39m     )\n\u001b[32m   2251\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2252\u001b[39m     pred = \u001b[38;5;28mself\u001b[39m.predict(dtrain, output_margin=\u001b[38;5;28;01mTrue\u001b[39;00m, training=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    n_estimators = trial.suggest_int(\"n_estimators\", 200, 1000)\n",
    "    max_depth = trial.suggest_int(\"max_depth\", 3, 20)\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 0.0001, 0.8, log=True)\n",
    "    \n",
    "    model = XGBRegressor(\n",
    "        n_estimators=n_estimators,\n",
    "        learning_rate=learning_rate,\n",
    "        max_depth=max_depth,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        random_state=SEED,\n",
    "        n_jobs=-1,\n",
    "        #reg_lambda=1.0,\n",
    "        eval_metric=\"rmse\",  \n",
    "        #early_stopping_rounds=5,        \n",
    "        tree_method=\"hist\", \n",
    "        device=\"cuda\",\n",
    "    )\n",
    "\n",
    "    model.fit(\n",
    "        train_inputs, train_targets,\n",
    "        eval_set=[(eval_inputs, eval_targets)],\n",
    "        verbose=False,\n",
    "    )\n",
    "\n",
    "    preds = model.predict(eval_inputs)\n",
    "    return r2_score(eval_targets, preds)\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "41a90d08-ce3e-45ab-b4b6-8703b1115659",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 834, 'max_depth': 10, 'learning_rate': 0.004921367727649843}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d7bb2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import r2_score\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "seeds = [SEED]#np.random.randint(0, 10**6, size=10).tolist()\n",
    "models = {\"1\": [], \"2\": [], \"3\": []}\n",
    "\n",
    "for seed in tqdm(seeds):\n",
    "    print(f\"Seed {seed}\")\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "    scores_mean = []\n",
    "    \n",
    "    for i in range(3):\n",
    "        splits = kf.split(inputs, targets)\n",
    "        scores = []\n",
    "        \n",
    "        for j, (train_idx, eval_idx) in enumerate(splits):\n",
    "            train_inputs, train_targets = inputs[train_idx], targets[train_idx, i]\n",
    "            eval_inputs, eval_targets = inputs[eval_idx], targets[eval_idx, i]\n",
    "            \n",
    "            _, _, mean, std = get_stats(train_inputs, p=False, r=True)\n",
    "            train_inputs = zscore(train_inputs, mean, std)\n",
    "            eval_inputs = zscore(eval_inputs, mean, std)\n",
    "            \n",
    "            model = XGBRegressor(\n",
    "                n_estimators=200,\n",
    "                learning_rate=0.05,\n",
    "                max_depth=3,\n",
    "                subsample=0.8,\n",
    "                colsample_bytree=0.8,\n",
    "                random_state=seed,\n",
    "                n_jobs=-1,\n",
    "                #reg_lambda=1.0,\n",
    "                eval_metric=\"rmse\",  \n",
    "                #early_stopping_rounds=5,        \n",
    "                tree_method=\"hist\", \n",
    "                device=\"cuda\",\n",
    "            )\n",
    "            \n",
    "            model.fit(\n",
    "                train_inputs, train_targets,\n",
    "                eval_set=[(eval_inputs, eval_targets)],\n",
    "                verbose=False,\n",
    "            )\n",
    "            \n",
    "            preds = model.predict(eval_inputs)\n",
    "            score = r2_score(eval_targets, preds)\n",
    "            scores.append(score)\n",
    "            models[str(i+1)].append((score, model, mean, std))\n",
    "        \n",
    "        scores = np.mean(scores)\n",
    "        scores_mean.append(scores)\n",
    "        print(f\"Mean R2 (target {i}): {scores:.4f}\")\n",
    "    \n",
    "    scores_mean = np.mean(scores_mean)\n",
    "    print(f\"Final: {scores_mean:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d20fe9e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_models(models):\n",
    "    best_models = []\n",
    "    \n",
    "    for i in range(1, 4):\n",
    "        score = float('-inf')\n",
    "        for s, model, mean, std in models[str(i)]:\n",
    "            if s > score:\n",
    "                score = s\n",
    "                best = model\n",
    "                mu = mean\n",
    "                sigma = std\n",
    "        best_models.append((best, score, mu, sigma))\n",
    "            \n",
    "    return best_models\n",
    "\n",
    "best_models = get_best_models(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e78700",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = {\"1\": [], \"2\": [], \"3\": []}\n",
    "for i in range(1, 4):\n",
    "    for s, m, mean, std in models[str(i)]:\n",
    "        scores[str(i)].append(s)    \n",
    "    scores[str(i)] = np.mean(scores[str(i)])\n",
    "    \n",
    "scores, np.mean([scores[\"1\"], scores[\"2\"], scores[\"3\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ddca50",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "for m, s, mu, sigma in best_models:\n",
    "    scores.append(s)\n",
    "scores, np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f83b584",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = os.path.join(path, files[6])\n",
    "test_df = pd.read_csv(csv_path)\n",
    "\n",
    "\n",
    "row1 = test_df.columns[1:].to_numpy().copy()\n",
    "row1[-1] = \"5611\"\n",
    "row1 = row1.astype(np.float64)\n",
    "\n",
    "\n",
    "cols = test_df.columns[1:]\n",
    "test_df = test_df[cols]\n",
    "test_df[\" 5611]\"] = test_df[\" 5611]\"].str.replace('[\\[\\]]', '', regex=True).astype('int64')\n",
    "test = test_df.to_numpy()\n",
    "\n",
    "test = np.insert(test, 0, row1, axis=0)\n",
    "test = test.reshape(-1, 2, 2048).mean(axis=1)\n",
    "\n",
    "get_stats(test)\n",
    "test = get_advanced_spectra_features(test)\n",
    "test = test.reshape(-1, 3 * 2048)\n",
    "test.shape, test.dtype, get_stats(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad514f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []\n",
    "\n",
    "for i in range(3):\n",
    "    local_preds = []\n",
    "    for _, model, mean, std in models[str(i + 1)]:\n",
    "        t = zscore(test.copy(), mean, std)\n",
    "        p = model.predict(test)\n",
    "        local_preds.append(p)\n",
    "    \n",
    "    local_preds = np.stack(local_preds).mean(axis=0)\n",
    "    preds.append(local_preds)\n",
    "    \n",
    "preds = np.column_stack(preds)\n",
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c3ef61a",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []\n",
    "\n",
    "for model, s, mean, std in best_models:\n",
    "    print(mean, std)\n",
    "    t = zscore(test.copy(), mean, std)\n",
    "    p = model.predict(t)\n",
    "    preds.append(p)\n",
    "    \n",
    "preds = np.column_stack(preds)\n",
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f8c869",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = ['Glucose', 'Sodium Acetate', 'Magnesium Sulfate']\n",
    "preds_df = pd.DataFrame(preds, columns=column_names)\n",
    "preds_df.insert(0, 'ID', [i+1 for i in range(len(preds_df))])\n",
    "preds_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "401b302e",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"xgboost.concat.10.seeds.top1.mu.sigma.done.csv\"\n",
    "preds_df.to_csv(name, index=False)\n",
    "f = pd.read_csv(f\"/kaggle/working/{name}\")\n",
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd1db15",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 (main venv)",
   "language": "python",
   "name": "main"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
