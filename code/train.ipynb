{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d75ce4bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.9/63.9 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m487.9/487.9 kB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Building wheel for bravado-core (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
     ]
    }
   ],
   "source": [
    "#!pip3 install -q  neptune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c4998a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def setup_reproducibility(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available(): torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.use_deterministic_algorithms(False, warn_only=True)\n",
    "    torch.set_float32_matmul_precision(\"high\")\n",
    "    \n",
    "SEED = 1000\n",
    "setup_reproducibility(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "185d0c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import get_cosine_schedule_with_warmup\n",
    "from scipy import signal\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from huggingface_hub import login, snapshot_download\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "def get_scheduler(optimizer, train_dl, epochs):\n",
    "    total_training_steps = len(train_dl) * epochs\n",
    "    warmup_steps = int(total_training_steps * 0.05)  # e.g. 5% warmup\n",
    "    \n",
    "    return get_cosine_schedule_with_warmup(\n",
    "        optimizer=optimizer,\n",
    "        num_warmup_steps=warmup_steps,\n",
    "        num_training_steps=total_training_steps\n",
    "    )\n",
    "\n",
    "\n",
    "def get_stats(tensor, p=True, r=False):\n",
    "    mean, std = tensor.mean(), tensor.std()\n",
    "    if p: print(f\"Mean: {mean}, Std: {std}\")\n",
    "    if r: return mean, std\n",
    "    \n",
    "    \n",
    "def zscore(tensor, mean=None, std=None):\n",
    "    if mean is None: mean = tensor.mean()\n",
    "    if std is None: std = tensor.std()\n",
    "    return (tensor - mean) / (std + 1e-8)\n",
    "\n",
    "\n",
    "def get_model_size(model):\n",
    "    print(sum(p.numel() for p in model.parameters()) / 1e6)\n",
    "    \n",
    "\n",
    "def get_index(iterable):\n",
    "    return random.randint(0, len(iterable) - 1)\n",
    "\n",
    "\n",
    "def get_indices(iterable, n):\n",
    "    return random.sample(range(len(iterable)), n)\n",
    "\n",
    "\n",
    "def split(inputs, targets, seed):\n",
    "    return train_test_split(\n",
    "        inputs,\n",
    "        targets, \n",
    "        test_size=0.2,\n",
    "        shuffle=True, \n",
    "        random_state=seed\n",
    "    ) \n",
    "\n",
    "\n",
    "def show_waves(waves, dpi=100):\n",
    "    \"\"\"\n",
    "    waves: numpy array of shape (3, N)\n",
    "    Creates three separate figures that stretch wide.\n",
    "    \"\"\"\n",
    "    N = waves.shape[1]\n",
    "    t = np.arange(N)\n",
    "\n",
    "    # Wide aspect ratio; height modest so each window fills width\n",
    "    for i in range(waves.shape[0]):\n",
    "        fig = plt.figure(figsize=(14, 4), dpi=dpi)  # wide figure\n",
    "        ax = fig.add_subplot(111)\n",
    "        ax.plot(t, waves[i], linewidth=1)\n",
    "        ax.set_title(f\"Wave {i+1}\")\n",
    "        ax.set_xlabel(\"Sample\")\n",
    "        ax.set_ylabel(\"Amplitude\")\n",
    "        ax.grid(True)\n",
    "        fig.tight_layout()  # reduce margins to use width\n",
    "        \n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "def hf_ds_download(hf_token, repo_id):\n",
    "    login(hf_token[1:])\n",
    "    return snapshot_download(repo_id, repo_type=\"dataset\")\n",
    "\n",
    "\n",
    "def get_spectra_features(X, b=False):\n",
    "    \"\"\"Create multi-channel features from spectra: raw, 1st derivative, 2nd derivative.\"\"\"\n",
    "    X_processed = np.zeros_like(X)\n",
    "    # Baseline correction and SNV\n",
    "    for i in tqdm(range(X.shape[0])):\n",
    "        poly = np.polyfit(np.arange(X.shape[1]), X[i], 3)\n",
    "        baseline = np.polyval(poly, np.arange(X.shape[1]))\n",
    "        corrected_spec = X[i] - baseline\n",
    "        #X_processed[i] = (corrected_spec - corrected_spec.mean()) / (corrected_spec.std() + 1e-8)\n",
    "        X_processed[i] = corrected_spec\n",
    "        \n",
    "    # Calculate derivatives\n",
    "    deriv1 = signal.savgol_filter(X_processed, window_length=11, polyorder=3, deriv=1, axis=1)\n",
    "    deriv2 = signal.savgol_filter(X_processed, window_length=11, polyorder=3, deriv=2, axis=1)\n",
    "\n",
    "    if b: return np.stack([X_processed, deriv1, deriv2], axis=1)\n",
    "    return np.stack([deriv1, deriv2], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3bfbf156",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 'sample_submission.csv'),\n",
       " (1, 'timegate.csv'),\n",
       " (2, 'mettler_toledo.csv'),\n",
       " (3, 'kaiser.csv'),\n",
       " (4, 'anton_532.csv'),\n",
       " (5, 'transfer_plate.csv'),\n",
       " (6, '96_samples.csv'),\n",
       " (7, 'tornado.csv'),\n",
       " (8, 'tec5.csv'),\n",
       " (9, 'metrohm.csv'),\n",
       " (10, 'anton_785.csv')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "path = \"/kaggle/input/dig-4-bio-raman-transfer-learning-challenge\"\n",
    "files = os.listdir(path)\n",
    "[(i, files[i]) for i in range(len(files))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58096ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "def load_transfer_data():\n",
    "    csv_path = os.path.join(path, files[5])\n",
    "    df = pd.read_csv(csv_path)\n",
    "\n",
    "    input_cols = df.columns[1:2049]\n",
    "    target_cols = df.columns[2050:]\n",
    "\n",
    "    targets  = df[target_cols].dropna().to_numpy()\n",
    "\n",
    "    df = df[input_cols]\n",
    "    df['Unnamed: 1'] = df['Unnamed: 1'].str.replace(\"[\\[\\]]\", \"\", regex=True).astype('int64')\n",
    "    df['Unnamed: 2048'] = df['Unnamed: 2048'].str.replace(\"[\\[\\]]\", \"\", regex=True).astype('int64')\n",
    "\n",
    "    inputs = df.to_numpy().reshape(-1, 2, 2048)\n",
    "    inputs = inputs.mean(axis=1)\n",
    "\n",
    "    return inputs, targets\n",
    "\n",
    "\n",
    "def load_test_data():\n",
    "    test = pd.read_csv(os.path.join(path, files[6]))\n",
    "\n",
    "    row1 = test.columns[1:].to_numpy().copy()\n",
    "    row1[-1] = \"5611\"\n",
    "    row1 = row1.astype(np.float64)\n",
    "\n",
    "\n",
    "    cols = test.columns[1:]\n",
    "    test = test[cols]\n",
    "    test[\" 5611]\"] = test[\" 5611]\"].str.replace('[\\[\\]]', '', regex=True).astype('int64')\n",
    "    test = test.to_numpy()\n",
    "\n",
    "    test = np.insert(test, 0, row1, axis=0)\n",
    "    return test.reshape(-1, 2, 2048).mean(axis=1)\n",
    "\n",
    "\n",
    "def load_all_datasets():\n",
    "    train_inputs = []\n",
    "    train_targets = []\n",
    "    \n",
    "    timegate = pd.read_csv(os.path.join(path, files[1]))\n",
    "\n",
    "    timegate.drop(columns=\"fold_idx\", inplace=True)\n",
    "    timegate.drop(columns=\"MSM_present\", inplace=True)\n",
    "    timegate_inputs = timegate[timegate.columns[:-3]].to_numpy()\n",
    "    timegate_targets = timegate[timegate.columns[-3:]].to_numpy()\n",
    "\n",
    "    train_inputs.append(timegate_inputs)\n",
    "    train_targets.append(timegate_targets)\n",
    "    \n",
    "    mettler_toledo = pd.read_csv(os.path.join(path, files[2]))\n",
    "\n",
    "    mettler_toledo.drop(columns=\"fold_idx\", inplace=True)\n",
    "    mettler_toledo.drop(columns=\"MSM_present\", inplace=True)\n",
    "    mettler_toledo_inputs = mettler_toledo[mettler_toledo.columns[:-3]].to_numpy()\n",
    "    mettler_toledo_targets = mettler_toledo[mettler_toledo.columns[-3:]].to_numpy()\n",
    "\n",
    "    train_inputs.append(mettler_toledo_inputs)\n",
    "    train_targets.append(mettler_toledo_targets)\n",
    "    \n",
    "    kaiser = pd.read_csv(os.path.join(path, files[3]))\n",
    "\n",
    "    kaiser.drop(columns=\"fold_idx\", inplace=True)\n",
    "    kaiser.drop(columns=\"MSM_present\", inplace=True)\n",
    "    kaiser_inputs = kaiser[kaiser.columns[:-3]].to_numpy()\n",
    "    kaiser_targets = kaiser[kaiser.columns[-3:]].to_numpy()\n",
    "\n",
    "    train_inputs.append(kaiser_inputs)\n",
    "    train_targets.append(kaiser_targets)\n",
    "    \n",
    "    anton = pd.read_csv(os.path.join(path, files[4]))\n",
    "\n",
    "    anton.drop(columns=\"fold_idx\", inplace=True)\n",
    "    anton.drop(columns=\"MSM_present\", inplace=True)\n",
    "    anton_inputs = anton[anton.columns[:-3]].to_numpy()\n",
    "    anton_targets = anton[anton.columns[-3:]].to_numpy()\n",
    "\n",
    "    train_inputs.append(anton_inputs)\n",
    "    train_targets.append(anton_targets)\n",
    "    \n",
    "    tornado = pd.read_csv(os.path.join(path, files[7]))\n",
    "\n",
    "    tornado.drop(columns=\"fold_idx\", inplace=True)\n",
    "    tornado.drop(columns=\"MSM_present\", inplace=True)\n",
    "    tornado_inputs = tornado[tornado.columns[:-3]].to_numpy()\n",
    "    tornado_targets = tornado[tornado.columns[-3:]].to_numpy()\n",
    "\n",
    "    train_inputs.append(tornado_inputs)\n",
    "    train_targets.append(tornado_targets)\n",
    "    \n",
    "    csv_path = os.path.join(path, files[8])\n",
    "    tec5 = pd.read_csv(csv_path)\n",
    "\n",
    "    tec5.drop(columns=\"fold_idx\", inplace=True)\n",
    "    tec5.drop(columns=\"MSM_present\", inplace=True)\n",
    "    tec5_inputs = tec5[tec5.columns[:-3]].to_numpy()\n",
    "    tec5_targets = tec5[tec5.columns[-3:]].to_numpy()\n",
    "\n",
    "    train_inputs.append(tec5_inputs)\n",
    "    train_targets.append(tec5_targets)\n",
    "    \n",
    "    csv_path = os.path.join(path, files[9])\n",
    "    metrohm = pd.read_csv(csv_path)\n",
    "\n",
    "    metrohm.drop(columns=\"fold_idx\", inplace=True)\n",
    "    metrohm.drop(columns=\"MSM_present\", inplace=True)\n",
    "    metrohm_inputs = metrohm[metrohm.columns[:-3]].to_numpy()\n",
    "    metrohm_targets = metrohm[metrohm.columns[-3:]].to_numpy()\n",
    "\n",
    "    train_inputs.append(metrohm_inputs)\n",
    "    train_targets.append(metrohm_targets)\n",
    "    \n",
    "    csv_path = os.path.join(path, files[10])\n",
    "    anton785 = pd.read_csv(csv_path)\n",
    "\n",
    "    anton785.drop(columns=\"fold_idx\", inplace=True)\n",
    "    anton785.drop(columns=\"MSM_present\", inplace=True)\n",
    "    anton785_inputs = anton785[anton785.columns[:-3]].to_numpy()\n",
    "    anton785_targets = anton785[anton785.columns[-3:]].to_numpy()\n",
    "\n",
    "    train_inputs.append(anton785_inputs)\n",
    "    train_targets.append(anton785_targets)\n",
    "    \n",
    "    return train_inputs, train_targets\n",
    "\n",
    "inputs_list, targets_list = load_all_datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "40aa78b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    for i in range(len(inputs_list)):\n",
    "        indices = get_indices(inputs_list[i], 96)\n",
    "        inputs_list[i] = inputs_list[i][indices]\n",
    "        targets_list[i] = targets_list[i][indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "33584f53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d165d4d0986e4a7a824d7d23d3746f63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/133 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e4fb0103daa475f9a2c3231dec3f47d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/275 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdbef475adc749e8b351e687aef1cc7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/134 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef196a78afc94449a5f02f12a4ff8063",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/270 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0b23aa851e748b68e94378d4920204e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/385 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa74090d57e14d63a7b29f6cb814e3ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/395 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d314cb09f7f42fdb9e4a7a96885d4c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/399 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "330cdeab9dae4bda8272666a629bef85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/270 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[(133, 2, 511),\n",
       " (275, 2, 2901),\n",
       " (134, 2, 6593),\n",
       " (270, 2, 1651),\n",
       " (385, 2, 3001),\n",
       " (395, 2, 3126),\n",
       " (399, 2, 1917),\n",
       " (270, 2, 1101)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_list = [get_spectra_features(inputs_list[i]) for i in range(len(inputs_list))]\n",
    "[i.shape for i in inputs_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "04b147b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([torch.Size([133, 2, 2048]),\n",
       "  torch.Size([275, 2, 2048]),\n",
       "  torch.Size([134, 2, 2048]),\n",
       "  torch.Size([270, 2, 2048]),\n",
       "  torch.Size([385, 2, 2048]),\n",
       "  torch.Size([395, 2, 2048]),\n",
       "  torch.Size([399, 2, 2048]),\n",
       "  torch.Size([270, 2, 2048])],\n",
       " [torch.Size([133, 3]),\n",
       "  torch.Size([275, 3]),\n",
       "  torch.Size([134, 3]),\n",
       "  torch.Size([270, 3]),\n",
       "  torch.Size([385, 3]),\n",
       "  torch.Size([395, 3]),\n",
       "  torch.Size([399, 3]),\n",
       "  torch.Size([270, 3])])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "def foo(inputs, targets):\n",
    "    for i in range(len(inputs)):\n",
    "        x = inputs[i]\n",
    "        x = torch.tensor(x)\n",
    "        inputs[i] = F.interpolate(x, size=2048, mode=\"nearest-exact\")\n",
    "\n",
    "    #inputs = torch.cat(inputs)\n",
    "    targets = [torch.tensor(t) for t in targets]\n",
    "    #targets = torch.cat(targets)\n",
    "    return inputs, targets\n",
    "    \n",
    "inputs_list, targets_list = foo(inputs_list, targets_list)\n",
    "[i.shape for i in inputs_list], [i.shape for i in targets_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b16a1447",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "if False:\n",
    "    for i in range(len(inputs_list)):\n",
    "        inputs = inputs_list[i]\n",
    "        targets = targets_list[i]\n",
    "        train_inputs, eval_inputs, train_targets, eval_targets = split(inputs, targets, SEED)\n",
    "        \n",
    "        inputs_list[i] = (train_inputs, eval_inputs)\n",
    "        targets_list[i] = (train_targets, eval_targets)\n",
    "        \n",
    "    def foo(inputs, targets):\n",
    "        for i in range(len(inputs)):\n",
    "            train_inputs, eval_inputs = inputs[i]\n",
    "            train_inputs = torch.tensor(train_inputs)\n",
    "            eval_inputs = torch.tensor(eval_inputs)\n",
    "            train_inputs = F.interpolate(train_inputs, size=2048, mode=\"nearest-exact\")\n",
    "            eval_inputs = F.interpolate(eval_inputs, size=2048, mode=\"nearest-exact\")   \n",
    "            inputs[i] = (train_inputs, eval_inputs)\n",
    "\n",
    "        train_inputs = [i[0] for i in inputs]\n",
    "        eval_inputs = [i[1] for i in inputs]\n",
    "        train_inputs = torch.cat(train_inputs)\n",
    "        eval_inputs = torch.cat(eval_inputs)\n",
    "        \n",
    "        train_targets = [torch.tensor(t[0]) for t in targets]\n",
    "        eval_targets = [torch.tensor(t[1]) for t in targets]\n",
    "        train_targets = torch.cat(train_targets)\n",
    "        eval_targets = torch.cat(eval_targets)\n",
    "\n",
    "        return train_inputs, eval_inputs, train_targets, eval_targets\n",
    "        \n",
    "    train_inputs, eval_inputs, train_targets, eval_targets = foo(inputs_list, targets_list)\n",
    "    train_inputs.shape, eval_inputs.shape, train_targets.shape, eval_targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "74ef9524",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b32fc5e372764854bd9b4006c435a723",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/96 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "transfer_inputs, transfer_targets = load_transfer_data()\n",
    "transfer_inputs = get_spectra_features(transfer_inputs)\n",
    "#train_transfer_inputs, eval_transfer_inputs, train_transfer_targets, eval_transfer_targets = split(transfer_inputs, transfer_targets, SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6ac83271",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 9)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_list.append(torch.tensor(transfer_inputs))\n",
    "targets_list.append(torch.tensor(transfer_targets))\n",
    "len(targets_list), len(inputs_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5f970b1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([torch.Size([133, 2, 2048]),\n",
       "  torch.Size([275, 2, 2048]),\n",
       "  torch.Size([134, 2, 2048]),\n",
       "  torch.Size([270, 2, 2048]),\n",
       "  torch.Size([385, 2, 2048]),\n",
       "  torch.Size([395, 2, 2048]),\n",
       "  torch.Size([399, 2, 2048]),\n",
       "  torch.Size([270, 2, 2048]),\n",
       "  torch.Size([96, 2, 2048])],\n",
       " [torch.Size([133, 3]),\n",
       "  torch.Size([275, 3]),\n",
       "  torch.Size([134, 3]),\n",
       "  torch.Size([270, 3]),\n",
       "  torch.Size([385, 3]),\n",
       "  torch.Size([395, 3]),\n",
       "  torch.Size([399, 3]),\n",
       "  torch.Size([270, 3]),\n",
       "  torch.Size([96, 3])])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i.shape for i in inputs_list], [i.shape for i in targets_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2304b01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    train_inputs = torch.cat([train_inputs, torch.tensor(train_transfer_inputs)])\n",
    "    eval_inputs = torch.cat([eval_inputs, torch.tensor(eval_transfer_inputs)])\n",
    "    train_targets = torch.cat([train_targets, torch.tensor(train_transfer_targets)])\n",
    "    eval_targets = torch.cat([eval_targets, torch.tensor(eval_transfer_targets)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2788ef81",
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    min, max, mu, sigma = get_stats(train_inputs, r=True)\n",
    "    train_inputs = zscore(train_inputs)\n",
    "    eval_inputs = zscore(eval_inputs)\n",
    "    get_stats(train_inputs), get_stats(eval_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bf4e0457",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "if False:\n",
    "    train_ds = TensorDataset(train_inputs.float(), train_targets.float())\n",
    "    eval_ds = TensorDataset(eval_inputs.float(), eval_targets.float())\n",
    "    len(train_ds), len(eval_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "982956a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "def build_loader(\n",
    "    SEED,\n",
    "    ds,\n",
    "    train=True,\n",
    "    batch_size=1,\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    "    drop_last=True,\n",
    "    pin_memory=True,\n",
    "    persistent_workers=False,\n",
    "):\n",
    "    def seed_worker(worker_id):\n",
    "        worker_seed = torch.initial_seed() % 2**32\n",
    "        np.random.seed(worker_seed)\n",
    "        random.seed(worker_seed)\n",
    "\n",
    "    generator = torch.Generator()\n",
    "    generator.manual_seed(SEED if train else SEED+5232)\n",
    "\n",
    "    return DataLoader(\n",
    "        ds,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=pin_memory,\n",
    "        drop_last=drop_last,\n",
    "        persistent_workers=persistent_workers,\n",
    "        worker_init_fn=seed_worker,\n",
    "        generator=generator,\n",
    "        #sampler=DistributedSampler(\n",
    "        #    train_ds,\n",
    "        #    shuffle=True,\n",
    "        #    drop_last=True,\n",
    "        #    seed=config.seed\n",
    "        #)\n",
    "    )\n",
    "    \n",
    "    \n",
    "def return_dls(train_ds, eval_ds, train_batch_size, eval_batch_size):\n",
    "    train_dl = build_loader(\n",
    "        SEED,\n",
    "        train_ds,\n",
    "        train=True,\n",
    "        batch_size=train_batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=0,\n",
    "        drop_last=False,\n",
    "        pin_memory=True,\n",
    "        persistent_workers=False,\n",
    "    )\n",
    "\n",
    "    eval_dl = build_loader(\n",
    "        SEED,\n",
    "        eval_ds,\n",
    "        train=False,\n",
    "        batch_size=eval_batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=0,\n",
    "        drop_last=False,\n",
    "        pin_memory=True,\n",
    "        persistent_workers=False,\n",
    "    )\n",
    "    \n",
    "    return train_dl, eval_dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0ac2d7d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import neptune\n",
    "\n",
    "\n",
    "def setup_neptune():\n",
    "    if not RESUME:\n",
    "        neptune_run = neptune.init_run(\n",
    "            project=\"arbaaz/kaggle-spect\",\n",
    "            name=MODEL_NAME,\n",
    "            api_token=\"eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiJlOGE2YjNiZS1mZGUyLTRjYjItYTg5Yy1mZWJkZTIzNzE1NmIifQ==\"\n",
    "        )\n",
    "\n",
    "        neptune_run[\"h_parameters\"] = {\n",
    "            \"seed\": SEED,\n",
    "            \"model_name\": MODEL_NAME,\n",
    "            \"optimizer_name\": \"nadam\",\n",
    "            \"learning_rate\": LR,\n",
    "            \"scheduler_name\": \"default\",\n",
    "            \"weight_decay\": WD,\n",
    "            \"num_epochs\": EPOCHS,\n",
    "            \"batch_size\": BATCH_SIZE,\n",
    "        }\n",
    "        if DROPOUT: neptune_run[\"h_parameters\"] = {\"dropout\": DROPOUT}\n",
    "        if DROP_PATH_RATE: neptune_run[\"h_parameters\"] = {\"drop_path_rate\": DROP_PATH_RATE}\n",
    "    else:\n",
    "        neptune_run = neptune.init_run(\n",
    "            project=\"arbaaz/crunchdao-structural-break\",\n",
    "            with_id=config.with_id,\n",
    "            api_token=\"eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiJlOGE2YjNiZS1mZGUyLTRjYjItYTg5Yy1mZWJkZTIzNzE1NmIifQ==\"\n",
    "        )\n",
    "\n",
    "    return neptune_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "560637b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "\n",
    "def loss_fn(logits, targets):\n",
    "    logits = logits.view(-1)\n",
    "    targets = targets.view(-1)\n",
    "    return F.mse_loss(logits, targets)\n",
    "\n",
    "\n",
    "def metric_fn(logits, targets):\n",
    "    preds = logits.cpu().detach().numpy()\n",
    "    targets = targets.cpu().detach().numpy()\n",
    "    \n",
    "    dim1 = r2_score(targets[:, 0], preds[:, 0])\n",
    "    dim2 = r2_score(targets[:, 1], preds[:, 1])\n",
    "    dim3 = r2_score(targets[:, 2], preds[:, 2])\n",
    "    \n",
    "    mean_r2 = (dim1 + dim2 + dim3) / 3\n",
    "    \n",
    "    return dim1, dim2, dim3, mean_r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "47e91d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    \"\"\"A residual block with two 1D convolutional layers.\"\"\"\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels, out_channels, kernel_size, stride, padding=kernel_size//2)\n",
    "        self.bn1 = nn.BatchNorm1d(out_channels)\n",
    "        self.elu = nn.ELU()\n",
    "        self.conv2 = nn.Conv1d(out_channels, out_channels, kernel_size, padding=kernel_size//2)\n",
    "        self.bn2 = nn.BatchNorm1d(out_channels)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv1d(in_channels, out_channels, kernel_size=1, stride=stride),\n",
    "                nn.BatchNorm1d(out_channels)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.elu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = self.elu(out)\n",
    "        return out\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    \"\"\"A deeper ResNet-style 1D CNN for Raman spectra.\"\"\"\n",
    "    def __init__(self, dropout, input_channels=3, num_classes=3):\n",
    "        super().__init__()\n",
    "        self.in_channels = 64\n",
    "        self.conv1 = nn.Conv1d(input_channels, 64, kernel_size=7, stride=2, padding=3)\n",
    "        self.bn1 = nn.BatchNorm1d(64)\n",
    "        self.elu = nn.GELU()\n",
    "        self.maxpool = nn.MaxPool1d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        self.layer1 = self._make_layer(64, 2, stride=1)\n",
    "        self.layer2 = self._make_layer(128, 2, stride=2)\n",
    "        self.layer3 = self._make_layer(256, 2, stride=2)\n",
    "        self.layer4 = self._make_layer(512, 2, stride=2)\n",
    "\n",
    "        self.avgpool = nn.AdaptiveAvgPool1d(1)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ELU(),\n",
    "            nn.Dropout(dropout), # Increased dropout for better regularization\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "\n",
    "    def _make_layer(self, out_channels, num_blocks, stride):\n",
    "        strides = [stride] + [1] * (num_blocks - 1)\n",
    "        layers = []\n",
    "        for s in strides:\n",
    "            layers.append(ResidualBlock(self.in_channels, out_channels, stride=s))\n",
    "            self.in_channels = out_channels\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.elu(self.bn1(self.conv1(x)))\n",
    "        x = self.maxpool(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "26cd0209",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "def train(\n",
    "    model, \n",
    "    optimizer,\n",
    "    device,\n",
    "    scaler, \n",
    "    scheduler,\n",
    "    train_dl,\n",
    "    eval_dl,\n",
    "    epochs,\n",
    "    checkpoint_name,\n",
    "    score=-float(\"inf\"),\n",
    "    neptune_run=None,\n",
    "    p=True,\n",
    "):  \n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "        all_logits = []\n",
    "        all_targets = []\n",
    "        \n",
    "        for inputs, targets in train_dl:\n",
    "            inputs = inputs.to(device, non_blocking=True)\n",
    "            targets = targets.to(device, non_blocking=True)\n",
    "            \n",
    "            with torch.amp.autocast(device_type=device, dtype=torch.float16, cache_enabled=True):\n",
    "                logits = model(inputs)\n",
    "                loss = loss_fn(logits, targets)\n",
    "            \n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            optimizer.zero_grad()\n",
    "            scheduler.step()\n",
    "            if neptune_run is not None:  neptune_run[\"lr_step\"].append(scheduler.get_last_lr()[0])\n",
    "            \n",
    "            total_loss += loss.detach().cpu()\n",
    "            all_logits.append(logits.detach().cpu())\n",
    "            all_targets.append(targets.detach().cpu())\n",
    "        \n",
    "        all_logits = torch.cat(all_logits)\n",
    "        all_targets = torch.cat(all_targets)\n",
    "\n",
    "        one, two, three, r2 = metric_fn(all_logits, all_targets)\n",
    "        total_loss = total_loss / len(train_dl)\n",
    "        \n",
    "        model.eval()\n",
    "        eval_total_loss = 0.0\n",
    "        eval_all_logits = []\n",
    "        eval_all_targets = []\n",
    "\n",
    "        for inputs, targets in eval_dl:\n",
    "            inputs = inputs.to(device, non_blocking=True)\n",
    "            targets = targets.to(device, non_blocking=True)\n",
    "\n",
    "            with torch.inference_mode():\n",
    "                #with torch.amp.autocast(device_type=device, dtype=torch.float16, cache_enabled=True):\n",
    "                logits = model(inputs)\n",
    "                loss = loss_fn(logits, targets)\n",
    "\n",
    "            eval_total_loss += loss.detach().cpu()\n",
    "            eval_all_logits.append(logits.detach().cpu())\n",
    "            eval_all_targets.append(targets.detach().cpu())\n",
    "        \n",
    "        eval_all_logits = torch.cat(eval_all_logits)\n",
    "        eval_all_targets = torch.cat(eval_all_targets)\n",
    "\n",
    "        eval_one, eval_two, eval_three, eval_r2 = metric_fn(eval_all_logits, eval_all_targets)\n",
    "        eval_total_loss = eval_total_loss / len(eval_dl)\n",
    "        \n",
    "        if eval_r2 > score:\n",
    "            score = eval_r2\n",
    "            data = {\"state_dict\": model.state_dict()}\n",
    "            data[\"epoch\"] = epoch \n",
    "            data[\"score\"] = score\n",
    "            torch.save(data, f\"/kaggle/working/{checkpoint_name}\")\n",
    "        \n",
    "        if neptune_run is not None:\n",
    "            neptune_run[\"train/loss\"].append(total_loss)\n",
    "            neptune_run[\"eval/loss\"].append(eval_total_loss)\n",
    "            neptune_run[\"train/r2\"].append(r2)\n",
    "            neptune_run[\"eval/r2\"].append(eval_r2)\n",
    "            neptune_run[\"train/one\"].append(one)\n",
    "            neptune_run[\"train/two\"].append(two)\n",
    "            neptune_run[\"train/three\"].append(three)\n",
    "            neptune_run[\"eval/one\"].append(eval_one)\n",
    "            neptune_run[\"eval/two\"].append(eval_two)\n",
    "            neptune_run[\"eval/three\"].append(eval_three)\n",
    "            \n",
    "        if p and epoch % 5 == 0:\n",
    "            print(\n",
    "                f\"Epoch: {epoch}, \"\n",
    "                f\"train/loss: {total_loss:.4f}, \"\n",
    "                f\"eval/loss: {eval_total_loss:.4f}, \"\n",
    "                f\"train/r2: {r2:.4f}, \"\n",
    "                f\"eval/r2: {eval_r2:.4f}, \"\n",
    "                f\"train/one: {one:.4f}, \"\n",
    "                f\"train/two: {two:.4f}, \"\n",
    "                f\"train/three: {three:.4f}, \"\n",
    "                f\"eval/one: {eval_one:.4f}, \"\n",
    "                f\"eval/two: {eval_two:.4f}, \"\n",
    "                f\"eval/three: {eval_three:.4f} \"\n",
    "            )\n",
    "            \n",
    "    if neptune_run is not None: neptune_run.stop()\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c6678e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings#; warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "EPOCHS = 500\n",
    "WD = 1e-3\n",
    "LR = 1e-4\n",
    "\n",
    "DROPOUT = 0.5\n",
    "DROP_PATH_RATE = None\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "RESUME = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "853355ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.981251\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[neptune] [warning] NeptuneWarning: By default, these monitoring options are disabled in interactive sessions: 'capture_stdout', 'capture_stderr', 'capture_traceback', 'capture_hardware_metrics'. You can set them to 'True' when initializing the run and the monitoring will continue until you call run.stop() or the kernel stops. NOTE: To track the source files, pass their paths to the 'source_code' argument. For help, see: https://docs-legacy.neptune.ai/logging/source_code/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[neptune] [info   ] Neptune initialized. Open in the app: https://app.neptune.ai/arbaaz/kaggle-spect/e/KAG-115\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "978bd624eb0a47e9afff10546f95faac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:227: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, train/loss: 10.9952, eval/loss: 9.4135, train/r2: -0.9180, eval/r2: -0.9590, train/one: -0.6888, train/two: -1.2974, train/three: -0.7679, eval/one: -0.5827, eval/two: -1.4716, eval/three: -0.8228 \n",
      "Epoch: 5, train/loss: 10.5800, eval/loss: 9.4208, train/r2: -0.8190, eval/r2: -0.9804, train/one: -0.6289, train/two: -1.1526, train/three: -0.6754, eval/one: -0.5823, eval/two: -1.5361, eval/three: -0.8228 \n",
      "Epoch: 10, train/loss: 9.3109, eval/loss: 9.3149, train/r2: -0.5736, eval/r2: -0.9348, train/one: -0.4390, train/two: -0.8527, train/three: -0.4292, eval/one: -0.5696, eval/two: -1.4616, eval/three: -0.7733 \n",
      "Epoch: 15, train/loss: 7.8283, eval/loss: 8.5719, train/r2: -0.3621, eval/r2: -0.7215, train/one: -0.2065, train/two: -0.6674, train/three: -0.2123, eval/one: -0.4566, eval/two: -1.1419, eval/three: -0.5660 \n",
      "Epoch: 20, train/loss: 6.5561, eval/loss: 6.6204, train/r2: -0.1663, eval/r2: -0.3297, train/one: -0.0054, train/two: -0.4379, train/three: -0.0556, eval/one: -0.1241, eval/two: -0.6469, eval/three: -0.2182 \n",
      "Epoch: 25, train/loss: 5.8777, eval/loss: 5.7141, train/r2: -0.0349, eval/r2: 0.0139, train/one: 0.0991, train/two: -0.2440, train/three: 0.0403, eval/one: 0.0071, eval/two: 0.0110, eval/three: 0.0236 \n",
      "Epoch: 30, train/loss: 5.9105, eval/loss: 6.3973, train/r2: -0.1064, eval/r2: -0.0112, train/one: 0.0977, train/two: -0.4589, train/three: 0.0419, eval/one: -0.1340, eval/two: 0.0591, eval/three: 0.0413 \n",
      "Epoch: 35, train/loss: 5.6611, eval/loss: 5.8198, train/r2: -0.0474, eval/r2: 0.0518, train/one: 0.1360, train/two: -0.3479, train/three: 0.0698, eval/one: -0.0264, eval/two: 0.0799, eval/three: 0.1020 \n",
      "Epoch: 40, train/loss: 5.4517, eval/loss: 5.2281, train/r2: 0.0015, eval/r2: 0.0612, train/one: 0.1676, train/two: -0.2637, train/three: 0.1007, eval/one: 0.1020, eval/two: 0.0441, eval/three: 0.0374 \n",
      "Epoch: 45, train/loss: 5.2171, eval/loss: 5.6255, train/r2: 0.0447, eval/r2: -0.0455, train/one: 0.2060, train/two: -0.1810, train/three: 0.1092, eval/one: 0.0331, eval/two: -0.1725, eval/three: 0.0031 \n",
      "Epoch: 50, train/loss: 4.9923, eval/loss: 5.3587, train/r2: 0.0363, eval/r2: 0.0228, train/one: 0.2442, train/two: -0.2724, train/three: 0.1371, eval/one: 0.0841, eval/two: 0.0021, eval/three: -0.0179 \n",
      "Epoch: 55, train/loss: 4.5869, eval/loss: 4.9724, train/r2: 0.1113, eval/r2: 0.0606, train/one: 0.3082, train/two: -0.1537, train/three: 0.1793, eval/one: 0.1510, eval/two: -0.0464, eval/three: 0.0773 \n",
      "Epoch: 60, train/loss: 4.3437, eval/loss: 5.5501, train/r2: 0.1230, eval/r2: 0.0336, train/one: 0.3511, train/two: -0.1572, train/three: 0.1750, eval/one: 0.0430, eval/two: 0.0720, eval/three: -0.0142 \n",
      "Epoch: 65, train/loss: 4.0898, eval/loss: 4.5779, train/r2: 0.1237, eval/r2: 0.1227, train/one: 0.3945, train/two: -0.2197, train/three: 0.1963, eval/one: 0.2224, eval/two: 0.0235, eval/three: 0.1222 \n",
      "Epoch: 70, train/loss: 3.7688, eval/loss: 5.1242, train/r2: 0.1537, eval/r2: 0.1169, train/one: 0.4481, train/two: -0.2046, train/three: 0.2176, eval/one: 0.1025, eval/two: 0.0549, eval/three: 0.1932 \n",
      "Epoch: 75, train/loss: 3.8374, eval/loss: 7.2359, train/r2: 0.1380, eval/r2: 0.0145, train/one: 0.4321, train/two: -0.2914, train/three: 0.2732, eval/one: -0.3336, eval/two: 0.1051, eval/three: 0.2720 \n",
      "Epoch: 80, train/loss: 3.7315, eval/loss: 4.1234, train/r2: 0.1448, eval/r2: 0.2305, train/one: 0.4510, train/two: -0.2853, train/three: 0.2686, eval/one: 0.2864, eval/two: 0.0853, eval/three: 0.3198 \n",
      "Epoch: 85, train/loss: 3.5101, eval/loss: 4.1341, train/r2: 0.1841, eval/r2: 0.2360, train/one: 0.4846, train/two: -0.2406, train/three: 0.3082, eval/one: 0.2828, eval/two: 0.0965, eval/three: 0.3286 \n",
      "Epoch: 90, train/loss: 3.3092, eval/loss: 4.1215, train/r2: 0.2186, eval/r2: 0.2333, train/one: 0.5168, train/two: -0.1864, train/three: 0.3255, eval/one: 0.2842, eval/two: 0.0728, eval/three: 0.3429 \n",
      "Epoch: 95, train/loss: 3.1842, eval/loss: 3.6962, train/r2: 0.2564, eval/r2: 0.2705, train/one: 0.5336, train/two: -0.1257, train/three: 0.3612, eval/one: 0.3661, eval/two: 0.0754, eval/three: 0.3701 \n",
      "Epoch: 100, train/loss: 3.0535, eval/loss: 3.5450, train/r2: 0.2269, eval/r2: 0.2840, train/one: 0.5577, train/two: -0.2508, train/three: 0.3739, eval/one: 0.3959, eval/two: 0.0829, eval/three: 0.3733 \n",
      "Epoch: 105, train/loss: 2.9351, eval/loss: 3.4338, train/r2: 0.2492, eval/r2: 0.3037, train/one: 0.5717, train/two: -0.2661, train/three: 0.4420, eval/one: 0.4122, eval/two: 0.0778, eval/three: 0.4212 \n",
      "Epoch: 110, train/loss: 2.8139, eval/loss: 3.5386, train/r2: 0.3125, eval/r2: 0.2875, train/one: 0.5872, train/two: -0.1162, train/three: 0.4666, eval/one: 0.3947, eval/two: 0.0730, eval/three: 0.3950 \n",
      "Epoch: 115, train/loss: 2.7198, eval/loss: 3.5746, train/r2: 0.3163, eval/r2: 0.2536, train/one: 0.6001, train/two: -0.1605, train/three: 0.5093, eval/one: 0.3990, eval/two: 0.0521, eval/three: 0.3098 \n",
      "Epoch: 120, train/loss: 2.6988, eval/loss: 3.4251, train/r2: 0.3270, eval/r2: 0.3167, train/one: 0.6028, train/two: -0.1354, train/three: 0.5135, eval/one: 0.4070, eval/two: 0.0648, eval/three: 0.4783 \n",
      "Epoch: 125, train/loss: 2.7761, eval/loss: 3.8625, train/r2: 0.2748, eval/r2: 0.2325, train/one: 0.5993, train/two: -0.2059, train/three: 0.4310, eval/one: 0.3436, eval/two: 0.0662, eval/three: 0.2877 \n",
      "Epoch: 130, train/loss: 2.4964, eval/loss: 4.4317, train/r2: 0.3406, eval/r2: 0.0634, train/one: 0.6354, train/two: -0.1583, train/three: 0.5446, eval/one: 0.2804, eval/two: 0.0065, eval/three: -0.0969 \n",
      "Epoch: 135, train/loss: 2.5257, eval/loss: 3.4330, train/r2: 0.3300, eval/r2: 0.3161, train/one: 0.6334, train/two: -0.1576, train/three: 0.5141, eval/one: 0.4067, eval/two: 0.0763, eval/three: 0.4654 \n",
      "Epoch: 140, train/loss: 2.4350, eval/loss: 3.5029, train/r2: 0.3311, eval/r2: 0.3095, train/one: 0.6454, train/two: -0.2157, train/three: 0.5636, eval/one: 0.3959, eval/two: 0.0969, eval/three: 0.4357 \n",
      "Epoch: 145, train/loss: 2.3796, eval/loss: 3.6027, train/r2: 0.3432, eval/r2: 0.2896, train/one: 0.6565, train/two: -0.1662, train/three: 0.5392, eval/one: 0.3805, eval/two: 0.0861, eval/three: 0.4022 \n",
      "Epoch: 150, train/loss: 2.2984, eval/loss: 3.5139, train/r2: 0.3669, eval/r2: 0.3246, train/one: 0.6655, train/two: -0.1520, train/three: 0.5872, eval/one: 0.3856, eval/two: 0.0873, eval/three: 0.5009 \n",
      "Epoch: 155, train/loss: 2.2720, eval/loss: 4.2761, train/r2: 0.3955, eval/r2: 0.2774, train/one: 0.6664, train/two: -0.0902, train/three: 0.6104, eval/one: 0.2295, eval/two: 0.0773, eval/three: 0.5254 \n",
      "Epoch: 160, train/loss: 2.6533, eval/loss: 4.1499, train/r2: 0.3366, eval/r2: 0.3016, train/one: 0.6028, train/two: -0.1965, train/three: 0.6034, eval/one: 0.2531, eval/two: 0.1232, eval/three: 0.5284 \n",
      "Epoch: 165, train/loss: 2.3106, eval/loss: 5.3081, train/r2: 0.3949, eval/r2: 0.2355, train/one: 0.6586, train/two: -0.0958, train/three: 0.6219, eval/one: 0.0125, eval/two: 0.0993, eval/three: 0.5948 \n",
      "Epoch: 170, train/loss: 2.1439, eval/loss: 4.7500, train/r2: 0.3620, eval/r2: 0.2732, train/one: 0.6892, train/two: -0.2392, train/three: 0.6359, eval/one: 0.1232, eval/two: 0.0871, eval/three: 0.6092 \n",
      "Epoch: 175, train/loss: 2.1327, eval/loss: 3.2607, train/r2: 0.3920, eval/r2: 0.3800, train/one: 0.6894, train/two: -0.1480, train/three: 0.6346, eval/one: 0.4221, eval/two: 0.1106, eval/three: 0.6073 \n",
      "Epoch: 180, train/loss: 2.1410, eval/loss: 3.1483, train/r2: 0.3771, eval/r2: 0.3383, train/one: 0.6899, train/two: -0.1808, train/three: 0.6222, eval/one: 0.4649, eval/two: 0.0971, eval/three: 0.4527 \n",
      "Epoch: 185, train/loss: 2.0275, eval/loss: 3.2377, train/r2: 0.4002, eval/r2: 0.3003, train/one: 0.7042, train/two: -0.1790, train/three: 0.6754, eval/one: 0.4607, eval/two: 0.0935, eval/three: 0.3468 \n",
      "Epoch: 190, train/loss: 2.0079, eval/loss: 3.1597, train/r2: 0.4024, eval/r2: 0.3483, train/one: 0.7068, train/two: -0.1834, train/three: 0.6837, eval/one: 0.4575, eval/two: 0.0941, eval/three: 0.4932 \n",
      "Epoch: 195, train/loss: 1.9437, eval/loss: 3.1186, train/r2: 0.4255, eval/r2: 0.3850, train/one: 0.7170, train/two: -0.1216, train/three: 0.6810, eval/one: 0.4495, eval/two: 0.0828, eval/three: 0.6228 \n",
      "Epoch: 200, train/loss: 1.9197, eval/loss: 3.2273, train/r2: 0.4483, eval/r2: 0.3119, train/one: 0.7198, train/two: -0.0568, train/three: 0.6820, eval/one: 0.4568, eval/two: 0.0827, eval/three: 0.3963 \n",
      "Epoch: 205, train/loss: 1.8469, eval/loss: 3.1681, train/r2: 0.4506, eval/r2: 0.3901, train/one: 0.7316, train/two: -0.0741, train/three: 0.6942, eval/one: 0.4365, eval/two: 0.0891, eval/three: 0.6447 \n",
      "Epoch: 210, train/loss: 1.8576, eval/loss: 3.2001, train/r2: 0.4290, eval/r2: 0.2659, train/one: 0.7328, train/two: -0.1196, train/three: 0.6737, eval/one: 0.4846, eval/two: 0.0931, eval/three: 0.2201 \n",
      "Epoch: 215, train/loss: 1.8131, eval/loss: 2.9037, train/r2: 0.4282, eval/r2: 0.4261, train/one: 0.7378, train/two: -0.1625, train/three: 0.7092, eval/one: 0.4824, eval/two: 0.0965, eval/three: 0.6994 \n",
      "Epoch: 220, train/loss: 2.2175, eval/loss: 3.1056, train/r2: 0.3443, eval/r2: 0.4130, train/one: 0.6839, train/two: -0.2072, train/three: 0.5562, eval/one: 0.4432, eval/two: 0.1103, eval/three: 0.6855 \n",
      "Epoch: 225, train/loss: 1.7596, eval/loss: 2.9911, train/r2: 0.4213, eval/r2: 0.4096, train/one: 0.7480, train/two: -0.1909, train/three: 0.7069, eval/one: 0.4700, eval/two: 0.1007, eval/three: 0.6580 \n",
      "Epoch: 230, train/loss: 1.8069, eval/loss: 3.0123, train/r2: 0.4316, eval/r2: 0.3912, train/one: 0.7400, train/two: -0.1388, train/three: 0.6936, eval/one: 0.4712, eval/two: 0.0820, eval/three: 0.6204 \n",
      "Epoch: 235, train/loss: 1.6834, eval/loss: 2.8874, train/r2: 0.4404, eval/r2: 0.4206, train/one: 0.7597, train/two: -0.1527, train/three: 0.7142, eval/one: 0.4887, eval/two: 0.0971, eval/three: 0.6760 \n",
      "Epoch: 240, train/loss: 1.6864, eval/loss: 2.8190, train/r2: 0.4481, eval/r2: 0.4300, train/one: 0.7586, train/two: -0.1296, train/three: 0.7154, eval/one: 0.5015, eval/two: 0.1082, eval/three: 0.6801 \n",
      "Epoch: 245, train/loss: 1.6452, eval/loss: 2.8664, train/r2: 0.4579, eval/r2: 0.4339, train/one: 0.7646, train/two: -0.1139, train/three: 0.7231, eval/one: 0.4883, eval/two: 0.1036, eval/three: 0.7099 \n",
      "Epoch: 250, train/loss: 1.6512, eval/loss: 2.7974, train/r2: 0.4538, eval/r2: 0.4400, train/one: 0.7641, train/two: -0.1229, train/three: 0.7203, eval/one: 0.5019, eval/two: 0.1064, eval/three: 0.7116 \n",
      "Epoch: 255, train/loss: 1.6396, eval/loss: 2.8958, train/r2: 0.4555, eval/r2: 0.4198, train/one: 0.7651, train/two: -0.1294, train/three: 0.7308, eval/one: 0.4888, eval/two: 0.1121, eval/three: 0.6586 \n",
      "Epoch: 260, train/loss: 1.5900, eval/loss: 2.9861, train/r2: 0.4806, eval/r2: 0.4247, train/one: 0.7719, train/two: -0.0662, train/three: 0.7361, eval/one: 0.4646, eval/two: 0.1015, eval/three: 0.7079 \n",
      "Epoch: 265, train/loss: 1.6683, eval/loss: 3.5331, train/r2: 0.4374, eval/r2: 0.3935, train/one: 0.7611, train/two: -0.1811, train/three: 0.7321, eval/one: 0.3511, eval/two: 0.0921, eval/three: 0.7373 \n",
      "Epoch: 270, train/loss: 1.6030, eval/loss: 3.3579, train/r2: 0.4676, eval/r2: 0.3929, train/one: 0.7726, train/two: -0.0804, train/three: 0.7105, eval/one: 0.3932, eval/two: 0.1038, eval/three: 0.6817 \n",
      "Epoch: 275, train/loss: 1.5332, eval/loss: 2.8976, train/r2: 0.4808, eval/r2: 0.3995, train/one: 0.7816, train/two: -0.0801, train/three: 0.7409, eval/one: 0.4963, eval/two: 0.1024, eval/three: 0.5997 \n",
      "Epoch: 280, train/loss: 1.5517, eval/loss: 2.7631, train/r2: 0.4594, eval/r2: 0.4491, train/one: 0.7816, train/two: -0.1220, train/three: 0.7187, eval/one: 0.5067, eval/two: 0.1146, eval/three: 0.7260 \n",
      "Epoch: 285, train/loss: 1.4791, eval/loss: 2.7563, train/r2: 0.4841, eval/r2: 0.4499, train/one: 0.7899, train/two: -0.0919, train/three: 0.7544, eval/one: 0.5081, eval/two: 0.1169, eval/three: 0.7248 \n",
      "Epoch: 290, train/loss: 1.5392, eval/loss: 2.7493, train/r2: 0.4820, eval/r2: 0.4496, train/one: 0.7792, train/two: -0.0893, train/three: 0.7561, eval/one: 0.5086, eval/two: 0.1051, eval/three: 0.7353 \n",
      "Epoch: 295, train/loss: 1.4808, eval/loss: 2.8040, train/r2: 0.4974, eval/r2: 0.4366, train/one: 0.7893, train/two: -0.0459, train/three: 0.7487, eval/one: 0.5031, eval/two: 0.1170, eval/three: 0.6898 \n",
      "Epoch: 300, train/loss: 1.4769, eval/loss: 2.7258, train/r2: 0.4970, eval/r2: 0.4575, train/one: 0.7889, train/two: -0.0595, train/three: 0.7615, eval/one: 0.5131, eval/two: 0.1277, eval/three: 0.7316 \n",
      "Epoch: 305, train/loss: 1.4792, eval/loss: 2.7222, train/r2: 0.4898, eval/r2: 0.4600, train/one: 0.7887, train/two: -0.0840, train/three: 0.7649, eval/one: 0.5124, eval/two: 0.1247, eval/three: 0.7428 \n",
      "Epoch: 310, train/loss: 1.4762, eval/loss: 2.7735, train/r2: 0.4699, eval/r2: 0.4515, train/one: 0.7914, train/two: -0.1358, train/three: 0.7541, eval/one: 0.5033, eval/two: 0.1152, eval/three: 0.7361 \n",
      "Epoch: 315, train/loss: 1.4324, eval/loss: 2.8915, train/r2: 0.5044, eval/r2: 0.4249, train/one: 0.7956, train/two: -0.0536, train/three: 0.7712, eval/one: 0.4870, eval/two: 0.1077, eval/three: 0.6799 \n",
      "Epoch: 320, train/loss: 1.4718, eval/loss: 2.7619, train/r2: 0.4913, eval/r2: 0.4576, train/one: 0.7908, train/two: -0.0716, train/three: 0.7547, eval/one: 0.5037, eval/two: 0.1197, eval/three: 0.7494 \n",
      "Epoch: 325, train/loss: 1.4891, eval/loss: 2.8158, train/r2: 0.4926, eval/r2: 0.4466, train/one: 0.7887, train/two: -0.0523, train/three: 0.7412, eval/one: 0.4955, eval/two: 0.1131, eval/three: 0.7313 \n",
      "Epoch: 330, train/loss: 1.4471, eval/loss: 2.7650, train/r2: 0.4782, eval/r2: 0.4565, train/one: 0.7955, train/two: -0.1212, train/three: 0.7602, eval/one: 0.5030, eval/two: 0.1147, eval/three: 0.7517 \n",
      "Epoch: 335, train/loss: 1.4218, eval/loss: 2.7878, train/r2: 0.4982, eval/r2: 0.4461, train/one: 0.7987, train/two: -0.0656, train/three: 0.7614, eval/one: 0.5006, eval/two: 0.0993, eval/three: 0.7385 \n",
      "Epoch: 340, train/loss: 1.4297, eval/loss: 2.8308, train/r2: 0.4913, eval/r2: 0.4471, train/one: 0.7972, train/two: -0.0904, train/three: 0.7670, eval/one: 0.4895, eval/two: 0.0927, eval/three: 0.7591 \n",
      "Epoch: 345, train/loss: 1.3894, eval/loss: 2.8387, train/r2: 0.5041, eval/r2: 0.4457, train/one: 0.8024, train/two: -0.0716, train/three: 0.7815, eval/one: 0.4892, eval/two: 0.1010, eval/three: 0.7469 \n",
      "Epoch: 350, train/loss: 1.4444, eval/loss: 2.8074, train/r2: 0.5189, eval/r2: 0.4593, train/one: 0.7927, train/two: -0.0051, train/three: 0.7691, eval/one: 0.4926, eval/two: 0.1202, eval/three: 0.7653 \n",
      "Epoch: 355, train/loss: 1.4320, eval/loss: 2.7761, train/r2: 0.4700, eval/r2: 0.4610, train/one: 0.7981, train/two: -0.1563, train/three: 0.7681, eval/one: 0.4995, eval/two: 0.1238, eval/three: 0.7596 \n",
      "Epoch: 360, train/loss: 1.4068, eval/loss: 2.7694, train/r2: 0.4889, eval/r2: 0.4609, train/one: 0.8013, train/two: -0.1034, train/three: 0.7687, eval/one: 0.5010, eval/two: 0.1236, eval/three: 0.7581 \n",
      "Epoch: 365, train/loss: 1.4131, eval/loss: 2.7643, train/r2: 0.5172, eval/r2: 0.4576, train/one: 0.7979, train/two: -0.0213, train/three: 0.7751, eval/one: 0.5028, eval/two: 0.1160, eval/three: 0.7540 \n",
      "Epoch: 370, train/loss: 1.4053, eval/loss: 2.7462, train/r2: 0.5065, eval/r2: 0.4637, train/one: 0.8010, train/two: -0.0443, train/three: 0.7628, eval/one: 0.5049, eval/two: 0.1215, eval/three: 0.7648 \n",
      "Epoch: 375, train/loss: 1.3484, eval/loss: 2.7878, train/r2: 0.5178, eval/r2: 0.4632, train/one: 0.8098, train/two: -0.0265, train/three: 0.7701, eval/one: 0.4960, eval/two: 0.1252, eval/three: 0.7684 \n",
      "Epoch: 380, train/loss: 1.4023, eval/loss: 2.7706, train/r2: 0.5056, eval/r2: 0.4634, train/one: 0.8006, train/two: -0.0577, train/three: 0.7740, eval/one: 0.4993, eval/two: 0.1206, eval/three: 0.7702 \n",
      "Epoch: 385, train/loss: 1.4127, eval/loss: 2.7899, train/r2: 0.4949, eval/r2: 0.4594, train/one: 0.7998, train/two: -0.0844, train/three: 0.7693, eval/one: 0.4962, eval/two: 0.1173, eval/three: 0.7648 \n",
      "Epoch: 390, train/loss: 1.3489, eval/loss: 2.7734, train/r2: 0.4916, eval/r2: 0.4588, train/one: 0.8116, train/two: -0.1040, train/three: 0.7672, eval/one: 0.4999, eval/two: 0.1139, eval/three: 0.7627 \n",
      "Epoch: 395, train/loss: 1.3847, eval/loss: 2.8133, train/r2: 0.4746, eval/r2: 0.4559, train/one: 0.8059, train/two: -0.1545, train/three: 0.7725, eval/one: 0.4922, eval/two: 0.1154, eval/three: 0.7600 \n",
      "Epoch: 400, train/loss: 1.3966, eval/loss: 2.8369, train/r2: 0.4834, eval/r2: 0.4574, train/one: 0.8034, train/two: -0.1229, train/three: 0.7696, eval/one: 0.4865, eval/two: 0.1191, eval/three: 0.7666 \n",
      "Epoch: 405, train/loss: 1.3555, eval/loss: 2.8273, train/r2: 0.4813, eval/r2: 0.4599, train/one: 0.8103, train/two: -0.1427, train/three: 0.7762, eval/one: 0.4880, eval/two: 0.1226, eval/three: 0.7692 \n",
      "Epoch: 410, train/loss: 1.3497, eval/loss: 2.8149, train/r2: 0.5247, eval/r2: 0.4614, train/one: 0.8079, train/two: -0.0181, train/three: 0.7843, eval/one: 0.4903, eval/two: 0.1239, eval/three: 0.7700 \n",
      "Epoch: 415, train/loss: 1.3578, eval/loss: 2.7758, train/r2: 0.4821, eval/r2: 0.4628, train/one: 0.8092, train/two: -0.1464, train/three: 0.7836, eval/one: 0.4984, eval/two: 0.1214, eval/three: 0.7686 \n",
      "Epoch: 420, train/loss: 1.3366, eval/loss: 2.8007, train/r2: 0.5046, eval/r2: 0.4600, train/one: 0.8123, train/two: -0.0729, train/three: 0.7745, eval/one: 0.4931, eval/two: 0.1142, eval/three: 0.7727 \n",
      "Epoch: 425, train/loss: 1.3381, eval/loss: 2.7806, train/r2: 0.5067, eval/r2: 0.4614, train/one: 0.8111, train/two: -0.0756, train/three: 0.7845, eval/one: 0.4972, eval/two: 0.1152, eval/three: 0.7719 \n",
      "Epoch: 430, train/loss: 1.3532, eval/loss: 2.7835, train/r2: 0.5071, eval/r2: 0.4610, train/one: 0.8074, train/two: -0.0823, train/three: 0.7961, eval/one: 0.4970, eval/two: 0.1175, eval/three: 0.7684 \n",
      "Epoch: 435, train/loss: 1.3307, eval/loss: 2.7772, train/r2: 0.5098, eval/r2: 0.4636, train/one: 0.8129, train/two: -0.0606, train/three: 0.7770, eval/one: 0.4977, eval/two: 0.1213, eval/three: 0.7718 \n",
      "Epoch: 440, train/loss: 1.3396, eval/loss: 2.7819, train/r2: 0.5148, eval/r2: 0.4623, train/one: 0.8101, train/two: -0.0533, train/three: 0.7875, eval/one: 0.4973, eval/two: 0.1219, eval/three: 0.7675 \n",
      "Epoch: 445, train/loss: 1.3353, eval/loss: 2.7857, train/r2: 0.5245, eval/r2: 0.4638, train/one: 0.8111, train/two: -0.0151, train/three: 0.7775, eval/one: 0.4959, eval/two: 0.1225, eval/three: 0.7730 \n",
      "Epoch: 450, train/loss: 1.3457, eval/loss: 2.7832, train/r2: 0.5009, eval/r2: 0.4619, train/one: 0.8114, train/two: -0.0780, train/three: 0.7691, eval/one: 0.4973, eval/two: 0.1229, eval/three: 0.7655 \n",
      "Epoch: 455, train/loss: 1.3445, eval/loss: 2.7855, train/r2: 0.5100, eval/r2: 0.4635, train/one: 0.8097, train/two: -0.0640, train/three: 0.7844, eval/one: 0.4960, eval/two: 0.1227, eval/three: 0.7719 \n",
      "Epoch: 460, train/loss: 1.3678, eval/loss: 2.7972, train/r2: 0.5096, eval/r2: 0.4620, train/one: 0.8070, train/two: -0.0464, train/three: 0.7680, eval/one: 0.4939, eval/two: 0.1220, eval/three: 0.7701 \n",
      "Epoch: 465, train/loss: 1.3740, eval/loss: 2.7952, train/r2: 0.5017, eval/r2: 0.4617, train/one: 0.8056, train/two: -0.0783, train/three: 0.7778, eval/one: 0.4944, eval/two: 0.1213, eval/three: 0.7694 \n",
      "Epoch: 470, train/loss: 1.3429, eval/loss: 2.7906, train/r2: 0.5062, eval/r2: 0.4619, train/one: 0.8101, train/two: -0.0784, train/three: 0.7868, eval/one: 0.4954, eval/two: 0.1209, eval/three: 0.7696 \n",
      "Epoch: 475, train/loss: 1.3264, eval/loss: 2.7865, train/r2: 0.5130, eval/r2: 0.4625, train/one: 0.8129, train/two: -0.0567, train/three: 0.7827, eval/one: 0.4960, eval/two: 0.1204, eval/three: 0.7710 \n",
      "Epoch: 480, train/loss: 1.3116, eval/loss: 2.7858, train/r2: 0.5122, eval/r2: 0.4630, train/one: 0.8153, train/two: -0.0653, train/three: 0.7866, eval/one: 0.4959, eval/two: 0.1202, eval/three: 0.7728 \n",
      "Epoch: 485, train/loss: 1.3505, eval/loss: 2.7860, train/r2: 0.5051, eval/r2: 0.4628, train/one: 0.8090, train/two: -0.0786, train/three: 0.7848, eval/one: 0.4959, eval/two: 0.1200, eval/three: 0.7725 \n",
      "Epoch: 490, train/loss: 1.3726, eval/loss: 2.7863, train/r2: 0.4962, eval/r2: 0.4626, train/one: 0.8074, train/two: -0.0827, train/three: 0.7639, eval/one: 0.4959, eval/two: 0.1199, eval/three: 0.7721 \n",
      "Epoch: 495, train/loss: 1.3562, eval/loss: 2.7865, train/r2: 0.5095, eval/r2: 0.4626, train/one: 0.8074, train/two: -0.0674, train/three: 0.7885, eval/one: 0.4959, eval/two: 0.1198, eval/three: 0.7721 \n",
      "[neptune] [info   ] Shutting down background jobs, please wait a moment...\n",
      "[neptune] [info   ] Done!\n",
      "[neptune] [info   ] Waiting for the remaining 44 operations to synchronize with Neptune. Do not kill this process.\n",
      "[neptune] [info   ] All 44 operations synced, thanks for waiting!\n",
      "[neptune] [info   ] Explore the metadata in the Neptune app: https://app.neptune.ai/arbaaz/kaggle-spect/e/KAG-115/metadata\n",
      "[neptune] [info   ] Neptune initialized. Open in the app: https://app.neptune.ai/arbaaz/kaggle-spect/e/KAG-116\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b13ad1f124484568b042ceb164a79292",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:227: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, train/loss: 10.7914, eval/loss: 11.2169, train/r2: -1.2139, eval/r2: -1.0102, train/one: -0.6690, train/two: -2.2253, train/three: -0.7475, eval/one: -0.7564, eval/two: -1.3936, eval/three: -0.8806 \n",
      "Epoch: 5, train/loss: 10.3653, eval/loss: 11.1924, train/r2: -1.1355, eval/r2: -1.0368, train/one: -0.5999, train/two: -2.0987, train/three: -0.7080, eval/one: -0.7457, eval/two: -1.4335, eval/three: -0.9313 \n",
      "Epoch: 10, train/loss: 9.1701, eval/loss: 11.2860, train/r2: -0.8728, eval/r2: -1.0591, train/one: -0.4133, train/two: -1.6568, train/three: -0.5482, eval/one: -0.7592, eval/two: -1.4626, eval/three: -0.9554 \n",
      "Epoch: 15, train/loss: 7.6785, eval/loss: 11.2892, train/r2: -0.5328, eval/r2: -1.0089, train/one: -0.1843, train/two: -1.0997, train/three: -0.3144, eval/one: -0.7722, eval/two: -1.4015, eval/three: -0.8530 \n",
      "Epoch: 20, train/loss: 6.4522, eval/loss: 9.8180, train/r2: -0.2206, eval/r2: -0.6617, train/one: 0.0046, train/two: -0.5114, train/three: -0.1548, eval/one: -0.5607, eval/two: -0.9698, eval/three: -0.4545 \n",
      "Epoch: 25, train/loss: 5.9096, eval/loss: 6.9368, train/r2: -0.1093, eval/r2: -0.0785, train/one: 0.0793, train/two: -0.4456, train/three: 0.0386, eval/one: -0.1077, eval/two: -0.0828, eval/three: -0.0451 \n",
      "Epoch: 30, train/loss: 5.8574, eval/loss: 6.3746, train/r2: -0.1717, eval/r2: -0.0521, train/one: 0.0991, train/two: -0.5845, train/three: -0.0298, eval/one: 0.0025, eval/two: -0.0112, eval/three: -0.1477 \n",
      "Epoch: 35, train/loss: 5.7043, eval/loss: 6.5968, train/r2: -0.0837, eval/r2: -0.1052, train/one: 0.1143, train/two: -0.4128, train/three: 0.0474, eval/one: -0.0262, eval/two: -0.0448, eval/three: -0.2445 \n",
      "Epoch: 40, train/loss: 5.5544, eval/loss: 5.8034, train/r2: -0.0318, eval/r2: 0.0419, train/one: 0.1335, train/two: -0.3295, train/three: 0.1005, eval/one: 0.0876, eval/two: 0.0331, eval/three: 0.0050 \n",
      "Epoch: 45, train/loss: 5.3248, eval/loss: 5.8861, train/r2: 0.0307, eval/r2: 0.0650, train/one: 0.1672, train/two: -0.2218, train/three: 0.1467, eval/one: 0.0633, eval/two: 0.0400, eval/three: 0.0915 \n",
      "Epoch: 50, train/loss: 5.0731, eval/loss: 6.5248, train/r2: 0.0630, eval/r2: 0.0215, train/one: 0.2087, train/two: -0.1931, train/three: 0.1734, eval/one: -0.0521, eval/two: 0.0105, eval/three: 0.1062 \n",
      "Epoch: 55, train/loss: 4.7541, eval/loss: 6.6052, train/r2: 0.0624, eval/r2: 0.0357, train/one: 0.2674, train/two: -0.2495, train/three: 0.1694, eval/one: -0.0691, eval/two: 0.0553, eval/three: 0.1209 \n",
      "Epoch: 60, train/loss: 4.3899, eval/loss: 6.0074, train/r2: 0.0987, eval/r2: 0.0863, train/one: 0.3285, train/two: -0.2375, train/three: 0.2050, eval/one: 0.0321, eval/two: 0.0483, eval/three: 0.1784 \n",
      "Epoch: 65, train/loss: 4.1304, eval/loss: 4.9694, train/r2: 0.1371, eval/r2: 0.1609, train/one: 0.3697, train/two: -0.2050, train/three: 0.2466, eval/one: 0.2149, eval/two: 0.0617, eval/three: 0.2062 \n",
      "Epoch: 70, train/loss: 3.7646, eval/loss: 5.0163, train/r2: 0.1469, eval/r2: 0.1764, train/one: 0.4349, train/two: -0.2530, train/three: 0.2587, eval/one: 0.2025, eval/two: 0.0888, eval/three: 0.2378 \n",
      "Epoch: 75, train/loss: 3.6035, eval/loss: 5.2126, train/r2: 0.1878, eval/r2: 0.1715, train/one: 0.4609, train/two: -0.1638, train/three: 0.2663, eval/one: 0.1636, eval/two: 0.0762, eval/three: 0.2746 \n",
      "Epoch: 80, train/loss: 3.3769, eval/loss: 3.9541, train/r2: 0.2019, eval/r2: 0.2653, train/one: 0.4948, train/two: -0.2301, train/three: 0.3411, eval/one: 0.3837, eval/two: 0.0872, eval/three: 0.3250 \n",
      "Epoch: 85, train/loss: 3.2609, eval/loss: 4.8552, train/r2: 0.1969, eval/r2: 0.2217, train/one: 0.5165, train/two: -0.2665, train/three: 0.3407, eval/one: 0.2175, eval/two: 0.0784, eval/three: 0.3691 \n",
      "Epoch: 90, train/loss: 3.1679, eval/loss: 4.0015, train/r2: 0.2281, eval/r2: 0.2826, train/one: 0.5272, train/two: -0.2304, train/three: 0.3875, eval/one: 0.3661, eval/two: 0.0686, eval/three: 0.4131 \n",
      "Epoch: 95, train/loss: 3.1177, eval/loss: 4.2772, train/r2: 0.2657, eval/r2: 0.2777, train/one: 0.5297, train/two: -0.1671, train/three: 0.4344, eval/one: 0.3141, eval/two: 0.0847, eval/three: 0.4343 \n",
      "Epoch: 100, train/loss: 2.9896, eval/loss: 4.0883, train/r2: 0.2971, eval/r2: 0.2868, train/one: 0.5486, train/two: -0.1186, train/three: 0.4612, eval/one: 0.3472, eval/two: 0.0689, eval/three: 0.4443 \n",
      "Epoch: 105, train/loss: 3.0269, eval/loss: 3.7741, train/r2: 0.2473, eval/r2: 0.3333, train/one: 0.5440, train/two: -0.2782, train/three: 0.4760, eval/one: 0.3937, eval/two: 0.0704, eval/three: 0.5360 \n",
      "Epoch: 110, train/loss: 2.8813, eval/loss: 3.4916, train/r2: 0.2891, eval/r2: 0.3554, train/one: 0.5679, train/two: -0.1738, train/three: 0.4733, eval/one: 0.4413, eval/two: 0.0577, eval/three: 0.5671 \n",
      "Epoch: 115, train/loss: 2.9850, eval/loss: 3.4834, train/r2: 0.2787, eval/r2: 0.3729, train/one: 0.5480, train/two: -0.2053, train/three: 0.4934, eval/one: 0.4398, eval/two: 0.0913, eval/three: 0.5878 \n",
      "Epoch: 120, train/loss: 2.9020, eval/loss: 3.7273, train/r2: 0.2971, eval/r2: 0.3541, train/one: 0.5563, train/two: -0.2219, train/three: 0.5570, eval/one: 0.3970, eval/two: 0.0857, eval/three: 0.5796 \n",
      "Epoch: 125, train/loss: 2.8337, eval/loss: 3.5291, train/r2: 0.2646, eval/r2: 0.3702, train/one: 0.5738, train/two: -0.3053, train/three: 0.5251, eval/one: 0.4310, eval/two: 0.0845, eval/three: 0.5950 \n",
      "Epoch: 130, train/loss: 2.6469, eval/loss: 3.6300, train/r2: 0.3429, eval/r2: 0.3659, train/one: 0.5985, train/two: -0.1422, train/three: 0.5725, eval/one: 0.4130, eval/two: 0.0923, eval/three: 0.5924 \n",
      "Epoch: 135, train/loss: 2.5999, eval/loss: 3.6468, train/r2: 0.3545, eval/r2: 0.3456, train/one: 0.6047, train/two: -0.1314, train/three: 0.5903, eval/one: 0.4146, eval/two: 0.0684, eval/three: 0.5537 \n",
      "Epoch: 140, train/loss: 2.5312, eval/loss: 3.3019, train/r2: 0.3274, eval/r2: 0.3910, train/one: 0.6195, train/two: -0.2235, train/three: 0.5863, eval/one: 0.4691, eval/two: 0.0851, eval/three: 0.6187 \n",
      "Epoch: 145, train/loss: 2.4600, eval/loss: 3.1709, train/r2: 0.3707, eval/r2: 0.3923, train/one: 0.6259, train/two: -0.1420, train/three: 0.6281, eval/one: 0.4954, eval/two: 0.0893, eval/three: 0.5923 \n",
      "Epoch: 150, train/loss: 2.6067, eval/loss: 4.5120, train/r2: 0.3502, eval/r2: 0.2038, train/one: 0.6011, train/two: -0.1717, train/three: 0.6213, eval/one: 0.2944, eval/two: 0.0934, eval/three: 0.2236 \n",
      "Epoch: 155, train/loss: 2.6391, eval/loss: 4.4583, train/r2: 0.3663, eval/r2: 0.2847, train/one: 0.5931, train/two: -0.1256, train/three: 0.6313, eval/one: 0.2718, eval/two: 0.0495, eval/three: 0.5329 \n",
      "Epoch: 160, train/loss: 2.6334, eval/loss: 3.1306, train/r2: 0.3520, eval/r2: 0.4131, train/one: 0.5959, train/two: -0.1624, train/three: 0.6224, eval/one: 0.4951, eval/two: 0.0800, eval/three: 0.6640 \n",
      "Epoch: 165, train/loss: 2.4069, eval/loss: 3.4604, train/r2: 0.3743, eval/r2: 0.3652, train/one: 0.6351, train/two: -0.1438, train/three: 0.6315, eval/one: 0.4461, eval/two: 0.0801, eval/three: 0.5694 \n",
      "Epoch: 170, train/loss: 2.2877, eval/loss: 3.9056, train/r2: 0.4067, eval/r2: 0.3787, train/one: 0.6519, train/two: -0.0943, train/three: 0.6626, eval/one: 0.3530, eval/two: 0.0922, eval/three: 0.6909 \n",
      "Epoch: 175, train/loss: 2.2477, eval/loss: 3.1495, train/r2: 0.4098, eval/r2: 0.4115, train/one: 0.6578, train/two: -0.1056, train/three: 0.6772, eval/one: 0.4926, eval/two: 0.0876, eval/three: 0.6543 \n",
      "Epoch: 180, train/loss: 2.2265, eval/loss: 3.2515, train/r2: 0.4213, eval/r2: 0.3705, train/one: 0.6620, train/two: -0.0614, train/three: 0.6634, eval/one: 0.4866, eval/two: 0.0843, eval/three: 0.5407 \n",
      "Epoch: 185, train/loss: 2.1136, eval/loss: 3.2052, train/r2: 0.4047, eval/r2: 0.3274, train/one: 0.6810, train/two: -0.1630, train/three: 0.6960, eval/one: 0.5118, eval/two: 0.0882, eval/three: 0.3824 \n",
      "Epoch: 190, train/loss: 2.2723, eval/loss: 3.4155, train/r2: 0.3725, eval/r2: 0.2799, train/one: 0.6632, train/two: -0.1386, train/three: 0.5929, eval/one: 0.4861, eval/two: 0.0819, eval/three: 0.2718 \n",
      "Epoch: 195, train/loss: 2.1383, eval/loss: 3.5454, train/r2: 0.4108, eval/r2: 0.3876, train/one: 0.6773, train/two: -0.1262, train/three: 0.6812, eval/one: 0.4226, eval/two: 0.0970, eval/three: 0.6432 \n",
      "Epoch: 200, train/loss: 2.0868, eval/loss: 3.1067, train/r2: 0.4060, eval/r2: 0.4387, train/one: 0.6861, train/two: -0.1606, train/three: 0.6924, eval/one: 0.4925, eval/two: 0.0991, eval/three: 0.7247 \n",
      "Epoch: 205, train/loss: 2.0309, eval/loss: 3.1704, train/r2: 0.4115, eval/r2: 0.4191, train/one: 0.6948, train/two: -0.1667, train/three: 0.7064, eval/one: 0.4865, eval/two: 0.0969, eval/three: 0.6737 \n",
      "Epoch: 210, train/loss: 2.0489, eval/loss: 3.2150, train/r2: 0.4262, eval/r2: 0.4149, train/one: 0.6893, train/two: -0.1303, train/three: 0.7196, eval/one: 0.4782, eval/two: 0.0876, eval/three: 0.6787 \n",
      "Epoch: 215, train/loss: 1.9995, eval/loss: 3.4771, train/r2: 0.4608, eval/r2: 0.3679, train/one: 0.6942, train/two: -0.0510, train/three: 0.7390, eval/one: 0.4420, eval/two: 0.0823, eval/three: 0.5792 \n",
      "Epoch: 220, train/loss: 2.0037, eval/loss: 3.0845, train/r2: 0.4359, eval/r2: 0.4337, train/one: 0.6973, train/two: -0.1048, train/three: 0.7152, eval/one: 0.4971, eval/two: 0.0825, eval/three: 0.7215 \n",
      "Epoch: 225, train/loss: 1.9842, eval/loss: 3.6860, train/r2: 0.4447, eval/r2: 0.3378, train/one: 0.6978, train/two: -0.1064, train/three: 0.7429, eval/one: 0.4118, eval/two: 0.0917, eval/three: 0.5099 \n",
      "Epoch: 230, train/loss: 1.8907, eval/loss: 3.0067, train/r2: 0.4538, eval/r2: 0.4313, train/one: 0.7141, train/two: -0.0984, train/three: 0.7457, eval/one: 0.5151, eval/two: 0.0976, eval/three: 0.6814 \n",
      "Epoch: 235, train/loss: 1.7821, eval/loss: 3.1260, train/r2: 0.4761, eval/r2: 0.4470, train/one: 0.7310, train/two: -0.0642, train/three: 0.7617, eval/one: 0.4853, eval/two: 0.0964, eval/three: 0.7593 \n",
      "Epoch: 240, train/loss: 1.8995, eval/loss: 3.9800, train/r2: 0.4488, eval/r2: 0.3920, train/one: 0.7121, train/two: -0.1194, train/three: 0.7537, eval/one: 0.3329, eval/two: 0.0891, eval/three: 0.7539 \n",
      "Epoch: 245, train/loss: 1.9722, eval/loss: 2.9322, train/r2: 0.4597, eval/r2: 0.4466, train/one: 0.6988, train/two: -0.0652, train/three: 0.7454, eval/one: 0.5241, eval/two: 0.0926, eval/three: 0.7231 \n",
      "Epoch: 250, train/loss: 1.7954, eval/loss: 3.4428, train/r2: 0.4730, eval/r2: 0.3985, train/one: 0.7309, train/two: -0.0497, train/three: 0.7377, eval/one: 0.4383, eval/two: 0.0866, eval/three: 0.6706 \n",
      "Epoch: 255, train/loss: 1.8056, eval/loss: 2.8933, train/r2: 0.4505, eval/r2: 0.3892, train/one: 0.7306, train/two: -0.1165, train/three: 0.7374, eval/one: 0.5511, eval/two: 0.0772, eval/three: 0.5392 \n",
      "Epoch: 260, train/loss: 1.7497, eval/loss: 2.7170, train/r2: 0.4740, eval/r2: 0.4562, train/one: 0.7406, train/two: -0.0399, train/three: 0.7214, eval/one: 0.5634, eval/two: 0.0887, eval/three: 0.7164 \n",
      "Epoch: 265, train/loss: 1.6933, eval/loss: 2.7789, train/r2: 0.4464, eval/r2: 0.4053, train/one: 0.7508, train/two: -0.1558, train/three: 0.7442, eval/one: 0.5704, eval/two: 0.0991, eval/three: 0.5464 \n",
      "Epoch: 270, train/loss: 1.6359, eval/loss: 2.8769, train/r2: 0.4821, eval/r2: 0.3929, train/one: 0.7584, train/two: -0.0617, train/three: 0.7498, eval/one: 0.5548, eval/two: 0.0947, eval/three: 0.5291 \n",
      "Epoch: 275, train/loss: 1.6366, eval/loss: 2.7706, train/r2: 0.5005, eval/r2: 0.4597, train/one: 0.7559, train/two: -0.0160, train/three: 0.7615, eval/one: 0.5510, eval/two: 0.0842, eval/three: 0.7440 \n",
      "Epoch: 280, train/loss: 1.5671, eval/loss: 3.1566, train/r2: 0.4988, eval/r2: 0.3421, train/one: 0.7675, train/two: -0.0471, train/three: 0.7761, eval/one: 0.5170, eval/two: 0.0955, eval/three: 0.4138 \n",
      "Epoch: 285, train/loss: 1.5615, eval/loss: 3.2069, train/r2: 0.5026, eval/r2: 0.3183, train/one: 0.7681, train/two: -0.0388, train/three: 0.7785, eval/one: 0.5153, eval/two: 0.0935, eval/three: 0.3460 \n",
      "Epoch: 290, train/loss: 1.7092, eval/loss: 2.7468, train/r2: 0.4969, eval/r2: 0.4664, train/one: 0.7431, train/two: -0.0113, train/three: 0.7590, eval/one: 0.5533, eval/two: 0.0837, eval/three: 0.7623 \n",
      "Epoch: 295, train/loss: 1.5901, eval/loss: 2.8599, train/r2: 0.4982, eval/r2: 0.4399, train/one: 0.7629, train/two: -0.0496, train/three: 0.7813, eval/one: 0.5415, eval/two: 0.0973, eval/three: 0.6808 \n",
      "Epoch: 300, train/loss: 1.6086, eval/loss: 3.0210, train/r2: 0.4972, eval/r2: 0.4634, train/one: 0.7593, train/two: -0.0526, train/three: 0.7849, eval/one: 0.5010, eval/two: 0.1012, eval/three: 0.7879 \n",
      "Epoch: 305, train/loss: 1.5819, eval/loss: 2.6341, train/r2: 0.4832, eval/r2: 0.4559, train/one: 0.7644, train/two: -0.1081, train/three: 0.7933, eval/one: 0.5805, eval/two: 0.0919, eval/three: 0.6952 \n",
      "Epoch: 310, train/loss: 1.5421, eval/loss: 3.1896, train/r2: 0.4846, eval/r2: 0.4372, train/one: 0.7718, train/two: -0.1090, train/three: 0.7910, eval/one: 0.4750, eval/two: 0.0850, eval/three: 0.7516 \n",
      "Epoch: 315, train/loss: 1.5216, eval/loss: 2.7165, train/r2: 0.5169, eval/r2: 0.4650, train/one: 0.7736, train/two: -0.0106, train/three: 0.7876, eval/one: 0.5608, eval/two: 0.0930, eval/three: 0.7410 \n",
      "Epoch: 320, train/loss: 1.5062, eval/loss: 2.8661, train/r2: 0.5019, eval/r2: 0.4675, train/one: 0.7777, train/two: -0.0570, train/three: 0.7851, eval/one: 0.5301, eval/two: 0.0955, eval/three: 0.7770 \n",
      "Epoch: 325, train/loss: 1.4895, eval/loss: 2.7134, train/r2: 0.5308, eval/r2: 0.4469, train/one: 0.7782, train/two: 0.0231, train/three: 0.7911, eval/one: 0.5681, eval/two: 0.0947, eval/three: 0.6778 \n",
      "Epoch: 330, train/loss: 1.4685, eval/loss: 2.9095, train/r2: 0.5258, eval/r2: 0.4315, train/one: 0.7829, train/two: 0.0097, train/three: 0.7846, eval/one: 0.5338, eval/two: 0.0896, eval/three: 0.6711 \n",
      "Epoch: 335, train/loss: 1.4484, eval/loss: 2.8029, train/r2: 0.5247, eval/r2: 0.4643, train/one: 0.7867, train/two: 0.0025, train/three: 0.7849, eval/one: 0.5439, eval/two: 0.0948, eval/three: 0.7543 \n",
      "Epoch: 340, train/loss: 1.4434, eval/loss: 2.8267, train/r2: 0.5067, eval/r2: 0.4709, train/one: 0.7894, train/two: -0.0479, train/three: 0.7788, eval/one: 0.5364, eval/two: 0.0921, eval/three: 0.7841 \n",
      "Epoch: 345, train/loss: 1.4424, eval/loss: 2.7234, train/r2: 0.5100, eval/r2: 0.4789, train/one: 0.7872, train/two: -0.0601, train/three: 0.8030, eval/one: 0.5546, eval/two: 0.0952, eval/three: 0.7870 \n",
      "Epoch: 350, train/loss: 1.4359, eval/loss: 2.8110, train/r2: 0.5035, eval/r2: 0.4617, train/one: 0.7910, train/two: -0.0586, train/three: 0.7781, eval/one: 0.5435, eval/two: 0.0982, eval/three: 0.7434 \n",
      "Epoch: 355, train/loss: 1.3857, eval/loss: 2.7175, train/r2: 0.5309, eval/r2: 0.4687, train/one: 0.7963, train/two: -0.0046, train/three: 0.8009, eval/one: 0.5592, eval/two: 0.0932, eval/three: 0.7538 \n",
      "Epoch: 360, train/loss: 1.4185, eval/loss: 2.7432, train/r2: 0.5113, eval/r2: 0.4656, train/one: 0.7929, train/two: -0.0458, train/three: 0.7867, eval/one: 0.5551, eval/two: 0.0923, eval/three: 0.7495 \n",
      "Epoch: 365, train/loss: 1.4481, eval/loss: 2.8027, train/r2: 0.5180, eval/r2: 0.4430, train/one: 0.7872, train/two: -0.0181, train/three: 0.7849, eval/one: 0.5514, eval/two: 0.0930, eval/three: 0.6847 \n",
      "Epoch: 370, train/loss: 1.4353, eval/loss: 2.6868, train/r2: 0.4883, eval/r2: 0.4752, train/one: 0.7922, train/two: -0.1050, train/three: 0.7776, eval/one: 0.5632, eval/two: 0.0947, eval/three: 0.7678 \n",
      "Epoch: 375, train/loss: 1.4048, eval/loss: 2.8811, train/r2: 0.5317, eval/r2: 0.4663, train/one: 0.7931, train/two: 0.0053, train/three: 0.7966, eval/one: 0.5274, eval/two: 0.0950, eval/three: 0.7765 \n",
      "Epoch: 380, train/loss: 1.3621, eval/loss: 2.6892, train/r2: 0.5482, eval/r2: 0.4837, train/one: 0.7986, train/two: 0.0361, train/three: 0.8099, eval/one: 0.5596, eval/two: 0.0936, eval/three: 0.7980 \n",
      "Epoch: 385, train/loss: 1.4012, eval/loss: 2.9976, train/r2: 0.5178, eval/r2: 0.4643, train/one: 0.7953, train/two: -0.0323, train/three: 0.7903, eval/one: 0.5044, eval/two: 0.0917, eval/three: 0.7967 \n",
      "Epoch: 390, train/loss: 1.3785, eval/loss: 2.6353, train/r2: 0.5301, eval/r2: 0.4876, train/one: 0.7964, train/two: -0.0212, train/three: 0.8152, eval/one: 0.5689, eval/two: 0.0919, eval/three: 0.8019 \n",
      "Epoch: 395, train/loss: 1.4075, eval/loss: 2.9918, train/r2: 0.5291, eval/r2: 0.4647, train/one: 0.7933, train/two: 0.0024, train/three: 0.7917, eval/one: 0.5053, eval/two: 0.0896, eval/three: 0.7992 \n",
      "Epoch: 400, train/loss: 1.3922, eval/loss: 2.7410, train/r2: 0.5188, eval/r2: 0.4814, train/one: 0.7960, train/two: -0.0401, train/three: 0.8005, eval/one: 0.5500, eval/two: 0.0929, eval/three: 0.8012 \n",
      "Epoch: 405, train/loss: 1.3668, eval/loss: 2.7109, train/r2: 0.5287, eval/r2: 0.4834, train/one: 0.7985, train/two: -0.0294, train/three: 0.8170, eval/one: 0.5554, eval/two: 0.0946, eval/three: 0.8003 \n",
      "Epoch: 410, train/loss: 1.3957, eval/loss: 2.6699, train/r2: 0.4985, eval/r2: 0.4860, train/one: 0.7965, train/two: -0.1050, train/three: 0.8040, eval/one: 0.5628, eval/two: 0.0949, eval/three: 0.8002 \n",
      "Epoch: 415, train/loss: 1.3930, eval/loss: 2.7184, train/r2: 0.5052, eval/r2: 0.4797, train/one: 0.7976, train/two: -0.0739, train/three: 0.7918, eval/one: 0.5551, eval/two: 0.0930, eval/three: 0.7910 \n",
      "Epoch: 420, train/loss: 1.3649, eval/loss: 2.7412, train/r2: 0.5388, eval/r2: 0.4777, train/one: 0.7997, train/two: 0.0170, train/three: 0.7998, eval/one: 0.5513, eval/two: 0.0937, eval/three: 0.7882 \n",
      "Epoch: 425, train/loss: 1.3956, eval/loss: 2.6717, train/r2: 0.5224, eval/r2: 0.4859, train/one: 0.7953, train/two: -0.0268, train/three: 0.7989, eval/one: 0.5624, eval/two: 0.0950, eval/three: 0.8004 \n",
      "Epoch: 430, train/loss: 1.3368, eval/loss: 2.6845, train/r2: 0.5383, eval/r2: 0.4849, train/one: 0.8036, train/two: -0.0028, train/three: 0.8140, eval/one: 0.5602, eval/two: 0.0946, eval/three: 0.8001 \n",
      "Epoch: 435, train/loss: 1.3494, eval/loss: 2.6920, train/r2: 0.5484, eval/r2: 0.4838, train/one: 0.8008, train/two: 0.0330, train/three: 0.8114, eval/one: 0.5591, eval/two: 0.0950, eval/three: 0.7972 \n",
      "Epoch: 440, train/loss: 1.3949, eval/loss: 2.7160, train/r2: 0.5159, eval/r2: 0.4841, train/one: 0.7957, train/two: -0.0490, train/three: 0.8011, eval/one: 0.5543, eval/two: 0.0961, eval/three: 0.8019 \n",
      "Epoch: 445, train/loss: 1.3739, eval/loss: 2.7632, train/r2: 0.5192, eval/r2: 0.4807, train/one: 0.7991, train/two: -0.0444, train/three: 0.8030, eval/one: 0.5459, eval/two: 0.0945, eval/three: 0.8016 \n",
      "Epoch: 450, train/loss: 1.3464, eval/loss: 2.7649, train/r2: 0.5400, eval/r2: 0.4803, train/one: 0.8017, train/two: 0.0038, train/three: 0.8146, eval/one: 0.5457, eval/two: 0.0945, eval/three: 0.8007 \n",
      "Epoch: 455, train/loss: 1.3384, eval/loss: 2.6980, train/r2: 0.5218, eval/r2: 0.4834, train/one: 0.8043, train/two: -0.0551, train/three: 0.8162, eval/one: 0.5579, eval/two: 0.0935, eval/three: 0.7987 \n",
      "Epoch: 460, train/loss: 1.3352, eval/loss: 2.7391, train/r2: 0.5423, eval/r2: 0.4809, train/one: 0.8044, train/two: 0.0176, train/three: 0.8047, eval/one: 0.5505, eval/two: 0.0931, eval/three: 0.7990 \n",
      "Epoch: 465, train/loss: 1.3574, eval/loss: 2.7375, train/r2: 0.5295, eval/r2: 0.4815, train/one: 0.8006, train/two: -0.0240, train/three: 0.8118, eval/one: 0.5506, eval/two: 0.0927, eval/three: 0.8012 \n",
      "Epoch: 470, train/loss: 1.3631, eval/loss: 2.7619, train/r2: 0.5463, eval/r2: 0.4799, train/one: 0.7992, train/two: 0.0372, train/three: 0.8024, eval/one: 0.5463, eval/two: 0.0924, eval/three: 0.8009 \n",
      "Epoch: 475, train/loss: 1.3298, eval/loss: 2.7252, train/r2: 0.5199, eval/r2: 0.4820, train/one: 0.8081, train/two: -0.0397, train/three: 0.7914, eval/one: 0.5528, eval/two: 0.0923, eval/three: 0.8008 \n",
      "Epoch: 480, train/loss: 1.3101, eval/loss: 2.7258, train/r2: 0.5445, eval/r2: 0.4819, train/one: 0.8084, train/two: 0.0150, train/three: 0.8102, eval/one: 0.5528, eval/two: 0.0925, eval/three: 0.8004 \n",
      "Epoch: 485, train/loss: 1.3222, eval/loss: 2.7382, train/r2: 0.5327, eval/r2: 0.4812, train/one: 0.8061, train/two: -0.0287, train/three: 0.8207, eval/one: 0.5506, eval/two: 0.0926, eval/three: 0.8003 \n",
      "Epoch: 490, train/loss: 1.3142, eval/loss: 2.7454, train/r2: 0.5141, eval/r2: 0.4808, train/one: 0.8096, train/two: -0.0797, train/three: 0.8124, eval/one: 0.5493, eval/two: 0.0927, eval/three: 0.8003 \n",
      "Epoch: 495, train/loss: 1.3598, eval/loss: 2.7478, train/r2: 0.5182, eval/r2: 0.4807, train/one: 0.8021, train/two: -0.0466, train/three: 0.7989, eval/one: 0.5488, eval/two: 0.0927, eval/three: 0.8005 \n",
      "[neptune] [info   ] Shutting down background jobs, please wait a moment...\n",
      "[neptune] [info   ] Done!\n",
      "[neptune] [info   ] Waiting for the remaining 143 operations to synchronize with Neptune. Do not kill this process.\n",
      "[neptune] [info   ] All 143 operations synced, thanks for waiting!\n",
      "[neptune] [info   ] Explore the metadata in the Neptune app: https://app.neptune.ai/arbaaz/kaggle-spect/e/KAG-116/metadata\n",
      "[neptune] [info   ] Neptune initialized. Open in the app: https://app.neptune.ai/arbaaz/kaggle-spect/e/KAG-117\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef45500bb8c04e408ee6d5d5fc68ec10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:227: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, train/loss: 10.7957, eval/loss: 11.7631, train/r2: -0.9378, eval/r2: -0.9137, train/one: -0.7158, train/two: -1.3330, train/three: -0.7646, eval/one: -0.7674, eval/two: -1.2828, eval/three: -0.6908 \n",
      "Epoch: 5, train/loss: 10.4325, eval/loss: 11.7986, train/r2: -0.8467, eval/r2: -0.8878, train/one: -0.6586, train/two: -1.1615, train/three: -0.7200, eval/one: -0.7763, eval/two: -1.2094, eval/three: -0.6776 \n",
      "Epoch: 10, train/loss: 9.2403, eval/loss: 11.8391, train/r2: -0.6363, eval/r2: -0.8309, train/one: -0.4679, train/two: -0.9054, train/three: -0.5356, eval/one: -0.7884, eval/two: -1.0451, eval/three: -0.6591 \n",
      "Epoch: 15, train/loss: 7.6756, eval/loss: 11.4464, train/r2: -0.4209, eval/r2: -0.6896, train/one: -0.2092, train/two: -0.7128, train/three: -0.3408, eval/one: -0.7379, eval/two: -0.7708, eval/three: -0.5601 \n",
      "Epoch: 20, train/loss: 6.3466, eval/loss: 9.6891, train/r2: -0.1874, eval/r2: -0.3897, train/one: 0.0009, train/two: -0.4564, train/three: -0.1068, eval/one: -0.4785, eval/two: -0.4284, eval/three: -0.2622 \n",
      "Epoch: 25, train/loss: 5.6465, eval/loss: 7.4207, train/r2: -0.0686, eval/r2: -0.0489, train/one: 0.1119, train/two: -0.3333, train/three: 0.0156, eval/one: -0.1300, eval/two: -0.0103, eval/three: -0.0063 \n",
      "Epoch: 30, train/loss: 5.5835, eval/loss: 6.1931, train/r2: -0.0875, eval/r2: 0.0247, train/one: 0.1246, train/two: -0.4071, train/three: 0.0201, eval/one: 0.0768, eval/two: 0.0005, eval/three: -0.0032 \n",
      "Epoch: 35, train/loss: 5.5386, eval/loss: 6.1993, train/r2: -0.0578, eval/r2: 0.0390, train/one: 0.1296, train/two: -0.3377, train/three: 0.0347, eval/one: 0.0756, eval/two: 0.0539, eval/three: -0.0126 \n",
      "Epoch: 40, train/loss: 5.3359, eval/loss: 7.4927, train/r2: 0.0091, eval/r2: -0.0718, train/one: 0.1576, train/two: -0.2203, train/three: 0.0900, eval/one: -0.1493, eval/two: -0.1596, eval/three: 0.0935 \n",
      "Epoch: 45, train/loss: 5.0872, eval/loss: 9.3610, train/r2: 0.0218, eval/r2: -0.2050, train/one: 0.1991, train/two: -0.2679, train/three: 0.1341, eval/one: -0.4641, eval/two: -0.2560, eval/three: 0.1051 \n",
      "Epoch: 50, train/loss: 4.8320, eval/loss: 9.3844, train/r2: 0.0542, eval/r2: -0.1644, train/one: 0.2426, train/two: -0.2339, train/three: 0.1538, eval/one: -0.4667, eval/two: -0.0835, eval/three: 0.0569 \n",
      "Epoch: 55, train/loss: 4.6691, eval/loss: 8.4738, train/r2: 0.0687, eval/r2: -0.0828, train/one: 0.2711, train/two: -0.2273, train/three: 0.1623, eval/one: -0.3171, eval/two: -0.0160, eval/three: 0.0846 \n",
      "Epoch: 60, train/loss: 4.3188, eval/loss: 6.4120, train/r2: 0.1186, eval/r2: 0.0583, train/one: 0.3332, train/two: -0.1355, train/three: 0.1580, eval/one: 0.0255, eval/two: 0.0154, eval/three: 0.1340 \n",
      "Epoch: 65, train/loss: 4.0567, eval/loss: 5.5596, train/r2: 0.1167, eval/r2: 0.1374, train/one: 0.3745, train/two: -0.2675, train/three: 0.2430, eval/one: 0.1611, eval/two: 0.0390, eval/three: 0.2120 \n",
      "Epoch: 70, train/loss: 3.8949, eval/loss: 5.0963, train/r2: 0.1187, eval/r2: 0.1682, train/one: 0.4073, train/two: -0.2621, train/three: 0.2109, eval/one: 0.2386, eval/two: 0.0483, eval/three: 0.2177 \n",
      "Epoch: 75, train/loss: 3.5347, eval/loss: 4.7594, train/r2: 0.1933, eval/r2: 0.1986, train/one: 0.4628, train/two: -0.1655, train/three: 0.2826, eval/one: 0.2930, eval/two: 0.0641, eval/three: 0.2386 \n",
      "Epoch: 80, train/loss: 3.4231, eval/loss: 4.4275, train/r2: 0.1770, eval/r2: 0.2369, train/one: 0.4845, train/two: -0.2388, train/three: 0.2852, eval/one: 0.3433, eval/two: 0.0738, eval/three: 0.2938 \n",
      "Epoch: 85, train/loss: 3.2612, eval/loss: 4.2412, train/r2: 0.2111, eval/r2: 0.2548, train/one: 0.5077, train/two: -0.2101, train/three: 0.3355, eval/one: 0.3721, eval/two: 0.0727, eval/three: 0.3196 \n",
      "Epoch: 90, train/loss: 3.4964, eval/loss: 4.1813, train/r2: 0.1984, eval/r2: 0.2591, train/one: 0.4644, train/two: -0.2104, train/three: 0.3412, eval/one: 0.3822, eval/two: 0.0758, eval/three: 0.3195 \n",
      "Epoch: 95, train/loss: 3.2637, eval/loss: 3.9598, train/r2: 0.2256, eval/r2: 0.2743, train/one: 0.5020, train/two: -0.2085, train/three: 0.3832, eval/one: 0.4193, eval/two: 0.0819, eval/three: 0.3218 \n",
      "Epoch: 100, train/loss: 3.0349, eval/loss: 3.9046, train/r2: 0.3078, eval/r2: 0.2922, train/one: 0.5343, train/two: -0.0443, train/three: 0.4332, eval/one: 0.4238, eval/two: 0.0848, eval/three: 0.3681 \n",
      "Epoch: 105, train/loss: 2.8975, eval/loss: 3.8236, train/r2: 0.2765, eval/r2: 0.2925, train/one: 0.5622, train/two: -0.1652, train/three: 0.4324, eval/one: 0.4393, eval/two: 0.0884, eval/three: 0.3499 \n",
      "Epoch: 110, train/loss: 2.8383, eval/loss: 3.8652, train/r2: 0.2727, eval/r2: 0.2933, train/one: 0.5732, train/two: -0.1911, train/three: 0.4361, eval/one: 0.4308, eval/two: 0.0847, eval/three: 0.3644 \n",
      "Epoch: 115, train/loss: 2.7770, eval/loss: 3.7501, train/r2: 0.3128, eval/r2: 0.2749, train/one: 0.5768, train/two: -0.1304, train/three: 0.4919, eval/one: 0.4585, eval/two: 0.0819, eval/three: 0.2841 \n",
      "Epoch: 120, train/loss: 2.7874, eval/loss: 3.6486, train/r2: 0.3125, eval/r2: 0.3261, train/one: 0.5739, train/two: -0.1390, train/three: 0.5025, eval/one: 0.4601, eval/two: 0.0814, eval/three: 0.4366 \n",
      "Epoch: 125, train/loss: 2.6968, eval/loss: 3.7734, train/r2: 0.3176, eval/r2: 0.2902, train/one: 0.5892, train/two: -0.1532, train/three: 0.5168, eval/one: 0.4487, eval/two: 0.0802, eval/three: 0.3417 \n",
      "Epoch: 130, train/loss: 2.7136, eval/loss: 3.6320, train/r2: 0.3264, eval/r2: 0.3393, train/one: 0.5828, train/two: -0.1506, train/three: 0.5470, eval/one: 0.4593, eval/two: 0.0873, eval/three: 0.4713 \n",
      "Epoch: 135, train/loss: 2.6111, eval/loss: 3.6584, train/r2: 0.3461, eval/r2: 0.3359, train/one: 0.5977, train/two: -0.1371, train/three: 0.5776, eval/one: 0.4551, eval/two: 0.0836, eval/three: 0.4688 \n",
      "Epoch: 140, train/loss: 2.5753, eval/loss: 3.5991, train/r2: 0.3580, eval/r2: 0.3509, train/one: 0.6017, train/two: -0.1257, train/three: 0.5980, eval/one: 0.4615, eval/two: 0.0874, eval/three: 0.5037 \n",
      "Epoch: 145, train/loss: 2.5213, eval/loss: 3.8075, train/r2: 0.3482, eval/r2: 0.2607, train/one: 0.6163, train/two: -0.1263, train/three: 0.5547, eval/one: 0.4522, eval/two: 0.0787, eval/three: 0.2513 \n",
      "Epoch: 150, train/loss: 3.1538, eval/loss: 3.6327, train/r2: 0.2735, eval/r2: 0.3273, train/one: 0.5119, train/two: -0.1560, train/three: 0.4647, eval/one: 0.4629, eval/two: 0.0836, eval/three: 0.4353 \n",
      "Epoch: 155, train/loss: 2.4901, eval/loss: 3.5847, train/r2: 0.3482, eval/r2: 0.3161, train/one: 0.6194, train/two: -0.1603, train/three: 0.5855, eval/one: 0.4741, eval/two: 0.0661, eval/three: 0.4082 \n",
      "Epoch: 160, train/loss: 2.6777, eval/loss: 4.8910, train/r2: 0.3381, eval/r2: 0.1523, train/one: 0.5909, train/two: -0.0981, train/three: 0.5215, eval/one: 0.2850, eval/two: 0.0745, eval/three: 0.0975 \n",
      "Epoch: 165, train/loss: 2.5009, eval/loss: 3.6179, train/r2: 0.3626, eval/r2: 0.3083, train/one: 0.6185, train/two: -0.0918, train/three: 0.5611, eval/one: 0.4711, eval/two: 0.0718, eval/three: 0.3820 \n",
      "Epoch: 170, train/loss: 2.3793, eval/loss: 3.4887, train/r2: 0.3858, eval/r2: 0.3511, train/one: 0.6359, train/two: -0.0802, train/three: 0.6015, eval/one: 0.4818, eval/two: 0.0824, eval/three: 0.4892 \n",
      "Epoch: 175, train/loss: 2.3114, eval/loss: 3.5305, train/r2: 0.3797, eval/r2: 0.3578, train/one: 0.6485, train/two: -0.1165, train/three: 0.6072, eval/one: 0.4728, eval/two: 0.0958, eval/three: 0.5047 \n",
      "Epoch: 180, train/loss: 2.2249, eval/loss: 3.5558, train/r2: 0.4084, eval/r2: 0.3255, train/one: 0.6589, train/two: -0.0822, train/three: 0.6484, eval/one: 0.4788, eval/two: 0.0925, eval/three: 0.4052 \n",
      "Epoch: 185, train/loss: 2.2228, eval/loss: 3.4849, train/r2: 0.3912, eval/r2: 0.3689, train/one: 0.6615, train/two: -0.1257, train/three: 0.6378, eval/one: 0.4770, eval/two: 0.0889, eval/three: 0.5409 \n",
      "Epoch: 190, train/loss: 2.1421, eval/loss: 3.4482, train/r2: 0.3828, eval/r2: 0.3724, train/one: 0.6756, train/two: -0.1822, train/three: 0.6549, eval/one: 0.4834, eval/two: 0.0967, eval/three: 0.5371 \n",
      "Epoch: 195, train/loss: 2.1572, eval/loss: 3.7261, train/r2: 0.4311, eval/r2: 0.3268, train/one: 0.6677, train/two: -0.0477, train/three: 0.6734, eval/one: 0.4465, eval/two: 0.0949, eval/three: 0.4389 \n",
      "Epoch: 200, train/loss: 2.2488, eval/loss: 3.5706, train/r2: 0.4271, eval/r2: 0.3448, train/one: 0.6495, train/two: -0.0580, train/three: 0.6899, eval/one: 0.4692, eval/two: 0.0899, eval/three: 0.4753 \n",
      "Epoch: 205, train/loss: 2.1355, eval/loss: 3.3235, train/r2: 0.4285, eval/r2: 0.3907, train/one: 0.6720, train/two: -0.0589, train/three: 0.6723, eval/one: 0.5007, eval/two: 0.0965, eval/three: 0.5749 \n",
      "Epoch: 210, train/loss: 2.1147, eval/loss: 3.8377, train/r2: 0.4329, eval/r2: 0.3156, train/one: 0.6746, train/two: -0.0596, train/three: 0.6836, eval/one: 0.4294, eval/two: 0.0953, eval/three: 0.4221 \n",
      "Epoch: 215, train/loss: 1.9677, eval/loss: 3.5692, train/r2: 0.4573, eval/r2: 0.3784, train/one: 0.6990, train/two: -0.0247, train/three: 0.6976, eval/one: 0.4583, eval/two: 0.0933, eval/three: 0.5834 \n",
      "Epoch: 220, train/loss: 1.9473, eval/loss: 3.4505, train/r2: 0.4542, eval/r2: 0.3848, train/one: 0.7026, train/two: -0.0425, train/three: 0.7024, eval/one: 0.4789, eval/two: 0.0980, eval/three: 0.5774 \n",
      "Epoch: 225, train/loss: 1.8976, eval/loss: 3.4142, train/r2: 0.4601, eval/r2: 0.3962, train/one: 0.7104, train/two: -0.0438, train/three: 0.7138, eval/one: 0.4823, eval/two: 0.1027, eval/three: 0.6037 \n",
      "Epoch: 230, train/loss: 1.9093, eval/loss: 3.5098, train/r2: 0.4429, eval/r2: 0.3832, train/one: 0.7091, train/two: -0.0981, train/three: 0.7178, eval/one: 0.4686, eval/two: 0.1019, eval/three: 0.5792 \n",
      "Epoch: 235, train/loss: 1.8036, eval/loss: 3.4160, train/r2: 0.4780, eval/r2: 0.3692, train/one: 0.7246, train/two: -0.0274, train/three: 0.7369, eval/one: 0.4909, eval/two: 0.1007, eval/three: 0.5160 \n",
      "Epoch: 240, train/loss: 1.8359, eval/loss: 3.3470, train/r2: 0.4513, eval/r2: 0.3865, train/one: 0.7220, train/two: -0.0874, train/three: 0.7193, eval/one: 0.4976, eval/two: 0.0961, eval/three: 0.5659 \n",
      "Epoch: 245, train/loss: 1.8781, eval/loss: 3.1688, train/r2: 0.4387, eval/r2: 0.4207, train/one: 0.7150, train/two: -0.1185, train/three: 0.7195, eval/one: 0.5194, eval/two: 0.0951, eval/three: 0.6476 \n",
      "Epoch: 250, train/loss: 1.8257, eval/loss: 3.3962, train/r2: 0.4692, eval/r2: 0.4016, train/one: 0.7214, train/two: -0.0470, train/three: 0.7333, eval/one: 0.4835, eval/two: 0.0994, eval/three: 0.6217 \n",
      "Epoch: 255, train/loss: 1.8436, eval/loss: 3.4555, train/r2: 0.4661, eval/r2: 0.4053, train/one: 0.7180, train/two: -0.0560, train/three: 0.7364, eval/one: 0.4705, eval/two: 0.0925, eval/three: 0.6527 \n",
      "Epoch: 260, train/loss: 1.9092, eval/loss: 3.2505, train/r2: 0.4582, eval/r2: 0.3847, train/one: 0.7056, train/two: -0.0756, train/three: 0.7445, eval/one: 0.5163, eval/two: 0.0957, eval/three: 0.5420 \n",
      "Epoch: 265, train/loss: 1.8356, eval/loss: 3.4727, train/r2: 0.4719, eval/r2: 0.4142, train/one: 0.7188, train/two: -0.0428, train/three: 0.7399, eval/one: 0.4649, eval/two: 0.0996, eval/three: 0.6780 \n",
      "Epoch: 270, train/loss: 1.7486, eval/loss: 3.2172, train/r2: 0.4667, eval/r2: 0.4269, train/one: 0.7359, train/two: -0.0689, train/three: 0.7330, eval/one: 0.5082, eval/two: 0.0948, eval/three: 0.6778 \n",
      "Epoch: 275, train/loss: 1.7087, eval/loss: 3.0811, train/r2: 0.4695, eval/r2: 0.4382, train/one: 0.7411, train/two: -0.0889, train/three: 0.7563, eval/one: 0.5304, eval/two: 0.1004, eval/three: 0.6836 \n",
      "Epoch: 280, train/loss: 1.6555, eval/loss: 3.2841, train/r2: 0.4828, eval/r2: 0.4152, train/one: 0.7489, train/two: -0.0698, train/three: 0.7693, eval/one: 0.5004, eval/two: 0.1045, eval/three: 0.6406 \n",
      "Epoch: 285, train/loss: 1.6677, eval/loss: 3.2163, train/r2: 0.4864, eval/r2: 0.3996, train/one: 0.7485, train/two: -0.0354, train/three: 0.7460, eval/one: 0.5183, eval/two: 0.1019, eval/three: 0.5787 \n",
      "Epoch: 290, train/loss: 1.6632, eval/loss: 3.2872, train/r2: 0.4759, eval/r2: 0.4187, train/one: 0.7494, train/two: -0.0749, train/three: 0.7532, eval/one: 0.4982, eval/two: 0.0995, eval/three: 0.6582 \n",
      "Epoch: 295, train/loss: 1.6380, eval/loss: 3.3903, train/r2: 0.4796, eval/r2: 0.3408, train/one: 0.7523, train/two: -0.0840, train/three: 0.7703, eval/one: 0.5054, eval/two: 0.1005, eval/three: 0.4165 \n",
      "Epoch: 300, train/loss: 1.5803, eval/loss: 3.3034, train/r2: 0.4763, eval/r2: 0.4162, train/one: 0.7630, train/two: -0.1082, train/three: 0.7742, eval/one: 0.4965, eval/two: 0.1050, eval/three: 0.6472 \n",
      "Epoch: 305, train/loss: 1.5761, eval/loss: 3.6542, train/r2: 0.5083, eval/r2: 0.2865, train/one: 0.7628, train/two: 0.0033, train/three: 0.7587, eval/one: 0.4746, eval/two: 0.1041, eval/three: 0.2810 \n",
      "Epoch: 310, train/loss: 1.5430, eval/loss: 3.0977, train/r2: 0.5024, eval/r2: 0.4252, train/one: 0.7676, train/two: -0.0394, train/three: 0.7792, eval/one: 0.5323, eval/two: 0.1065, eval/three: 0.6368 \n",
      "Epoch: 315, train/loss: 1.5364, eval/loss: 3.3995, train/r2: 0.4963, eval/r2: 0.3499, train/one: 0.7706, train/two: -0.0456, train/three: 0.7640, eval/one: 0.5010, eval/two: 0.1052, eval/three: 0.4434 \n",
      "Epoch: 320, train/loss: 1.4915, eval/loss: 3.3065, train/r2: 0.5223, eval/r2: 0.4051, train/one: 0.7756, train/two: 0.0098, train/three: 0.7817, eval/one: 0.4998, eval/two: 0.1064, eval/three: 0.6092 \n",
      "Epoch: 325, train/loss: 1.5314, eval/loss: 3.2852, train/r2: 0.4991, eval/r2: 0.4210, train/one: 0.7701, train/two: -0.0508, train/three: 0.7782, eval/one: 0.4984, eval/two: 0.1059, eval/three: 0.6587 \n",
      "Epoch: 330, train/loss: 1.5470, eval/loss: 3.5097, train/r2: 0.4940, eval/r2: 0.3596, train/one: 0.7678, train/two: -0.0614, train/three: 0.7756, eval/one: 0.4772, eval/two: 0.1072, eval/three: 0.4943 \n",
      "Epoch: 335, train/loss: 1.5069, eval/loss: 3.1761, train/r2: 0.5068, eval/r2: 0.4106, train/one: 0.7745, train/two: -0.0275, train/three: 0.7736, eval/one: 0.5225, eval/two: 0.1061, eval/three: 0.6030 \n",
      "Epoch: 340, train/loss: 1.4611, eval/loss: 3.2843, train/r2: 0.5227, eval/r2: 0.3823, train/one: 0.7804, train/two: -0.0026, train/three: 0.7903, eval/one: 0.5121, eval/two: 0.1099, eval/three: 0.5249 \n",
      "Epoch: 345, train/loss: 1.4990, eval/loss: 3.5125, train/r2: 0.5258, eval/r2: 0.3706, train/one: 0.7737, train/two: 0.0201, train/three: 0.7836, eval/one: 0.4733, eval/two: 0.1118, eval/three: 0.5267 \n",
      "Epoch: 350, train/loss: 1.4964, eval/loss: 3.6265, train/r2: 0.5039, eval/r2: 0.4047, train/one: 0.7758, train/two: -0.0475, train/three: 0.7835, eval/one: 0.4401, eval/two: 0.1097, eval/three: 0.6644 \n",
      "Epoch: 355, train/loss: 1.4500, eval/loss: 3.2090, train/r2: 0.5247, eval/r2: 0.4227, train/one: 0.7820, train/two: -0.0019, train/three: 0.7938, eval/one: 0.5121, eval/two: 0.1051, eval/three: 0.6509 \n",
      "Epoch: 360, train/loss: 1.4939, eval/loss: 3.2060, train/r2: 0.4799, eval/r2: 0.4297, train/one: 0.7783, train/two: -0.1185, train/three: 0.7799, eval/one: 0.5103, eval/two: 0.1056, eval/three: 0.6731 \n",
      "Epoch: 365, train/loss: 1.4452, eval/loss: 3.2845, train/r2: 0.5190, eval/r2: 0.4238, train/one: 0.7846, train/two: -0.0070, train/three: 0.7795, eval/one: 0.4977, eval/two: 0.1077, eval/three: 0.6659 \n",
      "Epoch: 370, train/loss: 1.4355, eval/loss: 3.2255, train/r2: 0.5174, eval/r2: 0.4354, train/one: 0.7855, train/two: -0.0246, train/three: 0.7912, eval/one: 0.5049, eval/two: 0.1084, eval/three: 0.6929 \n",
      "Epoch: 375, train/loss: 1.4206, eval/loss: 3.1696, train/r2: 0.5076, eval/r2: 0.4398, train/one: 0.7886, train/two: -0.0609, train/three: 0.7952, eval/one: 0.5140, eval/two: 0.1090, eval/three: 0.6963 \n",
      "Epoch: 380, train/loss: 1.4277, eval/loss: 3.3317, train/r2: 0.4944, eval/r2: 0.4297, train/one: 0.7895, train/two: -0.0868, train/three: 0.7806, eval/one: 0.4871, eval/two: 0.1108, eval/three: 0.6910 \n",
      "Epoch: 385, train/loss: 1.4305, eval/loss: 3.1864, train/r2: 0.5119, eval/r2: 0.4386, train/one: 0.7868, train/two: -0.0419, train/three: 0.7908, eval/one: 0.5114, eval/two: 0.1103, eval/three: 0.6941 \n",
      "Epoch: 390, train/loss: 1.4322, eval/loss: 3.2411, train/r2: 0.5312, eval/r2: 0.4341, train/one: 0.7855, train/two: 0.0211, train/three: 0.7871, eval/one: 0.5027, eval/two: 0.1113, eval/three: 0.6883 \n",
      "Epoch: 395, train/loss: 1.4082, eval/loss: 3.3651, train/r2: 0.5060, eval/r2: 0.4286, train/one: 0.7917, train/two: -0.0610, train/three: 0.7871, eval/one: 0.4813, eval/two: 0.1116, eval/three: 0.6931 \n",
      "Epoch: 400, train/loss: 1.3928, eval/loss: 3.2211, train/r2: 0.5208, eval/r2: 0.4378, train/one: 0.7923, train/two: -0.0308, train/three: 0.8009, eval/one: 0.5052, eval/two: 0.1106, eval/three: 0.6976 \n",
      "Epoch: 405, train/loss: 1.3834, eval/loss: 3.2001, train/r2: 0.5396, eval/r2: 0.4354, train/one: 0.7933, train/two: 0.0312, train/three: 0.7942, eval/one: 0.5099, eval/two: 0.1109, eval/three: 0.6854 \n",
      "Epoch: 410, train/loss: 1.4005, eval/loss: 3.2869, train/r2: 0.5022, eval/r2: 0.4339, train/one: 0.7926, train/two: -0.0829, train/three: 0.7968, eval/one: 0.4941, eval/two: 0.1112, eval/three: 0.6963 \n",
      "Epoch: 415, train/loss: 1.4173, eval/loss: 3.2856, train/r2: 0.5231, eval/r2: 0.4322, train/one: 0.7885, train/two: -0.0105, train/three: 0.7913, eval/one: 0.4951, eval/two: 0.1127, eval/three: 0.6887 \n",
      "Epoch: 420, train/loss: 1.3498, eval/loss: 3.2536, train/r2: 0.5422, eval/r2: 0.4376, train/one: 0.7979, train/two: 0.0177, train/three: 0.8111, eval/one: 0.4992, eval/two: 0.1119, eval/three: 0.7016 \n",
      "Epoch: 425, train/loss: 1.3510, eval/loss: 3.2748, train/r2: 0.5350, eval/r2: 0.4368, train/one: 0.7995, train/two: 0.0089, train/three: 0.7968, eval/one: 0.4954, eval/two: 0.1105, eval/three: 0.7046 \n",
      "Epoch: 430, train/loss: 1.3811, eval/loss: 3.2759, train/r2: 0.5188, eval/r2: 0.4372, train/one: 0.7939, train/two: -0.0470, train/three: 0.8094, eval/one: 0.4953, eval/two: 0.1131, eval/three: 0.7032 \n",
      "Epoch: 435, train/loss: 1.3549, eval/loss: 3.2934, train/r2: 0.5329, eval/r2: 0.4336, train/one: 0.7979, train/two: -0.0077, train/three: 0.8084, eval/one: 0.4931, eval/two: 0.1119, eval/three: 0.6960 \n",
      "Epoch: 440, train/loss: 1.3706, eval/loss: 3.2198, train/r2: 0.5236, eval/r2: 0.4408, train/one: 0.7962, train/two: -0.0265, train/three: 0.8010, eval/one: 0.5045, eval/two: 0.1119, eval/three: 0.7060 \n",
      "Epoch: 445, train/loss: 1.3600, eval/loss: 3.2309, train/r2: 0.5172, eval/r2: 0.4390, train/one: 0.7988, train/two: -0.0469, train/three: 0.7997, eval/one: 0.5030, eval/two: 0.1116, eval/three: 0.7024 \n",
      "Epoch: 450, train/loss: 1.3688, eval/loss: 3.2656, train/r2: 0.5307, eval/r2: 0.4380, train/one: 0.7963, train/two: -0.0033, train/three: 0.7991, eval/one: 0.4969, eval/two: 0.1124, eval/three: 0.7048 \n",
      "Epoch: 455, train/loss: 1.3599, eval/loss: 3.2458, train/r2: 0.5355, eval/r2: 0.4396, train/one: 0.7976, train/two: 0.0098, train/three: 0.7991, eval/one: 0.5001, eval/two: 0.1127, eval/three: 0.7061 \n",
      "Epoch: 460, train/loss: 1.3475, eval/loss: 3.2611, train/r2: 0.5353, eval/r2: 0.4389, train/one: 0.8004, train/two: 0.0119, train/three: 0.7935, eval/one: 0.4974, eval/two: 0.1125, eval/three: 0.7069 \n",
      "Epoch: 465, train/loss: 1.3773, eval/loss: 3.2804, train/r2: 0.5274, eval/r2: 0.4382, train/one: 0.7953, train/two: -0.0081, train/three: 0.7950, eval/one: 0.4940, eval/two: 0.1123, eval/three: 0.7084 \n",
      "Epoch: 470, train/loss: 1.3563, eval/loss: 3.2593, train/r2: 0.5282, eval/r2: 0.4373, train/one: 0.7987, train/two: -0.0141, train/three: 0.8001, eval/one: 0.4983, eval/two: 0.1121, eval/three: 0.7016 \n",
      "Epoch: 475, train/loss: 1.3755, eval/loss: 3.2695, train/r2: 0.5268, eval/r2: 0.4365, train/one: 0.7951, train/two: -0.0156, train/three: 0.8008, eval/one: 0.4966, eval/two: 0.1124, eval/three: 0.7006 \n",
      "Epoch: 480, train/loss: 1.3403, eval/loss: 3.2600, train/r2: 0.5470, eval/r2: 0.4384, train/one: 0.8009, train/two: 0.0465, train/three: 0.7938, eval/one: 0.4978, eval/two: 0.1121, eval/three: 0.7052 \n",
      "Epoch: 485, train/loss: 1.3911, eval/loss: 3.2576, train/r2: 0.5098, eval/r2: 0.4390, train/one: 0.7944, train/two: -0.0550, train/three: 0.7899, eval/one: 0.4980, eval/two: 0.1120, eval/three: 0.7071 \n",
      "Epoch: 490, train/loss: 1.3514, eval/loss: 3.2532, train/r2: 0.5197, eval/r2: 0.4393, train/one: 0.7997, train/two: -0.0457, train/three: 0.8051, eval/one: 0.4987, eval/two: 0.1119, eval/three: 0.7073 \n",
      "Epoch: 495, train/loss: 1.3714, eval/loss: 3.2527, train/r2: 0.5126, eval/r2: 0.4392, train/one: 0.7986, train/two: -0.0428, train/three: 0.7820, eval/one: 0.4988, eval/two: 0.1119, eval/three: 0.7069 \n",
      "[neptune] [info   ] Shutting down background jobs, please wait a moment...\n",
      "[neptune] [info   ] Done!\n",
      "[neptune] [info   ] Waiting for the remaining 187 operations to synchronize with Neptune. Do not kill this process.\n",
      "[neptune] [info   ] All 187 operations synced, thanks for waiting!\n",
      "[neptune] [info   ] Explore the metadata in the Neptune app: https://app.neptune.ai/arbaaz/kaggle-spect/e/KAG-117/metadata\n",
      "[neptune] [info   ] Neptune initialized. Open in the app: https://app.neptune.ai/arbaaz/kaggle-spect/e/KAG-118\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e32fb8250ad6490cb798f2d6fae445f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:227: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, train/loss: 10.0982, eval/loss: 12.7455, train/r2: -0.8499, eval/r2: -1.1427, train/one: -0.6414, train/two: -1.4154, train/three: -0.4930, eval/one: -0.8497, eval/two: -1.9075, eval/three: -0.6707 \n",
      "Epoch: 5, train/loss: 9.7241, eval/loss: 12.6161, train/r2: -0.7870, eval/r2: -1.0415, train/one: -0.5790, train/two: -1.3314, train/three: -0.4507, eval/one: -0.8394, eval/two: -1.6787, eval/three: -0.6065 \n",
      "Epoch: 10, train/loss: 8.5579, eval/loss: 12.3292, train/r2: -0.5874, eval/r2: -0.9300, train/one: -0.3865, train/two: -1.0759, train/three: -0.2999, eval/one: -0.8052, eval/two: -1.4617, eval/three: -0.5232 \n",
      "Epoch: 15, train/loss: 7.1142, eval/loss: 11.3702, train/r2: -0.3519, eval/r2: -0.7293, train/one: -0.1449, train/two: -0.7709, train/three: -0.1398, eval/one: -0.6727, eval/two: -1.1743, eval/three: -0.3409 \n",
      "Epoch: 20, train/loss: 5.9114, eval/loss: 9.0523, train/r2: -0.1116, eval/r2: -0.3318, train/one: 0.0520, train/two: -0.3938, train/three: 0.0071, eval/one: -0.3332, eval/two: -0.5784, eval/three: -0.0838 \n",
      "Epoch: 25, train/loss: 5.6378, eval/loss: 7.8446, train/r2: -0.0575, eval/r2: -0.0950, train/one: 0.0989, train/two: -0.2888, train/three: 0.0173, eval/one: -0.1539, eval/two: -0.1251, eval/three: -0.0059 \n",
      "Epoch: 30, train/loss: 5.5127, eval/loss: 7.0888, train/r2: -0.0711, eval/r2: -0.0135, train/one: 0.1193, train/two: -0.3965, train/three: 0.0638, eval/one: -0.0340, eval/two: -0.0030, eval/three: -0.0034 \n",
      "Epoch: 35, train/loss: 5.3949, eval/loss: 7.0600, train/r2: 0.0098, eval/r2: 0.0091, train/one: 0.1336, train/two: -0.1925, train/three: 0.0882, eval/one: -0.0387, eval/two: -0.0364, eval/three: 0.1025 \n",
      "Epoch: 40, train/loss: 5.2474, eval/loss: 7.5574, train/r2: 0.0409, eval/r2: -0.0798, train/one: 0.1547, train/two: -0.1708, train/three: 0.1388, eval/one: -0.1140, eval/two: -0.2077, eval/three: 0.0821 \n",
      "Epoch: 45, train/loss: 4.8829, eval/loss: 8.2354, train/r2: 0.0841, eval/r2: -0.1325, train/one: 0.2152, train/two: -0.1599, train/three: 0.1971, eval/one: -0.2229, eval/two: -0.2561, eval/three: 0.0816 \n",
      "Epoch: 50, train/loss: 4.7956, eval/loss: 8.5949, train/r2: 0.0775, eval/r2: -0.1175, train/one: 0.2315, train/two: -0.2039, train/three: 0.2050, eval/one: -0.2895, eval/two: -0.2245, eval/three: 0.1615 \n",
      "Epoch: 55, train/loss: 4.3524, eval/loss: 6.8776, train/r2: 0.1349, eval/r2: 0.0029, train/one: 0.3074, train/two: -0.1487, train/three: 0.2460, eval/one: -0.0153, eval/two: -0.1710, eval/three: 0.1951 \n",
      "Epoch: 60, train/loss: 4.0139, eval/loss: 6.2382, train/r2: 0.1458, eval/r2: 0.0461, train/one: 0.3705, train/two: -0.1804, train/three: 0.2473, eval/one: 0.0871, eval/two: -0.1546, eval/three: 0.2057 \n",
      "Epoch: 65, train/loss: 4.3098, eval/loss: 6.1747, train/r2: 0.1196, eval/r2: 0.0776, train/one: 0.3146, train/two: -0.2229, train/three: 0.2672, eval/one: 0.0931, eval/two: -0.0993, eval/three: 0.2390 \n",
      "Epoch: 70, train/loss: 3.7994, eval/loss: 4.8194, train/r2: 0.1861, eval/r2: 0.2003, train/one: 0.4030, train/two: -0.1498, train/three: 0.3050, eval/one: 0.3054, eval/two: -0.0016, eval/three: 0.2970 \n",
      "Epoch: 75, train/loss: 3.5421, eval/loss: 4.2583, train/r2: 0.1840, eval/r2: 0.2254, train/one: 0.4483, train/two: -0.2396, train/three: 0.3433, eval/one: 0.3986, eval/two: 0.0049, eval/three: 0.2726 \n",
      "Epoch: 80, train/loss: 3.3412, eval/loss: 4.6947, train/r2: 0.2023, eval/r2: 0.2140, train/one: 0.4831, train/two: -0.2394, train/three: 0.3634, eval/one: 0.3231, eval/two: -0.0057, eval/three: 0.3247 \n",
      "Epoch: 85, train/loss: 3.1362, eval/loss: 4.9191, train/r2: 0.2758, eval/r2: 0.2125, train/one: 0.5147, train/two: -0.0721, train/three: 0.3850, eval/one: 0.2812, eval/two: -0.0317, eval/three: 0.3880 \n",
      "Epoch: 90, train/loss: 3.1690, eval/loss: 4.4908, train/r2: 0.2682, eval/r2: 0.2148, train/one: 0.5042, train/two: -0.1380, train/three: 0.4384, eval/one: 0.3539, eval/two: -0.0718, eval/three: 0.3624 \n",
      "Epoch: 95, train/loss: 3.0010, eval/loss: 4.3240, train/r2: 0.2646, eval/r2: 0.2630, train/one: 0.5355, train/two: -0.1872, train/three: 0.4453, eval/one: 0.3753, eval/two: 0.0089, eval/three: 0.4050 \n",
      "Epoch: 100, train/loss: 2.8805, eval/loss: 3.9692, train/r2: 0.2660, eval/r2: 0.2996, train/one: 0.5559, train/two: -0.2287, train/three: 0.4707, eval/one: 0.4265, eval/two: -0.0012, eval/three: 0.4736 \n",
      "Epoch: 105, train/loss: 2.7886, eval/loss: 4.3715, train/r2: 0.3031, eval/r2: 0.2815, train/one: 0.5694, train/two: -0.1446, train/three: 0.4846, eval/one: 0.3594, eval/two: -0.0093, eval/three: 0.4943 \n",
      "Epoch: 110, train/loss: 2.6912, eval/loss: 3.7585, train/r2: 0.3144, eval/r2: 0.3252, train/one: 0.5840, train/two: -0.1580, train/three: 0.5170, eval/one: 0.4563, eval/two: 0.0004, eval/three: 0.5190 \n",
      "Epoch: 115, train/loss: 2.5975, eval/loss: 4.0565, train/r2: 0.3499, eval/r2: 0.3013, train/one: 0.5975, train/two: -0.0836, train/three: 0.5356, eval/one: 0.4099, eval/two: -0.0056, eval/three: 0.4996 \n",
      "Epoch: 120, train/loss: 2.5792, eval/loss: 4.1531, train/r2: 0.3256, eval/r2: 0.3202, train/one: 0.6055, train/two: -0.1344, train/three: 0.5056, eval/one: 0.3887, eval/two: 0.0195, eval/three: 0.5525 \n",
      "Epoch: 125, train/loss: 2.7967, eval/loss: 4.0403, train/r2: 0.3300, eval/r2: 0.3086, train/one: 0.5615, train/two: -0.1049, train/three: 0.5334, eval/one: 0.4138, eval/two: 0.0341, eval/three: 0.4781 \n",
      "Epoch: 130, train/loss: 2.6355, eval/loss: 3.6731, train/r2: 0.3642, eval/r2: 0.3322, train/one: 0.5860, train/two: -0.0656, train/three: 0.5722, eval/one: 0.4735, eval/two: 0.0498, eval/three: 0.4733 \n",
      "Epoch: 135, train/loss: 2.5352, eval/loss: 3.8411, train/r2: 0.3516, eval/r2: 0.3520, train/one: 0.6078, train/two: -0.1037, train/three: 0.5508, eval/one: 0.4349, eval/two: 0.0228, eval/three: 0.5983 \n",
      "Epoch: 140, train/loss: 2.3832, eval/loss: 3.8199, train/r2: 0.3696, eval/r2: 0.2982, train/one: 0.6335, train/two: -0.0943, train/three: 0.5697, eval/one: 0.4552, eval/two: 0.0178, eval/three: 0.4216 \n",
      "Epoch: 145, train/loss: 2.2982, eval/loss: 3.9129, train/r2: 0.3584, eval/r2: 0.2123, train/one: 0.6457, train/two: -0.1926, train/three: 0.6220, eval/one: 0.4644, eval/two: 0.0028, eval/three: 0.1697 \n",
      "Epoch: 150, train/loss: 2.3334, eval/loss: 3.9509, train/r2: 0.4027, eval/r2: 0.2333, train/one: 0.6357, train/two: -0.0516, train/three: 0.6240, eval/one: 0.4499, eval/two: -0.0101, eval/three: 0.2601 \n",
      "Epoch: 155, train/loss: 2.2162, eval/loss: 3.9057, train/r2: 0.3848, eval/r2: 0.3424, train/one: 0.6594, train/two: -0.1260, train/three: 0.6210, eval/one: 0.4258, eval/two: 0.0156, eval/three: 0.5858 \n",
      "Epoch: 160, train/loss: 2.1382, eval/loss: 3.8202, train/r2: 0.4098, eval/r2: 0.3263, train/one: 0.6699, train/two: -0.0888, train/three: 0.6483, eval/one: 0.4470, eval/two: 0.0259, eval/three: 0.5061 \n",
      "Epoch: 165, train/loss: 2.6649, eval/loss: 6.1770, train/r2: 0.3242, eval/r2: 0.1310, train/one: 0.5874, train/two: -0.1415, train/three: 0.5269, eval/one: 0.0869, eval/two: 0.0341, eval/three: 0.2719 \n",
      "Epoch: 170, train/loss: 2.2803, eval/loss: 6.2702, train/r2: 0.4028, eval/r2: 0.1862, train/one: 0.6451, train/two: -0.0673, train/three: 0.6307, eval/one: 0.0539, eval/two: 0.0466, eval/three: 0.4579 \n",
      "Epoch: 175, train/loss: 2.3166, eval/loss: 4.1265, train/r2: 0.3830, eval/r2: 0.2449, train/one: 0.6399, train/two: -0.1188, train/three: 0.6279, eval/one: 0.4205, eval/two: 0.0587, eval/three: 0.2555 \n",
      "Epoch: 180, train/loss: 2.1153, eval/loss: 4.0123, train/r2: 0.4047, eval/r2: 0.3609, train/one: 0.6771, train/two: -0.0830, train/three: 0.6201, eval/one: 0.4025, eval/two: 0.0351, eval/three: 0.6451 \n",
      "Epoch: 185, train/loss: 2.0445, eval/loss: 3.7693, train/r2: 0.4209, eval/r2: 0.1608, train/one: 0.6879, train/two: -0.0611, train/three: 0.6358, eval/one: 0.5082, eval/two: 0.0255, eval/three: -0.0514 \n",
      "Epoch: 190, train/loss: 2.0115, eval/loss: 3.8631, train/r2: 0.4142, eval/r2: 0.3047, train/one: 0.6949, train/two: -0.0850, train/three: 0.6327, eval/one: 0.4455, eval/two: 0.0191, eval/three: 0.4496 \n",
      "Epoch: 195, train/loss: 1.8720, eval/loss: 3.9083, train/r2: 0.4394, eval/r2: 0.3080, train/one: 0.7141, train/two: -0.0881, train/three: 0.6922, eval/one: 0.4374, eval/two: 0.0302, eval/three: 0.4564 \n",
      "Epoch: 200, train/loss: 1.8241, eval/loss: 4.4019, train/r2: 0.4588, eval/r2: 0.1545, train/one: 0.7227, train/two: -0.0276, train/three: 0.6813, eval/one: 0.3992, eval/two: 0.0538, eval/three: 0.0106 \n",
      "Epoch: 205, train/loss: 1.7852, eval/loss: 3.8284, train/r2: 0.4560, eval/r2: 0.3200, train/one: 0.7273, train/two: -0.0738, train/three: 0.7145, eval/one: 0.4503, eval/two: 0.0600, eval/three: 0.4499 \n",
      "Epoch: 210, train/loss: 1.8783, eval/loss: 3.7646, train/r2: 0.4388, eval/r2: 0.3063, train/one: 0.7143, train/two: -0.0755, train/three: 0.6776, eval/one: 0.4646, eval/two: 0.0427, eval/three: 0.4117 \n",
      "Epoch: 215, train/loss: 1.8217, eval/loss: 3.6125, train/r2: 0.4235, eval/r2: 0.3994, train/one: 0.7246, train/two: -0.1474, train/three: 0.6935, eval/one: 0.4635, eval/two: 0.0537, eval/three: 0.6810 \n",
      "Epoch: 220, train/loss: 1.8076, eval/loss: 3.6382, train/r2: 0.4446, eval/r2: 0.3738, train/one: 0.7221, train/two: -0.1222, train/three: 0.7340, eval/one: 0.4667, eval/two: 0.0505, eval/three: 0.6042 \n",
      "Epoch: 225, train/loss: 1.8153, eval/loss: 3.6960, train/r2: 0.4636, eval/r2: 0.3696, train/one: 0.7210, train/two: -0.0452, train/three: 0.7151, eval/one: 0.4572, eval/two: 0.0449, eval/three: 0.6066 \n",
      "Epoch: 230, train/loss: 1.6799, eval/loss: 3.7697, train/r2: 0.4763, eval/r2: 0.3976, train/one: 0.7445, train/two: -0.0440, train/three: 0.7284, eval/one: 0.4356, eval/two: 0.0501, eval/three: 0.7072 \n",
      "Epoch: 235, train/loss: 1.6943, eval/loss: 3.4810, train/r2: 0.4786, eval/r2: 0.4199, train/one: 0.7388, train/two: -0.0613, train/three: 0.7583, eval/one: 0.4803, eval/two: 0.0499, eval/three: 0.7293 \n",
      "Epoch: 240, train/loss: 1.7015, eval/loss: 3.6938, train/r2: 0.4700, eval/r2: 0.3695, train/one: 0.7398, train/two: -0.0694, train/three: 0.7396, eval/one: 0.4566, eval/two: 0.0320, eval/three: 0.6200 \n",
      "Epoch: 245, train/loss: 1.7353, eval/loss: 4.3006, train/r2: 0.4561, eval/r2: 0.2731, train/one: 0.7335, train/two: -0.1149, train/three: 0.7497, eval/one: 0.3796, eval/two: 0.0495, eval/three: 0.3903 \n",
      "Epoch: 250, train/loss: 1.5888, eval/loss: 4.0057, train/r2: 0.4917, eval/r2: 0.3729, train/one: 0.7571, train/two: -0.0491, train/three: 0.7672, eval/one: 0.4014, eval/two: 0.0536, eval/three: 0.6636 \n",
      "Epoch: 255, train/loss: 1.6189, eval/loss: 3.5990, train/r2: 0.4905, eval/r2: 0.4066, train/one: 0.7529, train/two: -0.0326, train/three: 0.7513, eval/one: 0.4631, eval/two: 0.0468, eval/three: 0.7099 \n",
      "Epoch: 260, train/loss: 1.6233, eval/loss: 3.6200, train/r2: 0.4756, eval/r2: 0.4032, train/one: 0.7517, train/two: -0.0918, train/three: 0.7669, eval/one: 0.4596, eval/two: 0.0368, eval/three: 0.7132 \n",
      "Epoch: 265, train/loss: 1.5678, eval/loss: 3.6332, train/r2: 0.5192, eval/r2: 0.4074, train/one: 0.7589, train/two: 0.0292, train/three: 0.7695, eval/one: 0.4560, eval/two: 0.0383, eval/three: 0.7279 \n",
      "Epoch: 270, train/loss: 1.6391, eval/loss: 3.5899, train/r2: 0.4691, eval/r2: 0.4086, train/one: 0.7506, train/two: -0.0942, train/three: 0.7510, eval/one: 0.4643, eval/two: 0.0491, eval/three: 0.7125 \n",
      "Epoch: 275, train/loss: 1.5629, eval/loss: 3.7657, train/r2: 0.4946, eval/r2: 0.4013, train/one: 0.7619, train/two: -0.0432, train/three: 0.7652, eval/one: 0.4347, eval/two: 0.0447, eval/three: 0.7246 \n",
      "Epoch: 280, train/loss: 1.5825, eval/loss: 4.1079, train/r2: 0.5112, eval/r2: 0.3069, train/one: 0.7568, train/two: 0.0087, train/three: 0.7682, eval/one: 0.4025, eval/two: 0.0375, eval/three: 0.4807 \n",
      "Epoch: 285, train/loss: 1.6005, eval/loss: 3.8022, train/r2: 0.4894, eval/r2: 0.3965, train/one: 0.7546, train/two: -0.0584, train/three: 0.7719, eval/one: 0.4299, eval/two: 0.0468, eval/three: 0.7128 \n",
      "Epoch: 290, train/loss: 1.5562, eval/loss: 3.7810, train/r2: 0.5118, eval/r2: 0.3933, train/one: 0.7613, train/two: 0.0009, train/three: 0.7731, eval/one: 0.4351, eval/two: 0.0517, eval/three: 0.6930 \n",
      "Epoch: 295, train/loss: 1.5065, eval/loss: 3.9785, train/r2: 0.5121, eval/r2: 0.3627, train/one: 0.7698, train/two: -0.0158, train/three: 0.7822, eval/one: 0.4098, eval/two: 0.0573, eval/three: 0.6210 \n",
      "Epoch: 300, train/loss: 1.5369, eval/loss: 3.8205, train/r2: 0.5123, eval/r2: 0.3599, train/one: 0.7648, train/two: -0.0014, train/three: 0.7735, eval/one: 0.4389, eval/two: 0.0557, eval/three: 0.5851 \n",
      "Epoch: 305, train/loss: 1.4921, eval/loss: 3.8622, train/r2: 0.5063, eval/r2: 0.3971, train/one: 0.7732, train/two: -0.0332, train/three: 0.7789, eval/one: 0.4195, eval/two: 0.0537, eval/three: 0.7181 \n",
      "Epoch: 310, train/loss: 1.4710, eval/loss: 3.7654, train/r2: 0.5204, eval/r2: 0.4059, train/one: 0.7759, train/two: 0.0030, train/three: 0.7823, eval/one: 0.4339, eval/two: 0.0513, eval/three: 0.7324 \n",
      "Epoch: 315, train/loss: 1.4908, eval/loss: 3.8982, train/r2: 0.4895, eval/r2: 0.3959, train/one: 0.7732, train/two: -0.1003, train/three: 0.7956, eval/one: 0.4135, eval/two: 0.0541, eval/three: 0.7203 \n",
      "Epoch: 320, train/loss: 1.4585, eval/loss: 3.7890, train/r2: 0.5174, eval/r2: 0.4072, train/one: 0.7792, train/two: -0.0009, train/three: 0.7739, eval/one: 0.4294, eval/two: 0.0530, eval/three: 0.7392 \n",
      "Epoch: 325, train/loss: 1.4531, eval/loss: 3.8631, train/r2: 0.5112, eval/r2: 0.4022, train/one: 0.7788, train/two: -0.0404, train/three: 0.7952, eval/one: 0.4177, eval/two: 0.0536, eval/three: 0.7352 \n",
      "Epoch: 330, train/loss: 1.4924, eval/loss: 3.9523, train/r2: 0.5036, eval/r2: 0.3928, train/one: 0.7727, train/two: -0.0482, train/three: 0.7864, eval/one: 0.4042, eval/two: 0.0476, eval/three: 0.7266 \n",
      "Epoch: 335, train/loss: 1.4669, eval/loss: 3.9208, train/r2: 0.4993, eval/r2: 0.3960, train/one: 0.7775, train/two: -0.0694, train/three: 0.7897, eval/one: 0.4083, eval/two: 0.0405, eval/three: 0.7391 \n",
      "Epoch: 340, train/loss: 1.4178, eval/loss: 3.8777, train/r2: 0.5202, eval/r2: 0.3908, train/one: 0.7833, train/two: -0.0343, train/three: 0.8114, eval/one: 0.4165, eval/two: 0.0274, eval/three: 0.7285 \n",
      "Epoch: 345, train/loss: 1.4304, eval/loss: 4.0115, train/r2: 0.5142, eval/r2: 0.3713, train/one: 0.7825, train/two: -0.0391, train/three: 0.7990, eval/one: 0.3987, eval/two: 0.0271, eval/three: 0.6880 \n",
      "Epoch: 350, train/loss: 1.4161, eval/loss: 3.9268, train/r2: 0.5212, eval/r2: 0.3795, train/one: 0.7847, train/two: -0.0200, train/three: 0.7988, eval/one: 0.4119, eval/two: 0.0349, eval/three: 0.6917 \n",
      "Epoch: 355, train/loss: 1.4001, eval/loss: 4.0393, train/r2: 0.5245, eval/r2: 0.3833, train/one: 0.7873, train/two: -0.0151, train/three: 0.8014, eval/one: 0.3911, eval/two: 0.0414, eval/three: 0.7173 \n",
      "Epoch: 360, train/loss: 1.3842, eval/loss: 3.9080, train/r2: 0.5163, eval/r2: 0.3957, train/one: 0.7902, train/two: -0.0503, train/three: 0.8092, eval/one: 0.4109, eval/two: 0.0441, eval/three: 0.7321 \n",
      "Epoch: 365, train/loss: 1.4060, eval/loss: 3.9599, train/r2: 0.5207, eval/r2: 0.3940, train/one: 0.7871, train/two: -0.0197, train/three: 0.7947, eval/one: 0.4023, eval/two: 0.0458, eval/three: 0.7338 \n",
      "Epoch: 370, train/loss: 1.3734, eval/loss: 3.9438, train/r2: 0.5281, eval/r2: 0.3933, train/one: 0.7923, train/two: -0.0073, train/three: 0.7992, eval/one: 0.4053, eval/two: 0.0438, eval/three: 0.7307 \n",
      "Epoch: 375, train/loss: 1.3888, eval/loss: 3.9760, train/r2: 0.5107, eval/r2: 0.3904, train/one: 0.7915, train/two: -0.0491, train/three: 0.7897, eval/one: 0.4001, eval/two: 0.0404, eval/three: 0.7306 \n",
      "Epoch: 380, train/loss: 1.3901, eval/loss: 3.9879, train/r2: 0.5191, eval/r2: 0.3893, train/one: 0.7895, train/two: -0.0349, train/three: 0.8027, eval/one: 0.3985, eval/two: 0.0418, eval/three: 0.7276 \n",
      "Epoch: 385, train/loss: 1.3837, eval/loss: 3.9587, train/r2: 0.5296, eval/r2: 0.3951, train/one: 0.7897, train/two: -0.0062, train/three: 0.8053, eval/one: 0.4021, eval/two: 0.0443, eval/three: 0.7390 \n",
      "Epoch: 390, train/loss: 1.3913, eval/loss: 4.0249, train/r2: 0.5135, eval/r2: 0.3924, train/one: 0.7896, train/two: -0.0517, train/three: 0.8025, eval/one: 0.3913, eval/two: 0.0471, eval/three: 0.7390 \n",
      "Epoch: 395, train/loss: 1.3279, eval/loss: 3.9267, train/r2: 0.5371, eval/r2: 0.3972, train/one: 0.8001, train/two: 0.0107, train/three: 0.8005, eval/one: 0.4074, eval/two: 0.0475, eval/three: 0.7366 \n",
      "Epoch: 400, train/loss: 1.3625, eval/loss: 3.9752, train/r2: 0.5203, eval/r2: 0.3942, train/one: 0.7948, train/two: -0.0340, train/three: 0.8001, eval/one: 0.3995, eval/two: 0.0459, eval/three: 0.7372 \n",
      "Epoch: 405, train/loss: 1.3627, eval/loss: 3.9839, train/r2: 0.5240, eval/r2: 0.3944, train/one: 0.7947, train/two: -0.0206, train/three: 0.7979, eval/one: 0.3979, eval/two: 0.0464, eval/three: 0.7390 \n",
      "Epoch: 410, train/loss: 1.3612, eval/loss: 4.0762, train/r2: 0.5196, eval/r2: 0.3900, train/one: 0.7949, train/two: -0.0383, train/three: 0.8023, eval/one: 0.3826, eval/two: 0.0437, eval/three: 0.7438 \n",
      "Epoch: 415, train/loss: 1.3741, eval/loss: 4.0503, train/r2: 0.5280, eval/r2: 0.3902, train/one: 0.7915, train/two: -0.0137, train/three: 0.8060, eval/one: 0.3868, eval/two: 0.0401, eval/three: 0.7438 \n",
      "Epoch: 420, train/loss: 1.3634, eval/loss: 4.0483, train/r2: 0.5304, eval/r2: 0.3901, train/one: 0.7942, train/two: 0.0004, train/three: 0.7966, eval/one: 0.3873, eval/two: 0.0404, eval/three: 0.7425 \n",
      "Epoch: 425, train/loss: 1.3544, eval/loss: 4.0527, train/r2: 0.5416, eval/r2: 0.3910, train/one: 0.7941, train/two: 0.0227, train/three: 0.8080, eval/one: 0.3863, eval/two: 0.0413, eval/three: 0.7453 \n",
      "Epoch: 430, train/loss: 1.3251, eval/loss: 4.0689, train/r2: 0.5249, eval/r2: 0.3881, train/one: 0.8007, train/two: -0.0358, train/three: 0.8097, eval/one: 0.3844, eval/two: 0.0423, eval/three: 0.7377 \n",
      "Epoch: 435, train/loss: 1.3518, eval/loss: 4.0307, train/r2: 0.5319, eval/r2: 0.3935, train/one: 0.7952, train/two: -0.0083, train/three: 0.8088, eval/one: 0.3897, eval/two: 0.0443, eval/three: 0.7466 \n",
      "Epoch: 440, train/loss: 1.3184, eval/loss: 4.0759, train/r2: 0.5397, eval/r2: 0.3896, train/one: 0.8018, train/two: 0.0173, train/three: 0.8000, eval/one: 0.3827, eval/two: 0.0434, eval/three: 0.7425 \n",
      "Epoch: 445, train/loss: 1.3483, eval/loss: 4.0216, train/r2: 0.5310, eval/r2: 0.3917, train/one: 0.7963, train/two: -0.0084, train/three: 0.8052, eval/one: 0.3919, eval/two: 0.0443, eval/three: 0.7389 \n",
      "Epoch: 450, train/loss: 1.3739, eval/loss: 4.0483, train/r2: 0.5156, eval/r2: 0.3921, train/one: 0.7925, train/two: -0.0510, train/three: 0.8053, eval/one: 0.3869, eval/two: 0.0435, eval/three: 0.7460 \n",
      "Epoch: 455, train/loss: 1.3526, eval/loss: 4.0607, train/r2: 0.5179, eval/r2: 0.3885, train/one: 0.7974, train/two: -0.0375, train/three: 0.7937, eval/one: 0.3858, eval/two: 0.0437, eval/three: 0.7362 \n",
      "Epoch: 460, train/loss: 1.3727, eval/loss: 4.0244, train/r2: 0.5394, eval/r2: 0.3930, train/one: 0.7912, train/two: 0.0232, train/three: 0.8040, eval/one: 0.3909, eval/two: 0.0439, eval/three: 0.7442 \n",
      "Epoch: 465, train/loss: 1.3325, eval/loss: 4.0625, train/r2: 0.5357, eval/r2: 0.3912, train/one: 0.7992, train/two: 0.0054, train/three: 0.8026, eval/one: 0.3846, eval/two: 0.0439, eval/three: 0.7451 \n",
      "Epoch: 470, train/loss: 1.3587, eval/loss: 4.0659, train/r2: 0.5320, eval/r2: 0.3905, train/one: 0.7936, train/two: -0.0090, train/three: 0.8115, eval/one: 0.3843, eval/two: 0.0440, eval/three: 0.7432 \n",
      "Epoch: 475, train/loss: 1.3295, eval/loss: 4.0549, train/r2: 0.5202, eval/r2: 0.3911, train/one: 0.8012, train/two: -0.0394, train/three: 0.7988, eval/one: 0.3861, eval/two: 0.0440, eval/three: 0.7432 \n",
      "Epoch: 480, train/loss: 1.3748, eval/loss: 4.0513, train/r2: 0.5311, eval/r2: 0.3916, train/one: 0.7910, train/two: -0.0057, train/three: 0.8078, eval/one: 0.3865, eval/two: 0.0437, eval/three: 0.7446 \n",
      "Epoch: 485, train/loss: 1.3262, eval/loss: 4.0537, train/r2: 0.5414, eval/r2: 0.3915, train/one: 0.7998, train/two: 0.0199, train/three: 0.8046, eval/one: 0.3861, eval/two: 0.0436, eval/three: 0.7447 \n",
      "Epoch: 490, train/loss: 1.3326, eval/loss: 4.0523, train/r2: 0.5406, eval/r2: 0.3914, train/one: 0.7981, train/two: 0.0130, train/three: 0.8107, eval/one: 0.3864, eval/two: 0.0436, eval/three: 0.7441 \n",
      "Epoch: 495, train/loss: 1.3365, eval/loss: 4.0521, train/r2: 0.5352, eval/r2: 0.3913, train/one: 0.7971, train/two: -0.0087, train/three: 0.8173, eval/one: 0.3865, eval/two: 0.0436, eval/three: 0.7439 \n",
      "[neptune] [info   ] Shutting down background jobs, please wait a moment...\n",
      "[neptune] [info   ] Done!\n",
      "[neptune] [info   ] Waiting for the remaining 176 operations to synchronize with Neptune. Do not kill this process.\n",
      "[neptune] [info   ] All 176 operations synced, thanks for waiting!\n",
      "[neptune] [info   ] Explore the metadata in the Neptune app: https://app.neptune.ai/arbaaz/kaggle-spect/e/KAG-118/metadata\n",
      "[neptune] [info   ] Neptune initialized. Open in the app: https://app.neptune.ai/arbaaz/kaggle-spect/e/KAG-119\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c4d03a48e41401ab4cb3aced02e08c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:227: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, train/loss: 11.4333, eval/loss: 9.4346, train/r2: -0.9897, eval/r2: -0.8921, train/one: -0.7744, train/two: -1.5552, train/three: -0.6396, eval/one: -0.6093, eval/two: -1.3454, eval/three: -0.7215 \n",
      "Epoch: 5, train/loss: 10.9800, eval/loss: 9.3908, train/r2: -0.8953, eval/r2: -0.8613, train/one: -0.7037, train/two: -1.3912, train/three: -0.5909, eval/one: -0.6024, eval/two: -1.2599, eval/three: -0.7217 \n",
      "Epoch: 10, train/loss: 9.7212, eval/loss: 9.4655, train/r2: -0.7125, eval/r2: -0.8209, train/one: -0.4957, train/two: -1.1129, train/three: -0.5288, eval/one: -0.6228, eval/two: -1.1490, eval/three: -0.6911 \n",
      "Epoch: 15, train/loss: 8.2117, eval/loss: 9.3854, train/r2: -0.5111, eval/r2: -0.7661, train/one: -0.2425, train/two: -0.8089, train/three: -0.4819, eval/one: -0.6158, eval/two: -1.0513, eval/three: -0.6313 \n",
      "Epoch: 20, train/loss: 6.7399, eval/loss: 7.4951, train/r2: -0.2501, eval/r2: -0.4621, train/one: -0.0097, train/two: -0.4146, train/three: -0.3260, eval/one: -0.2739, eval/two: -0.6709, eval/three: -0.4416 \n",
      "Epoch: 25, train/loss: 5.9395, eval/loss: 5.8760, train/r2: -0.1152, eval/r2: -0.1043, train/one: 0.1009, train/two: -0.3975, train/three: -0.0489, eval/one: -0.0061, eval/two: -0.2266, eval/three: -0.0802 \n",
      "Epoch: 30, train/loss: 5.7681, eval/loss: 6.0084, train/r2: -0.0786, eval/r2: -0.1152, train/one: 0.1221, train/two: -0.3905, train/three: 0.0325, eval/one: -0.0392, eval/two: -0.3022, eval/three: -0.0043 \n",
      "Epoch: 35, train/loss: 5.7388, eval/loss: 5.2669, train/r2: -0.0624, eval/r2: 0.0550, train/one: 0.1283, train/two: -0.3245, train/three: 0.0092, eval/one: 0.0905, eval/two: -0.0094, eval/three: 0.0837 \n",
      "Epoch: 40, train/loss: 5.5525, eval/loss: 4.9150, train/r2: -0.0120, eval/r2: 0.1215, train/one: 0.1533, train/two: -0.2556, train/three: 0.0663, eval/one: 0.1485, eval/two: 0.0448, eval/three: 0.1712 \n",
      "Epoch: 45, train/loss: 5.2670, eval/loss: 4.9021, train/r2: 0.0245, eval/r2: 0.1040, train/one: 0.1987, train/two: -0.2306, train/three: 0.1054, eval/one: 0.1536, eval/two: 0.0015, eval/three: 0.1567 \n",
      "Epoch: 50, train/loss: 4.9278, eval/loss: 5.2664, train/r2: 0.0940, eval/r2: 0.0720, train/one: 0.2488, train/two: -0.1420, train/three: 0.1751, eval/one: 0.0837, eval/two: -0.0122, eval/three: 0.1445 \n",
      "Epoch: 55, train/loss: 4.5345, eval/loss: 4.5448, train/r2: 0.0845, eval/r2: 0.1236, train/one: 0.3223, train/two: -0.2189, train/three: 0.1501, eval/one: 0.2239, eval/two: -0.0107, eval/three: 0.1575 \n",
      "Epoch: 60, train/loss: 4.1241, eval/loss: 5.6607, train/r2: 0.1355, eval/r2: 0.0032, train/one: 0.3880, train/two: -0.1842, train/three: 0.2027, eval/one: 0.0095, eval/two: -0.1390, eval/three: 0.1393 \n",
      "Epoch: 65, train/loss: 3.8213, eval/loss: 3.9432, train/r2: 0.1801, eval/r2: 0.2128, train/one: 0.4371, train/two: -0.1251, train/three: 0.2284, eval/one: 0.3276, eval/two: 0.0345, eval/three: 0.2764 \n",
      "Epoch: 70, train/loss: 3.6277, eval/loss: 4.0333, train/r2: 0.1574, eval/r2: 0.2078, train/one: 0.4737, train/two: -0.2274, train/three: 0.2260, eval/one: 0.3102, eval/two: 0.0404, eval/three: 0.2728 \n",
      "Epoch: 75, train/loss: 3.4768, eval/loss: 3.9289, train/r2: 0.1752, eval/r2: 0.2049, train/one: 0.4926, train/two: -0.2750, train/three: 0.3080, eval/one: 0.3348, eval/two: 0.0438, eval/three: 0.2360 \n",
      "Epoch: 80, train/loss: 3.3484, eval/loss: 3.7785, train/r2: 0.2141, eval/r2: 0.2312, train/one: 0.5099, train/two: -0.2102, train/three: 0.3427, eval/one: 0.3580, eval/two: 0.0442, eval/three: 0.2915 \n",
      "Epoch: 85, train/loss: 3.3443, eval/loss: 3.9607, train/r2: 0.2182, eval/r2: 0.2161, train/one: 0.5081, train/two: -0.2226, train/three: 0.3691, eval/one: 0.3227, eval/two: 0.0375, eval/three: 0.2881 \n",
      "Epoch: 90, train/loss: 3.1113, eval/loss: 3.6029, train/r2: 0.2281, eval/r2: 0.2551, train/one: 0.5485, train/two: -0.2424, train/three: 0.3784, eval/one: 0.3811, eval/two: -0.0182, eval/three: 0.4023 \n",
      "Epoch: 95, train/loss: 3.0021, eval/loss: 3.7777, train/r2: 0.2665, eval/r2: 0.2423, train/one: 0.5587, train/two: -0.2160, train/three: 0.4568, eval/one: 0.3431, eval/two: -0.0585, eval/three: 0.4422 \n",
      "Epoch: 100, train/loss: 2.8686, eval/loss: 4.0356, train/r2: 0.2731, eval/r2: 0.2107, train/one: 0.5831, train/two: -0.2108, train/three: 0.4471, eval/one: 0.3038, eval/two: -0.0044, eval/three: 0.3326 \n",
      "Epoch: 105, train/loss: 2.9006, eval/loss: 3.4598, train/r2: 0.2729, eval/r2: 0.2749, train/one: 0.5750, train/two: -0.2307, train/three: 0.4744, eval/one: 0.4008, eval/two: -0.0598, eval/three: 0.4836 \n",
      "Epoch: 110, train/loss: 2.8636, eval/loss: 3.6073, train/r2: 0.2879, eval/r2: 0.2892, train/one: 0.5781, train/two: -0.2171, train/three: 0.5026, eval/one: 0.3702, eval/two: 0.0117, eval/three: 0.4855 \n",
      "Epoch: 115, train/loss: 2.8319, eval/loss: 4.5050, train/r2: 0.3050, eval/r2: 0.1915, train/one: 0.5833, train/two: -0.1637, train/three: 0.4954, eval/one: 0.2012, eval/two: -0.0612, eval/three: 0.4346 \n",
      "Epoch: 120, train/loss: 2.6520, eval/loss: 3.8772, train/r2: 0.3430, eval/r2: 0.1979, train/one: 0.6081, train/two: -0.1305, train/three: 0.5513, eval/one: 0.3272, eval/two: -0.1615, eval/three: 0.4280 \n",
      "Epoch: 125, train/loss: 2.7135, eval/loss: 3.4172, train/r2: 0.3415, eval/r2: 0.3011, train/one: 0.6012, train/two: -0.0809, train/three: 0.5041, eval/one: 0.4013, eval/two: -0.0491, eval/three: 0.5513 \n",
      "Epoch: 130, train/loss: 2.5015, eval/loss: 3.2323, train/r2: 0.3546, eval/r2: 0.2853, train/one: 0.6322, train/two: -0.1453, train/three: 0.5770, eval/one: 0.4574, eval/two: 0.0363, eval/three: 0.3620 \n",
      "Epoch: 135, train/loss: 2.5944, eval/loss: 3.4055, train/r2: 0.3336, eval/r2: 0.3260, train/one: 0.6195, train/two: -0.1658, train/three: 0.5471, eval/one: 0.3987, eval/two: -0.0071, eval/three: 0.5864 \n",
      "Epoch: 140, train/loss: 2.6652, eval/loss: 3.5112, train/r2: 0.3231, eval/r2: 0.1671, train/one: 0.6081, train/two: -0.1791, train/three: 0.5403, eval/one: 0.4336, eval/two: -0.0342, eval/three: 0.1019 \n",
      "Epoch: 145, train/loss: 2.5968, eval/loss: 3.3950, train/r2: 0.3691, eval/r2: 0.1717, train/one: 0.6139, train/two: -0.0844, train/three: 0.5777, eval/one: 0.4522, eval/two: -0.0853, eval/three: 0.1483 \n",
      "Epoch: 150, train/loss: 2.4199, eval/loss: 3.8681, train/r2: 0.3560, eval/r2: 0.1359, train/one: 0.6460, train/two: -0.1634, train/three: 0.5854, eval/one: 0.3480, eval/two: -0.2097, eval/three: 0.2693 \n",
      "Epoch: 155, train/loss: 2.4629, eval/loss: 3.5129, train/r2: 0.3429, eval/r2: 0.3111, train/one: 0.6391, train/two: -0.1966, train/three: 0.5860, eval/one: 0.3766, eval/two: -0.0459, eval/three: 0.6027 \n",
      "Epoch: 160, train/loss: 2.3759, eval/loss: 3.2953, train/r2: 0.3798, eval/r2: 0.3121, train/one: 0.6490, train/two: -0.1322, train/three: 0.6227, eval/one: 0.4283, eval/two: -0.0091, eval/three: 0.5172 \n",
      "Epoch: 165, train/loss: 2.3578, eval/loss: 3.3623, train/r2: 0.3564, eval/r2: 0.2726, train/one: 0.6552, train/two: -0.1947, train/three: 0.6087, eval/one: 0.4277, eval/two: -0.0184, eval/three: 0.4085 \n",
      "Epoch: 170, train/loss: 2.3758, eval/loss: 3.4745, train/r2: 0.3808, eval/r2: 0.2057, train/one: 0.6475, train/two: -0.1448, train/three: 0.6398, eval/one: 0.4328, eval/two: 0.0214, eval/three: 0.1629 \n",
      "Epoch: 175, train/loss: 2.2676, eval/loss: 3.1984, train/r2: 0.3905, eval/r2: 0.2384, train/one: 0.6660, train/two: -0.1371, train/three: 0.6426, eval/one: 0.4774, eval/two: -0.0158, eval/three: 0.2537 \n",
      "Epoch: 180, train/loss: 2.2203, eval/loss: 3.4755, train/r2: 0.4133, eval/r2: 0.2623, train/one: 0.6713, train/two: -0.0934, train/three: 0.6621, eval/one: 0.4091, eval/two: 0.0059, eval/three: 0.3720 \n",
      "Epoch: 185, train/loss: 2.2064, eval/loss: 3.1336, train/r2: 0.4133, eval/r2: 0.3409, train/one: 0.6728, train/two: -0.1062, train/three: 0.6733, eval/one: 0.4542, eval/two: 0.0027, eval/three: 0.5657 \n",
      "Epoch: 190, train/loss: 2.1777, eval/loss: 3.3269, train/r2: 0.4264, eval/r2: 0.3350, train/one: 0.6767, train/two: -0.0744, train/three: 0.6767, eval/one: 0.4122, eval/two: -0.0113, eval/three: 0.6040 \n",
      "Epoch: 195, train/loss: 2.1925, eval/loss: 3.2504, train/r2: 0.4356, eval/r2: 0.2753, train/one: 0.6733, train/two: -0.0451, train/three: 0.6787, eval/one: 0.4536, eval/two: 0.0026, eval/three: 0.3696 \n",
      "Epoch: 200, train/loss: 2.1363, eval/loss: 3.4425, train/r2: 0.4295, eval/r2: 0.3372, train/one: 0.6840, train/two: -0.0716, train/three: 0.6762, eval/one: 0.3811, eval/two: -0.0554, eval/three: 0.6859 \n",
      "Epoch: 205, train/loss: 2.1124, eval/loss: 3.3100, train/r2: 0.4371, eval/r2: 0.3126, train/one: 0.6870, train/two: -0.0610, train/three: 0.6852, eval/one: 0.4272, eval/two: 0.0136, eval/three: 0.4969 \n",
      "Epoch: 210, train/loss: 2.0187, eval/loss: 2.9125, train/r2: 0.4427, eval/r2: 0.3883, train/one: 0.7017, train/two: -0.0792, train/three: 0.7056, eval/one: 0.4831, eval/two: -0.0149, eval/three: 0.6968 \n",
      "Epoch: 215, train/loss: 2.0708, eval/loss: 3.4152, train/r2: 0.4301, eval/r2: 0.2069, train/one: 0.6933, train/two: -0.1075, train/three: 0.7046, eval/one: 0.4452, eval/two: 0.0191, eval/three: 0.1564 \n",
      "Epoch: 220, train/loss: 2.0279, eval/loss: 3.0454, train/r2: 0.4491, eval/r2: 0.3615, train/one: 0.7007, train/two: -0.0462, train/three: 0.6930, eval/one: 0.4636, eval/two: -0.0187, eval/three: 0.6397 \n",
      "Epoch: 225, train/loss: 2.3374, eval/loss: 4.2238, train/r2: 0.3736, eval/r2: 0.2836, train/one: 0.6540, train/two: -0.1840, train/three: 0.6507, eval/one: 0.2372, eval/two: 0.0255, eval/three: 0.5881 \n",
      "Epoch: 230, train/loss: 2.2568, eval/loss: 2.7559, train/r2: 0.3961, eval/r2: 0.3878, train/one: 0.6668, train/two: -0.1306, train/three: 0.6521, eval/one: 0.5143, eval/two: -0.0498, eval/three: 0.6988 \n",
      "Epoch: 235, train/loss: 2.1581, eval/loss: 3.2222, train/r2: 0.4057, eval/r2: 0.3516, train/one: 0.6822, train/two: -0.1361, train/three: 0.6711, eval/one: 0.4261, eval/two: -0.0389, eval/three: 0.6677 \n",
      "Epoch: 240, train/loss: 2.0685, eval/loss: 3.1923, train/r2: 0.4295, eval/r2: 0.3492, train/one: 0.6924, train/two: -0.1243, train/three: 0.7203, eval/one: 0.4375, eval/two: -0.0025, eval/three: 0.6127 \n",
      "Epoch: 245, train/loss: 2.0352, eval/loss: 2.7179, train/r2: 0.4417, eval/r2: 0.4088, train/one: 0.7009, train/two: -0.0573, train/three: 0.6813, eval/one: 0.5203, eval/two: 0.0039, eval/three: 0.7023 \n",
      "Epoch: 250, train/loss: 1.9436, eval/loss: 2.7270, train/r2: 0.4768, eval/r2: 0.4074, train/one: 0.7116, train/two: -0.0001, train/three: 0.7189, eval/one: 0.5185, eval/two: 0.0003, eval/three: 0.7034 \n",
      "Epoch: 255, train/loss: 1.9612, eval/loss: 2.7959, train/r2: 0.4466, eval/r2: 0.3673, train/one: 0.7127, train/two: -0.0671, train/three: 0.6942, eval/one: 0.5199, eval/two: 0.0121, eval/three: 0.5698 \n",
      "Epoch: 260, train/loss: 1.9063, eval/loss: 3.1729, train/r2: 0.4501, eval/r2: 0.2286, train/one: 0.7199, train/two: -0.0925, train/three: 0.7228, eval/one: 0.4902, eval/two: 0.0157, eval/three: 0.1799 \n",
      "Epoch: 265, train/loss: 1.8843, eval/loss: 3.1992, train/r2: 0.4669, eval/r2: 0.1885, train/one: 0.7215, train/two: -0.0576, train/three: 0.7367, eval/one: 0.5020, eval/two: 0.0370, eval/three: 0.0266 \n",
      "Epoch: 270, train/loss: 1.9184, eval/loss: 2.8953, train/r2: 0.4610, eval/r2: 0.2880, train/one: 0.7185, train/two: -0.0404, train/three: 0.7050, eval/one: 0.5311, eval/two: 0.0373, eval/three: 0.2957 \n",
      "Epoch: 275, train/loss: 1.8977, eval/loss: 2.8805, train/r2: 0.4529, eval/r2: 0.3504, train/one: 0.7210, train/two: -0.0886, train/three: 0.7262, eval/one: 0.5084, eval/two: 0.0187, eval/three: 0.5240 \n",
      "Epoch: 280, train/loss: 1.8528, eval/loss: 2.6585, train/r2: 0.4869, eval/r2: 0.4110, train/one: 0.7263, train/two: 0.0047, train/three: 0.7298, eval/one: 0.5341, eval/two: 0.0179, eval/three: 0.6811 \n",
      "Epoch: 285, train/loss: 1.8707, eval/loss: 2.7679, train/r2: 0.4632, eval/r2: 0.3840, train/one: 0.7231, train/two: -0.0825, train/three: 0.7489, eval/one: 0.5203, eval/two: 0.0185, eval/three: 0.6132 \n",
      "Epoch: 290, train/loss: 1.8247, eval/loss: 2.7122, train/r2: 0.4721, eval/r2: 0.3931, train/one: 0.7305, train/two: -0.0663, train/three: 0.7521, eval/one: 0.5246, eval/two: -0.0255, eval/three: 0.6801 \n",
      "Epoch: 295, train/loss: 1.8405, eval/loss: 2.8186, train/r2: 0.4751, eval/r2: 0.3024, train/one: 0.7284, train/two: -0.0437, train/three: 0.7406, eval/one: 0.5412, eval/two: 0.0245, eval/three: 0.3416 \n",
      "Epoch: 300, train/loss: 1.8337, eval/loss: 3.0236, train/r2: 0.4860, eval/r2: 0.4037, train/one: 0.7279, train/two: -0.0222, train/three: 0.7524, eval/one: 0.4545, eval/two: 0.0039, eval/three: 0.7527 \n",
      "Epoch: 305, train/loss: 1.8511, eval/loss: 2.6770, train/r2: 0.4719, eval/r2: 0.4044, train/one: 0.7260, train/two: -0.0599, train/three: 0.7497, eval/one: 0.5328, eval/two: 0.0204, eval/three: 0.6599 \n",
      "Epoch: 310, train/loss: 1.7895, eval/loss: 2.9104, train/r2: 0.4782, eval/r2: 0.3748, train/one: 0.7353, train/two: -0.0653, train/three: 0.7646, eval/one: 0.4884, eval/two: -0.0187, eval/three: 0.6546 \n",
      "Epoch: 315, train/loss: 1.7889, eval/loss: 2.6090, train/r2: 0.4923, eval/r2: 0.4283, train/one: 0.7344, train/two: -0.0226, train/three: 0.7651, eval/one: 0.5365, eval/two: 0.0002, eval/three: 0.7482 \n",
      "Epoch: 320, train/loss: 1.7555, eval/loss: 2.7492, train/r2: 0.5027, eval/r2: 0.4161, train/one: 0.7403, train/two: 0.0102, train/three: 0.7576, eval/one: 0.5086, eval/two: -0.0146, eval/three: 0.7544 \n",
      "Epoch: 325, train/loss: 1.7211, eval/loss: 2.6273, train/r2: 0.4818, eval/r2: 0.3930, train/one: 0.7483, train/two: -0.0562, train/three: 0.7533, eval/one: 0.5481, eval/two: 0.0192, eval/three: 0.6117 \n",
      "Epoch: 330, train/loss: 1.7643, eval/loss: 2.8276, train/r2: 0.4810, eval/r2: 0.3692, train/one: 0.7411, train/two: -0.0461, train/three: 0.7480, eval/one: 0.5134, eval/two: 0.0240, eval/three: 0.5701 \n",
      "Epoch: 335, train/loss: 1.7227, eval/loss: 2.6876, train/r2: 0.4710, eval/r2: 0.4229, train/one: 0.7485, train/two: -0.0931, train/three: 0.7577, eval/one: 0.5210, eval/two: -0.0017, eval/three: 0.7492 \n",
      "Epoch: 340, train/loss: 1.6908, eval/loss: 2.5201, train/r2: 0.4827, eval/r2: 0.4471, train/one: 0.7534, train/two: -0.0627, train/three: 0.7573, eval/one: 0.5517, eval/two: 0.0260, eval/three: 0.7637 \n",
      "Epoch: 345, train/loss: 1.6900, eval/loss: 2.5121, train/r2: 0.5045, eval/r2: 0.4495, train/one: 0.7524, train/two: 0.0087, train/three: 0.7524, eval/one: 0.5529, eval/two: 0.0289, eval/three: 0.7666 \n",
      "Epoch: 350, train/loss: 1.6734, eval/loss: 2.5489, train/r2: 0.4938, eval/r2: 0.4407, train/one: 0.7550, train/two: -0.0394, train/three: 0.7658, eval/one: 0.5456, eval/two: 0.0046, eval/three: 0.7719 \n",
      "Epoch: 355, train/loss: 1.6585, eval/loss: 2.6981, train/r2: 0.4818, eval/r2: 0.4055, train/one: 0.7597, train/two: -0.0661, train/three: 0.7518, eval/one: 0.5272, eval/two: 0.0155, eval/three: 0.6737 \n",
      "Epoch: 360, train/loss: 1.6562, eval/loss: 2.5217, train/r2: 0.4883, eval/r2: 0.4385, train/one: 0.7588, train/two: -0.0555, train/three: 0.7616, eval/one: 0.5541, eval/two: 0.0209, eval/three: 0.7404 \n",
      "Epoch: 365, train/loss: 1.6457, eval/loss: 2.5392, train/r2: 0.4898, eval/r2: 0.4379, train/one: 0.7602, train/two: -0.0580, train/three: 0.7671, eval/one: 0.5489, eval/two: 0.0060, eval/three: 0.7589 \n",
      "Epoch: 370, train/loss: 1.6531, eval/loss: 2.5833, train/r2: 0.4966, eval/r2: 0.4287, train/one: 0.7590, train/two: -0.0289, train/three: 0.7598, eval/one: 0.5432, eval/two: 0.0104, eval/three: 0.7325 \n",
      "Epoch: 375, train/loss: 1.6321, eval/loss: 2.7186, train/r2: 0.5070, eval/r2: 0.4177, train/one: 0.7610, train/two: -0.0111, train/three: 0.7711, eval/one: 0.5170, eval/two: 0.0066, eval/three: 0.7297 \n",
      "Epoch: 380, train/loss: 1.6047, eval/loss: 2.5838, train/r2: 0.5048, eval/r2: 0.4309, train/one: 0.7656, train/two: -0.0286, train/three: 0.7776, eval/one: 0.5412, eval/two: 0.0012, eval/three: 0.7504 \n",
      "Epoch: 385, train/loss: 1.6152, eval/loss: 2.5382, train/r2: 0.4924, eval/r2: 0.4388, train/one: 0.7654, train/two: -0.0556, train/three: 0.7673, eval/one: 0.5475, eval/two: -0.0056, eval/three: 0.7746 \n",
      "Epoch: 390, train/loss: 1.5990, eval/loss: 2.5543, train/r2: 0.5151, eval/r2: 0.4404, train/one: 0.7661, train/two: 0.0043, train/three: 0.7750, eval/one: 0.5443, eval/two: 0.0028, eval/three: 0.7740 \n",
      "Epoch: 395, train/loss: 1.6211, eval/loss: 2.6469, train/r2: 0.4847, eval/r2: 0.4400, train/one: 0.7649, train/two: -0.0788, train/three: 0.7680, eval/one: 0.5264, eval/two: 0.0259, eval/three: 0.7676 \n",
      "Epoch: 400, train/loss: 1.5949, eval/loss: 2.5470, train/r2: 0.4932, eval/r2: 0.4444, train/one: 0.7687, train/two: -0.0598, train/three: 0.7707, eval/one: 0.5466, eval/two: 0.0240, eval/three: 0.7626 \n",
      "Epoch: 405, train/loss: 1.5701, eval/loss: 2.6692, train/r2: 0.5112, eval/r2: 0.4332, train/one: 0.7713, train/two: -0.0155, train/three: 0.7776, eval/one: 0.5221, eval/two: 0.0076, eval/three: 0.7697 \n",
      "Epoch: 410, train/loss: 1.5384, eval/loss: 2.5467, train/r2: 0.5144, eval/r2: 0.4429, train/one: 0.7766, train/two: -0.0132, train/three: 0.7797, eval/one: 0.5460, eval/two: 0.0128, eval/three: 0.7700 \n",
      "Epoch: 415, train/loss: 1.5387, eval/loss: 2.5189, train/r2: 0.5151, eval/r2: 0.4428, train/one: 0.7779, train/two: 0.0042, train/three: 0.7632, eval/one: 0.5525, eval/two: 0.0154, eval/three: 0.7604 \n",
      "Epoch: 420, train/loss: 1.5747, eval/loss: 2.5356, train/r2: 0.5049, eval/r2: 0.4455, train/one: 0.7719, train/two: -0.0234, train/three: 0.7661, eval/one: 0.5476, eval/two: 0.0132, eval/three: 0.7756 \n",
      "Epoch: 425, train/loss: 1.6021, eval/loss: 2.5845, train/r2: 0.4901, eval/r2: 0.4381, train/one: 0.7673, train/two: -0.0720, train/three: 0.7749, eval/one: 0.5400, eval/two: 0.0169, eval/three: 0.7575 \n",
      "Epoch: 430, train/loss: 1.5096, eval/loss: 2.7006, train/r2: 0.5112, eval/r2: 0.4334, train/one: 0.7837, train/two: -0.0105, train/three: 0.7605, eval/one: 0.5155, eval/two: 0.0116, eval/three: 0.7731 \n",
      "Epoch: 435, train/loss: 1.5475, eval/loss: 2.7615, train/r2: 0.5202, eval/r2: 0.4309, train/one: 0.7745, train/two: 0.0057, train/three: 0.7803, eval/one: 0.5033, eval/two: 0.0149, eval/three: 0.7745 \n",
      "Epoch: 440, train/loss: 1.5179, eval/loss: 2.6288, train/r2: 0.5244, eval/r2: 0.4416, train/one: 0.7790, train/two: 0.0074, train/three: 0.7868, eval/one: 0.5291, eval/two: 0.0199, eval/three: 0.7759 \n",
      "Epoch: 445, train/loss: 1.5789, eval/loss: 2.5867, train/r2: 0.4925, eval/r2: 0.4439, train/one: 0.7720, train/two: -0.0611, train/three: 0.7666, eval/one: 0.5374, eval/two: 0.0191, eval/three: 0.7753 \n",
      "Epoch: 450, train/loss: 1.5273, eval/loss: 2.5686, train/r2: 0.5294, eval/r2: 0.4469, train/one: 0.7780, train/two: 0.0354, train/three: 0.7748, eval/one: 0.5406, eval/two: 0.0219, eval/three: 0.7783 \n",
      "Epoch: 455, train/loss: 1.5166, eval/loss: 2.6336, train/r2: 0.5330, eval/r2: 0.4396, train/one: 0.7795, train/two: 0.0424, train/three: 0.7770, eval/one: 0.5289, eval/two: 0.0206, eval/three: 0.7694 \n",
      "Epoch: 460, train/loss: 1.5206, eval/loss: 2.5575, train/r2: 0.5146, eval/r2: 0.4469, train/one: 0.7801, train/two: -0.0132, train/three: 0.7768, eval/one: 0.5429, eval/two: 0.0197, eval/three: 0.7781 \n",
      "Epoch: 465, train/loss: 1.5568, eval/loss: 2.5871, train/r2: 0.5201, eval/r2: 0.4443, train/one: 0.7721, train/two: -0.0006, train/three: 0.7887, eval/one: 0.5370, eval/two: 0.0171, eval/three: 0.7786 \n",
      "Epoch: 470, train/loss: 1.5541, eval/loss: 2.5553, train/r2: 0.5160, eval/r2: 0.4466, train/one: 0.7742, train/two: 0.0003, train/three: 0.7734, eval/one: 0.5432, eval/two: 0.0174, eval/three: 0.7791 \n",
      "Epoch: 475, train/loss: 1.5374, eval/loss: 2.5631, train/r2: 0.5087, eval/r2: 0.4457, train/one: 0.7778, train/two: -0.0246, train/three: 0.7728, eval/one: 0.5418, eval/two: 0.0171, eval/three: 0.7780 \n",
      "Epoch: 480, train/loss: 1.4897, eval/loss: 2.6289, train/r2: 0.5020, eval/r2: 0.4409, train/one: 0.7861, train/two: -0.0615, train/three: 0.7813, eval/one: 0.5290, eval/two: 0.0163, eval/three: 0.7773 \n",
      "Epoch: 485, train/loss: 1.5516, eval/loss: 2.5841, train/r2: 0.5215, eval/r2: 0.4447, train/one: 0.7734, train/two: 0.0070, train/three: 0.7843, eval/one: 0.5376, eval/two: 0.0177, eval/three: 0.7789 \n",
      "Epoch: 490, train/loss: 1.5570, eval/loss: 2.5658, train/r2: 0.5072, eval/r2: 0.4464, train/one: 0.7745, train/two: -0.0245, train/three: 0.7717, eval/one: 0.5411, eval/two: 0.0187, eval/three: 0.7793 \n",
      "Epoch: 495, train/loss: 1.5764, eval/loss: 2.5703, train/r2: 0.5042, eval/r2: 0.4461, train/one: 0.7708, train/two: -0.0347, train/three: 0.7764, eval/one: 0.5402, eval/two: 0.0188, eval/three: 0.7793 \n",
      "[neptune] [info   ] Shutting down background jobs, please wait a moment...\n",
      "[neptune] [info   ] Done!\n",
      "[neptune] [info   ] Waiting for the remaining 176 operations to synchronize with Neptune. Do not kill this process.\n",
      "[neptune] [info   ] All 176 operations synced, thanks for waiting!\n",
      "[neptune] [info   ] Explore the metadata in the Neptune app: https://app.neptune.ai/arbaaz/kaggle-spect/e/KAG-119/metadata\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "\n",
    "mus, sigmas = [], []\n",
    "scores = []\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=SEED)\n",
    "splits = kfold.split(range(96))\n",
    "\n",
    "for fold, (train_idx, eval_idx) in enumerate(splits):\n",
    "    MODEL_NAME = f\"resnet.pretrain.fold.{fold}\"\n",
    "    checkpoint_name = f\"pretrain.fold.{fold}.pt\"\n",
    "    \n",
    "    train_inputs = torch.cat([inputs_list[i][train_idx] for i in range(len(inputs_list))])\n",
    "    train_targets = torch.cat([targets_list[i][train_idx] for i in range(len(inputs_list))])\n",
    "    eval_inputs = torch.cat([inputs_list[i][eval_idx] for i in range(len(inputs_list))])\n",
    "    eval_targets = torch.cat([targets_list[i][eval_idx] for i in range(len(inputs_list))])\n",
    "\n",
    "    mu, sigma = get_stats(train_inputs, p=False, r=True)\n",
    "    train_inputs = zscore(train_inputs, mu, sigma)\n",
    "    eval_inputs = zscore(eval_inputs, mu, sigma)\n",
    "    mus.append(mu)\n",
    "    sigmas.append(sigma)\n",
    "    \n",
    "    train_ds = TensorDataset(train_inputs.float(), train_targets.float())\n",
    "    eval_ds = TensorDataset(eval_inputs.float(), eval_targets.float())\n",
    "    \n",
    "    BATCH_SIZE = len(train_ds)\n",
    "    train_dl, eval_dl = return_dls(train_ds, eval_ds, BATCH_SIZE, len(eval_ds))\n",
    "    \n",
    "    model = ResNet(input_channels=2, dropout=DROPOUT).to(device)\n",
    "    if fold == 0: print(get_model_size(model))\n",
    "    \n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=LR, weight_decay=WD, foreach=True)\n",
    "    scaler = torch.amp.GradScaler(device)\n",
    "    scheduler = get_scheduler(optimizer, train_dl, EPOCHS)\n",
    "    \n",
    "    score = train(\n",
    "            model, \n",
    "            optimizer, \n",
    "            device,\n",
    "            scaler,\n",
    "            scheduler,\n",
    "            train_dl, \n",
    "            eval_dl,\n",
    "            EPOCHS,\n",
    "            checkpoint_name,\n",
    "            neptune_run=setup_neptune(),\n",
    "        )\n",
    "    \n",
    "    scores.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "04b24816",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5373212199292232, 248.6726517269414)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mus[1].item(), sigmas[1].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d63d1321",
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_path = f\"/kaggle/working/{checkpoint_name}\"\n",
    "ckpt = torch.load(ckpt_path, weights_only=False)\n",
    "ckpt[\"epoch\"], ckpt[\"score\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc86886e",
   "metadata": {},
   "outputs": [],
   "source": [
    "(443, 0.4866819899481086)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b99917",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = load_test_data()\n",
    "get_stats(test)\n",
    "test = get_spectra_features(test)\n",
    "test = torch.tensor(test)\n",
    "test = zscore(test, mu, sigma).float()\n",
    "test.shape, test.dtype, get_stats(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc6d0b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet(input_channels=2).to(device)\n",
    "model.load_state_dict(ckpt[\"state_dict\"])\n",
    "model.eval()\n",
    "\n",
    "with torch.inference_mode():\n",
    "    preds = model(test.cuda())\n",
    "\n",
    "preds = preds.cpu().detach().double().numpy()\n",
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3273410",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_stats(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62f94bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = ['Glucose', 'Sodium Acetate', 'Magnesium Sulfate']\n",
    "preds_df = pd.DataFrame(preds, columns=column_names)\n",
    "preds_df.insert(0, 'ID', [i+1 for i in range(len(preds_df))])\n",
    "preds_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a49bf07",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = MODEL_NAME+\".finetune.transfer.in.pretrain.csv\"\n",
    "preds_df.to_csv(name, index=False)\n",
    "f = pd.read_csv(f\"/kaggle/working/{name}\")\n",
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc35f1cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
