{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d75ce4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install -q  neptune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c4998a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def setup_reproducibility(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available(): torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.use_deterministic_algorithms(False, warn_only=True)\n",
    "    torch.set_float32_matmul_precision(\"high\")\n",
    "    \n",
    "SEED = 1000\n",
    "setup_reproducibility(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "185d0c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import get_cosine_schedule_with_warmup\n",
    "from scipy import signal\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from huggingface_hub import login, snapshot_download\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "def get_scheduler(optimizer, train_dl, epochs):\n",
    "    total_training_steps = len(train_dl) * epochs\n",
    "    warmup_steps = int(total_training_steps * 0.05)  # e.g. 5% warmup\n",
    "    \n",
    "    return get_cosine_schedule_with_warmup(\n",
    "        optimizer=optimizer,\n",
    "        num_warmup_steps=warmup_steps,\n",
    "        num_training_steps=total_training_steps\n",
    "    )\n",
    "\n",
    "\n",
    "def get_stats(tensor, p=True, r=False):\n",
    "    mean, std = tensor.mean(), tensor.std()\n",
    "    if p: print(f\"Mean: {mean}, Std: {std}\")\n",
    "    if r: return mean, std\n",
    "    \n",
    "    \n",
    "def zscore(tensor, mean=None, std=None):\n",
    "    if mean is None: mean = tensor.mean()\n",
    "    if std is None: std = tensor.std()\n",
    "    return (tensor - mean) / (std + 1e-8)\n",
    "\n",
    "\n",
    "def get_model_size(model):\n",
    "    print(sum(p.numel() for p in model.parameters()) / 1e6)\n",
    "    \n",
    "\n",
    "def get_index(iterable):\n",
    "    return random.randint(0, len(iterable) - 1)\n",
    "\n",
    "\n",
    "def get_indices(iterable, n):\n",
    "    return random.sample(range(len(iterable)), n)\n",
    "\n",
    "\n",
    "def split(inputs, targets, seed):\n",
    "    return train_test_split(\n",
    "        inputs,\n",
    "        targets, \n",
    "        test_size=0.2,\n",
    "        shuffle=True, \n",
    "        random_state=seed\n",
    "    ) \n",
    "\n",
    "\n",
    "def show_waves(waves, dpi=100):\n",
    "    \"\"\"\n",
    "    waves: numpy array of shape (3, N)\n",
    "    Creates three separate figures that stretch wide.\n",
    "    \"\"\"\n",
    "    N = waves.shape[1]\n",
    "    t = np.arange(N)\n",
    "\n",
    "    # Wide aspect ratio; height modest so each window fills width\n",
    "    for i in range(waves.shape[0]):\n",
    "        fig = plt.figure(figsize=(14, 4), dpi=dpi)  # wide figure\n",
    "        ax = fig.add_subplot(111)\n",
    "        ax.plot(t, waves[i], linewidth=1)\n",
    "        ax.set_title(f\"Wave {i+1}\")\n",
    "        ax.set_xlabel(\"Sample\")\n",
    "        ax.set_ylabel(\"Amplitude\")\n",
    "        ax.grid(True)\n",
    "        fig.tight_layout()  # reduce margins to use width\n",
    "        \n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "def hf_ds_download(hf_token, repo_id):\n",
    "    login(hf_token[1:])\n",
    "    return snapshot_download(repo_id, repo_type=\"dataset\")\n",
    "\n",
    "\n",
    "def get_spectra_features(X, b=False):\n",
    "    \"\"\"Create multi-channel features from spectra: raw, 1st derivative, 2nd derivative.\"\"\"\n",
    "    X_processed = np.zeros_like(X)\n",
    "    # Baseline correction and SNV\n",
    "    for i in tqdm(range(X.shape[0])):\n",
    "        poly = np.polyfit(np.arange(X.shape[1]), X[i], 3)\n",
    "        baseline = np.polyval(poly, np.arange(X.shape[1]))\n",
    "        corrected_spec = X[i] - baseline\n",
    "        #X_processed[i] = (corrected_spec - corrected_spec.mean()) / (corrected_spec.std() + 1e-8)\n",
    "        X_processed[i] = corrected_spec\n",
    "        \n",
    "    # Calculate derivatives\n",
    "    deriv1 = signal.savgol_filter(X_processed, window_length=11, polyorder=3, deriv=1, axis=1)\n",
    "    deriv2 = signal.savgol_filter(X_processed, window_length=11, polyorder=3, deriv=2, axis=1)\n",
    "\n",
    "    if b: return np.stack([X_processed, deriv1, deriv2], axis=1)\n",
    "    return np.stack([deriv1, deriv2], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3bfbf156",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 'sample_submission.csv'),\n",
       " (1, 'timegate.csv'),\n",
       " (2, 'mettler_toledo.csv'),\n",
       " (3, 'kaiser.csv'),\n",
       " (4, 'anton_532.csv'),\n",
       " (5, 'transfer_plate.csv'),\n",
       " (6, '96_samples.csv'),\n",
       " (7, 'tornado.csv'),\n",
       " (8, 'tec5.csv'),\n",
       " (9, 'metrohm.csv'),\n",
       " (10, 'anton_785.csv')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "path = \"/kaggle/input/dig-4-bio-raman-transfer-learning-challenge\"\n",
    "files = os.listdir(path)\n",
    "[(i, files[i]) for i in range(len(files))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "58096ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "def load_transfer_data():\n",
    "    csv_path = os.path.join(path, files[5])\n",
    "    df = pd.read_csv(csv_path)\n",
    "\n",
    "    input_cols = df.columns[1:2049]\n",
    "    target_cols = df.columns[2050:]\n",
    "\n",
    "    targets  = df[target_cols].dropna().to_numpy()\n",
    "\n",
    "    df = df[input_cols]\n",
    "    df['Unnamed: 1'] = df['Unnamed: 1'].str.replace(\"[\\[\\]]\", \"\", regex=True).astype('int64')\n",
    "    df['Unnamed: 2048'] = df['Unnamed: 2048'].str.replace(\"[\\[\\]]\", \"\", regex=True).astype('int64')\n",
    "\n",
    "    inputs = df.to_numpy().reshape(-1, 2, 2048)\n",
    "    inputs = inputs.mean(axis=1)\n",
    "\n",
    "    return inputs, targets\n",
    "\n",
    "\n",
    "def load_test_data():\n",
    "    test = pd.read_csv(os.path.join(path, files[6]))\n",
    "\n",
    "    row1 = test.columns[1:].to_numpy().copy()\n",
    "    row1[-1] = \"5611\"\n",
    "    row1 = row1.astype(np.float64)\n",
    "\n",
    "\n",
    "    cols = test.columns[1:]\n",
    "    test = test[cols]\n",
    "    test[\" 5611]\"] = test[\" 5611]\"].str.replace('[\\[\\]]', '', regex=True).astype('int64')\n",
    "    test = test.to_numpy()\n",
    "\n",
    "    test = np.insert(test, 0, row1, axis=0)\n",
    "    return test.reshape(-1, 2, 2048).mean(axis=1)\n",
    "\n",
    "\n",
    "def load_all_datasets():\n",
    "    train_inputs = []\n",
    "    train_targets = []\n",
    "    \n",
    "    timegate = pd.read_csv(os.path.join(path, files[1]))\n",
    "\n",
    "    timegate.drop(columns=\"fold_idx\", inplace=True)\n",
    "    timegate.drop(columns=\"MSM_present\", inplace=True)\n",
    "    timegate_inputs = timegate[timegate.columns[:-3]].to_numpy()\n",
    "    timegate_targets = timegate[timegate.columns[-3:]].to_numpy()\n",
    "\n",
    "    train_inputs.append(timegate_inputs)\n",
    "    train_targets.append(timegate_targets)\n",
    "    \n",
    "    mettler_toledo = pd.read_csv(os.path.join(path, files[2]))\n",
    "\n",
    "    mettler_toledo.drop(columns=\"fold_idx\", inplace=True)\n",
    "    mettler_toledo.drop(columns=\"MSM_present\", inplace=True)\n",
    "    mettler_toledo_inputs = mettler_toledo[mettler_toledo.columns[:-3]].to_numpy()\n",
    "    mettler_toledo_targets = mettler_toledo[mettler_toledo.columns[-3:]].to_numpy()\n",
    "\n",
    "    train_inputs.append(mettler_toledo_inputs)\n",
    "    train_targets.append(mettler_toledo_targets)\n",
    "    \n",
    "    kaiser = pd.read_csv(os.path.join(path, files[3]))\n",
    "\n",
    "    kaiser.drop(columns=\"fold_idx\", inplace=True)\n",
    "    kaiser.drop(columns=\"MSM_present\", inplace=True)\n",
    "    kaiser_inputs = kaiser[kaiser.columns[:-3]].to_numpy()\n",
    "    kaiser_targets = kaiser[kaiser.columns[-3:]].to_numpy()\n",
    "\n",
    "    train_inputs.append(kaiser_inputs)\n",
    "    train_targets.append(kaiser_targets)\n",
    "    \n",
    "    anton = pd.read_csv(os.path.join(path, files[4]))\n",
    "\n",
    "    anton.drop(columns=\"fold_idx\", inplace=True)\n",
    "    anton.drop(columns=\"MSM_present\", inplace=True)\n",
    "    anton_inputs = anton[anton.columns[:-3]].to_numpy()\n",
    "    anton_targets = anton[anton.columns[-3:]].to_numpy()\n",
    "\n",
    "    train_inputs.append(anton_inputs)\n",
    "    train_targets.append(anton_targets)\n",
    "    \n",
    "    tornado = pd.read_csv(os.path.join(path, files[7]))\n",
    "\n",
    "    tornado.drop(columns=\"fold_idx\", inplace=True)\n",
    "    tornado.drop(columns=\"MSM_present\", inplace=True)\n",
    "    tornado_inputs = tornado[tornado.columns[:-3]].to_numpy()\n",
    "    tornado_targets = tornado[tornado.columns[-3:]].to_numpy()\n",
    "\n",
    "    train_inputs.append(tornado_inputs)\n",
    "    train_targets.append(tornado_targets)\n",
    "    \n",
    "    csv_path = os.path.join(path, files[8])\n",
    "    tec5 = pd.read_csv(csv_path)\n",
    "\n",
    "    tec5.drop(columns=\"fold_idx\", inplace=True)\n",
    "    tec5.drop(columns=\"MSM_present\", inplace=True)\n",
    "    tec5_inputs = tec5[tec5.columns[:-3]].to_numpy()\n",
    "    tec5_targets = tec5[tec5.columns[-3:]].to_numpy()\n",
    "\n",
    "    train_inputs.append(tec5_inputs)\n",
    "    train_targets.append(tec5_targets)\n",
    "    \n",
    "    csv_path = os.path.join(path, files[9])\n",
    "    metrohm = pd.read_csv(csv_path)\n",
    "\n",
    "    metrohm.drop(columns=\"fold_idx\", inplace=True)\n",
    "    metrohm.drop(columns=\"MSM_present\", inplace=True)\n",
    "    metrohm_inputs = metrohm[metrohm.columns[:-3]].to_numpy()\n",
    "    metrohm_targets = metrohm[metrohm.columns[-3:]].to_numpy()\n",
    "\n",
    "    train_inputs.append(metrohm_inputs)\n",
    "    train_targets.append(metrohm_targets)\n",
    "    \n",
    "    csv_path = os.path.join(path, files[10])\n",
    "    anton785 = pd.read_csv(csv_path)\n",
    "\n",
    "    anton785.drop(columns=\"fold_idx\", inplace=True)\n",
    "    anton785.drop(columns=\"MSM_present\", inplace=True)\n",
    "    anton785_inputs = anton785[anton785.columns[:-3]].to_numpy()\n",
    "    anton785_targets = anton785[anton785.columns[-3:]].to_numpy()\n",
    "\n",
    "    train_inputs.append(anton785_inputs)\n",
    "    train_targets.append(anton785_targets)\n",
    "    \n",
    "    return train_inputs, train_targets\n",
    "\n",
    "inputs_list, targets_list = load_all_datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "40aa78b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    for i in range(len(inputs_list)):\n",
    "        indices = get_indices(inputs_list[i], 96)\n",
    "        inputs_list[i] = inputs_list[i][indices]\n",
    "        targets_list[i] = targets_list[i][indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "33584f53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e659fcd20fcc457587d2e3676a27701d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/133 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dea2bf447c1c4646b01c3aa5e32aa93b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/275 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddd1da12864343d98f3f44d5db5cb6f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/134 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14ffe05badd849b08d4c5e22e101e2c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/270 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f0fc6209b1445be83771e5015a51fe5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/385 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d39d4e0003e4da7a45313edcb060329",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/395 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ada5e4933c2e46ef8701ef79917f1574",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/399 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1179af746ec41fb8bfa3fbe254b14f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/270 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[(133, 2, 511),\n",
       " (275, 2, 2901),\n",
       " (134, 2, 6593),\n",
       " (270, 2, 1651),\n",
       " (385, 2, 3001),\n",
       " (395, 2, 3126),\n",
       " (399, 2, 1917),\n",
       " (270, 2, 1101)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_list = [get_spectra_features(inputs_list[i]) for i in range(len(inputs_list))]\n",
    "[i.shape for i in inputs_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "04b147b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([torch.Size([133, 2, 2048]),\n",
       "  torch.Size([275, 2, 2048]),\n",
       "  torch.Size([134, 2, 2048]),\n",
       "  torch.Size([270, 2, 2048]),\n",
       "  torch.Size([385, 2, 2048]),\n",
       "  torch.Size([395, 2, 2048]),\n",
       "  torch.Size([399, 2, 2048]),\n",
       "  torch.Size([270, 2, 2048])],\n",
       " [torch.Size([133, 3]),\n",
       "  torch.Size([275, 3]),\n",
       "  torch.Size([134, 3]),\n",
       "  torch.Size([270, 3]),\n",
       "  torch.Size([385, 3]),\n",
       "  torch.Size([395, 3]),\n",
       "  torch.Size([399, 3]),\n",
       "  torch.Size([270, 3])])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "def foo(inputs, targets):\n",
    "    for i in range(len(inputs)):\n",
    "        x = inputs[i]\n",
    "        x = torch.tensor(x)\n",
    "        inputs[i] = F.interpolate(x, size=2048, mode=\"nearest-exact\")\n",
    "\n",
    "    #inputs = torch.cat(inputs)\n",
    "    targets = [torch.tensor(t) for t in targets]\n",
    "    #targets = torch.cat(targets)\n",
    "    return inputs, targets\n",
    "    \n",
    "inputs_list, targets_list = foo(inputs_list, targets_list)\n",
    "[i.shape for i in inputs_list], [i.shape for i in targets_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b16a1447",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "if False:\n",
    "    for i in range(len(inputs_list)):\n",
    "        inputs = inputs_list[i]\n",
    "        targets = targets_list[i]\n",
    "        train_inputs, eval_inputs, train_targets, eval_targets = split(inputs, targets, SEED)\n",
    "        \n",
    "        inputs_list[i] = (train_inputs, eval_inputs)\n",
    "        targets_list[i] = (train_targets, eval_targets)\n",
    "        \n",
    "    def foo(inputs, targets):\n",
    "        for i in range(len(inputs)):\n",
    "            train_inputs, eval_inputs = inputs[i]\n",
    "            train_inputs = torch.tensor(train_inputs)\n",
    "            eval_inputs = torch.tensor(eval_inputs)\n",
    "            train_inputs = F.interpolate(train_inputs, size=2048, mode=\"nearest-exact\")\n",
    "            eval_inputs = F.interpolate(eval_inputs, size=2048, mode=\"nearest-exact\")   \n",
    "            inputs[i] = (train_inputs, eval_inputs)\n",
    "\n",
    "        train_inputs = [i[0] for i in inputs]\n",
    "        eval_inputs = [i[1] for i in inputs]\n",
    "        train_inputs = torch.cat(train_inputs)\n",
    "        eval_inputs = torch.cat(eval_inputs)\n",
    "        \n",
    "        train_targets = [torch.tensor(t[0]) for t in targets]\n",
    "        eval_targets = [torch.tensor(t[1]) for t in targets]\n",
    "        train_targets = torch.cat(train_targets)\n",
    "        eval_targets = torch.cat(eval_targets)\n",
    "\n",
    "        return train_inputs, eval_inputs, train_targets, eval_targets\n",
    "        \n",
    "    train_inputs, eval_inputs, train_targets, eval_targets = foo(inputs_list, targets_list)\n",
    "    train_inputs.shape, eval_inputs.shape, train_targets.shape, eval_targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "74ef9524",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1de66aea044411082022a7ee3756d3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/96 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "transfer_inputs, transfer_targets = load_transfer_data()\n",
    "transfer_inputs = get_spectra_features(transfer_inputs)\n",
    "#train_transfer_inputs, eval_transfer_inputs, train_transfer_targets, eval_transfer_targets = split(transfer_inputs, transfer_targets, SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6ac83271",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 9)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_list.append(torch.tensor(transfer_inputs))\n",
    "targets_list.append(torch.tensor(transfer_targets))\n",
    "len(targets_list), len(inputs_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5f970b1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([torch.Size([133, 2, 2048]),\n",
       "  torch.Size([275, 2, 2048]),\n",
       "  torch.Size([134, 2, 2048]),\n",
       "  torch.Size([270, 2, 2048]),\n",
       "  torch.Size([385, 2, 2048]),\n",
       "  torch.Size([395, 2, 2048]),\n",
       "  torch.Size([399, 2, 2048]),\n",
       "  torch.Size([270, 2, 2048]),\n",
       "  torch.Size([96, 2, 2048])],\n",
       " [torch.Size([133, 3]),\n",
       "  torch.Size([275, 3]),\n",
       "  torch.Size([134, 3]),\n",
       "  torch.Size([270, 3]),\n",
       "  torch.Size([385, 3]),\n",
       "  torch.Size([395, 3]),\n",
       "  torch.Size([399, 3]),\n",
       "  torch.Size([270, 3]),\n",
       "  torch.Size([96, 3])])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i.shape for i in inputs_list], [i.shape for i in targets_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2304b01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    train_inputs = torch.cat([train_inputs, torch.tensor(train_transfer_inputs)])\n",
    "    eval_inputs = torch.cat([eval_inputs, torch.tensor(eval_transfer_inputs)])\n",
    "    train_targets = torch.cat([train_targets, torch.tensor(train_transfer_targets)])\n",
    "    eval_targets = torch.cat([eval_targets, torch.tensor(eval_transfer_targets)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2788ef81",
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    min, max, mu, sigma = get_stats(train_inputs, r=True)\n",
    "    train_inputs = zscore(train_inputs)\n",
    "    eval_inputs = zscore(eval_inputs)\n",
    "    get_stats(train_inputs), get_stats(eval_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bf4e0457",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "if False:\n",
    "    train_ds = TensorDataset(train_inputs.float(), train_targets.float())\n",
    "    eval_ds = TensorDataset(eval_inputs.float(), eval_targets.float())\n",
    "    len(train_ds), len(eval_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "982956a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "def build_loader(\n",
    "    SEED,\n",
    "    ds,\n",
    "    train=True,\n",
    "    batch_size=1,\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    "    drop_last=True,\n",
    "    pin_memory=True,\n",
    "    persistent_workers=False,\n",
    "):\n",
    "    def seed_worker(worker_id):\n",
    "        worker_seed = torch.initial_seed() % 2**32\n",
    "        np.random.seed(worker_seed)\n",
    "        random.seed(worker_seed)\n",
    "\n",
    "    generator = torch.Generator()\n",
    "    generator.manual_seed(SEED if train else SEED+5232)\n",
    "\n",
    "    return DataLoader(\n",
    "        ds,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=pin_memory,\n",
    "        drop_last=drop_last,\n",
    "        persistent_workers=persistent_workers,\n",
    "        worker_init_fn=seed_worker,\n",
    "        generator=generator,\n",
    "        #sampler=DistributedSampler(\n",
    "        #    train_ds,\n",
    "        #    shuffle=True,\n",
    "        #    drop_last=True,\n",
    "        #    seed=config.seed\n",
    "        #)\n",
    "    )\n",
    "    \n",
    "    \n",
    "def return_dls(train_ds, eval_ds, train_batch_size, eval_batch_size):\n",
    "    train_dl = build_loader(\n",
    "        SEED,\n",
    "        train_ds,\n",
    "        train=True,\n",
    "        batch_size=train_batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=0,\n",
    "        drop_last=False,\n",
    "        pin_memory=True,\n",
    "        persistent_workers=False,\n",
    "    )\n",
    "\n",
    "    eval_dl = build_loader(\n",
    "        SEED,\n",
    "        eval_ds,\n",
    "        train=False,\n",
    "        batch_size=eval_batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=0,\n",
    "        drop_last=False,\n",
    "        pin_memory=True,\n",
    "        persistent_workers=False,\n",
    "    )\n",
    "    \n",
    "    return train_dl, eval_dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0ac2d7d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import neptune\n",
    "\n",
    "\n",
    "def setup_neptune():\n",
    "    if not RESUME:\n",
    "        neptune_run = neptune.init_run(\n",
    "            project=\"arbaaz/kaggle-spect\",\n",
    "            name=MODEL_NAME,\n",
    "            api_token=\"eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiJlOGE2YjNiZS1mZGUyLTRjYjItYTg5Yy1mZWJkZTIzNzE1NmIifQ==\"\n",
    "        )\n",
    "\n",
    "        neptune_run[\"h_parameters\"] = {\n",
    "            \"seed\": SEED,\n",
    "            \"model_name\": MODEL_NAME,\n",
    "            \"optimizer_name\": \"nadam\",\n",
    "            \"learning_rate\": LR,\n",
    "            \"scheduler_name\": \"default\",\n",
    "            \"weight_decay\": WD,\n",
    "            \"num_epochs\": EPOCHS,\n",
    "            \"batch_size\": BATCH_SIZE,\n",
    "        }\n",
    "        if DROPOUT: neptune_run[\"h_parameters\"] = {\"dropout\": DROPOUT}\n",
    "        if DROP_PATH_RATE: neptune_run[\"h_parameters\"] = {\"drop_path_rate\": DROP_PATH_RATE}\n",
    "    else:\n",
    "        neptune_run = neptune.init_run(\n",
    "            project=\"arbaaz/crunchdao-structural-break\",\n",
    "            with_id=config.with_id,\n",
    "            api_token=\"eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiJlOGE2YjNiZS1mZGUyLTRjYjItYTg5Yy1mZWJkZTIzNzE1NmIifQ==\"\n",
    "        )\n",
    "\n",
    "    return neptune_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "560637b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "\n",
    "def loss_fn(logits, targets):\n",
    "    logits = logits.view(-1)\n",
    "    targets = targets.view(-1)\n",
    "    return F.mse_loss(logits, targets)\n",
    "\n",
    "\n",
    "def metric_fn(logits, targets):\n",
    "    preds = logits.cpu().detach().numpy()\n",
    "    targets = targets.cpu().detach().numpy()\n",
    "    \n",
    "    dim1 = r2_score(targets[:, 0], preds[:, 0])\n",
    "    dim2 = r2_score(targets[:, 1], preds[:, 1])\n",
    "    dim3 = r2_score(targets[:, 2], preds[:, 2])\n",
    "    \n",
    "    mean_r2 = (dim1 + dim2 + dim3) / 3\n",
    "    \n",
    "    return dim1, dim2, dim3, mean_r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "47e91d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    \"\"\"A residual block with two 1D convolutional layers.\"\"\"\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels, out_channels, kernel_size, stride, padding=kernel_size//2)\n",
    "        self.bn1 = nn.BatchNorm1d(out_channels)\n",
    "        self.elu = nn.ELU()\n",
    "        self.conv2 = nn.Conv1d(out_channels, out_channels, kernel_size, padding=kernel_size//2)\n",
    "        self.bn2 = nn.BatchNorm1d(out_channels)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv1d(in_channels, out_channels, kernel_size=1, stride=stride),\n",
    "                nn.BatchNorm1d(out_channels)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.elu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = self.elu(out)\n",
    "        return out\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    \"\"\"A deeper ResNet-style 1D CNN for Raman spectra.\"\"\"\n",
    "    def __init__(self, dropout, input_channels=3, num_classes=3):\n",
    "        super().__init__()\n",
    "        self.in_channels = 64\n",
    "        self.conv1 = nn.Conv1d(input_channels, 64, kernel_size=7, stride=2, padding=3)\n",
    "        self.bn1 = nn.BatchNorm1d(64)\n",
    "        self.elu = nn.GELU()\n",
    "        self.maxpool = nn.MaxPool1d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        self.layer1 = self._make_layer(64, 2, stride=1)\n",
    "        self.layer2 = self._make_layer(128, 2, stride=2)\n",
    "        self.layer3 = self._make_layer(256, 2, stride=2)\n",
    "        self.layer4 = self._make_layer(512, 2, stride=2)\n",
    "\n",
    "        self.avgpool = nn.AdaptiveAvgPool1d(1)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ELU(),\n",
    "            nn.Dropout(dropout), # Increased dropout for better regularization\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "\n",
    "    def _make_layer(self, out_channels, num_blocks, stride):\n",
    "        strides = [stride] + [1] * (num_blocks - 1)\n",
    "        layers = []\n",
    "        for s in strides:\n",
    "            layers.append(ResidualBlock(self.in_channels, out_channels, stride=s))\n",
    "            self.in_channels = out_channels\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.elu(self.bn1(self.conv1(x)))\n",
    "        x = self.maxpool(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26cd0209",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "def train(\n",
    "    model, \n",
    "    optimizer,\n",
    "    device,\n",
    "    scaler, \n",
    "    scheduler,\n",
    "    train_dl,\n",
    "    eval_dl,\n",
    "    epochs,\n",
    "    checkpoint_name,\n",
    "    score=-float(\"inf\"),\n",
    "    neptune_run=None,\n",
    "    p=True,\n",
    "):  \n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "        all_logits = []\n",
    "        all_targets = []\n",
    "        \n",
    "        for inputs, targets in train_dl:\n",
    "            inputs = inputs.to(device, non_blocking=True)\n",
    "            targets = targets.to(device, non_blocking=True)\n",
    "            \n",
    "            with torch.amp.autocast(device_type=device, dtype=torch.float16, cache_enabled=True):\n",
    "                logits = model(inputs)\n",
    "                loss = loss_fn(logits, targets)\n",
    "            \n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            optimizer.zero_grad()\n",
    "            scheduler.step()\n",
    "            if neptune_run is not None:  neptune_run[\"lr_step\"].append(scheduler.get_last_lr()[0])\n",
    "            \n",
    "            total_loss += loss.detach().cpu()\n",
    "            all_logits.append(logits.detach().cpu())\n",
    "            all_targets.append(targets.detach().cpu())\n",
    "        \n",
    "        all_logits = torch.cat(all_logits)\n",
    "        all_targets = torch.cat(all_targets)\n",
    "\n",
    "        one, two, three, r2 = metric_fn(all_logits, all_targets)\n",
    "        total_loss = total_loss / len(train_dl)\n",
    "        \n",
    "        model.eval()\n",
    "        eval_total_loss = 0.0\n",
    "        eval_all_logits = []\n",
    "        eval_all_targets = []\n",
    "\n",
    "        for inputs, targets in eval_dl:\n",
    "            inputs = inputs.to(device, non_blocking=True)\n",
    "            targets = targets.to(device, non_blocking=True)\n",
    "\n",
    "            with torch.inference_mode():\n",
    "                #with torch.amp.autocast(device_type=device, dtype=torch.float16, cache_enabled=True):\n",
    "                logits = model(inputs)\n",
    "                loss = loss_fn(logits, targets)\n",
    "\n",
    "            eval_total_loss += loss.detach().cpu()\n",
    "            eval_all_logits.append(logits.detach().cpu())\n",
    "            eval_all_targets.append(targets.detach().cpu())\n",
    "        \n",
    "        eval_all_logits = torch.cat(eval_all_logits)\n",
    "        eval_all_targets = torch.cat(eval_all_targets)\n",
    "\n",
    "        eval_one, eval_two, eval_three, eval_r2 = metric_fn(eval_all_logits, eval_all_targets)\n",
    "        eval_total_loss = eval_total_loss / len(eval_dl)\n",
    "        \n",
    "        if eval_r2 > score:\n",
    "            score = eval_r2\n",
    "            data = {\"state_dict\": model.state_dict()}\n",
    "            data[\"epoch\"] = epoch \n",
    "            data[\"score\"] = score\n",
    "            torch.save(data, f\"/kaggle/working/{checkpoint_name}\")\n",
    "        \n",
    "        if neptune_run is not None:\n",
    "            neptune_run[\"train/loss\"].append(total_loss)\n",
    "            neptune_run[\"eval/loss\"].append(eval_total_loss)\n",
    "            neptune_run[\"train/r2\"].append(r2)\n",
    "            neptune_run[\"eval/r2\"].append(eval_r2)\n",
    "            neptune_run[\"train/one\"].append(one)\n",
    "            neptune_run[\"train/two\"].append(two)\n",
    "            neptune_run[\"train/three\"].append(three)\n",
    "            neptune_run[\"eval/one\"].append(eval_one)\n",
    "            neptune_run[\"eval/two\"].append(eval_two)\n",
    "            neptune_run[\"eval/three\"].append(eval_three)\n",
    "            \n",
    "        if p and epoch % 5 == 0:\n",
    "            print(\n",
    "                f\"Epoch: {epoch}, \"\n",
    "                f\"train/loss: {total_loss:.4f}, \"\n",
    "                f\"eval/loss: {eval_total_loss:.4f}, \"\n",
    "                f\"train/r2: {r2:.4f}, \"\n",
    "                f\"eval/r2: {eval_r2:.4f}, \"\n",
    "                f\"train/one: {one:.4f}, \"\n",
    "                f\"train/two: {two:.4f}, \"\n",
    "                f\"train/three: {three:.4f}, \"\n",
    "                f\"eval/one: {eval_one:.4f}, \"\n",
    "                f\"eval/two: {eval_two:.4f}, \"\n",
    "                f\"eval/three: {eval_three:.4f} \"\n",
    "            )\n",
    "            \n",
    "    if neptune_run is not None: neptune_run.stop()\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c6678e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings#; warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "EPOCHS = 500\n",
    "WD = 1e-3\n",
    "LR = 1e-4\n",
    "\n",
    "DROPOUT = 0.5\n",
    "#DROP_PATH_RATE = 0.0\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "RESUME = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "853355ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.981251\n",
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24c932d7eef3437cb5fb1c016e51cc7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:227: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, train/loss: 11.2464, eval/loss: 9.5109, train/r2: -1.2558, eval/r2: -0.9679, train/one: -0.7138, train/two: -2.3070, train/three: -0.7467, eval/one: -0.6092, eval/two: -1.5417, eval/three: -0.7527 \n",
      "Epoch: 5, train/loss: 10.6874, eval/loss: 9.4922, train/r2: -1.1235, eval/r2: -0.9154, train/one: -0.6317, train/two: -2.1010, train/three: -0.6378, eval/one: -0.6120, eval/two: -1.3989, eval/three: -0.7352 \n",
      "Epoch: 10, train/loss: 9.4248, eval/loss: 9.4877, train/r2: -0.7439, eval/r2: -0.8537, train/one: -0.4481, train/two: -1.3500, train/three: -0.4337, eval/one: -0.6184, eval/two: -1.2222, eval/three: -0.7204 \n",
      "Epoch: 15, train/loss: 7.7384, eval/loss: 9.0460, train/r2: -0.3398, eval/r2: -0.6978, train/one: -0.1956, train/two: -0.6556, train/three: -0.1683, eval/one: -0.5481, eval/two: -0.8907, eval/three: -0.6544 \n",
      "Epoch: 20, train/loss: 6.3762, eval/loss: 6.9918, train/r2: -0.1368, eval/r2: -0.2394, train/one: 0.0227, train/two: -0.4020, train/three: -0.0312, eval/one: -0.2056, eval/two: -0.2559, eval/three: -0.2567 \n",
      "Epoch: 25, train/loss: 5.8953, eval/loss: 6.3131, train/r2: -0.1307, eval/r2: -0.0887, train/one: 0.1038, train/two: -0.5157, train/three: 0.0199, eval/one: -0.0867, eval/two: 0.0021, eval/three: -0.1814 \n",
      "Epoch: 30, train/loss: 6.1326, eval/loss: 7.3567, train/r2: -0.1415, eval/r2: -0.1693, train/one: 0.0610, train/two: -0.5189, train/three: 0.0334, eval/one: -0.3007, eval/two: -0.0778, eval/three: -0.1294 \n",
      "Epoch: 35, train/loss: 5.7177, eval/loss: 6.5706, train/r2: -0.0405, eval/r2: -0.0372, train/one: 0.1267, train/two: -0.3036, train/three: 0.0554, eval/one: -0.1621, eval/two: 0.0616, eval/three: -0.0112 \n",
      "Epoch: 40, train/loss: 5.5271, eval/loss: 5.7084, train/r2: -0.0136, eval/r2: 0.0579, train/one: 0.1559, train/two: -0.2881, train/three: 0.0913, eval/one: -0.0014, eval/two: 0.0974, eval/three: 0.0776 \n",
      "Epoch: 45, train/loss: 5.3754, eval/loss: 5.3324, train/r2: 0.0244, eval/r2: 0.0454, train/one: 0.1793, train/two: -0.2120, train/three: 0.1060, eval/one: 0.0811, eval/two: 0.0105, eval/three: 0.0445 \n",
      "Epoch: 50, train/loss: 5.0193, eval/loss: 6.6129, train/r2: 0.0279, eval/r2: -0.1957, train/one: 0.2438, train/two: -0.2516, train/three: 0.0914, eval/one: -0.1539, eval/two: -0.4003, eval/three: -0.0328 \n",
      "Epoch: 55, train/loss: 4.6425, eval/loss: 6.5759, train/r2: 0.0649, eval/r2: -0.2142, train/one: 0.3025, train/two: -0.2722, train/three: 0.1643, eval/one: -0.1459, eval/two: -0.4782, eval/three: -0.0185 \n",
      "Epoch: 60, train/loss: 4.4270, eval/loss: 4.7690, train/r2: 0.0578, eval/r2: 0.0632, train/one: 0.3429, train/two: -0.3158, train/three: 0.1463, eval/one: 0.1859, eval/two: -0.1426, eval/three: 0.1462 \n",
      "Epoch: 65, train/loss: 4.3334, eval/loss: 9.1764, train/r2: 0.0610, eval/r2: -0.2404, train/one: 0.3578, train/two: -0.3392, train/three: 0.1645, eval/one: -0.6823, eval/two: -0.0184, eval/three: -0.0206 \n",
      "Epoch: 70, train/loss: 3.7765, eval/loss: 4.1053, train/r2: 0.1490, eval/r2: 0.1845, train/one: 0.4465, train/two: -0.2228, train/three: 0.2233, eval/one: 0.3037, eval/two: 0.0206, eval/three: 0.2293 \n",
      "Epoch: 75, train/loss: 3.7048, eval/loss: 3.8722, train/r2: 0.1663, eval/r2: 0.2032, train/one: 0.4567, train/two: -0.1986, train/three: 0.2406, eval/one: 0.3493, eval/two: 0.0223, eval/three: 0.2381 \n",
      "Epoch: 80, train/loss: 3.4481, eval/loss: 3.9910, train/r2: 0.1808, eval/r2: 0.1872, train/one: 0.4972, train/two: -0.2475, train/three: 0.2926, eval/one: 0.3258, eval/two: -0.0059, eval/three: 0.2417 \n",
      "Epoch: 85, train/loss: 3.3458, eval/loss: 4.2177, train/r2: 0.1903, eval/r2: 0.2034, train/one: 0.5146, train/two: -0.2384, train/three: 0.2946, eval/one: 0.2690, eval/two: 0.0170, eval/three: 0.3241 \n",
      "Epoch: 90, train/loss: 3.1176, eval/loss: 6.6217, train/r2: 0.2270, eval/r2: 0.0156, train/one: 0.5513, train/two: -0.1847, train/three: 0.3144, eval/one: -0.1975, eval/two: 0.0597, eval/three: 0.1846 \n",
      "Epoch: 95, train/loss: 3.0138, eval/loss: 3.6862, train/r2: 0.2377, eval/r2: 0.2640, train/one: 0.5654, train/two: -0.2114, train/three: 0.3592, eval/one: 0.3684, eval/two: 0.0498, eval/three: 0.3737 \n",
      "Epoch: 100, train/loss: 2.9708, eval/loss: 3.8545, train/r2: 0.2466, eval/r2: 0.2700, train/one: 0.5709, train/two: -0.2089, train/three: 0.3778, eval/one: 0.3278, eval/two: 0.0576, eval/three: 0.4247 \n",
      "Epoch: 105, train/loss: 2.9118, eval/loss: 3.7860, train/r2: 0.2456, eval/r2: 0.2551, train/one: 0.5754, train/two: -0.2884, train/three: 0.4498, eval/one: 0.3499, eval/two: 0.0545, eval/three: 0.3610 \n",
      "Epoch: 110, train/loss: 2.8461, eval/loss: 3.5629, train/r2: 0.2858, eval/r2: 0.3114, train/one: 0.5820, train/two: -0.2049, train/three: 0.4805, eval/one: 0.3793, eval/two: 0.0798, eval/three: 0.4752 \n",
      "Epoch: 115, train/loss: 2.7146, eval/loss: 4.0690, train/r2: 0.3022, eval/r2: 0.2484, train/one: 0.6031, train/two: -0.1923, train/three: 0.4959, eval/one: 0.2886, eval/two: 0.0640, eval/three: 0.3926 \n",
      "Epoch: 120, train/loss: 2.6342, eval/loss: 3.6164, train/r2: 0.3085, eval/r2: 0.3251, train/one: 0.6150, train/two: -0.2095, train/three: 0.5201, eval/one: 0.3599, eval/two: 0.0716, eval/three: 0.5437 \n",
      "Epoch: 125, train/loss: 2.5962, eval/loss: 3.5773, train/r2: 0.3120, eval/r2: 0.3370, train/one: 0.6193, train/two: -0.2295, train/three: 0.5462, eval/one: 0.3643, eval/two: 0.0776, eval/three: 0.5692 \n",
      "Epoch: 130, train/loss: 2.5562, eval/loss: 4.0413, train/r2: 0.3260, eval/r2: 0.1930, train/one: 0.6268, train/two: -0.1806, train/three: 0.5318, eval/one: 0.3227, eval/two: 0.0919, eval/three: 0.1642 \n",
      "Epoch: 135, train/loss: 2.3974, eval/loss: 3.5735, train/r2: 0.3262, eval/r2: 0.3530, train/one: 0.6538, train/two: -0.2220, train/three: 0.5470, eval/one: 0.3615, eval/two: 0.1072, eval/three: 0.5903 \n",
      "Epoch: 140, train/loss: 2.3984, eval/loss: 3.4878, train/r2: 0.3594, eval/r2: 0.3453, train/one: 0.6507, train/two: -0.1289, train/three: 0.5565, eval/one: 0.3821, eval/two: 0.0845, eval/three: 0.5692 \n",
      "Epoch: 145, train/loss: 2.6071, eval/loss: 3.9828, train/r2: 0.3390, eval/r2: 0.3273, train/one: 0.6120, train/two: -0.1847, train/three: 0.5898, eval/one: 0.2775, eval/two: 0.0993, eval/three: 0.6052 \n",
      "Epoch: 150, train/loss: 2.4644, eval/loss: 3.3731, train/r2: 0.3351, eval/r2: 0.3578, train/one: 0.6370, train/two: -0.2297, train/three: 0.5979, eval/one: 0.4025, eval/two: 0.0800, eval/three: 0.5910 \n",
      "Epoch: 155, train/loss: 2.3117, eval/loss: 3.3442, train/r2: 0.3804, eval/r2: 0.3718, train/one: 0.6598, train/two: -0.1345, train/three: 0.6160, eval/one: 0.4029, eval/two: 0.0799, eval/three: 0.6326 \n",
      "Epoch: 160, train/loss: 2.2193, eval/loss: 3.3777, train/r2: 0.3820, eval/r2: 0.3506, train/one: 0.6757, train/two: -0.1517, train/three: 0.6220, eval/one: 0.4047, eval/two: 0.0804, eval/three: 0.5666 \n",
      "Epoch: 165, train/loss: 2.1762, eval/loss: 3.2223, train/r2: 0.3398, eval/r2: 0.3819, train/one: 0.6833, train/two: -0.3179, train/three: 0.6541, eval/one: 0.4266, eval/two: 0.0799, eval/three: 0.6392 \n",
      "Epoch: 170, train/loss: 2.1177, eval/loss: 3.3181, train/r2: 0.3993, eval/r2: 0.3730, train/one: 0.6901, train/two: -0.1449, train/three: 0.6527, eval/one: 0.4111, eval/two: 0.1029, eval/three: 0.6050 \n",
      "Epoch: 175, train/loss: 2.1204, eval/loss: 3.4114, train/r2: 0.3924, eval/r2: 0.3601, train/one: 0.6886, train/two: -0.1811, train/three: 0.6696, eval/one: 0.3940, eval/two: 0.0916, eval/three: 0.5947 \n",
      "Epoch: 180, train/loss: 2.1654, eval/loss: 3.4407, train/r2: 0.4074, eval/r2: 0.3604, train/one: 0.6809, train/two: -0.1134, train/three: 0.6547, eval/one: 0.3879, eval/two: 0.0993, eval/three: 0.5940 \n",
      "Epoch: 185, train/loss: 2.0484, eval/loss: 3.2558, train/r2: 0.4162, eval/r2: 0.3766, train/one: 0.6998, train/two: -0.1218, train/three: 0.6706, eval/one: 0.4208, eval/two: 0.0764, eval/three: 0.6327 \n",
      "Epoch: 190, train/loss: 2.0885, eval/loss: 4.5330, train/r2: 0.4161, eval/r2: 0.2947, train/one: 0.6921, train/two: -0.1219, train/three: 0.6780, eval/one: 0.1642, eval/two: 0.0920, eval/three: 0.6280 \n",
      "Epoch: 195, train/loss: 1.9753, eval/loss: 3.5449, train/r2: 0.4357, eval/r2: 0.3421, train/one: 0.7116, train/two: -0.0750, train/three: 0.6706, eval/one: 0.3735, eval/two: 0.1124, eval/three: 0.5403 \n",
      "Epoch: 200, train/loss: 1.9758, eval/loss: 3.1053, train/r2: 0.4407, eval/r2: 0.3759, train/one: 0.7105, train/two: -0.0681, train/three: 0.6796, eval/one: 0.4535, eval/two: 0.0554, eval/three: 0.6189 \n",
      "Epoch: 205, train/loss: 1.9679, eval/loss: 3.1299, train/r2: 0.4382, eval/r2: 0.3875, train/one: 0.7125, train/two: -0.0715, train/three: 0.6737, eval/one: 0.4480, eval/two: 0.1027, eval/three: 0.6118 \n",
      "Epoch: 210, train/loss: 2.0178, eval/loss: 3.2708, train/r2: 0.4199, eval/r2: 0.3320, train/one: 0.7045, train/two: -0.1219, train/three: 0.6770, eval/one: 0.4394, eval/two: 0.0962, eval/three: 0.4605 \n",
      "Epoch: 215, train/loss: 1.9344, eval/loss: 3.0387, train/r2: 0.4353, eval/r2: 0.3923, train/one: 0.7153, train/two: -0.1236, train/three: 0.7143, eval/one: 0.4659, eval/two: 0.0935, eval/three: 0.6175 \n",
      "Epoch: 220, train/loss: 1.9671, eval/loss: 3.2627, train/r2: 0.4161, eval/r2: 0.3392, train/one: 0.7112, train/two: -0.1711, train/three: 0.7081, eval/one: 0.4387, eval/two: 0.1023, eval/three: 0.4765 \n",
      "Epoch: 225, train/loss: 1.8721, eval/loss: 3.1332, train/r2: 0.4318, eval/r2: 0.4068, train/one: 0.7276, train/two: -0.1347, train/three: 0.7024, eval/one: 0.4379, eval/two: 0.0958, eval/three: 0.6867 \n",
      "Epoch: 230, train/loss: 1.8799, eval/loss: 3.7124, train/r2: 0.4677, eval/r2: 0.3523, train/one: 0.7225, train/two: -0.0384, train/three: 0.7190, eval/one: 0.3269, eval/two: 0.0818, eval/three: 0.6481 \n",
      "Epoch: 235, train/loss: 1.9788, eval/loss: 3.0555, train/r2: 0.4067, eval/r2: 0.4064, train/one: 0.7096, train/two: -0.1990, train/three: 0.7093, eval/one: 0.4554, eval/two: 0.0902, eval/three: 0.6737 \n",
      "Epoch: 240, train/loss: 1.8327, eval/loss: 2.9730, train/r2: 0.4394, eval/r2: 0.3809, train/one: 0.7336, train/two: -0.1244, train/three: 0.7091, eval/one: 0.4846, eval/two: 0.0800, eval/three: 0.5780 \n",
      "Epoch: 245, train/loss: 1.7700, eval/loss: 3.4541, train/r2: 0.4523, eval/r2: 0.3638, train/one: 0.7444, train/two: -0.0910, train/three: 0.7035, eval/one: 0.3806, eval/two: 0.0753, eval/three: 0.6354 \n",
      "Epoch: 250, train/loss: 1.7786, eval/loss: 3.1195, train/r2: 0.4569, eval/r2: 0.4100, train/one: 0.7409, train/two: -0.0937, train/three: 0.7236, eval/one: 0.4393, eval/two: 0.0923, eval/three: 0.6984 \n",
      "Epoch: 255, train/loss: 1.8103, eval/loss: 2.9409, train/r2: 0.4514, eval/r2: 0.4324, train/one: 0.7359, train/two: -0.1013, train/three: 0.7194, eval/one: 0.4728, eval/two: 0.1120, eval/three: 0.7126 \n",
      "Epoch: 260, train/loss: 1.7563, eval/loss: 2.9448, train/r2: 0.4618, eval/r2: 0.4279, train/one: 0.7442, train/two: -0.0869, train/three: 0.7283, eval/one: 0.4729, eval/two: 0.1036, eval/three: 0.7072 \n",
      "Epoch: 265, train/loss: 1.7101, eval/loss: 2.8818, train/r2: 0.4821, eval/r2: 0.4440, train/one: 0.7512, train/two: -0.0313, train/three: 0.7265, eval/one: 0.4814, eval/two: 0.1134, eval/three: 0.7372 \n",
      "Epoch: 270, train/loss: 1.6834, eval/loss: 2.8763, train/r2: 0.4620, eval/r2: 0.4401, train/one: 0.7561, train/two: -0.1109, train/three: 0.7407, eval/one: 0.4862, eval/two: 0.1291, eval/three: 0.7050 \n",
      "Epoch: 275, train/loss: 1.6778, eval/loss: 3.9567, train/r2: 0.4406, eval/r2: 0.3617, train/one: 0.7584, train/two: -0.1782, train/three: 0.7418, eval/one: 0.2688, eval/two: 0.1035, eval/three: 0.7126 \n",
      "Epoch: 280, train/loss: 1.8900, eval/loss: 5.2352, train/r2: 0.4644, eval/r2: 0.2321, train/one: 0.7198, train/two: -0.0591, train/three: 0.7324, eval/one: 0.0206, eval/two: 0.0088, eval/three: 0.6669 \n",
      "Epoch: 285, train/loss: 1.7467, eval/loss: 4.3456, train/r2: 0.4876, eval/r2: 0.3030, train/one: 0.7436, train/two: -0.0161, train/three: 0.7352, eval/one: 0.2002, eval/two: 0.0597, eval/three: 0.6490 \n",
      "Epoch: 290, train/loss: 1.8955, eval/loss: 4.0053, train/r2: 0.4432, eval/r2: 0.3049, train/one: 0.7204, train/two: -0.1209, train/three: 0.7300, eval/one: 0.2832, eval/two: 0.1071, eval/three: 0.5243 \n",
      "Epoch: 295, train/loss: 1.7429, eval/loss: 3.4675, train/r2: 0.4633, eval/r2: 0.3806, train/one: 0.7454, train/two: -0.0965, train/three: 0.7412, eval/one: 0.3720, eval/two: 0.0922, eval/three: 0.6775 \n",
      "Epoch: 300, train/loss: 1.7733, eval/loss: 3.2422, train/r2: 0.4606, eval/r2: 0.4175, train/one: 0.7406, train/two: -0.0941, train/three: 0.7354, eval/one: 0.4090, eval/two: 0.1046, eval/three: 0.7390 \n",
      "Epoch: 305, train/loss: 1.7261, eval/loss: 2.9093, train/r2: 0.4453, eval/r2: 0.4478, train/one: 0.7499, train/two: -0.1508, train/three: 0.7367, eval/one: 0.4743, eval/two: 0.1212, eval/three: 0.7478 \n",
      "Epoch: 310, train/loss: 1.6749, eval/loss: 2.8961, train/r2: 0.4768, eval/r2: 0.4542, train/one: 0.7558, train/two: -0.0759, train/three: 0.7506, eval/one: 0.4750, eval/two: 0.1257, eval/three: 0.7619 \n",
      "Epoch: 315, train/loss: 1.6500, eval/loss: 2.9294, train/r2: 0.4858, eval/r2: 0.4305, train/one: 0.7586, train/two: -0.0647, train/three: 0.7634, eval/one: 0.4762, eval/two: 0.1110, eval/three: 0.7042 \n",
      "Epoch: 320, train/loss: 1.7000, eval/loss: 2.8945, train/r2: 0.4687, eval/r2: 0.4461, train/one: 0.7519, train/two: -0.0967, train/three: 0.7508, eval/one: 0.4781, eval/two: 0.1187, eval/three: 0.7416 \n",
      "Epoch: 325, train/loss: 1.6417, eval/loss: 2.8743, train/r2: 0.4785, eval/r2: 0.4579, train/one: 0.7610, train/two: -0.0833, train/three: 0.7579, eval/one: 0.4788, eval/two: 0.1295, eval/three: 0.7653 \n",
      "Epoch: 330, train/loss: 1.6218, eval/loss: 2.8832, train/r2: 0.4910, eval/r2: 0.4464, train/one: 0.7640, train/two: -0.0455, train/three: 0.7546, eval/one: 0.4812, eval/two: 0.1234, eval/three: 0.7347 \n",
      "Epoch: 335, train/loss: 1.5917, eval/loss: 2.8776, train/r2: 0.4842, eval/r2: 0.4444, train/one: 0.7699, train/two: -0.0709, train/three: 0.7536, eval/one: 0.4823, eval/two: 0.1137, eval/three: 0.7372 \n",
      "Epoch: 340, train/loss: 1.6236, eval/loss: 2.8993, train/r2: 0.4914, eval/r2: 0.4442, train/one: 0.7630, train/two: -0.0516, train/three: 0.7628, eval/one: 0.4777, eval/two: 0.1165, eval/three: 0.7385 \n",
      "Epoch: 345, train/loss: 1.6423, eval/loss: 2.9076, train/r2: 0.4985, eval/r2: 0.4349, train/one: 0.7602, train/two: -0.0158, train/three: 0.7511, eval/one: 0.4799, eval/two: 0.1168, eval/three: 0.7079 \n",
      "Epoch: 350, train/loss: 1.6281, eval/loss: 2.8387, train/r2: 0.4881, eval/r2: 0.4517, train/one: 0.7635, train/two: -0.0490, train/three: 0.7498, eval/one: 0.4882, eval/two: 0.1156, eval/three: 0.7514 \n",
      "Epoch: 355, train/loss: 1.6093, eval/loss: 2.8372, train/r2: 0.4928, eval/r2: 0.4595, train/one: 0.7653, train/two: -0.0522, train/three: 0.7653, eval/one: 0.4858, eval/two: 0.1218, eval/three: 0.7711 \n",
      "Epoch: 360, train/loss: 1.5694, eval/loss: 2.8686, train/r2: 0.4904, eval/r2: 0.4574, train/one: 0.7732, train/two: -0.0589, train/three: 0.7570, eval/one: 0.4792, eval/two: 0.1197, eval/three: 0.7734 \n",
      "Epoch: 365, train/loss: 1.5902, eval/loss: 2.8752, train/r2: 0.4773, eval/r2: 0.4506, train/one: 0.7698, train/two: -0.1018, train/three: 0.7640, eval/one: 0.4794, eval/two: 0.1077, eval/three: 0.7648 \n",
      "Epoch: 370, train/loss: 1.6005, eval/loss: 2.8480, train/r2: 0.5054, eval/r2: 0.4520, train/one: 0.7660, train/two: -0.0156, train/three: 0.7660, eval/one: 0.4849, eval/two: 0.1068, eval/three: 0.7642 \n",
      "Epoch: 375, train/loss: 1.5702, eval/loss: 2.9305, train/r2: 0.4941, eval/r2: 0.4505, train/one: 0.7726, train/two: -0.0502, train/three: 0.7599, eval/one: 0.4677, eval/two: 0.1169, eval/three: 0.7667 \n",
      "Epoch: 380, train/loss: 1.5932, eval/loss: 2.9562, train/r2: 0.4852, eval/r2: 0.4479, train/one: 0.7690, train/two: -0.0746, train/three: 0.7613, eval/one: 0.4634, eval/two: 0.1210, eval/three: 0.7593 \n",
      "Epoch: 385, train/loss: 1.5722, eval/loss: 2.8968, train/r2: 0.4855, eval/r2: 0.4531, train/one: 0.7730, train/two: -0.0738, train/three: 0.7572, eval/one: 0.4741, eval/two: 0.1147, eval/three: 0.7704 \n",
      "Epoch: 390, train/loss: 1.5337, eval/loss: 2.9377, train/r2: 0.4806, eval/r2: 0.4489, train/one: 0.7796, train/two: -0.1017, train/three: 0.7638, eval/one: 0.4656, eval/two: 0.1072, eval/three: 0.7740 \n",
      "Epoch: 395, train/loss: 1.5751, eval/loss: 2.9204, train/r2: 0.5021, eval/r2: 0.4486, train/one: 0.7714, train/two: -0.0233, train/three: 0.7582, eval/one: 0.4692, eval/two: 0.1021, eval/three: 0.7745 \n",
      "Epoch: 400, train/loss: 1.6022, eval/loss: 2.9016, train/r2: 0.4923, eval/r2: 0.4523, train/one: 0.7672, train/two: -0.0484, train/three: 0.7582, eval/one: 0.4724, eval/two: 0.1067, eval/three: 0.7779 \n",
      "Epoch: 405, train/loss: 1.5143, eval/loss: 2.9085, train/r2: 0.4960, eval/r2: 0.4525, train/one: 0.7814, train/two: -0.0659, train/three: 0.7725, eval/one: 0.4709, eval/two: 0.1081, eval/three: 0.7786 \n",
      "Epoch: 410, train/loss: 1.5169, eval/loss: 2.9621, train/r2: 0.4953, eval/r2: 0.4480, train/one: 0.7809, train/two: -0.0683, train/three: 0.7734, eval/one: 0.4612, eval/two: 0.1138, eval/three: 0.7688 \n",
      "Epoch: 415, train/loss: 1.5340, eval/loss: 2.9120, train/r2: 0.4952, eval/r2: 0.4543, train/one: 0.7778, train/two: -0.0660, train/three: 0.7740, eval/one: 0.4702, eval/two: 0.1164, eval/three: 0.7763 \n",
      "Epoch: 420, train/loss: 1.5125, eval/loss: 2.9161, train/r2: 0.5083, eval/r2: 0.4556, train/one: 0.7810, train/two: -0.0271, train/three: 0.7710, eval/one: 0.4688, eval/two: 0.1168, eval/three: 0.7811 \n",
      "Epoch: 425, train/loss: 1.5218, eval/loss: 2.9142, train/r2: 0.4987, eval/r2: 0.4543, train/one: 0.7804, train/two: -0.0505, train/three: 0.7662, eval/one: 0.4694, eval/two: 0.1131, eval/three: 0.7805 \n",
      "Epoch: 430, train/loss: 1.5421, eval/loss: 2.9237, train/r2: 0.4938, eval/r2: 0.4530, train/one: 0.7764, train/two: -0.0692, train/three: 0.7742, eval/one: 0.4676, eval/two: 0.1120, eval/three: 0.7793 \n",
      "Epoch: 435, train/loss: 1.5361, eval/loss: 2.9208, train/r2: 0.4991, eval/r2: 0.4533, train/one: 0.7776, train/two: -0.0493, train/three: 0.7691, eval/one: 0.4681, eval/two: 0.1112, eval/three: 0.7806 \n",
      "Epoch: 440, train/loss: 1.5405, eval/loss: 2.9425, train/r2: 0.4916, eval/r2: 0.4516, train/one: 0.7775, train/two: -0.0689, train/three: 0.7662, eval/one: 0.4639, eval/two: 0.1124, eval/three: 0.7785 \n",
      "Epoch: 445, train/loss: 1.5112, eval/loss: 2.9287, train/r2: 0.5027, eval/r2: 0.4522, train/one: 0.7813, train/two: -0.0484, train/three: 0.7751, eval/one: 0.4667, eval/two: 0.1107, eval/three: 0.7792 \n",
      "Epoch: 450, train/loss: 1.5035, eval/loss: 2.9337, train/r2: 0.5100, eval/r2: 0.4516, train/one: 0.7822, train/two: -0.0270, train/three: 0.7747, eval/one: 0.4655, eval/two: 0.1080, eval/three: 0.7812 \n",
      "Epoch: 455, train/loss: 1.5068, eval/loss: 2.9320, train/r2: 0.5250, eval/r2: 0.4513, train/one: 0.7803, train/two: 0.0154, train/three: 0.7792, eval/one: 0.4660, eval/two: 0.1078, eval/three: 0.7800 \n",
      "Epoch: 460, train/loss: 1.5335, eval/loss: 2.9314, train/r2: 0.4988, eval/r2: 0.4516, train/one: 0.7786, train/two: -0.0443, train/three: 0.7622, eval/one: 0.4660, eval/two: 0.1077, eval/three: 0.7810 \n",
      "Epoch: 465, train/loss: 1.5335, eval/loss: 2.9462, train/r2: 0.4973, eval/r2: 0.4504, train/one: 0.7784, train/two: -0.0531, train/three: 0.7665, eval/one: 0.4632, eval/two: 0.1085, eval/three: 0.7796 \n",
      "Epoch: 470, train/loss: 1.5000, eval/loss: 2.9370, train/r2: 0.5050, eval/r2: 0.4517, train/one: 0.7835, train/two: -0.0398, train/three: 0.7713, eval/one: 0.4647, eval/two: 0.1084, eval/three: 0.7819 \n",
      "Epoch: 475, train/loss: 1.5428, eval/loss: 2.9292, train/r2: 0.4719, eval/r2: 0.4525, train/one: 0.7783, train/two: -0.1296, train/three: 0.7668, eval/one: 0.4662, eval/two: 0.1088, eval/three: 0.7824 \n",
      "Epoch: 480, train/loss: 1.4941, eval/loss: 2.9308, train/r2: 0.5109, eval/r2: 0.4523, train/one: 0.7842, train/two: -0.0214, train/three: 0.7699, eval/one: 0.4660, eval/two: 0.1092, eval/three: 0.7817 \n",
      "Epoch: 485, train/loss: 1.4925, eval/loss: 2.9311, train/r2: 0.4926, eval/r2: 0.4522, train/one: 0.7851, train/two: -0.0846, train/three: 0.7774, eval/one: 0.4659, eval/two: 0.1092, eval/three: 0.7814 \n",
      "Epoch: 490, train/loss: 1.5075, eval/loss: 2.9306, train/r2: 0.5088, eval/r2: 0.4522, train/one: 0.7817, train/two: -0.0290, train/three: 0.7736, eval/one: 0.4661, eval/two: 0.1092, eval/three: 0.7813 \n",
      "Epoch: 495, train/loss: 1.5425, eval/loss: 2.9308, train/r2: 0.4934, eval/r2: 0.4521, train/one: 0.7768, train/two: -0.0660, train/three: 0.7694, eval/one: 0.4660, eval/two: 0.1090, eval/three: 0.7814 \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cbc26c8dd6342b297143f12f58cf4ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:227: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, train/loss: 10.8819, eval/loss: 11.1388, train/r2: -1.0619, eval/r2: -0.8403, train/one: -0.7004, train/two: -1.7872, train/three: -0.6982, eval/one: -0.7668, eval/two: -1.0247, eval/three: -0.7293 \n",
      "Epoch: 5, train/loss: 10.4406, eval/loss: 11.2186, train/r2: -0.9790, eval/r2: -0.8613, train/one: -0.6322, train/two: -1.6847, train/three: -0.6200, eval/one: -0.7848, eval/two: -1.1247, eval/three: -0.6744 \n",
      "Epoch: 10, train/loss: 9.1197, eval/loss: 11.1345, train/r2: -0.7203, eval/r2: -0.8846, train/one: -0.4208, train/two: -1.2626, train/three: -0.4774, eval/one: -0.7722, eval/two: -1.2573, eval/three: -0.6242 \n",
      "Epoch: 15, train/loss: 7.6124, eval/loss: 10.2756, train/r2: -0.4220, eval/r2: -0.7943, train/one: -0.1831, train/two: -0.8055, train/three: -0.2773, eval/one: -0.6277, eval/two: -1.2095, eval/three: -0.5458 \n",
      "Epoch: 20, train/loss: 6.3327, eval/loss: 7.7561, train/r2: -0.1821, eval/r2: -0.3228, train/one: 0.0200, train/two: -0.4551, train/three: -0.1113, eval/one: -0.2251, eval/two: -0.5123, eval/three: -0.2309 \n",
      "Epoch: 25, train/loss: 5.8429, eval/loss: 6.4310, train/r2: -0.0996, eval/r2: 0.0176, train/one: 0.0900, train/two: -0.4367, train/three: 0.0480, eval/one: -0.0262, eval/two: 0.0693, eval/three: 0.0096 \n",
      "Epoch: 30, train/loss: 5.7719, eval/loss: 6.7676, train/r2: -0.0967, eval/r2: -0.0918, train/one: 0.1051, train/two: -0.4160, train/three: 0.0208, eval/one: -0.0717, eval/two: -0.1118, eval/three: -0.0919 \n",
      "Epoch: 35, train/loss: 5.5515, eval/loss: 6.2584, train/r2: -0.0445, eval/r2: 0.0169, train/one: 0.1356, train/two: -0.3615, train/three: 0.0924, eval/one: 0.0027, eval/two: 0.0070, eval/three: 0.0410 \n",
      "Epoch: 40, train/loss: 5.4532, eval/loss: 7.2857, train/r2: -0.0155, eval/r2: -0.0758, train/one: 0.1475, train/two: -0.3335, train/three: 0.1396, eval/one: -0.1838, eval/two: -0.1352, eval/three: 0.0915 \n",
      "Epoch: 45, train/loss: 5.0378, eval/loss: 7.6632, train/r2: 0.0458, eval/r2: -0.0859, train/one: 0.2160, train/two: -0.2555, train/three: 0.1770, eval/one: -0.2505, eval/two: -0.0777, eval/three: 0.0706 \n",
      "Epoch: 50, train/loss: 4.7693, eval/loss: 8.5060, train/r2: 0.0572, eval/r2: -0.1333, train/one: 0.2663, train/two: -0.2498, train/three: 0.1551, eval/one: -0.4023, eval/two: -0.0734, eval/three: 0.0757 \n",
      "Epoch: 55, train/loss: 4.3862, eval/loss: 7.5277, train/r2: 0.0933, eval/r2: -0.0632, train/one: 0.3312, train/two: -0.2370, train/three: 0.1856, eval/one: -0.2301, eval/two: -0.0633, eval/three: 0.1040 \n",
      "Epoch: 60, train/loss: 4.1670, eval/loss: 6.6736, train/r2: 0.0976, eval/r2: 0.0495, train/one: 0.3729, train/two: -0.2439, train/three: 0.1639, eval/one: -0.0870, eval/two: 0.0637, eval/three: 0.1717 \n",
      "Epoch: 65, train/loss: 3.8919, eval/loss: 5.1868, train/r2: 0.1372, eval/r2: 0.1517, train/one: 0.4165, train/two: -0.2153, train/three: 0.2104, eval/one: 0.1752, eval/two: 0.0687, eval/three: 0.2113 \n",
      "Epoch: 70, train/loss: 3.7387, eval/loss: 4.4358, train/r2: 0.1258, eval/r2: 0.2022, train/one: 0.4417, train/two: -0.3162, train/three: 0.2521, eval/one: 0.3067, eval/two: 0.0558, eval/three: 0.2442 \n",
      "Epoch: 75, train/loss: 3.5056, eval/loss: 4.3310, train/r2: 0.1887, eval/r2: 0.2265, train/one: 0.4751, train/two: -0.2169, train/three: 0.3078, eval/one: 0.3206, eval/two: 0.0733, eval/three: 0.2855 \n",
      "Epoch: 80, train/loss: 3.3788, eval/loss: 4.3080, train/r2: 0.2195, eval/r2: 0.2354, train/one: 0.4940, train/two: -0.1681, train/three: 0.3326, eval/one: 0.3219, eval/two: 0.0724, eval/three: 0.3118 \n",
      "Epoch: 85, train/loss: 3.2644, eval/loss: 4.2494, train/r2: 0.1997, eval/r2: 0.2398, train/one: 0.5146, train/two: -0.2675, train/three: 0.3521, eval/one: 0.3316, eval/two: 0.0667, eval/three: 0.3210 \n",
      "Epoch: 90, train/loss: 3.1307, eval/loss: 3.7678, train/r2: 0.2149, eval/r2: 0.2633, train/one: 0.5380, train/two: -0.2459, train/three: 0.3526, eval/one: 0.4197, eval/two: 0.0657, eval/three: 0.3046 \n",
      "Epoch: 95, train/loss: 2.9707, eval/loss: 3.5240, train/r2: 0.2820, eval/r2: 0.3173, train/one: 0.5539, train/two: -0.1605, train/three: 0.4526, eval/one: 0.4494, eval/two: 0.0674, eval/three: 0.4350 \n",
      "Epoch: 100, train/loss: 3.2068, eval/loss: 8.9070, train/r2: 0.2438, eval/r2: -0.0539, train/one: 0.5147, train/two: -0.2200, train/three: 0.4366, eval/one: -0.5135, eval/two: -0.0951, eval/three: 0.4469 \n",
      "Epoch: 105, train/loss: 3.2575, eval/loss: 5.6172, train/r2: 0.2398, eval/r2: 0.2014, train/one: 0.5033, train/two: -0.2483, train/three: 0.4645, eval/one: 0.0705, eval/two: 0.0652, eval/three: 0.4685 \n",
      "Epoch: 110, train/loss: 3.2396, eval/loss: 5.2263, train/r2: 0.2688, eval/r2: 0.1840, train/one: 0.5052, train/two: -0.1564, train/three: 0.4575, eval/one: 0.1449, eval/two: -0.0437, eval/three: 0.4507 \n",
      "Epoch: 115, train/loss: 3.0972, eval/loss: 3.9121, train/r2: 0.2991, eval/r2: 0.3100, train/one: 0.5278, train/two: -0.1031, train/three: 0.4725, eval/one: 0.3742, eval/two: 0.0681, eval/three: 0.4877 \n",
      "Epoch: 120, train/loss: 2.9549, eval/loss: 3.9984, train/r2: 0.2957, eval/r2: 0.2967, train/one: 0.5504, train/two: -0.1785, train/three: 0.5150, eval/one: 0.3630, eval/two: 0.0826, eval/three: 0.4445 \n",
      "Epoch: 125, train/loss: 2.8213, eval/loss: 3.7375, train/r2: 0.3380, eval/r2: 0.2912, train/one: 0.5697, train/two: -0.0957, train/three: 0.5398, eval/one: 0.4151, eval/two: 0.0588, eval/three: 0.3997 \n",
      "Epoch: 130, train/loss: 2.6929, eval/loss: 3.7026, train/r2: 0.3464, eval/r2: 0.3071, train/one: 0.5907, train/two: -0.1132, train/three: 0.5617, eval/one: 0.4191, eval/two: 0.0872, eval/three: 0.4149 \n",
      "Epoch: 135, train/loss: 2.6226, eval/loss: 4.0499, train/r2: 0.3287, eval/r2: 0.3237, train/one: 0.6050, train/two: -0.1792, train/three: 0.5604, eval/one: 0.3438, eval/two: 0.0917, eval/three: 0.5358 \n",
      "Epoch: 140, train/loss: 2.5664, eval/loss: 3.4422, train/r2: 0.3350, eval/r2: 0.3655, train/one: 0.6142, train/two: -0.1766, train/three: 0.5675, eval/one: 0.4492, eval/two: 0.0749, eval/three: 0.5726 \n",
      "Epoch: 145, train/loss: 2.5393, eval/loss: 3.3135, train/r2: 0.3461, eval/r2: 0.3933, train/one: 0.6185, train/two: -0.1462, train/three: 0.5660, eval/one: 0.4659, eval/two: 0.0837, eval/three: 0.6302 \n",
      "Epoch: 150, train/loss: 2.4635, eval/loss: 3.2766, train/r2: 0.3606, eval/r2: 0.3681, train/one: 0.6293, train/two: -0.1369, train/three: 0.5894, eval/one: 0.4821, eval/two: 0.0806, eval/three: 0.5415 \n",
      "Epoch: 155, train/loss: 2.4949, eval/loss: 3.2433, train/r2: 0.3515, eval/r2: 0.3774, train/one: 0.6277, train/two: -0.1227, train/three: 0.5496, eval/one: 0.4848, eval/two: 0.0745, eval/three: 0.5731 \n",
      "Epoch: 160, train/loss: 3.0583, eval/loss: 4.5377, train/r2: 0.3081, eval/r2: 0.2760, train/one: 0.5247, train/two: -0.1832, train/three: 0.5828, eval/one: 0.2622, eval/two: 0.0830, eval/three: 0.4827 \n",
      "Epoch: 165, train/loss: 2.8724, eval/loss: 3.6207, train/r2: 0.3492, eval/r2: 0.3519, train/one: 0.5521, train/two: -0.1300, train/three: 0.6256, eval/one: 0.4171, eval/two: 0.0632, eval/three: 0.5754 \n",
      "Epoch: 170, train/loss: 2.4740, eval/loss: 3.4136, train/r2: 0.3887, eval/r2: 0.3963, train/one: 0.6217, train/two: -0.0882, train/three: 0.6328, eval/one: 0.4431, eval/two: 0.0676, eval/three: 0.6782 \n",
      "Epoch: 175, train/loss: 2.3832, eval/loss: 3.2139, train/r2: 0.3802, eval/r2: 0.4170, train/one: 0.6374, train/two: -0.1463, train/three: 0.6493, eval/one: 0.4767, eval/two: 0.0774, eval/three: 0.6967 \n",
      "Epoch: 180, train/loss: 2.2627, eval/loss: 3.0645, train/r2: 0.4182, eval/r2: 0.4209, train/one: 0.6559, train/two: -0.0618, train/three: 0.6605, eval/one: 0.5052, eval/two: 0.0763, eval/three: 0.6813 \n",
      "Epoch: 185, train/loss: 2.2550, eval/loss: 3.1341, train/r2: 0.4075, eval/r2: 0.4159, train/one: 0.6558, train/two: -0.1191, train/three: 0.6858, eval/one: 0.4929, eval/two: 0.0746, eval/three: 0.6801 \n",
      "Epoch: 190, train/loss: 2.2222, eval/loss: 3.0788, train/r2: 0.3926, eval/r2: 0.4122, train/one: 0.6664, train/two: -0.1337, train/three: 0.6453, eval/one: 0.5050, eval/two: 0.0718, eval/three: 0.6598 \n",
      "Epoch: 195, train/loss: 2.3129, eval/loss: 3.3976, train/r2: 0.3215, eval/r2: 0.2121, train/one: 0.6774, train/two: -0.0992, train/three: 0.3863, eval/one: 0.5129, eval/two: 0.0685, eval/three: 0.0549 \n",
      "Epoch: 200, train/loss: 2.0907, eval/loss: 3.2963, train/r2: 0.4300, eval/r2: 0.3561, train/one: 0.6855, train/two: -0.0675, train/three: 0.6719, eval/one: 0.4789, eval/two: 0.0441, eval/three: 0.5454 \n",
      "Epoch: 205, train/loss: 2.1345, eval/loss: 3.0582, train/r2: 0.4202, eval/r2: 0.4262, train/one: 0.6767, train/two: -0.1054, train/three: 0.6893, eval/one: 0.5036, eval/two: 0.0665, eval/three: 0.7086 \n",
      "Epoch: 210, train/loss: 2.0488, eval/loss: 3.5656, train/r2: 0.4345, eval/r2: 0.4046, train/one: 0.6907, train/two: -0.0844, train/three: 0.6971, eval/one: 0.4112, eval/two: 0.0842, eval/three: 0.7185 \n",
      "Epoch: 215, train/loss: 2.0101, eval/loss: 2.8481, train/r2: 0.4331, eval/r2: 0.4465, train/one: 0.6978, train/two: -0.0969, train/three: 0.6984, eval/one: 0.5395, eval/two: 0.0774, eval/three: 0.7226 \n",
      "Epoch: 220, train/loss: 2.0182, eval/loss: 2.8326, train/r2: 0.4347, eval/r2: 0.4395, train/one: 0.6949, train/two: -0.1034, train/three: 0.7126, eval/one: 0.5460, eval/two: 0.0864, eval/three: 0.6860 \n",
      "Epoch: 225, train/loss: 1.8467, eval/loss: 3.2520, train/r2: 0.4446, eval/r2: 0.4300, train/one: 0.7256, train/two: -0.1051, train/three: 0.7132, eval/one: 0.4657, eval/two: 0.0913, eval/three: 0.7331 \n",
      "Epoch: 230, train/loss: 1.8816, eval/loss: 3.3220, train/r2: 0.4584, eval/r2: 0.4042, train/one: 0.7174, train/two: -0.0646, train/three: 0.7224, eval/one: 0.4600, eval/two: 0.0819, eval/three: 0.6707 \n",
      "Epoch: 235, train/loss: 1.8475, eval/loss: 3.9906, train/r2: 0.4681, eval/r2: 0.3515, train/one: 0.7223, train/two: -0.0481, train/three: 0.7299, eval/one: 0.3450, eval/two: 0.0853, eval/three: 0.6243 \n",
      "Epoch: 240, train/loss: 1.7946, eval/loss: 3.2186, train/r2: 0.4496, eval/r2: 0.4087, train/one: 0.7360, train/two: -0.0865, train/three: 0.6994, eval/one: 0.4798, eval/two: 0.0884, eval/three: 0.6578 \n",
      "Epoch: 245, train/loss: 1.7568, eval/loss: 2.9401, train/r2: 0.4433, eval/r2: 0.4407, train/one: 0.7442, train/two: -0.1040, train/three: 0.6896, eval/one: 0.5235, eval/two: 0.0808, eval/three: 0.7180 \n",
      "Epoch: 250, train/loss: 1.7328, eval/loss: 2.8699, train/r2: 0.4705, eval/r2: 0.4220, train/one: 0.7416, train/two: -0.0775, train/three: 0.7475, eval/one: 0.5446, eval/two: 0.0834, eval/three: 0.6379 \n",
      "Epoch: 255, train/loss: 1.7486, eval/loss: 2.6913, train/r2: 0.4660, eval/r2: 0.4727, train/one: 0.7400, train/two: -0.0785, train/three: 0.7366, eval/one: 0.5630, eval/two: 0.0919, eval/three: 0.7634 \n",
      "Epoch: 260, train/loss: 1.6649, eval/loss: 2.6546, train/r2: 0.4810, eval/r2: 0.4763, train/one: 0.7537, train/two: -0.0542, train/three: 0.7437, eval/one: 0.5689, eval/two: 0.0902, eval/three: 0.7699 \n",
      "Epoch: 265, train/loss: 2.4089, eval/loss: 4.0235, train/r2: 0.4190, eval/r2: 0.3952, train/one: 0.6250, train/two: -0.0745, train/three: 0.7065, eval/one: 0.3230, eval/two: 0.0888, eval/three: 0.7738 \n",
      "Epoch: 270, train/loss: 1.7588, eval/loss: 2.8746, train/r2: 0.4714, eval/r2: 0.4581, train/one: 0.7374, train/two: -0.0642, train/three: 0.7411, eval/one: 0.5304, eval/two: 0.0808, eval/three: 0.7631 \n",
      "Epoch: 275, train/loss: 1.7022, eval/loss: 2.9845, train/r2: 0.4760, eval/r2: 0.3520, train/one: 0.7454, train/two: -0.0814, train/three: 0.7641, eval/one: 0.5454, eval/two: 0.0684, eval/three: 0.4422 \n",
      "Epoch: 280, train/loss: 1.7144, eval/loss: 2.7941, train/r2: 0.4823, eval/r2: 0.4568, train/one: 0.7422, train/two: -0.0653, train/three: 0.7699, eval/one: 0.5458, eval/two: 0.0677, eval/three: 0.7569 \n",
      "Epoch: 285, train/loss: 1.6110, eval/loss: 3.0370, train/r2: 0.4893, eval/r2: 0.4338, train/one: 0.7606, train/two: -0.0637, train/three: 0.7710, eval/one: 0.5060, eval/two: 0.0754, eval/three: 0.7200 \n",
      "Epoch: 290, train/loss: 1.5685, eval/loss: 3.4122, train/r2: 0.4931, eval/r2: 0.4203, train/one: 0.7683, train/two: -0.0578, train/three: 0.7686, eval/one: 0.4363, eval/two: 0.0842, eval/three: 0.7402 \n",
      "Epoch: 295, train/loss: 1.6073, eval/loss: 2.9148, train/r2: 0.4758, eval/r2: 0.4023, train/one: 0.7625, train/two: -0.1023, train/three: 0.7674, eval/one: 0.5430, eval/two: 0.0873, eval/three: 0.5765 \n",
      "Epoch: 300, train/loss: 1.5519, eval/loss: 2.7378, train/r2: 0.5127, eval/r2: 0.4712, train/one: 0.7686, train/two: -0.0146, train/three: 0.7841, eval/one: 0.5533, eval/two: 0.0825, eval/three: 0.7778 \n",
      "Epoch: 305, train/loss: 1.5665, eval/loss: 2.7041, train/r2: 0.4974, eval/r2: 0.4771, train/one: 0.7698, train/two: -0.0304, train/three: 0.7527, eval/one: 0.5587, eval/two: 0.0903, eval/three: 0.7824 \n",
      "Epoch: 310, train/loss: 1.5385, eval/loss: 2.7123, train/r2: 0.5075, eval/r2: 0.4761, train/one: 0.7731, train/two: -0.0156, train/three: 0.7652, eval/one: 0.5572, eval/two: 0.0890, eval/three: 0.7821 \n",
      "Epoch: 315, train/loss: 1.5254, eval/loss: 2.7392, train/r2: 0.5035, eval/r2: 0.4515, train/one: 0.7742, train/two: -0.0470, train/three: 0.7832, eval/one: 0.5606, eval/two: 0.0878, eval/three: 0.7062 \n",
      "Epoch: 320, train/loss: 1.5548, eval/loss: 2.7340, train/r2: 0.4936, eval/r2: 0.4606, train/one: 0.7702, train/two: -0.0652, train/three: 0.7758, eval/one: 0.5582, eval/two: 0.0866, eval/three: 0.7370 \n",
      "Epoch: 325, train/loss: 1.5316, eval/loss: 2.8074, train/r2: 0.4848, eval/r2: 0.3957, train/one: 0.7757, train/two: -0.0894, train/three: 0.7680, eval/one: 0.5674, eval/two: 0.0921, eval/three: 0.5275 \n",
      "Epoch: 330, train/loss: 1.4584, eval/loss: 2.9374, train/r2: 0.4988, eval/r2: 0.4465, train/one: 0.7876, train/two: -0.0650, train/three: 0.7738, eval/one: 0.5231, eval/two: 0.0933, eval/three: 0.7232 \n",
      "Epoch: 335, train/loss: 1.4845, eval/loss: 2.6634, train/r2: 0.5078, eval/r2: 0.4816, train/one: 0.7811, train/two: -0.0445, train/three: 0.7868, eval/one: 0.5651, eval/two: 0.0897, eval/three: 0.7900 \n",
      "Epoch: 340, train/loss: 1.4733, eval/loss: 2.9798, train/r2: 0.4937, eval/r2: 0.4596, train/one: 0.7855, train/two: -0.0745, train/three: 0.7702, eval/one: 0.5094, eval/two: 0.0886, eval/three: 0.7809 \n",
      "Epoch: 345, train/loss: 1.4834, eval/loss: 2.8784, train/r2: 0.4957, eval/r2: 0.4400, train/one: 0.7827, train/two: -0.0755, train/three: 0.7798, eval/one: 0.5370, eval/two: 0.0896, eval/three: 0.6936 \n",
      "Epoch: 350, train/loss: 1.4203, eval/loss: 2.7010, train/r2: 0.5201, eval/r2: 0.4790, train/one: 0.7926, train/two: -0.0114, train/three: 0.7790, eval/one: 0.5583, eval/two: 0.0876, eval/three: 0.7910 \n",
      "Epoch: 355, train/loss: 1.4474, eval/loss: 2.8235, train/r2: 0.5086, eval/r2: 0.4705, train/one: 0.7871, train/two: -0.0555, train/three: 0.7943, eval/one: 0.5365, eval/two: 0.0841, eval/three: 0.7910 \n",
      "Epoch: 360, train/loss: 1.4393, eval/loss: 2.8915, train/r2: 0.5011, eval/r2: 0.4589, train/one: 0.7897, train/two: -0.0747, train/three: 0.7881, eval/one: 0.5274, eval/two: 0.0883, eval/three: 0.7611 \n",
      "Epoch: 365, train/loss: 1.4485, eval/loss: 2.8021, train/r2: 0.5101, eval/r2: 0.4517, train/one: 0.7878, train/two: -0.0406, train/three: 0.7831, eval/one: 0.5482, eval/two: 0.0910, eval/three: 0.7160 \n",
      "Epoch: 370, train/loss: 1.4468, eval/loss: 2.9828, train/r2: 0.4869, eval/r2: 0.4555, train/one: 0.7900, train/two: -0.1098, train/three: 0.7806, eval/one: 0.5104, eval/two: 0.0891, eval/three: 0.7671 \n",
      "Epoch: 375, train/loss: 1.4347, eval/loss: 2.7067, train/r2: 0.5029, eval/r2: 0.4788, train/one: 0.7902, train/two: -0.0716, train/three: 0.7901, eval/one: 0.5570, eval/two: 0.0845, eval/three: 0.7949 \n",
      "Epoch: 380, train/loss: 1.4547, eval/loss: 2.8565, train/r2: 0.5005, eval/r2: 0.4665, train/one: 0.7885, train/two: -0.0574, train/three: 0.7705, eval/one: 0.5312, eval/two: 0.0833, eval/three: 0.7850 \n",
      "Epoch: 385, train/loss: 1.4430, eval/loss: 2.9939, train/r2: 0.5102, eval/r2: 0.4566, train/one: 0.7893, train/two: -0.0369, train/three: 0.7781, eval/one: 0.5073, eval/two: 0.0841, eval/three: 0.7783 \n",
      "Epoch: 390, train/loss: 1.4099, eval/loss: 2.7747, train/r2: 0.5165, eval/r2: 0.4752, train/one: 0.7935, train/two: -0.0378, train/three: 0.7937, eval/one: 0.5449, eval/two: 0.0873, eval/three: 0.7934 \n",
      "Epoch: 395, train/loss: 1.3836, eval/loss: 2.7051, train/r2: 0.5335, eval/r2: 0.4809, train/one: 0.7969, train/two: 0.0074, train/three: 0.7963, eval/one: 0.5568, eval/two: 0.0871, eval/three: 0.7986 \n",
      "Epoch: 400, train/loss: 1.3732, eval/loss: 2.6954, train/r2: 0.5234, eval/r2: 0.4802, train/one: 0.7989, train/two: -0.0319, train/three: 0.8032, eval/one: 0.5593, eval/two: 0.0907, eval/three: 0.7906 \n",
      "Epoch: 405, train/loss: 1.3834, eval/loss: 2.7878, train/r2: 0.5045, eval/r2: 0.4712, train/one: 0.7984, train/two: -0.0879, train/three: 0.8032, eval/one: 0.5439, eval/two: 0.0901, eval/three: 0.7796 \n",
      "Epoch: 410, train/loss: 1.3829, eval/loss: 2.7587, train/r2: 0.5267, eval/r2: 0.4773, train/one: 0.7982, train/two: -0.0066, train/three: 0.7885, eval/one: 0.5474, eval/two: 0.0878, eval/three: 0.7967 \n",
      "Epoch: 415, train/loss: 1.3764, eval/loss: 2.7258, train/r2: 0.5349, eval/r2: 0.4787, train/one: 0.7982, train/two: 0.0110, train/three: 0.7956, eval/one: 0.5534, eval/two: 0.0869, eval/three: 0.7960 \n",
      "Epoch: 420, train/loss: 1.3833, eval/loss: 2.7866, train/r2: 0.5081, eval/r2: 0.4756, train/one: 0.7969, train/two: -0.0899, train/three: 0.8173, eval/one: 0.5423, eval/two: 0.0863, eval/three: 0.7982 \n",
      "Epoch: 425, train/loss: 1.4052, eval/loss: 2.7485, train/r2: 0.5036, eval/r2: 0.4781, train/one: 0.7941, train/two: -0.0908, train/three: 0.8075, eval/one: 0.5491, eval/two: 0.0878, eval/three: 0.7974 \n",
      "Epoch: 430, train/loss: 1.3710, eval/loss: 2.7695, train/r2: 0.5100, eval/r2: 0.4767, train/one: 0.8003, train/two: -0.0727, train/three: 0.8025, eval/one: 0.5453, eval/two: 0.0867, eval/three: 0.7981 \n",
      "Epoch: 435, train/loss: 1.3683, eval/loss: 2.8290, train/r2: 0.5051, eval/r2: 0.4742, train/one: 0.8011, train/two: -0.0883, train/three: 0.8025, eval/one: 0.5344, eval/two: 0.0885, eval/three: 0.7996 \n",
      "Epoch: 440, train/loss: 1.4009, eval/loss: 2.8255, train/r2: 0.5072, eval/r2: 0.4747, train/one: 0.7957, train/two: -0.0692, train/three: 0.7952, eval/one: 0.5350, eval/two: 0.0894, eval/three: 0.7996 \n",
      "Epoch: 445, train/loss: 1.3455, eval/loss: 2.7480, train/r2: 0.4958, eval/r2: 0.4791, train/one: 0.8048, train/two: -0.1331, train/three: 0.8156, eval/one: 0.5489, eval/two: 0.0884, eval/three: 0.7999 \n",
      "Epoch: 450, train/loss: 1.3690, eval/loss: 2.8473, train/r2: 0.5079, eval/r2: 0.4737, train/one: 0.8009, train/two: -0.0792, train/three: 0.8022, eval/one: 0.5311, eval/two: 0.0901, eval/three: 0.7998 \n",
      "Epoch: 455, train/loss: 1.3698, eval/loss: 2.7648, train/r2: 0.5180, eval/r2: 0.4785, train/one: 0.8008, train/two: -0.0396, train/three: 0.7927, eval/one: 0.5460, eval/two: 0.0901, eval/three: 0.7993 \n",
      "Epoch: 460, train/loss: 1.4028, eval/loss: 2.8074, train/r2: 0.5044, eval/r2: 0.4753, train/one: 0.7960, train/two: -0.0728, train/three: 0.7901, eval/one: 0.5385, eval/two: 0.0892, eval/three: 0.7981 \n",
      "Epoch: 465, train/loss: 1.3741, eval/loss: 2.7891, train/r2: 0.4931, eval/r2: 0.4766, train/one: 0.8032, train/two: -0.1000, train/three: 0.7762, eval/one: 0.5417, eval/two: 0.0896, eval/three: 0.7986 \n",
      "Epoch: 470, train/loss: 1.3837, eval/loss: 2.8183, train/r2: 0.5106, eval/r2: 0.4751, train/one: 0.7978, train/two: -0.0702, train/three: 0.8041, eval/one: 0.5363, eval/two: 0.0892, eval/three: 0.7998 \n",
      "Epoch: 475, train/loss: 1.3595, eval/loss: 2.7765, train/r2: 0.5034, eval/r2: 0.4771, train/one: 0.8031, train/two: -0.0933, train/three: 0.8005, eval/one: 0.5439, eval/two: 0.0884, eval/three: 0.7989 \n",
      "Epoch: 480, train/loss: 1.3556, eval/loss: 2.7728, train/r2: 0.4990, eval/r2: 0.4776, train/one: 0.8050, train/two: -0.0978, train/three: 0.7897, eval/one: 0.5445, eval/two: 0.0885, eval/three: 0.7998 \n",
      "Epoch: 485, train/loss: 1.3253, eval/loss: 2.7993, train/r2: 0.5327, eval/r2: 0.4760, train/one: 0.8067, train/two: -0.0155, train/three: 0.8071, eval/one: 0.5397, eval/two: 0.0885, eval/three: 0.7998 \n",
      "Epoch: 490, train/loss: 1.3483, eval/loss: 2.8127, train/r2: 0.4832, eval/r2: 0.4752, train/one: 0.8068, train/two: -0.1537, train/three: 0.7966, eval/one: 0.5373, eval/two: 0.0885, eval/three: 0.8000 \n",
      "Epoch: 495, train/loss: 1.3564, eval/loss: 2.8141, train/r2: 0.5225, eval/r2: 0.4752, train/one: 0.8013, train/two: -0.0458, train/three: 0.8120, eval/one: 0.5371, eval/two: 0.0885, eval/three: 0.8001 \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4724b21e4eb430abd1ec2826c3bb65c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:227: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, train/loss: 10.2039, eval/loss: 11.6049, train/r2: -0.7315, eval/r2: -0.8693, train/one: -0.6345, train/two: -0.9568, train/three: -0.6033, eval/one: -0.7533, eval/two: -1.2880, eval/three: -0.5666 \n",
      "Epoch: 5, train/loss: 9.7401, eval/loss: 11.7562, train/r2: -0.6314, eval/r2: -0.9200, train/one: -0.5602, train/two: -0.7864, train/three: -0.5475, eval/one: -0.7755, eval/two: -1.4105, eval/three: -0.5740 \n",
      "Epoch: 10, train/loss: 8.5496, eval/loss: 11.6348, train/r2: -0.4468, eval/r2: -0.8629, train/one: -0.3666, train/two: -0.5942, train/three: -0.3797, eval/one: -0.7613, eval/two: -1.2913, eval/three: -0.5363 \n",
      "Epoch: 15, train/loss: 6.9663, eval/loss: 10.4778, train/r2: -0.2530, eval/r2: -0.6163, train/one: -0.1042, train/two: -0.4848, train/three: -0.1700, eval/one: -0.5879, eval/two: -0.8506, eval/three: -0.4104 \n",
      "Epoch: 20, train/loss: 5.9975, eval/loss: 7.9158, train/r2: -0.1224, eval/r2: -0.1873, train/one: 0.0544, train/two: -0.3925, train/three: -0.0290, eval/one: -0.1985, eval/two: -0.2588, eval/three: -0.1046 \n",
      "Epoch: 25, train/loss: 5.6727, eval/loss: 6.4100, train/r2: -0.1039, eval/r2: 0.0044, train/one: 0.1090, train/two: -0.4423, train/three: 0.0217, eval/one: 0.0435, eval/two: 0.0074, eval/three: -0.0378 \n",
      "Epoch: 30, train/loss: 5.6201, eval/loss: 6.1406, train/r2: -0.0776, eval/r2: 0.0306, train/one: 0.1165, train/two: -0.3759, train/three: 0.0265, eval/one: 0.0904, eval/two: 0.0638, eval/three: -0.0625 \n",
      "Epoch: 35, train/loss: 5.3556, eval/loss: 5.9718, train/r2: 0.0077, eval/r2: 0.0662, train/one: 0.1527, train/two: -0.2356, train/three: 0.1059, eval/one: 0.1101, eval/two: 0.0651, eval/three: 0.0234 \n",
      "Epoch: 40, train/loss: 5.3388, eval/loss: 6.0091, train/r2: 0.0353, eval/r2: 0.0794, train/one: 0.1530, train/two: -0.1626, train/three: 0.1156, eval/one: 0.0960, eval/two: 0.0359, eval/three: 0.1063 \n",
      "Epoch: 45, train/loss: 5.0986, eval/loss: 6.7613, train/r2: 0.0377, eval/r2: 0.0201, train/one: 0.1948, train/two: -0.2282, train/three: 0.1464, eval/one: -0.0306, eval/two: -0.0232, eval/three: 0.1140 \n",
      "Epoch: 50, train/loss: 4.7773, eval/loss: 7.2753, train/r2: 0.0959, eval/r2: -0.0310, train/one: 0.2495, train/two: -0.1186, train/three: 0.1568, eval/one: -0.1098, eval/two: -0.0213, eval/three: 0.0382 \n",
      "Epoch: 55, train/loss: 4.5522, eval/loss: 7.5100, train/r2: 0.0797, eval/r2: -0.0292, train/one: 0.2955, train/two: -0.1804, train/three: 0.1241, eval/one: -0.1565, eval/two: -0.0428, eval/three: 0.1116 \n",
      "Epoch: 60, train/loss: 4.3452, eval/loss: 6.2060, train/r2: 0.1006, eval/r2: 0.0668, train/one: 0.3283, train/two: -0.1985, train/three: 0.1720, eval/one: 0.0608, eval/two: 0.0095, eval/three: 0.1300 \n",
      "Epoch: 65, train/loss: 4.0760, eval/loss: 5.0977, train/r2: 0.1108, eval/r2: 0.1133, train/one: 0.3763, train/two: -0.2316, train/three: 0.1878, eval/one: 0.2573, eval/two: 0.0518, eval/three: 0.0308 \n",
      "Epoch: 70, train/loss: 3.7472, eval/loss: 5.9833, train/r2: 0.1761, eval/r2: 0.0485, train/one: 0.4299, train/two: -0.1227, train/three: 0.2212, eval/one: 0.1117, eval/two: 0.0396, eval/three: -0.0057 \n",
      "Epoch: 75, train/loss: 3.5851, eval/loss: 8.4253, train/r2: 0.1824, eval/r2: -0.0578, train/one: 0.4550, train/two: -0.1808, train/three: 0.2731, eval/one: -0.3114, eval/two: 0.0405, eval/three: 0.0974 \n",
      "Epoch: 80, train/loss: 3.5132, eval/loss: 9.3675, train/r2: 0.1730, eval/r2: -0.0697, train/one: 0.4659, train/two: -0.2554, train/three: 0.3083, eval/one: -0.4862, eval/two: 0.0213, eval/three: 0.2557 \n",
      "Epoch: 85, train/loss: 3.4106, eval/loss: 5.4669, train/r2: 0.1812, eval/r2: 0.1725, train/one: 0.4857, train/two: -0.2358, train/three: 0.2937, eval/one: 0.1672, eval/two: 0.0460, eval/three: 0.3042 \n",
      "Epoch: 90, train/loss: 3.2348, eval/loss: 3.9631, train/r2: 0.2205, eval/r2: 0.2620, train/one: 0.5132, train/two: -0.1732, train/three: 0.3216, eval/one: 0.4205, eval/two: 0.0560, eval/three: 0.3095 \n",
      "Epoch: 95, train/loss: 3.1992, eval/loss: 4.1321, train/r2: 0.2152, eval/r2: 0.2645, train/one: 0.5169, train/two: -0.2299, train/three: 0.3586, eval/one: 0.3894, eval/two: 0.0734, eval/three: 0.3307 \n",
      "Epoch: 100, train/loss: 3.0309, eval/loss: 4.1315, train/r2: 0.2505, eval/r2: 0.2725, train/one: 0.5439, train/two: -0.1714, train/three: 0.3790, eval/one: 0.3860, eval/two: 0.0643, eval/three: 0.3672 \n",
      "Epoch: 105, train/loss: 3.0181, eval/loss: 4.7265, train/r2: 0.2661, eval/r2: 0.1847, train/one: 0.5405, train/two: -0.1746, train/three: 0.4324, eval/one: 0.3049, eval/two: 0.0748, eval/three: 0.1744 \n",
      "Epoch: 110, train/loss: 2.8048, eval/loss: 3.9059, train/r2: 0.3068, eval/r2: 0.2580, train/one: 0.5745, train/two: -0.1188, train/three: 0.4646, eval/one: 0.4345, eval/two: 0.0766, eval/three: 0.2628 \n",
      "Epoch: 115, train/loss: 2.7015, eval/loss: 4.1083, train/r2: 0.2917, eval/r2: 0.2664, train/one: 0.5947, train/two: -0.1846, train/three: 0.4651, eval/one: 0.3938, eval/two: 0.0798, eval/three: 0.3255 \n",
      "Epoch: 120, train/loss: 2.5999, eval/loss: 3.9745, train/r2: 0.3222, eval/r2: 0.3053, train/one: 0.6090, train/two: -0.1354, train/three: 0.4929, eval/one: 0.4052, eval/two: 0.0741, eval/three: 0.4366 \n",
      "Epoch: 125, train/loss: 2.8881, eval/loss: 4.1410, train/r2: 0.3149, eval/r2: 0.3026, train/one: 0.5546, train/two: -0.1171, train/three: 0.5071, eval/one: 0.3752, eval/two: 0.0776, eval/three: 0.4550 \n",
      "Epoch: 130, train/loss: 2.7442, eval/loss: 4.0406, train/r2: 0.3187, eval/r2: 0.3071, train/one: 0.5803, train/two: -0.1403, train/three: 0.5163, eval/one: 0.3922, eval/two: 0.0740, eval/three: 0.4551 \n",
      "Epoch: 135, train/loss: 2.6628, eval/loss: 4.8583, train/r2: 0.3064, eval/r2: 0.2537, train/one: 0.5977, train/two: -0.1798, train/three: 0.5014, eval/one: 0.2565, eval/two: 0.0738, eval/three: 0.4307 \n",
      "Epoch: 140, train/loss: 2.4832, eval/loss: 3.8324, train/r2: 0.3592, eval/r2: 0.3047, train/one: 0.6224, train/two: -0.1022, train/three: 0.5576, eval/one: 0.4326, eval/two: 0.0787, eval/three: 0.4028 \n",
      "Epoch: 145, train/loss: 2.4362, eval/loss: 4.1383, train/r2: 0.3668, eval/r2: 0.3122, train/one: 0.6306, train/two: -0.0881, train/three: 0.5578, eval/one: 0.3721, eval/two: 0.0746, eval/three: 0.4898 \n",
      "Epoch: 150, train/loss: 2.8919, eval/loss: 5.3197, train/r2: 0.3253, eval/r2: 0.2257, train/one: 0.5478, train/two: -0.1396, train/three: 0.5676, eval/one: 0.1785, eval/two: 0.0653, eval/three: 0.4333 \n",
      "Epoch: 155, train/loss: 2.5442, eval/loss: 3.6493, train/r2: 0.3541, eval/r2: 0.2568, train/one: 0.6095, train/two: -0.1265, train/three: 0.5793, eval/one: 0.4814, eval/two: 0.0569, eval/three: 0.2320 \n",
      "Epoch: 160, train/loss: 2.3807, eval/loss: 3.5661, train/r2: 0.3736, eval/r2: 0.3159, train/one: 0.6400, train/two: -0.0813, train/three: 0.5622, eval/one: 0.4779, eval/two: 0.0687, eval/three: 0.4011 \n",
      "Epoch: 165, train/loss: 2.3667, eval/loss: 3.5678, train/r2: 0.3707, eval/r2: 0.3531, train/one: 0.6419, train/two: -0.1027, train/three: 0.5731, eval/one: 0.4646, eval/two: 0.0649, eval/three: 0.5298 \n",
      "Epoch: 170, train/loss: 2.2987, eval/loss: 3.5960, train/r2: 0.3991, eval/r2: 0.3411, train/one: 0.6514, train/two: -0.0394, train/three: 0.5854, eval/one: 0.4644, eval/two: 0.0755, eval/three: 0.4835 \n",
      "Epoch: 175, train/loss: 2.2733, eval/loss: 3.6487, train/r2: 0.3688, eval/r2: 0.3262, train/one: 0.6596, train/two: -0.1239, train/three: 0.5708, eval/one: 0.4604, eval/two: 0.0850, eval/three: 0.4334 \n",
      "Epoch: 180, train/loss: 2.2236, eval/loss: 3.5115, train/r2: 0.4006, eval/r2: 0.3319, train/one: 0.6641, train/two: -0.0618, train/three: 0.5995, eval/one: 0.4839, eval/two: 0.0808, eval/three: 0.4309 \n",
      "Epoch: 185, train/loss: 2.1685, eval/loss: 3.6159, train/r2: 0.3926, eval/r2: 0.3521, train/one: 0.6744, train/two: -0.1015, train/three: 0.6050, eval/one: 0.4573, eval/two: 0.0798, eval/three: 0.5193 \n",
      "Epoch: 190, train/loss: 2.0942, eval/loss: 3.6075, train/r2: 0.4045, eval/r2: 0.3555, train/one: 0.6863, train/two: -0.0902, train/three: 0.6176, eval/one: 0.4584, eval/two: 0.0882, eval/three: 0.5200 \n",
      "Epoch: 195, train/loss: 2.0517, eval/loss: 3.5267, train/r2: 0.4213, eval/r2: 0.3618, train/one: 0.6931, train/two: -0.0451, train/three: 0.6160, eval/one: 0.4713, eval/two: 0.0856, eval/three: 0.5286 \n",
      "Epoch: 200, train/loss: 2.0702, eval/loss: 3.9294, train/r2: 0.4031, eval/r2: 0.2753, train/one: 0.6883, train/two: -0.1250, train/three: 0.6460, eval/one: 0.4247, eval/two: 0.0825, eval/three: 0.3186 \n",
      "Epoch: 205, train/loss: 2.0439, eval/loss: 4.0570, train/r2: 0.4016, eval/r2: 0.2401, train/one: 0.6929, train/two: -0.1382, train/three: 0.6501, eval/one: 0.4130, eval/two: 0.0866, eval/three: 0.2206 \n",
      "Epoch: 210, train/loss: 2.0169, eval/loss: 3.4270, train/r2: 0.4221, eval/r2: 0.3825, train/one: 0.6952, train/two: -0.0943, train/three: 0.6653, eval/one: 0.4832, eval/two: 0.0887, eval/three: 0.5757 \n",
      "Epoch: 215, train/loss: 2.0207, eval/loss: 3.5499, train/r2: 0.3993, eval/r2: 0.3508, train/one: 0.7017, train/two: -0.1055, train/three: 0.6017, eval/one: 0.4714, eval/two: 0.0943, eval/three: 0.4865 \n",
      "Epoch: 220, train/loss: 1.9648, eval/loss: 4.0403, train/r2: 0.4360, eval/r2: 0.3572, train/one: 0.7051, train/two: -0.0492, train/three: 0.6520, eval/one: 0.3766, eval/two: 0.0894, eval/three: 0.6058 \n",
      "Epoch: 225, train/loss: 2.0038, eval/loss: 3.4580, train/r2: 0.4030, eval/r2: 0.3892, train/one: 0.6999, train/two: -0.1455, train/three: 0.6546, eval/one: 0.4754, eval/two: 0.0910, eval/three: 0.6012 \n",
      "Epoch: 230, train/loss: 1.9226, eval/loss: 3.4188, train/r2: 0.4417, eval/r2: 0.3904, train/one: 0.7109, train/two: -0.0558, train/three: 0.6701, eval/one: 0.4824, eval/two: 0.0917, eval/three: 0.5971 \n",
      "Epoch: 235, train/loss: 1.8809, eval/loss: 3.4193, train/r2: 0.4402, eval/r2: 0.3949, train/one: 0.7177, train/two: -0.0789, train/three: 0.6817, eval/one: 0.4807, eval/two: 0.0907, eval/three: 0.6132 \n",
      "Epoch: 240, train/loss: 1.8525, eval/loss: 3.7086, train/r2: 0.4404, eval/r2: 0.3816, train/one: 0.7219, train/two: -0.0951, train/three: 0.6944, eval/one: 0.4315, eval/two: 0.0988, eval/three: 0.6145 \n",
      "Epoch: 245, train/loss: 1.8373, eval/loss: 3.4027, train/r2: 0.4527, eval/r2: 0.3999, train/one: 0.7244, train/two: -0.0543, train/three: 0.6880, eval/one: 0.4826, eval/two: 0.0956, eval/three: 0.6214 \n",
      "Epoch: 250, train/loss: 1.7630, eval/loss: 3.3862, train/r2: 0.4659, eval/r2: 0.3995, train/one: 0.7350, train/two: -0.0515, train/three: 0.7141, eval/one: 0.4856, eval/two: 0.0938, eval/three: 0.6192 \n",
      "Epoch: 255, train/loss: 1.7363, eval/loss: 3.4844, train/r2: 0.4645, eval/r2: 0.4021, train/one: 0.7416, train/two: -0.0447, train/three: 0.6966, eval/one: 0.4665, eval/two: 0.0963, eval/three: 0.6437 \n",
      "Epoch: 260, train/loss: 1.7454, eval/loss: 3.4035, train/r2: 0.4853, eval/r2: 0.4051, train/one: 0.7364, train/two: -0.0001, train/three: 0.7197, eval/one: 0.4805, eval/two: 0.0945, eval/three: 0.6402 \n",
      "Epoch: 265, train/loss: 1.7372, eval/loss: 3.4026, train/r2: 0.4590, eval/r2: 0.3831, train/one: 0.7409, train/two: -0.0712, train/three: 0.7073, eval/one: 0.4878, eval/two: 0.0900, eval/three: 0.5713 \n",
      "Epoch: 270, train/loss: 1.7149, eval/loss: 3.4147, train/r2: 0.4571, eval/r2: 0.4051, train/one: 0.7447, train/two: -0.0860, train/three: 0.7128, eval/one: 0.4785, eval/two: 0.0958, eval/three: 0.6409 \n",
      "Epoch: 275, train/loss: 1.7673, eval/loss: 4.0363, train/r2: 0.4676, eval/r2: 0.3740, train/one: 0.7337, train/two: -0.0492, train/three: 0.7184, eval/one: 0.3726, eval/two: 0.0999, eval/three: 0.6494 \n",
      "Epoch: 280, train/loss: 1.7046, eval/loss: 3.7455, train/r2: 0.4793, eval/r2: 0.3472, train/one: 0.7445, train/two: -0.0260, train/three: 0.7193, eval/one: 0.4356, eval/two: 0.0915, eval/three: 0.5144 \n",
      "Epoch: 285, train/loss: 1.6645, eval/loss: 3.4691, train/r2: 0.4825, eval/r2: 0.4045, train/one: 0.7503, train/two: -0.0380, train/three: 0.7353, eval/one: 0.4680, eval/two: 0.0905, eval/three: 0.6551 \n",
      "Epoch: 290, train/loss: 1.6596, eval/loss: 3.4089, train/r2: 0.4758, eval/r2: 0.4075, train/one: 0.7506, train/two: -0.0705, train/three: 0.7473, eval/one: 0.4787, eval/two: 0.0943, eval/three: 0.6494 \n",
      "Epoch: 295, train/loss: 1.6558, eval/loss: 3.4046, train/r2: 0.4905, eval/r2: 0.4031, train/one: 0.7516, train/two: -0.0123, train/three: 0.7321, eval/one: 0.4811, eval/two: 0.0962, eval/three: 0.6319 \n",
      "Epoch: 300, train/loss: 1.6319, eval/loss: 3.3939, train/r2: 0.4816, eval/r2: 0.3931, train/one: 0.7559, train/two: -0.0521, train/three: 0.7409, eval/one: 0.4863, eval/two: 0.0934, eval/three: 0.5996 \n",
      "Epoch: 305, train/loss: 1.5981, eval/loss: 3.4278, train/r2: 0.4939, eval/r2: 0.4110, train/one: 0.7630, train/two: -0.0036, train/three: 0.7224, eval/one: 0.4741, eval/two: 0.0959, eval/three: 0.6629 \n",
      "Epoch: 310, train/loss: 1.5873, eval/loss: 3.4371, train/r2: 0.4953, eval/r2: 0.3800, train/one: 0.7623, train/two: -0.0279, train/three: 0.7514, eval/one: 0.4827, eval/two: 0.0943, eval/three: 0.5629 \n",
      "Epoch: 315, train/loss: 1.5853, eval/loss: 3.4402, train/r2: 0.4908, eval/r2: 0.4124, train/one: 0.7634, train/two: -0.0376, train/three: 0.7465, eval/one: 0.4710, eval/two: 0.0934, eval/three: 0.6727 \n",
      "Epoch: 320, train/loss: 1.5747, eval/loss: 3.3402, train/r2: 0.5005, eval/r2: 0.4146, train/one: 0.7627, train/two: -0.0305, train/three: 0.7694, eval/one: 0.4890, eval/two: 0.0927, eval/three: 0.6620 \n",
      "Epoch: 325, train/loss: 1.5890, eval/loss: 3.4828, train/r2: 0.4904, eval/r2: 0.4095, train/one: 0.7620, train/two: -0.0460, train/three: 0.7553, eval/one: 0.4639, eval/two: 0.0926, eval/three: 0.6720 \n",
      "Epoch: 330, train/loss: 1.5845, eval/loss: 3.3000, train/r2: 0.4967, eval/r2: 0.4232, train/one: 0.7620, train/two: -0.0315, train/three: 0.7595, eval/one: 0.4938, eval/two: 0.0947, eval/three: 0.6811 \n",
      "Epoch: 335, train/loss: 1.5975, eval/loss: 3.3537, train/r2: 0.4953, eval/r2: 0.4189, train/one: 0.7599, train/two: -0.0308, train/three: 0.7569, eval/one: 0.4851, eval/two: 0.0930, eval/three: 0.6787 \n",
      "Epoch: 340, train/loss: 1.5803, eval/loss: 3.8948, train/r2: 0.4940, eval/r2: 0.3892, train/one: 0.7620, train/two: -0.0506, train/three: 0.7706, eval/one: 0.3937, eval/two: 0.0962, eval/three: 0.6778 \n",
      "Epoch: 345, train/loss: 1.5871, eval/loss: 3.5095, train/r2: 0.5006, eval/r2: 0.4004, train/one: 0.7611, train/two: -0.0205, train/three: 0.7612, eval/one: 0.4623, eval/two: 0.0958, eval/three: 0.6430 \n",
      "Epoch: 350, train/loss: 1.5432, eval/loss: 3.4273, train/r2: 0.4983, eval/r2: 0.4169, train/one: 0.7683, train/two: -0.0477, train/three: 0.7741, eval/one: 0.4721, eval/two: 0.0957, eval/three: 0.6828 \n",
      "Epoch: 355, train/loss: 1.5422, eval/loss: 3.5112, train/r2: 0.5030, eval/r2: 0.3781, train/one: 0.7675, train/two: -0.0405, train/three: 0.7821, eval/one: 0.4696, eval/two: 0.0963, eval/three: 0.5683 \n",
      "Epoch: 360, train/loss: 1.5145, eval/loss: 3.3973, train/r2: 0.4971, eval/r2: 0.4190, train/one: 0.7742, train/two: -0.0520, train/three: 0.7690, eval/one: 0.4770, eval/two: 0.0957, eval/three: 0.6843 \n",
      "Epoch: 365, train/loss: 1.4799, eval/loss: 3.4868, train/r2: 0.5122, eval/r2: 0.4092, train/one: 0.7784, train/two: -0.0233, train/three: 0.7817, eval/one: 0.4635, eval/two: 0.0948, eval/three: 0.6692 \n",
      "Epoch: 370, train/loss: 1.4729, eval/loss: 3.4741, train/r2: 0.5161, eval/r2: 0.3903, train/one: 0.7800, train/two: -0.0068, train/three: 0.7751, eval/one: 0.4724, eval/two: 0.0957, eval/three: 0.6028 \n",
      "Epoch: 375, train/loss: 1.4897, eval/loss: 3.4924, train/r2: 0.5020, eval/r2: 0.4002, train/one: 0.7776, train/two: -0.0497, train/three: 0.7781, eval/one: 0.4657, eval/two: 0.0972, eval/three: 0.6376 \n",
      "Epoch: 380, train/loss: 1.4498, eval/loss: 3.4644, train/r2: 0.5178, eval/r2: 0.4123, train/one: 0.7837, train/two: -0.0114, train/three: 0.7810, eval/one: 0.4668, eval/two: 0.0967, eval/three: 0.6733 \n",
      "Epoch: 385, train/loss: 1.5065, eval/loss: 3.4775, train/r2: 0.5034, eval/r2: 0.4148, train/one: 0.7742, train/two: -0.0448, train/three: 0.7807, eval/one: 0.4637, eval/two: 0.0985, eval/three: 0.6822 \n",
      "Epoch: 390, train/loss: 1.4765, eval/loss: 3.5348, train/r2: 0.5211, eval/r2: 0.4052, train/one: 0.7786, train/two: 0.0044, train/three: 0.7802, eval/one: 0.4561, eval/two: 0.0979, eval/three: 0.6616 \n",
      "Epoch: 395, train/loss: 1.4848, eval/loss: 3.5256, train/r2: 0.5140, eval/r2: 0.4107, train/one: 0.7776, train/two: -0.0152, train/three: 0.7796, eval/one: 0.4559, eval/two: 0.0975, eval/three: 0.6786 \n",
      "Epoch: 400, train/loss: 1.4679, eval/loss: 3.4570, train/r2: 0.5425, eval/r2: 0.4178, train/one: 0.7795, train/two: 0.0777, train/three: 0.7704, eval/one: 0.4665, eval/two: 0.0992, eval/three: 0.6877 \n",
      "Epoch: 405, train/loss: 1.4521, eval/loss: 3.5268, train/r2: 0.4956, eval/r2: 0.4137, train/one: 0.7846, train/two: -0.0817, train/three: 0.7840, eval/one: 0.4548, eval/two: 0.0993, eval/three: 0.6869 \n",
      "Epoch: 410, train/loss: 1.4622, eval/loss: 3.5064, train/r2: 0.5085, eval/r2: 0.4068, train/one: 0.7828, train/two: -0.0292, train/three: 0.7720, eval/one: 0.4608, eval/two: 0.0971, eval/three: 0.6625 \n",
      "Epoch: 415, train/loss: 1.4327, eval/loss: 3.4924, train/r2: 0.5159, eval/r2: 0.4162, train/one: 0.7860, train/two: -0.0306, train/three: 0.7925, eval/one: 0.4604, eval/two: 0.0989, eval/three: 0.6894 \n",
      "Epoch: 420, train/loss: 1.4414, eval/loss: 3.5177, train/r2: 0.5120, eval/r2: 0.4148, train/one: 0.7852, train/two: -0.0356, train/three: 0.7864, eval/one: 0.4561, eval/two: 0.0988, eval/three: 0.6894 \n",
      "Epoch: 425, train/loss: 1.4486, eval/loss: 3.5307, train/r2: 0.5181, eval/r2: 0.4085, train/one: 0.7844, train/two: -0.0050, train/three: 0.7750, eval/one: 0.4559, eval/two: 0.0992, eval/three: 0.6703 \n",
      "Epoch: 430, train/loss: 1.4741, eval/loss: 3.5377, train/r2: 0.5257, eval/r2: 0.4068, train/one: 0.7776, train/two: 0.0072, train/three: 0.7924, eval/one: 0.4552, eval/two: 0.0999, eval/three: 0.6654 \n",
      "Epoch: 435, train/loss: 1.4291, eval/loss: 3.5201, train/r2: 0.5185, eval/r2: 0.4153, train/one: 0.7871, train/two: -0.0172, train/three: 0.7858, eval/one: 0.4555, eval/two: 0.0993, eval/three: 0.6911 \n",
      "Epoch: 440, train/loss: 1.4209, eval/loss: 3.5063, train/r2: 0.5412, eval/r2: 0.4161, train/one: 0.7873, train/two: 0.0538, train/three: 0.7825, eval/one: 0.4579, eval/two: 0.0994, eval/three: 0.6910 \n",
      "Epoch: 445, train/loss: 1.4021, eval/loss: 3.5159, train/r2: 0.5153, eval/r2: 0.4157, train/one: 0.7925, train/two: -0.0303, train/three: 0.7836, eval/one: 0.4562, eval/two: 0.0996, eval/three: 0.6912 \n",
      "Epoch: 450, train/loss: 1.4184, eval/loss: 3.5192, train/r2: 0.5140, eval/r2: 0.4164, train/one: 0.7898, train/two: -0.0289, train/three: 0.7811, eval/one: 0.4553, eval/two: 0.0992, eval/three: 0.6948 \n",
      "Epoch: 455, train/loss: 1.4288, eval/loss: 3.5116, train/r2: 0.5224, eval/r2: 0.4155, train/one: 0.7884, train/two: 0.0101, train/three: 0.7687, eval/one: 0.4571, eval/two: 0.0996, eval/three: 0.6897 \n",
      "Epoch: 460, train/loss: 1.4202, eval/loss: 3.5355, train/r2: 0.5289, eval/r2: 0.4154, train/one: 0.7887, train/two: 0.0199, train/three: 0.7780, eval/one: 0.4526, eval/two: 0.0993, eval/three: 0.6941 \n",
      "Epoch: 465, train/loss: 1.4552, eval/loss: 3.5205, train/r2: 0.5091, eval/r2: 0.4162, train/one: 0.7841, train/two: -0.0289, train/three: 0.7722, eval/one: 0.4551, eval/two: 0.0988, eval/three: 0.6945 \n",
      "Epoch: 470, train/loss: 1.4120, eval/loss: 3.5092, train/r2: 0.5319, eval/r2: 0.4171, train/one: 0.7902, train/two: 0.0299, train/three: 0.7755, eval/one: 0.4569, eval/two: 0.0990, eval/three: 0.6954 \n",
      "Epoch: 475, train/loss: 1.4212, eval/loss: 3.5387, train/r2: 0.5375, eval/r2: 0.4156, train/one: 0.7881, train/two: 0.0490, train/three: 0.7753, eval/one: 0.4520, eval/two: 0.0996, eval/three: 0.6953 \n",
      "Epoch: 480, train/loss: 1.4344, eval/loss: 3.5175, train/r2: 0.5290, eval/r2: 0.4166, train/one: 0.7858, train/two: 0.0200, train/three: 0.7811, eval/one: 0.4556, eval/two: 0.0996, eval/three: 0.6945 \n",
      "Epoch: 485, train/loss: 1.4747, eval/loss: 3.5191, train/r2: 0.4985, eval/r2: 0.4161, train/one: 0.7807, train/two: -0.0626, train/three: 0.7774, eval/one: 0.4555, eval/two: 0.0995, eval/three: 0.6933 \n",
      "Epoch: 490, train/loss: 1.4279, eval/loss: 3.5308, train/r2: 0.5195, eval/r2: 0.4156, train/one: 0.7878, train/two: -0.0082, train/three: 0.7789, eval/one: 0.4535, eval/two: 0.0994, eval/three: 0.6938 \n",
      "Epoch: 495, train/loss: 1.4279, eval/loss: 3.5340, train/r2: 0.5001, eval/r2: 0.4156, train/one: 0.7891, train/two: -0.0689, train/three: 0.7802, eval/one: 0.4528, eval/two: 0.0994, eval/three: 0.6945 \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b51caedf4c340ce929276c0e40c716d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:227: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, train/loss: 10.5894, eval/loss: 12.5787, train/r2: -1.1636, eval/r2: -1.0777, train/one: -0.6692, train/two: -1.8591, train/three: -0.9625, eval/one: -0.8228, eval/two: -1.6969, eval/three: -0.7135 \n",
      "Epoch: 5, train/loss: 10.1416, eval/loss: 12.6407, train/r2: -1.0401, eval/r2: -1.1025, train/one: -0.6018, train/two: -1.6490, train/three: -0.8695, eval/one: -0.8294, eval/two: -1.7361, eval/three: -0.7419 \n",
      "Epoch: 10, train/loss: 8.9601, eval/loss: 12.5542, train/r2: -0.7683, eval/r2: -1.0228, train/one: -0.4192, train/two: -1.2508, train/three: -0.6349, eval/one: -0.8218, eval/two: -1.5289, eval/three: -0.7177 \n",
      "Epoch: 15, train/loss: 7.4638, eval/loss: 11.4867, train/r2: -0.4625, eval/r2: -0.7507, train/one: -0.1849, train/two: -0.8619, train/three: -0.3406, eval/one: -0.6745, eval/two: -1.0250, eval/three: -0.5527 \n",
      "Epoch: 20, train/loss: 6.1538, eval/loss: 8.6062, train/r2: -0.1674, eval/r2: -0.2784, train/one: 0.0248, train/two: -0.3725, train/three: -0.1544, eval/one: -0.2585, eval/two: -0.4381, eval/three: -0.1387 \n",
      "Epoch: 25, train/loss: 5.6790, eval/loss: 7.0652, train/r2: -0.0560, eval/r2: -0.0464, train/one: 0.0897, train/two: -0.2898, train/three: 0.0322, eval/one: -0.0261, eval/two: -0.0836, eval/three: -0.0297 \n",
      "Epoch: 30, train/loss: 5.6760, eval/loss: 7.1054, train/r2: -0.0897, eval/r2: -0.1199, train/one: 0.0929, train/two: -0.3916, train/three: 0.0296, eval/one: -0.0090, eval/two: -0.0696, eval/three: -0.2812 \n",
      "Epoch: 35, train/loss: 5.5541, eval/loss: 6.6154, train/r2: -0.0412, eval/r2: -0.0230, train/one: 0.1134, train/two: -0.2567, train/three: 0.0196, eval/one: 0.0534, eval/two: -0.0073, eval/three: -0.1151 \n",
      "Epoch: 40, train/loss: 5.3402, eval/loss: 6.7603, train/r2: 0.0019, eval/r2: -0.0315, train/one: 0.1403, train/two: -0.2684, train/three: 0.1339, eval/one: 0.0159, eval/two: -0.1788, eval/three: 0.0683 \n",
      "Epoch: 45, train/loss: 5.1321, eval/loss: 6.9525, train/r2: 0.0542, eval/r2: -0.0293, train/one: 0.1743, train/two: -0.1637, train/three: 0.1521, eval/one: -0.0130, eval/two: -0.1039, eval/three: 0.0290 \n",
      "Epoch: 50, train/loss: 4.9065, eval/loss: 7.0209, train/r2: 0.0678, eval/r2: -0.0311, train/one: 0.2154, train/two: -0.1704, train/three: 0.1582, eval/one: -0.0240, eval/two: -0.0961, eval/three: 0.0269 \n",
      "Epoch: 55, train/loss: 4.6238, eval/loss: 7.4473, train/r2: 0.0925, eval/r2: -0.0464, train/one: 0.2665, train/two: -0.1535, train/three: 0.1646, eval/one: -0.0995, eval/two: -0.1431, eval/three: 0.1035 \n",
      "Epoch: 60, train/loss: 4.2227, eval/loss: 6.3270, train/r2: 0.1101, eval/r2: 0.0379, train/one: 0.3376, train/two: -0.2104, train/three: 0.2030, eval/one: 0.0811, eval/two: -0.0652, eval/three: 0.0977 \n",
      "Epoch: 65, train/loss: 3.9629, eval/loss: 5.8856, train/r2: 0.1032, eval/r2: 0.0908, train/one: 0.3910, train/two: -0.2432, train/three: 0.1617, eval/one: 0.1460, eval/two: -0.0363, eval/three: 0.1625 \n",
      "Epoch: 70, train/loss: 3.6501, eval/loss: 4.9761, train/r2: 0.1515, eval/r2: 0.1617, train/one: 0.4409, train/two: -0.2114, train/three: 0.2249, eval/one: 0.2893, eval/two: -0.0029, eval/three: 0.1987 \n",
      "Epoch: 75, train/loss: 3.6700, eval/loss: 5.6539, train/r2: 0.1534, eval/r2: 0.1190, train/one: 0.4345, train/two: -0.2275, train/three: 0.2531, eval/one: 0.1804, eval/two: -0.0141, eval/three: 0.1906 \n",
      "Epoch: 80, train/loss: 3.4515, eval/loss: 4.4251, train/r2: 0.1558, eval/r2: 0.2109, train/one: 0.4734, train/two: -0.2834, train/three: 0.2774, eval/one: 0.3753, eval/two: 0.0306, eval/three: 0.2269 \n",
      "Epoch: 85, train/loss: 3.2935, eval/loss: 4.2831, train/r2: 0.2155, eval/r2: 0.2373, train/one: 0.4950, train/two: -0.1702, train/three: 0.3217, eval/one: 0.3938, eval/two: 0.0462, eval/three: 0.2720 \n",
      "Epoch: 90, train/loss: 3.1607, eval/loss: 4.3479, train/r2: 0.2092, eval/r2: 0.1979, train/one: 0.5190, train/two: -0.2304, train/three: 0.3391, eval/one: 0.3932, eval/two: 0.0293, eval/three: 0.1713 \n",
      "Epoch: 95, train/loss: 3.0218, eval/loss: 4.1753, train/r2: 0.2534, eval/r2: 0.2013, train/one: 0.5393, train/two: -0.1482, train/three: 0.3691, eval/one: 0.4218, eval/two: 0.0142, eval/three: 0.1679 \n",
      "Epoch: 100, train/loss: 2.9227, eval/loss: 4.1481, train/r2: 0.2682, eval/r2: 0.2234, train/one: 0.5554, train/two: -0.1378, train/three: 0.3870, eval/one: 0.4211, eval/two: 0.0313, eval/three: 0.2179 \n",
      "Epoch: 105, train/loss: 2.7853, eval/loss: 4.5343, train/r2: 0.2882, eval/r2: 0.2585, train/one: 0.5746, train/two: -0.1559, train/three: 0.4459, eval/one: 0.3417, eval/two: 0.0418, eval/three: 0.3921 \n",
      "Epoch: 110, train/loss: 2.8924, eval/loss: 4.2370, train/r2: 0.2907, eval/r2: 0.2910, train/one: 0.5528, train/two: -0.1411, train/three: 0.4605, eval/one: 0.3839, eval/two: 0.0309, eval/three: 0.4582 \n",
      "Epoch: 115, train/loss: 2.6960, eval/loss: 4.6230, train/r2: 0.2969, eval/r2: 0.2845, train/one: 0.5886, train/two: -0.1681, train/three: 0.4702, eval/one: 0.3169, eval/two: 0.0323, eval/three: 0.5043 \n",
      "Epoch: 120, train/loss: 2.6910, eval/loss: 3.9882, train/r2: 0.3127, eval/r2: 0.3028, train/one: 0.5882, train/two: -0.1232, train/three: 0.4732, eval/one: 0.4237, eval/two: 0.0186, eval/three: 0.4662 \n",
      "Epoch: 125, train/loss: 2.5849, eval/loss: 3.8385, train/r2: 0.3214, eval/r2: 0.2765, train/one: 0.6022, train/two: -0.1711, train/three: 0.5331, eval/one: 0.4602, eval/two: 0.0360, eval/three: 0.3334 \n",
      "Epoch: 130, train/loss: 2.5540, eval/loss: 3.7088, train/r2: 0.3197, eval/r2: 0.3159, train/one: 0.6105, train/two: -0.1590, train/three: 0.5076, eval/one: 0.4697, eval/two: 0.0197, eval/three: 0.4582 \n",
      "Epoch: 135, train/loss: 2.4551, eval/loss: 4.1574, train/r2: 0.3273, eval/r2: 0.3084, train/one: 0.6272, train/two: -0.1681, train/three: 0.5227, eval/one: 0.3929, eval/two: 0.0338, eval/three: 0.4986 \n",
      "Epoch: 140, train/loss: 2.8141, eval/loss: 6.0666, train/r2: 0.2842, eval/r2: 0.1394, train/one: 0.5649, train/two: -0.2085, train/three: 0.4962, eval/one: 0.0999, eval/two: -0.0154, eval/three: 0.3337 \n",
      "Epoch: 145, train/loss: 2.8431, eval/loss: 6.8010, train/r2: 0.3386, eval/r2: 0.0109, train/one: 0.5503, train/two: -0.0877, train/three: 0.5533, eval/one: 0.0098, eval/two: -0.0032, eval/three: 0.0261 \n",
      "Epoch: 150, train/loss: 2.6307, eval/loss: 4.1916, train/r2: 0.3231, eval/r2: 0.3040, train/one: 0.5946, train/two: -0.1451, train/three: 0.5198, eval/one: 0.3925, eval/two: 0.0865, eval/three: 0.4331 \n",
      "Epoch: 155, train/loss: 2.4358, eval/loss: 3.8346, train/r2: 0.3543, eval/r2: 0.3473, train/one: 0.6248, train/two: -0.1304, train/three: 0.5685, eval/one: 0.4361, eval/two: 0.0054, eval/three: 0.6003 \n",
      "Epoch: 160, train/loss: 2.2851, eval/loss: 3.8019, train/r2: 0.3945, eval/r2: 0.3360, train/one: 0.6458, train/two: -0.0817, train/three: 0.6196, eval/one: 0.4478, eval/two: 0.0322, eval/three: 0.5280 \n",
      "Epoch: 165, train/loss: 2.2680, eval/loss: 4.2582, train/r2: 0.3689, eval/r2: 0.1860, train/one: 0.6524, train/two: -0.1485, train/three: 0.6029, eval/one: 0.4142, eval/two: 0.0436, eval/three: 0.1002 \n",
      "Epoch: 170, train/loss: 2.1902, eval/loss: 3.9508, train/r2: 0.3803, eval/r2: 0.3134, train/one: 0.6652, train/two: -0.1391, train/three: 0.6148, eval/one: 0.4282, eval/two: 0.0325, eval/three: 0.4796 \n",
      "Epoch: 175, train/loss: 2.1142, eval/loss: 4.3676, train/r2: 0.4096, eval/r2: 0.1337, train/one: 0.6753, train/two: -0.0846, train/three: 0.6381, eval/one: 0.4118, eval/two: 0.0532, eval/three: -0.0639 \n",
      "Epoch: 180, train/loss: 2.0506, eval/loss: 3.9133, train/r2: 0.4141, eval/r2: 0.2811, train/one: 0.6882, train/two: -0.0712, train/three: 0.6253, eval/one: 0.4438, eval/two: 0.0170, eval/three: 0.3825 \n",
      "Epoch: 185, train/loss: 2.0501, eval/loss: 4.1992, train/r2: 0.3847, eval/r2: 0.3289, train/one: 0.6894, train/two: -0.1711, train/three: 0.6359, eval/one: 0.3801, eval/two: 0.0472, eval/three: 0.5594 \n",
      "Epoch: 190, train/loss: 2.0732, eval/loss: 4.2094, train/r2: 0.3920, eval/r2: 0.2347, train/one: 0.6838, train/two: -0.1520, train/three: 0.6443, eval/one: 0.4086, eval/two: 0.0567, eval/three: 0.2389 \n",
      "Epoch: 195, train/loss: 2.0275, eval/loss: 4.0309, train/r2: 0.4110, eval/r2: 0.3275, train/one: 0.6951, train/two: -0.0615, train/three: 0.5994, eval/one: 0.4111, eval/two: 0.0521, eval/three: 0.5192 \n",
      "Epoch: 200, train/loss: 1.9427, eval/loss: 3.8037, train/r2: 0.4142, eval/r2: 0.3701, train/one: 0.7051, train/two: -0.1262, train/three: 0.6636, eval/one: 0.4380, eval/two: 0.0480, eval/three: 0.6242 \n",
      "Epoch: 205, train/loss: 1.9232, eval/loss: 3.6391, train/r2: 0.4192, eval/r2: 0.3468, train/one: 0.7072, train/two: -0.1272, train/three: 0.6776, eval/one: 0.4749, eval/two: 0.0488, eval/three: 0.5167 \n",
      "Epoch: 210, train/loss: 1.8847, eval/loss: 3.8708, train/r2: 0.4055, eval/r2: 0.2377, train/one: 0.7155, train/two: -0.1752, train/three: 0.6762, eval/one: 0.4679, eval/two: 0.0516, eval/three: 0.1936 \n",
      "Epoch: 215, train/loss: 1.8160, eval/loss: 3.6433, train/r2: 0.4442, eval/r2: 0.3692, train/one: 0.7241, train/two: -0.0867, train/three: 0.6952, eval/one: 0.4676, eval/two: 0.0544, eval/three: 0.5856 \n",
      "Epoch: 220, train/loss: 1.8079, eval/loss: 3.6795, train/r2: 0.4382, eval/r2: 0.3782, train/one: 0.7257, train/two: -0.1098, train/three: 0.6986, eval/one: 0.4582, eval/two: 0.0537, eval/three: 0.6228 \n",
      "Epoch: 225, train/loss: 1.8344, eval/loss: 3.8237, train/r2: 0.4616, eval/r2: 0.3041, train/one: 0.7197, train/two: -0.0265, train/three: 0.6915, eval/one: 0.4570, eval/two: 0.0699, eval/three: 0.3854 \n",
      "Epoch: 230, train/loss: 1.7579, eval/loss: 3.6665, train/r2: 0.4671, eval/r2: 0.3516, train/one: 0.7347, train/two: -0.0145, train/three: 0.6812, eval/one: 0.4696, eval/two: 0.0622, eval/three: 0.5229 \n",
      "Epoch: 235, train/loss: 1.7724, eval/loss: 3.6873, train/r2: 0.4623, eval/r2: 0.3915, train/one: 0.7297, train/two: -0.0523, train/three: 0.7095, eval/one: 0.4536, eval/two: 0.0659, eval/three: 0.6551 \n",
      "Epoch: 240, train/loss: 1.8096, eval/loss: 3.6542, train/r2: 0.4317, eval/r2: 0.3819, train/one: 0.7234, train/two: -0.1534, train/three: 0.7250, eval/one: 0.4631, eval/two: 0.0726, eval/three: 0.6098 \n",
      "Epoch: 245, train/loss: 1.7562, eval/loss: 3.8460, train/r2: 0.4571, eval/r2: 0.3387, train/one: 0.7324, train/two: -0.0785, train/three: 0.7175, eval/one: 0.4411, eval/two: 0.0571, eval/three: 0.5179 \n",
      "Epoch: 250, train/loss: 1.6295, eval/loss: 3.5421, train/r2: 0.4862, eval/r2: 0.4047, train/one: 0.7532, train/two: -0.0239, train/three: 0.7295, eval/one: 0.4757, eval/two: 0.0688, eval/three: 0.6696 \n",
      "Epoch: 255, train/loss: 1.6950, eval/loss: 3.5770, train/r2: 0.4872, eval/r2: 0.4060, train/one: 0.7389, train/two: -0.0271, train/three: 0.7498, eval/one: 0.4677, eval/two: 0.0522, eval/three: 0.6983 \n",
      "Epoch: 260, train/loss: 1.6643, eval/loss: 3.5372, train/r2: 0.4707, eval/r2: 0.3733, train/one: 0.7472, train/two: -0.0703, train/three: 0.7352, eval/one: 0.4851, eval/two: 0.0529, eval/three: 0.5819 \n",
      "Epoch: 265, train/loss: 1.6206, eval/loss: 3.4959, train/r2: 0.4669, eval/r2: 0.4151, train/one: 0.7548, train/two: -0.1002, train/three: 0.7460, eval/one: 0.4795, eval/two: 0.0545, eval/three: 0.7111 \n",
      "Epoch: 270, train/loss: 1.6239, eval/loss: 3.6370, train/r2: 0.4947, eval/r2: 0.3345, train/one: 0.7528, train/two: -0.0076, train/three: 0.7390, eval/one: 0.4790, eval/two: 0.0473, eval/three: 0.4771 \n",
      "Epoch: 275, train/loss: 1.6171, eval/loss: 3.7811, train/r2: 0.4883, eval/r2: 0.3974, train/one: 0.7534, train/two: -0.0401, train/three: 0.7516, eval/one: 0.4347, eval/two: 0.0626, eval/three: 0.6951 \n",
      "Epoch: 280, train/loss: 1.5914, eval/loss: 3.6259, train/r2: 0.4843, eval/r2: 0.3707, train/one: 0.7573, train/two: -0.0688, train/three: 0.7644, eval/one: 0.4714, eval/two: 0.0683, eval/three: 0.5724 \n",
      "Epoch: 285, train/loss: 1.6032, eval/loss: 3.7637, train/r2: 0.4812, eval/r2: 0.3752, train/one: 0.7582, train/two: -0.0473, train/three: 0.7328, eval/one: 0.4453, eval/two: 0.0695, eval/three: 0.6108 \n",
      "Epoch: 290, train/loss: 1.6039, eval/loss: 3.5472, train/r2: 0.4738, eval/r2: 0.4096, train/one: 0.7571, train/two: -0.0856, train/three: 0.7499, eval/one: 0.4718, eval/two: 0.0513, eval/three: 0.7056 \n",
      "Epoch: 295, train/loss: 1.5622, eval/loss: 3.5388, train/r2: 0.4752, eval/r2: 0.4074, train/one: 0.7642, train/two: -0.0952, train/three: 0.7566, eval/one: 0.4753, eval/two: 0.0666, eval/three: 0.6802 \n",
      "Epoch: 300, train/loss: 1.5380, eval/loss: 3.4815, train/r2: 0.5014, eval/r2: 0.4084, train/one: 0.7652, train/two: -0.0373, train/three: 0.7763, eval/one: 0.4855, eval/two: 0.0701, eval/three: 0.6696 \n",
      "Epoch: 305, train/loss: 1.5468, eval/loss: 3.6286, train/r2: 0.4945, eval/r2: 0.3520, train/one: 0.7642, train/two: -0.0545, train/three: 0.7737, eval/one: 0.4761, eval/two: 0.0601, eval/three: 0.5199 \n",
      "Epoch: 310, train/loss: 1.4788, eval/loss: 3.5048, train/r2: 0.5093, eval/r2: 0.4100, train/one: 0.7761, train/two: -0.0206, train/three: 0.7724, eval/one: 0.4798, eval/two: 0.0582, eval/three: 0.6921 \n",
      "Epoch: 315, train/loss: 1.5363, eval/loss: 3.4907, train/r2: 0.5027, eval/r2: 0.4158, train/one: 0.7671, train/two: -0.0164, train/three: 0.7575, eval/one: 0.4799, eval/two: 0.0505, eval/three: 0.7171 \n",
      "Epoch: 320, train/loss: 1.4762, eval/loss: 3.6756, train/r2: 0.4905, eval/r2: 0.4027, train/one: 0.7777, train/two: -0.0815, train/three: 0.7754, eval/one: 0.4497, eval/two: 0.0362, eval/three: 0.7220 \n",
      "Epoch: 325, train/loss: 1.4997, eval/loss: 3.5750, train/r2: 0.4840, eval/r2: 0.3712, train/one: 0.7743, train/two: -0.0914, train/three: 0.7690, eval/one: 0.4784, eval/two: 0.0451, eval/three: 0.5900 \n",
      "Epoch: 330, train/loss: 1.4518, eval/loss: 3.5529, train/r2: 0.4974, eval/r2: 0.4185, train/one: 0.7823, train/two: -0.0604, train/three: 0.7702, eval/one: 0.4682, eval/two: 0.0537, eval/three: 0.7335 \n",
      "Epoch: 335, train/loss: 1.4896, eval/loss: 3.6450, train/r2: 0.4958, eval/r2: 0.4092, train/one: 0.7755, train/two: -0.0556, train/three: 0.7676, eval/one: 0.4545, eval/two: 0.0526, eval/three: 0.7204 \n",
      "Epoch: 340, train/loss: 1.4460, eval/loss: 3.5589, train/r2: 0.5111, eval/r2: 0.4011, train/one: 0.7838, train/two: -0.0055, train/three: 0.7551, eval/one: 0.4731, eval/two: 0.0603, eval/three: 0.6700 \n",
      "Epoch: 345, train/loss: 1.3863, eval/loss: 3.5861, train/r2: 0.5298, eval/r2: 0.3997, train/one: 0.7912, train/two: 0.0152, train/three: 0.7829, eval/one: 0.4685, eval/two: 0.0580, eval/three: 0.6725 \n",
      "Epoch: 350, train/loss: 1.4273, eval/loss: 3.6189, train/r2: 0.5152, eval/r2: 0.3864, train/one: 0.7849, train/two: -0.0174, train/three: 0.7779, eval/one: 0.4674, eval/two: 0.0656, eval/three: 0.6261 \n",
      "Epoch: 355, train/loss: 1.4098, eval/loss: 3.4741, train/r2: 0.5182, eval/r2: 0.4152, train/one: 0.7867, train/two: -0.0247, train/three: 0.7925, eval/one: 0.4845, eval/two: 0.0674, eval/three: 0.6937 \n",
      "Epoch: 360, train/loss: 1.3822, eval/loss: 3.4813, train/r2: 0.5148, eval/r2: 0.4253, train/one: 0.7930, train/two: -0.0320, train/three: 0.7833, eval/one: 0.4800, eval/two: 0.0678, eval/three: 0.7281 \n",
      "Epoch: 365, train/loss: 1.4112, eval/loss: 3.5401, train/r2: 0.5310, eval/r2: 0.4075, train/one: 0.7861, train/two: 0.0204, train/three: 0.7867, eval/one: 0.4751, eval/two: 0.0679, eval/three: 0.6794 \n",
      "Epoch: 370, train/loss: 1.4153, eval/loss: 3.6196, train/r2: 0.4798, eval/r2: 0.4181, train/one: 0.7888, train/two: -0.1379, train/three: 0.7884, eval/one: 0.4576, eval/two: 0.0684, eval/three: 0.7282 \n",
      "Epoch: 375, train/loss: 1.3727, eval/loss: 3.5530, train/r2: 0.5263, eval/r2: 0.4183, train/one: 0.7927, train/two: -0.0110, train/three: 0.7972, eval/one: 0.4693, eval/two: 0.0661, eval/three: 0.7194 \n",
      "Epoch: 380, train/loss: 1.3993, eval/loss: 3.5500, train/r2: 0.5084, eval/r2: 0.4197, train/one: 0.7894, train/two: -0.0567, train/three: 0.7924, eval/one: 0.4693, eval/two: 0.0657, eval/three: 0.7242 \n",
      "Epoch: 385, train/loss: 1.3562, eval/loss: 3.5480, train/r2: 0.5071, eval/r2: 0.4139, train/one: 0.7966, train/two: -0.0790, train/three: 0.8039, eval/one: 0.4712, eval/two: 0.0625, eval/three: 0.7081 \n",
      "Epoch: 390, train/loss: 1.3938, eval/loss: 3.7011, train/r2: 0.4948, eval/r2: 0.4060, train/one: 0.7910, train/two: -0.1035, train/three: 0.7968, eval/one: 0.4460, eval/two: 0.0591, eval/three: 0.7129 \n",
      "Epoch: 395, train/loss: 1.3589, eval/loss: 3.6523, train/r2: 0.5068, eval/r2: 0.4029, train/one: 0.7967, train/two: -0.0733, train/three: 0.7971, eval/one: 0.4562, eval/two: 0.0647, eval/three: 0.6878 \n",
      "Epoch: 400, train/loss: 1.3621, eval/loss: 3.5092, train/r2: 0.5222, eval/r2: 0.4228, train/one: 0.7946, train/two: -0.0297, train/three: 0.8019, eval/one: 0.4754, eval/two: 0.0629, eval/three: 0.7301 \n",
      "Epoch: 405, train/loss: 1.3576, eval/loss: 3.5116, train/r2: 0.5264, eval/r2: 0.4225, train/one: 0.7958, train/two: -0.0112, train/three: 0.7947, eval/one: 0.4752, eval/two: 0.0642, eval/three: 0.7282 \n",
      "Epoch: 410, train/loss: 1.3527, eval/loss: 3.5318, train/r2: 0.5109, eval/r2: 0.4214, train/one: 0.7989, train/two: -0.0493, train/three: 0.7833, eval/one: 0.4719, eval/two: 0.0636, eval/three: 0.7287 \n",
      "Epoch: 415, train/loss: 1.3484, eval/loss: 3.5463, train/r2: 0.5159, eval/r2: 0.4211, train/one: 0.7978, train/two: -0.0504, train/three: 0.8002, eval/one: 0.4695, eval/two: 0.0647, eval/three: 0.7291 \n",
      "Epoch: 420, train/loss: 1.3551, eval/loss: 3.5331, train/r2: 0.5335, eval/r2: 0.4223, train/one: 0.7947, train/two: -0.0009, train/three: 0.8067, eval/one: 0.4716, eval/two: 0.0661, eval/three: 0.7292 \n",
      "Epoch: 425, train/loss: 1.3699, eval/loss: 3.5282, train/r2: 0.5257, eval/r2: 0.4234, train/one: 0.7931, train/two: -0.0159, train/three: 0.7998, eval/one: 0.4720, eval/two: 0.0657, eval/three: 0.7325 \n",
      "Epoch: 430, train/loss: 1.3169, eval/loss: 3.5338, train/r2: 0.5266, eval/r2: 0.4224, train/one: 0.8035, train/two: -0.0178, train/three: 0.7943, eval/one: 0.4714, eval/two: 0.0665, eval/three: 0.7293 \n",
      "Epoch: 435, train/loss: 1.3600, eval/loss: 3.5017, train/r2: 0.5304, eval/r2: 0.4258, train/one: 0.7946, train/two: -0.0026, train/three: 0.7992, eval/one: 0.4762, eval/two: 0.0672, eval/three: 0.7341 \n",
      "Epoch: 440, train/loss: 1.3495, eval/loss: 3.5286, train/r2: 0.5183, eval/r2: 0.4237, train/one: 0.7982, train/two: -0.0349, train/three: 0.7916, eval/one: 0.4720, eval/two: 0.0673, eval/three: 0.7317 \n",
      "Epoch: 445, train/loss: 1.3358, eval/loss: 3.5301, train/r2: 0.5443, eval/r2: 0.4238, train/one: 0.7988, train/two: 0.0409, train/three: 0.7933, eval/one: 0.4716, eval/two: 0.0662, eval/three: 0.7337 \n",
      "Epoch: 450, train/loss: 1.3539, eval/loss: 3.5031, train/r2: 0.5097, eval/r2: 0.4257, train/one: 0.7972, train/two: -0.0681, train/three: 0.8000, eval/one: 0.4758, eval/two: 0.0648, eval/three: 0.7364 \n",
      "Epoch: 455, train/loss: 1.3271, eval/loss: 3.5257, train/r2: 0.5186, eval/r2: 0.4242, train/one: 0.8011, train/two: -0.0510, train/three: 0.8056, eval/one: 0.4723, eval/two: 0.0664, eval/three: 0.7337 \n",
      "Epoch: 460, train/loss: 1.3441, eval/loss: 3.5359, train/r2: 0.5191, eval/r2: 0.4239, train/one: 0.7979, train/two: -0.0465, train/three: 0.8058, eval/one: 0.4706, eval/two: 0.0666, eval/three: 0.7345 \n",
      "Epoch: 465, train/loss: 1.3349, eval/loss: 3.5289, train/r2: 0.5275, eval/r2: 0.4245, train/one: 0.7986, train/two: -0.0264, train/three: 0.8104, eval/one: 0.4717, eval/two: 0.0671, eval/three: 0.7348 \n",
      "Epoch: 470, train/loss: 1.3491, eval/loss: 3.5144, train/r2: 0.5089, eval/r2: 0.4257, train/one: 0.7988, train/two: -0.0655, train/three: 0.7935, eval/one: 0.4739, eval/two: 0.0670, eval/three: 0.7363 \n",
      "Epoch: 475, train/loss: 1.3480, eval/loss: 3.5421, train/r2: 0.5223, eval/r2: 0.4241, train/one: 0.7976, train/two: -0.0292, train/three: 0.7985, eval/one: 0.4695, eval/two: 0.0675, eval/three: 0.7352 \n",
      "Epoch: 480, train/loss: 1.3825, eval/loss: 3.5340, train/r2: 0.5222, eval/r2: 0.4247, train/one: 0.7926, train/two: -0.0078, train/three: 0.7819, eval/one: 0.4708, eval/two: 0.0680, eval/three: 0.7352 \n",
      "Epoch: 485, train/loss: 1.3482, eval/loss: 3.5269, train/r2: 0.5130, eval/r2: 0.4252, train/one: 0.7987, train/two: -0.0525, train/three: 0.7929, eval/one: 0.4719, eval/two: 0.0681, eval/three: 0.7357 \n",
      "Epoch: 490, train/loss: 1.3158, eval/loss: 3.5237, train/r2: 0.5528, eval/r2: 0.4255, train/one: 0.8011, train/two: 0.0553, train/three: 0.8021, eval/one: 0.4724, eval/two: 0.0681, eval/three: 0.7361 \n",
      "Epoch: 495, train/loss: 1.3076, eval/loss: 3.5254, train/r2: 0.5277, eval/r2: 0.4255, train/one: 0.8040, train/two: -0.0277, train/three: 0.8069, eval/one: 0.4721, eval/two: 0.0681, eval/three: 0.7365 \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69473df9833444bfbaea2b4e4003c948",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:227: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, train/loss: 10.9612, eval/loss: 9.2846, train/r2: -0.8765, eval/r2: -0.8843, train/one: -0.6919, train/two: -1.2323, train/three: -0.7052, eval/one: -0.5836, eval/two: -1.3887, eval/three: -0.6805 \n",
      "Epoch: 5, train/loss: 10.5429, eval/loss: 9.4099, train/r2: -0.7544, eval/r2: -0.8770, train/one: -0.6344, train/two: -1.0297, train/three: -0.5990, eval/one: -0.6014, eval/two: -1.2680, eval/three: -0.7615 \n",
      "Epoch: 10, train/loss: 9.2852, eval/loss: 9.5220, train/r2: -0.5100, eval/r2: -0.8260, train/one: -0.4482, train/two: -0.7463, train/three: -0.3354, eval/one: -0.6227, eval/two: -1.0488, eval/three: -0.8065 \n",
      "Epoch: 15, train/loss: 7.6280, eval/loss: 9.1885, train/r2: -0.2529, eval/r2: -0.6480, train/one: -0.1896, train/two: -0.4808, train/three: -0.0883, eval/one: -0.5748, eval/two: -0.6458, eval/three: -0.7234 \n",
      "Epoch: 20, train/loss: 6.4066, eval/loss: 7.1242, train/r2: -0.0973, eval/r2: -0.1946, train/one: 0.0093, train/two: -0.3261, train/three: 0.0250, eval/one: -0.2350, eval/two: -0.1054, eval/three: -0.2434 \n",
      "Epoch: 25, train/loss: 5.9228, eval/loss: 5.5319, train/r2: -0.0986, eval/r2: 0.0224, train/one: 0.1025, train/two: -0.3522, train/three: -0.0461, eval/one: 0.0531, eval/two: 0.0735, eval/three: -0.0593 \n",
      "Epoch: 30, train/loss: 6.0019, eval/loss: 5.7194, train/r2: -0.1100, eval/r2: -0.0136, train/one: 0.0820, train/two: -0.4485, train/three: 0.0367, eval/one: 0.0253, eval/two: 0.0727, eval/three: -0.1387 \n",
      "Epoch: 35, train/loss: 5.7556, eval/loss: 5.6620, train/r2: -0.0315, eval/r2: -0.0468, train/one: 0.1166, train/two: -0.2951, train/three: 0.0839, eval/one: 0.0463, eval/two: 0.0297, eval/three: -0.2166 \n",
      "Epoch: 40, train/loss: 5.5404, eval/loss: 5.4862, train/r2: 0.0415, eval/r2: -0.0294, train/one: 0.1455, train/two: -0.1599, train/three: 0.1389, eval/one: 0.0656, eval/two: -0.0923, eval/three: -0.0615 \n",
      "Epoch: 45, train/loss: 5.1090, eval/loss: 5.4134, train/r2: 0.0887, eval/r2: -0.0106, train/one: 0.2194, train/two: -0.0958, train/three: 0.1426, eval/one: 0.0785, eval/two: -0.0542, eval/three: -0.0561 \n",
      "Epoch: 50, train/loss: 4.8592, eval/loss: 6.1142, train/r2: 0.0678, eval/r2: -0.1897, train/one: 0.2670, train/two: -0.1923, train/three: 0.1287, eval/one: -0.0160, eval/two: -0.1321, eval/three: -0.4210 \n",
      "Epoch: 55, train/loss: 4.6809, eval/loss: 5.2249, train/r2: 0.0845, eval/r2: 0.0031, train/one: 0.2953, train/two: -0.2002, train/three: 0.1585, eval/one: 0.1094, eval/two: -0.1074, eval/three: 0.0072 \n",
      "Epoch: 60, train/loss: 4.3777, eval/loss: 4.6682, train/r2: 0.1202, eval/r2: 0.0836, train/one: 0.3475, train/two: -0.1431, train/three: 0.1562, eval/one: 0.2079, eval/two: -0.0490, eval/three: 0.0918 \n",
      "Epoch: 65, train/loss: 3.9960, eval/loss: 4.1625, train/r2: 0.1322, eval/r2: 0.1557, train/one: 0.4132, train/two: -0.1971, train/three: 0.1806, eval/one: 0.2947, eval/two: -0.0253, eval/three: 0.1977 \n",
      "Epoch: 70, train/loss: 3.7235, eval/loss: 5.6415, train/r2: 0.1443, eval/r2: 0.0813, train/one: 0.4594, train/two: -0.2291, train/three: 0.2026, eval/one: 0.0062, eval/two: 0.0749, eval/three: 0.1628 \n",
      "Epoch: 75, train/loss: 3.5632, eval/loss: 5.0927, train/r2: 0.1614, eval/r2: 0.1186, train/one: 0.4840, train/two: -0.2372, train/three: 0.2375, eval/one: 0.1050, eval/two: -0.0055, eval/three: 0.2563 \n",
      "Epoch: 80, train/loss: 3.4022, eval/loss: 4.2642, train/r2: 0.2209, eval/r2: 0.1968, train/one: 0.5036, train/two: -0.1389, train/three: 0.2981, eval/one: 0.2598, eval/two: 0.0073, eval/three: 0.3234 \n",
      "Epoch: 85, train/loss: 3.2696, eval/loss: 4.7698, train/r2: 0.2187, eval/r2: 0.1522, train/one: 0.5252, train/two: -0.1954, train/three: 0.3262, eval/one: 0.1626, eval/two: -0.0152, eval/three: 0.3091 \n",
      "Epoch: 90, train/loss: 3.1667, eval/loss: 3.5508, train/r2: 0.2326, eval/r2: 0.2569, train/one: 0.5407, train/two: -0.1926, train/three: 0.3496, eval/one: 0.3919, eval/two: -0.0193, eval/three: 0.3981 \n",
      "Epoch: 95, train/loss: 3.0050, eval/loss: 3.5443, train/r2: 0.2605, eval/r2: 0.2647, train/one: 0.5633, train/two: -0.1841, train/three: 0.4022, eval/one: 0.3916, eval/two: -0.0072, eval/three: 0.4096 \n",
      "Epoch: 100, train/loss: 2.8628, eval/loss: 3.4865, train/r2: 0.2805, eval/r2: 0.2629, train/one: 0.5857, train/two: -0.1669, train/three: 0.4226, eval/one: 0.4051, eval/two: -0.0072, eval/three: 0.3909 \n",
      "Epoch: 105, train/loss: 2.8573, eval/loss: 3.5955, train/r2: 0.3056, eval/r2: 0.2119, train/one: 0.5828, train/two: -0.1126, train/three: 0.4466, eval/one: 0.3954, eval/two: -0.0564, eval/three: 0.2967 \n",
      "Epoch: 110, train/loss: 2.8856, eval/loss: 3.5904, train/r2: 0.2802, eval/r2: 0.2320, train/one: 0.5801, train/two: -0.1795, train/three: 0.4399, eval/one: 0.3921, eval/two: -0.0245, eval/three: 0.3284 \n",
      "Epoch: 115, train/loss: 2.6937, eval/loss: 3.8843, train/r2: 0.3198, eval/r2: 0.2417, train/one: 0.6058, train/two: -0.1568, train/three: 0.5104, eval/one: 0.3278, eval/two: 0.0187, eval/three: 0.3787 \n",
      "Epoch: 120, train/loss: 2.7375, eval/loss: 3.3132, train/r2: 0.2910, eval/r2: 0.2455, train/one: 0.6046, train/two: -0.1873, train/three: 0.4557, eval/one: 0.4380, eval/two: -0.1226, eval/three: 0.4211 \n",
      "Epoch: 125, train/loss: 2.6347, eval/loss: 3.6594, train/r2: 0.3323, eval/r2: 0.1868, train/one: 0.6146, train/two: -0.1381, train/three: 0.5204, eval/one: 0.3879, eval/two: -0.0849, eval/three: 0.2573 \n",
      "Epoch: 130, train/loss: 2.6261, eval/loss: 3.3941, train/r2: 0.3380, eval/r2: 0.2214, train/one: 0.6144, train/two: -0.1364, train/three: 0.5361, eval/one: 0.4321, eval/two: -0.0966, eval/three: 0.3288 \n",
      "Epoch: 135, train/loss: 2.5587, eval/loss: 3.4809, train/r2: 0.3557, eval/r2: 0.2763, train/one: 0.6250, train/two: -0.0975, train/three: 0.5394, eval/one: 0.3989, eval/two: -0.0284, eval/three: 0.4585 \n",
      "Epoch: 140, train/loss: 2.5327, eval/loss: 3.1904, train/r2: 0.3506, eval/r2: 0.3213, train/one: 0.6300, train/two: -0.1181, train/three: 0.5398, eval/one: 0.4463, eval/two: -0.0249, eval/three: 0.5423 \n",
      "Epoch: 145, train/loss: 2.4974, eval/loss: 3.2377, train/r2: 0.3719, eval/r2: 0.3245, train/one: 0.6332, train/two: -0.0768, train/three: 0.5592, eval/one: 0.4342, eval/two: -0.0285, eval/three: 0.5677 \n",
      "Epoch: 150, train/loss: 2.3892, eval/loss: 3.2613, train/r2: 0.3898, eval/r2: 0.3453, train/one: 0.6481, train/two: -0.0763, train/three: 0.5976, eval/one: 0.4274, eval/two: 0.0320, eval/three: 0.5766 \n",
      "Epoch: 155, train/loss: 2.4426, eval/loss: 3.5297, train/r2: 0.3758, eval/r2: 0.3033, train/one: 0.6385, train/two: -0.1196, train/three: 0.6085, eval/one: 0.3864, eval/two: 0.0539, eval/three: 0.4698 \n",
      "Epoch: 160, train/loss: 2.2695, eval/loss: 2.9928, train/r2: 0.4164, eval/r2: 0.3752, train/one: 0.6666, train/two: -0.0283, train/three: 0.6110, eval/one: 0.4734, eval/two: 0.0133, eval/three: 0.6389 \n",
      "Epoch: 165, train/loss: 2.5089, eval/loss: 6.7429, train/r2: 0.3792, eval/r2: 0.1302, train/one: 0.6258, train/two: -0.1038, train/three: 0.6157, eval/one: -0.2593, eval/two: 0.0500, eval/three: 0.6000 \n",
      "Epoch: 170, train/loss: 2.4312, eval/loss: 3.3361, train/r2: 0.3662, eval/r2: 0.2868, train/one: 0.6401, train/two: -0.1635, train/three: 0.6221, eval/one: 0.4195, eval/two: -0.0983, eval/three: 0.5393 \n",
      "Epoch: 175, train/loss: 2.2840, eval/loss: 3.6315, train/r2: 0.3778, eval/r2: 0.2854, train/one: 0.6640, train/two: -0.1735, train/three: 0.6430, eval/one: 0.3675, eval/two: 0.0228, eval/three: 0.4658 \n",
      "Epoch: 180, train/loss: 2.2381, eval/loss: 3.6610, train/r2: 0.4109, eval/r2: 0.2575, train/one: 0.6719, train/two: -0.0590, train/three: 0.6199, eval/one: 0.3664, eval/two: -0.0269, eval/three: 0.4331 \n",
      "Epoch: 185, train/loss: 2.2231, eval/loss: 3.7092, train/r2: 0.3931, eval/r2: 0.2407, train/one: 0.6755, train/two: -0.1196, train/three: 0.6233, eval/one: 0.3704, eval/two: 0.0510, eval/three: 0.3008 \n",
      "Epoch: 190, train/loss: 2.1620, eval/loss: 3.7246, train/r2: 0.4202, eval/r2: 0.2173, train/one: 0.6821, train/two: -0.0734, train/three: 0.6519, eval/one: 0.3788, eval/two: 0.0772, eval/three: 0.1960 \n",
      "Epoch: 195, train/loss: 2.0846, eval/loss: 3.6950, train/r2: 0.4337, eval/r2: 0.1934, train/one: 0.6939, train/two: -0.0582, train/three: 0.6654, eval/one: 0.3918, eval/two: 0.0509, eval/three: 0.1375 \n",
      "Epoch: 200, train/loss: 2.0369, eval/loss: 3.4740, train/r2: 0.4648, eval/r2: 0.2104, train/one: 0.6989, train/two: 0.0133, train/three: 0.6822, eval/one: 0.4330, eval/two: 0.0397, eval/three: 0.1585 \n",
      "Epoch: 205, train/loss: 2.0576, eval/loss: 3.0133, train/r2: 0.4226, eval/r2: 0.3713, train/one: 0.6975, train/two: -0.1190, train/three: 0.6893, eval/one: 0.4725, eval/two: 0.0341, eval/three: 0.6074 \n",
      "Epoch: 210, train/loss: 2.0844, eval/loss: 3.1305, train/r2: 0.4077, eval/r2: 0.3861, train/one: 0.6932, train/two: -0.1655, train/three: 0.6955, eval/one: 0.4395, eval/two: 0.0209, eval/three: 0.6979 \n",
      "Epoch: 215, train/loss: 2.0209, eval/loss: 2.8848, train/r2: 0.4208, eval/r2: 0.3982, train/one: 0.7027, train/two: -0.1480, train/three: 0.7078, eval/one: 0.4867, eval/two: -0.0030, eval/three: 0.7108 \n",
      "Epoch: 220, train/loss: 1.9743, eval/loss: 2.7412, train/r2: 0.4441, eval/r2: 0.3774, train/one: 0.7087, train/two: -0.0928, train/three: 0.7164, eval/one: 0.5331, eval/two: 0.0593, eval/three: 0.5399 \n",
      "Epoch: 225, train/loss: 1.8967, eval/loss: 2.7702, train/r2: 0.4364, eval/r2: 0.4123, train/one: 0.7238, train/two: -0.1235, train/three: 0.7088, eval/one: 0.5094, eval/two: 0.0232, eval/three: 0.7043 \n",
      "Epoch: 230, train/loss: 1.9266, eval/loss: 2.9558, train/r2: 0.4671, eval/r2: 0.4049, train/one: 0.7153, train/two: -0.0339, train/three: 0.7199, eval/one: 0.4713, eval/two: 0.0244, eval/three: 0.7192 \n",
      "Epoch: 235, train/loss: 2.4618, eval/loss: 6.2461, train/r2: 0.4248, eval/r2: 0.0804, train/one: 0.6248, train/two: -0.0383, train/three: 0.6879, eval/one: -0.1591, eval/two: -0.2255, eval/three: 0.6259 \n",
      "Epoch: 240, train/loss: 2.3875, eval/loss: 4.3846, train/r2: 0.4237, eval/r2: 0.0319, train/one: 0.6353, train/two: -0.0860, train/three: 0.7219, eval/one: 0.2660, eval/two: -0.2822, eval/three: 0.1118 \n",
      "Epoch: 245, train/loss: 2.0758, eval/loss: 3.1374, train/r2: 0.4639, eval/r2: 0.2268, train/one: 0.6892, train/two: -0.0112, train/three: 0.7137, eval/one: 0.4820, eval/two: -0.1429, eval/three: 0.3413 \n",
      "Epoch: 250, train/loss: 2.0230, eval/loss: 3.1743, train/r2: 0.4511, eval/r2: 0.3571, train/one: 0.6990, train/two: -0.0671, train/three: 0.7216, eval/one: 0.4330, eval/two: -0.0539, eval/three: 0.6922 \n",
      "Epoch: 255, train/loss: 1.9755, eval/loss: 2.6233, train/r2: 0.4711, eval/r2: 0.3948, train/one: 0.7056, train/two: -0.0195, train/three: 0.7271, eval/one: 0.5444, eval/two: -0.0173, eval/three: 0.6572 \n",
      "Epoch: 260, train/loss: 1.9472, eval/loss: 3.2376, train/r2: 0.4688, eval/r2: 0.3676, train/one: 0.7115, train/two: -0.0250, train/three: 0.7199, eval/one: 0.4235, eval/two: 0.0277, eval/three: 0.6517 \n",
      "Epoch: 265, train/loss: 1.8699, eval/loss: 2.7578, train/r2: 0.4917, eval/r2: 0.4080, train/one: 0.7215, train/two: 0.0070, train/three: 0.7465, eval/one: 0.5178, eval/two: 0.0609, eval/three: 0.6452 \n",
      "Epoch: 270, train/loss: 1.8634, eval/loss: 2.8418, train/r2: 0.4884, eval/r2: 0.3906, train/one: 0.7228, train/two: -0.0050, train/three: 0.7474, eval/one: 0.5042, eval/two: 0.0445, eval/three: 0.6232 \n",
      "Epoch: 275, train/loss: 1.8575, eval/loss: 3.0334, train/r2: 0.4502, eval/r2: 0.3805, train/one: 0.7275, train/two: -0.1137, train/three: 0.7369, eval/one: 0.4622, eval/two: 0.0127, eval/three: 0.6667 \n",
      "Epoch: 280, train/loss: 1.8077, eval/loss: 2.6430, train/r2: 0.4803, eval/r2: 0.4213, train/one: 0.7324, train/two: -0.0507, train/three: 0.7591, eval/one: 0.5321, eval/two: 0.0037, eval/three: 0.7281 \n",
      "Epoch: 285, train/loss: 1.8365, eval/loss: 2.7467, train/r2: 0.4794, eval/r2: 0.4145, train/one: 0.7268, train/two: -0.0531, train/three: 0.7646, eval/one: 0.5151, eval/two: 0.0353, eval/three: 0.6930 \n",
      "Epoch: 290, train/loss: 1.7773, eval/loss: 2.6887, train/r2: 0.4830, eval/r2: 0.4135, train/one: 0.7384, train/two: -0.0394, train/three: 0.7500, eval/one: 0.5294, eval/two: 0.0457, eval/three: 0.6654 \n",
      "Epoch: 295, train/loss: 1.7792, eval/loss: 2.5834, train/r2: 0.4885, eval/r2: 0.4336, train/one: 0.7373, train/two: -0.0269, train/three: 0.7551, eval/one: 0.5440, eval/two: 0.0367, eval/three: 0.7202 \n",
      "Epoch: 300, train/loss: 1.7077, eval/loss: 2.6573, train/r2: 0.5112, eval/r2: 0.4144, train/one: 0.7470, train/two: 0.0134, train/three: 0.7732, eval/one: 0.5342, eval/two: 0.0280, eval/three: 0.6810 \n",
      "Epoch: 305, train/loss: 1.7398, eval/loss: 2.5912, train/r2: 0.4811, eval/r2: 0.4232, train/one: 0.7439, train/two: -0.0667, train/three: 0.7661, eval/one: 0.5455, eval/two: 0.0287, eval/three: 0.6956 \n",
      "Epoch: 310, train/loss: 1.7175, eval/loss: 2.5919, train/r2: 0.4842, eval/r2: 0.4370, train/one: 0.7481, train/two: -0.0568, train/three: 0.7614, eval/one: 0.5400, eval/two: 0.0288, eval/three: 0.7421 \n",
      "Epoch: 315, train/loss: 1.6772, eval/loss: 2.6537, train/r2: 0.5022, eval/r2: 0.4285, train/one: 0.7531, train/two: -0.0200, train/three: 0.7735, eval/one: 0.5291, eval/two: 0.0243, eval/three: 0.7322 \n",
      "Epoch: 320, train/loss: 1.6661, eval/loss: 2.5576, train/r2: 0.5087, eval/r2: 0.4198, train/one: 0.7543, train/two: -0.0047, train/three: 0.7766, eval/one: 0.5553, eval/two: 0.0383, eval/three: 0.6657 \n",
      "Epoch: 325, train/loss: 1.6262, eval/loss: 2.6058, train/r2: 0.5108, eval/r2: 0.3996, train/one: 0.7624, train/two: 0.0050, train/three: 0.7649, eval/one: 0.5515, eval/two: 0.0309, eval/three: 0.6164 \n",
      "Epoch: 330, train/loss: 1.6182, eval/loss: 2.5667, train/r2: 0.5129, eval/r2: 0.4320, train/one: 0.7627, train/two: 0.0002, train/three: 0.7759, eval/one: 0.5469, eval/two: 0.0226, eval/three: 0.7266 \n",
      "Epoch: 335, train/loss: 1.5741, eval/loss: 2.5459, train/r2: 0.5195, eval/r2: 0.4363, train/one: 0.7696, train/two: 0.0057, train/three: 0.7832, eval/one: 0.5510, eval/two: 0.0339, eval/three: 0.7240 \n",
      "Epoch: 340, train/loss: 1.6012, eval/loss: 2.4887, train/r2: 0.5091, eval/r2: 0.4507, train/one: 0.7666, train/two: -0.0089, train/three: 0.7695, eval/one: 0.5583, eval/two: 0.0352, eval/three: 0.7587 \n",
      "Epoch: 345, train/loss: 1.5739, eval/loss: 2.4658, train/r2: 0.5091, eval/r2: 0.4547, train/one: 0.7719, train/two: -0.0099, train/three: 0.7654, eval/one: 0.5624, eval/two: 0.0407, eval/three: 0.7609 \n",
      "Epoch: 350, train/loss: 1.5846, eval/loss: 2.5377, train/r2: 0.5221, eval/r2: 0.4420, train/one: 0.7676, train/two: 0.0174, train/three: 0.7812, eval/one: 0.5507, eval/two: 0.0347, eval/three: 0.7407 \n",
      "Epoch: 355, train/loss: 1.5307, eval/loss: 2.6621, train/r2: 0.5246, eval/r2: 0.4077, train/one: 0.7777, train/two: 0.0206, train/three: 0.7755, eval/one: 0.5344, eval/two: 0.0162, eval/three: 0.6724 \n",
      "Epoch: 360, train/loss: 1.5670, eval/loss: 2.5602, train/r2: 0.4995, eval/r2: 0.4425, train/one: 0.7730, train/two: -0.0484, train/three: 0.7739, eval/one: 0.5439, eval/two: 0.0192, eval/three: 0.7644 \n",
      "Epoch: 365, train/loss: 1.5472, eval/loss: 2.5311, train/r2: 0.5085, eval/r2: 0.4485, train/one: 0.7750, train/two: -0.0340, train/three: 0.7845, eval/one: 0.5489, eval/two: 0.0275, eval/three: 0.7693 \n",
      "Epoch: 370, train/loss: 1.5468, eval/loss: 2.4622, train/r2: 0.4967, eval/r2: 0.4504, train/one: 0.7757, train/two: -0.0728, train/three: 0.7871, eval/one: 0.5631, eval/two: 0.0241, eval/three: 0.7642 \n",
      "Epoch: 375, train/loss: 1.5393, eval/loss: 2.4997, train/r2: 0.5067, eval/r2: 0.4397, train/one: 0.7770, train/two: -0.0363, train/three: 0.7794, eval/one: 0.5590, eval/two: 0.0249, eval/three: 0.7353 \n",
      "Epoch: 380, train/loss: 1.5415, eval/loss: 2.5736, train/r2: 0.5145, eval/r2: 0.4414, train/one: 0.7750, train/two: -0.0234, train/three: 0.7918, eval/one: 0.5417, eval/two: 0.0227, eval/three: 0.7599 \n",
      "Epoch: 385, train/loss: 1.4976, eval/loss: 2.6187, train/r2: 0.5204, eval/r2: 0.4408, train/one: 0.7827, train/two: -0.0110, train/three: 0.7894, eval/one: 0.5316, eval/two: 0.0193, eval/three: 0.7714 \n",
      "Epoch: 390, train/loss: 1.5288, eval/loss: 2.4888, train/r2: 0.5184, eval/r2: 0.4498, train/one: 0.7783, train/two: 0.0002, train/three: 0.7766, eval/one: 0.5570, eval/two: 0.0201, eval/three: 0.7722 \n",
      "Epoch: 395, train/loss: 1.4990, eval/loss: 2.4962, train/r2: 0.5191, eval/r2: 0.4479, train/one: 0.7825, train/two: -0.0147, train/three: 0.7896, eval/one: 0.5557, eval/two: 0.0164, eval/three: 0.7717 \n",
      "Epoch: 400, train/loss: 1.5090, eval/loss: 2.5684, train/r2: 0.5232, eval/r2: 0.4350, train/one: 0.7810, train/two: 0.0057, train/three: 0.7831, eval/one: 0.5446, eval/two: 0.0160, eval/three: 0.7445 \n",
      "Epoch: 405, train/loss: 1.4863, eval/loss: 2.5514, train/r2: 0.5262, eval/r2: 0.4383, train/one: 0.7840, train/two: 0.0008, train/three: 0.7938, eval/one: 0.5465, eval/two: 0.0098, eval/three: 0.7585 \n",
      "Epoch: 410, train/loss: 1.4316, eval/loss: 2.5005, train/r2: 0.5348, eval/r2: 0.4485, train/one: 0.7924, train/two: 0.0085, train/three: 0.8035, eval/one: 0.5546, eval/two: 0.0166, eval/three: 0.7742 \n",
      "Epoch: 415, train/loss: 1.4536, eval/loss: 2.4820, train/r2: 0.5106, eval/r2: 0.4489, train/one: 0.7916, train/two: -0.0459, train/three: 0.7862, eval/one: 0.5584, eval/two: 0.0160, eval/three: 0.7722 \n",
      "Epoch: 420, train/loss: 1.4579, eval/loss: 2.5341, train/r2: 0.5161, eval/r2: 0.4328, train/one: 0.7905, train/two: -0.0276, train/three: 0.7854, eval/one: 0.5531, eval/two: 0.0164, eval/three: 0.7289 \n",
      "Epoch: 425, train/loss: 1.4581, eval/loss: 2.4990, train/r2: 0.5353, eval/r2: 0.4478, train/one: 0.7885, train/two: 0.0246, train/three: 0.7928, eval/one: 0.5552, eval/two: 0.0166, eval/three: 0.7715 \n",
      "Epoch: 430, train/loss: 1.4200, eval/loss: 2.5331, train/r2: 0.5282, eval/r2: 0.4427, train/one: 0.7961, train/two: -0.0014, train/three: 0.7900, eval/one: 0.5493, eval/two: 0.0143, eval/three: 0.7645 \n",
      "Epoch: 435, train/loss: 1.4496, eval/loss: 2.4917, train/r2: 0.5345, eval/r2: 0.4474, train/one: 0.7905, train/two: 0.0257, train/three: 0.7872, eval/one: 0.5567, eval/two: 0.0145, eval/three: 0.7711 \n",
      "Epoch: 440, train/loss: 1.4535, eval/loss: 2.5363, train/r2: 0.5329, eval/r2: 0.4412, train/one: 0.7893, train/two: 0.0141, train/three: 0.7952, eval/one: 0.5491, eval/two: 0.0137, eval/three: 0.7607 \n",
      "Epoch: 445, train/loss: 1.4664, eval/loss: 2.4726, train/r2: 0.5232, eval/r2: 0.4499, train/one: 0.7883, train/two: -0.0064, train/three: 0.7878, eval/one: 0.5602, eval/two: 0.0169, eval/three: 0.7727 \n",
      "Epoch: 450, train/loss: 1.4649, eval/loss: 2.5406, train/r2: 0.5411, eval/r2: 0.4450, train/one: 0.7882, train/two: 0.0585, train/three: 0.7767, eval/one: 0.5468, eval/two: 0.0145, eval/three: 0.7736 \n",
      "Epoch: 455, train/loss: 1.4500, eval/loss: 2.4862, train/r2: 0.4963, eval/r2: 0.4464, train/one: 0.7936, train/two: -0.0869, train/three: 0.7820, eval/one: 0.5584, eval/two: 0.0156, eval/three: 0.7652 \n",
      "Epoch: 460, train/loss: 1.4369, eval/loss: 2.4987, train/r2: 0.5177, eval/r2: 0.4475, train/one: 0.7930, train/two: -0.0386, train/three: 0.7987, eval/one: 0.5552, eval/two: 0.0153, eval/three: 0.7721 \n",
      "Epoch: 465, train/loss: 1.4500, eval/loss: 2.4975, train/r2: 0.5198, eval/r2: 0.4464, train/one: 0.7923, train/two: -0.0109, train/three: 0.7780, eval/one: 0.5559, eval/two: 0.0151, eval/three: 0.7682 \n",
      "Epoch: 470, train/loss: 1.4594, eval/loss: 2.5059, train/r2: 0.5246, eval/r2: 0.4454, train/one: 0.7888, train/two: -0.0098, train/three: 0.7946, eval/one: 0.5544, eval/two: 0.0152, eval/three: 0.7665 \n",
      "Epoch: 475, train/loss: 1.4306, eval/loss: 2.5031, train/r2: 0.5229, eval/r2: 0.4474, train/one: 0.7952, train/two: -0.0093, train/three: 0.7828, eval/one: 0.5542, eval/two: 0.0149, eval/three: 0.7731 \n",
      "Epoch: 480, train/loss: 1.4301, eval/loss: 2.5008, train/r2: 0.4918, eval/r2: 0.4476, train/one: 0.7963, train/two: -0.1172, train/three: 0.7962, eval/one: 0.5547, eval/two: 0.0150, eval/three: 0.7731 \n",
      "Epoch: 485, train/loss: 1.4553, eval/loss: 2.4961, train/r2: 0.5109, eval/r2: 0.4476, train/one: 0.7911, train/two: -0.0463, train/three: 0.7880, eval/one: 0.5558, eval/two: 0.0156, eval/three: 0.7713 \n",
      "Epoch: 490, train/loss: 1.4191, eval/loss: 2.4958, train/r2: 0.5308, eval/r2: 0.4479, train/one: 0.7959, train/two: 0.0046, train/three: 0.7920, eval/one: 0.5557, eval/two: 0.0159, eval/three: 0.7721 \n",
      "Epoch: 495, train/loss: 1.4530, eval/loss: 2.4974, train/r2: 0.5320, eval/r2: 0.4480, train/one: 0.7902, train/two: 0.0197, train/three: 0.7860, eval/one: 0.5553, eval/two: 0.0159, eval/three: 0.7728 \n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "\n",
    "mus, sigmas = [], []\n",
    "scores = []\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=SEED)\n",
    "splits = kfold.split(range(96))\n",
    "\n",
    "for fold, (train_idx, eval_idx) in enumerate(splits):\n",
    "    MODEL_NAME = f\"resnet.pretrain.fold.{fold}\"\n",
    "    checkpoint_name = f\"pretrain.fold.{fold}.pt\"\n",
    "    \n",
    "    train_inputs = torch.cat([inputs_list[i][train_idx] for i in range(len(inputs_list))])\n",
    "    train_targets = torch.cat([targets_list[i][train_idx] for i in range(len(inputs_list))])\n",
    "    eval_inputs = torch.cat([inputs_list[i][eval_idx] for i in range(len(inputs_list))])\n",
    "    eval_targets = torch.cat([targets_list[i][eval_idx] for i in range(len(inputs_list))])\n",
    "\n",
    "    mu, sigma = get_stats(train_inputs, p=False, r=True)\n",
    "    train_inputs = zscore(train_inputs, mu, sigma)\n",
    "    eval_inputs = zscore(eval_inputs, mu, sigma)\n",
    "    mus.append(mu)\n",
    "    sigmas.append(sigma)\n",
    "    \n",
    "    train_ds = TensorDataset(train_inputs.float(), train_targets.float())\n",
    "    eval_ds = TensorDataset(eval_inputs.float(), eval_targets.float())\n",
    "    \n",
    "    BATCH_SIZE = len(train_ds)\n",
    "    train_dl, eval_dl = return_dls(train_ds, eval_ds, BATCH_SIZE, len(eval_ds))\n",
    "    \n",
    "    model = ResNet(input_channels=2, dropout=DROPOUT).to(device)\n",
    "    if fold == 0: print(get_model_size(model))\n",
    "    \n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=LR, weight_decay=WD, foreach=True)\n",
    "    scaler = torch.amp.GradScaler(device)\n",
    "    scheduler = get_scheduler(optimizer, train_dl, EPOCHS)\n",
    "    \n",
    "    score = train(\n",
    "            model, \n",
    "            optimizer, \n",
    "            device,\n",
    "            scaler,\n",
    "            scheduler,\n",
    "            train_dl, \n",
    "            eval_dl,\n",
    "            EPOCHS,\n",
    "            checkpoint_name,\n",
    "            neptune_run=None#setup_neptune(),\n",
    "        )\n",
    "    \n",
    "    scores.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d63d1321",
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_path = f\"/kaggle/working/{checkpoint_name}\"\n",
    "ckpt = torch.load(ckpt_path, weights_only=False)\n",
    "ckpt[\"epoch\"], ckpt[\"score\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc86886e",
   "metadata": {},
   "outputs": [],
   "source": [
    "(443, 0.4866819899481086)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b99917",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = load_test_data()\n",
    "get_stats(test)\n",
    "test = get_spectra_features(test)\n",
    "test = torch.tensor(test)\n",
    "test = zscore(test, mu, sigma).float()\n",
    "test.shape, test.dtype, get_stats(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc6d0b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet(input_channels=2).to(device)\n",
    "model.load_state_dict(ckpt[\"state_dict\"])\n",
    "model.eval()\n",
    "\n",
    "with torch.inference_mode():\n",
    "    preds = model(test.cuda())\n",
    "\n",
    "preds = preds.cpu().detach().double().numpy()\n",
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3273410",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_stats(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62f94bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = ['Glucose', 'Sodium Acetate', 'Magnesium Sulfate']\n",
    "preds_df = pd.DataFrame(preds, columns=column_names)\n",
    "preds_df.insert(0, 'ID', [i+1 for i in range(len(preds_df))])\n",
    "preds_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a49bf07",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = MODEL_NAME+\".finetune.transfer.in.pretrain.csv\"\n",
    "preds_df.to_csv(name, index=False)\n",
    "f = pd.read_csv(f\"/kaggle/working/{name}\")\n",
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc35f1cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
