{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d75ce4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install -q  neptune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c4998a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def setup_reproducibility(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available(): torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.use_deterministic_algorithms(False, warn_only=True)\n",
    "    torch.set_float32_matmul_precision(\"high\")\n",
    "    \n",
    "SEED = 1000\n",
    "setup_reproducibility(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "185d0c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import get_cosine_schedule_with_warmup\n",
    "from scipy import signal\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from huggingface_hub import login, snapshot_download\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "def get_scheduler(optimizer, train_dl, epochs):\n",
    "    total_training_steps = len(train_dl) * epochs\n",
    "    warmup_steps = int(total_training_steps * 0.05)  # e.g. 5% warmup\n",
    "    \n",
    "    return get_cosine_schedule_with_warmup(\n",
    "        optimizer=optimizer,\n",
    "        num_warmup_steps=warmup_steps,\n",
    "        num_training_steps=total_training_steps\n",
    "    )\n",
    "\n",
    "\n",
    "def get_stats(tensor, p=True, r=False):\n",
    "    mean, std = tensor.mean(), tensor.std()\n",
    "    if p: print(f\"Mean: {mean}, Std: {std}\")\n",
    "    if r: return mean, std\n",
    "    \n",
    "    \n",
    "def zscore(tensor, mean=None, std=None):\n",
    "    if mean is None: mean = tensor.mean()\n",
    "    if std is None: std = tensor.std()\n",
    "    return (tensor - mean) / (std + 1e-8)\n",
    "\n",
    "\n",
    "def get_model_size(model):\n",
    "    print(sum(p.numel() for p in model.parameters()) / 1e6)\n",
    "    \n",
    "\n",
    "def get_index(iterable):\n",
    "    return random.randint(0, len(iterable) - 1)\n",
    "\n",
    "\n",
    "def get_indices(iterable, n):\n",
    "    return random.sample(range(len(iterable)), n)\n",
    "\n",
    "\n",
    "def split(inputs, targets, seed):\n",
    "    return train_test_split(\n",
    "        inputs,\n",
    "        targets, \n",
    "        test_size=0.2,\n",
    "        shuffle=True, \n",
    "        random_state=seed\n",
    "    ) \n",
    "\n",
    "\n",
    "def show_waves(waves, dpi=100):\n",
    "    \"\"\"\n",
    "    waves: numpy array of shape (3, N)\n",
    "    Creates three separate figures that stretch wide.\n",
    "    \"\"\"\n",
    "    N = waves.shape[1]\n",
    "    t = np.arange(N)\n",
    "\n",
    "    # Wide aspect ratio; height modest so each window fills width\n",
    "    for i in range(waves.shape[0]):\n",
    "        fig = plt.figure(figsize=(14, 4), dpi=dpi)  # wide figure\n",
    "        ax = fig.add_subplot(111)\n",
    "        ax.plot(t, waves[i], linewidth=1)\n",
    "        ax.set_title(f\"Wave {i+1}\")\n",
    "        ax.set_xlabel(\"Sample\")\n",
    "        ax.set_ylabel(\"Amplitude\")\n",
    "        ax.grid(True)\n",
    "        fig.tight_layout()  # reduce margins to use width\n",
    "        \n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "def hf_ds_download(hf_token, repo_id):\n",
    "    login(hf_token[1:])\n",
    "    return snapshot_download(repo_id, repo_type=\"dataset\")\n",
    "\n",
    "\n",
    "def get_spectra_features(X, b=False):\n",
    "    \"\"\"Create multi-channel features from spectra: raw, 1st derivative, 2nd derivative.\"\"\"\n",
    "    X_processed = np.zeros_like(X)\n",
    "    # Baseline correction and SNV\n",
    "    for i in tqdm(range(X.shape[0])):\n",
    "        poly = np.polyfit(np.arange(X.shape[1]), X[i], 3)\n",
    "        baseline = np.polyval(poly, np.arange(X.shape[1]))\n",
    "        corrected_spec = X[i] - baseline\n",
    "        #X_processed[i] = (corrected_spec - corrected_spec.mean()) / (corrected_spec.std() + 1e-8)\n",
    "        X_processed[i] = corrected_spec\n",
    "        \n",
    "    # Calculate derivatives\n",
    "    deriv1 = signal.savgol_filter(X_processed, window_length=11, polyorder=3, deriv=1, axis=1)\n",
    "    deriv2 = signal.savgol_filter(X_processed, window_length=11, polyorder=3, deriv=2, axis=1)\n",
    "\n",
    "    if b: return np.stack([X_processed, deriv1, deriv2], axis=1)\n",
    "    return np.stack([deriv1, deriv2], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3bfbf156",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 'sample_submission.csv'),\n",
       " (1, 'timegate.csv'),\n",
       " (2, 'mettler_toledo.csv'),\n",
       " (3, 'kaiser.csv'),\n",
       " (4, 'anton_532.csv'),\n",
       " (5, 'transfer_plate.csv'),\n",
       " (6, '96_samples.csv'),\n",
       " (7, 'tornado.csv'),\n",
       " (8, 'tec5.csv'),\n",
       " (9, 'metrohm.csv'),\n",
       " (10, 'anton_785.csv')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "path = \"/kaggle/input/dig-4-bio-raman-transfer-learning-challenge\"\n",
    "files = os.listdir(path)\n",
    "[(i, files[i]) for i in range(len(files))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "58096ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "def load_transfer_data():\n",
    "    csv_path = os.path.join(path, files[5])\n",
    "    df = pd.read_csv(csv_path)\n",
    "\n",
    "    input_cols = df.columns[1:2049]\n",
    "    target_cols = df.columns[2050:]\n",
    "\n",
    "    targets  = df[target_cols].dropna().to_numpy()\n",
    "\n",
    "    df = df[input_cols]\n",
    "    df['Unnamed: 1'] = df['Unnamed: 1'].str.replace(\"[\\[\\]]\", \"\", regex=True).astype('int64')\n",
    "    df['Unnamed: 2048'] = df['Unnamed: 2048'].str.replace(\"[\\[\\]]\", \"\", regex=True).astype('int64')\n",
    "\n",
    "    inputs = df.to_numpy().reshape(-1, 2, 2048)\n",
    "    inputs = inputs.mean(axis=1)\n",
    "\n",
    "    return inputs, targets\n",
    "\n",
    "\n",
    "def load_test_data():\n",
    "    test = pd.read_csv(os.path.join(path, files[6]))\n",
    "\n",
    "    row1 = test.columns[1:].to_numpy().copy()\n",
    "    row1[-1] = \"5611\"\n",
    "    row1 = row1.astype(np.float64)\n",
    "\n",
    "\n",
    "    cols = test.columns[1:]\n",
    "    test = test[cols]\n",
    "    test[\" 5611]\"] = test[\" 5611]\"].str.replace('[\\[\\]]', '', regex=True).astype('int64')\n",
    "    test = test.to_numpy()\n",
    "\n",
    "    test = np.insert(test, 0, row1, axis=0)\n",
    "    return test.reshape(-1, 2, 2048).mean(axis=1)\n",
    "\n",
    "\n",
    "def load_all_datasets():\n",
    "    train_inputs = []\n",
    "    train_targets = []\n",
    "    \n",
    "    timegate = pd.read_csv(os.path.join(path, files[1]))\n",
    "\n",
    "    timegate.drop(columns=\"fold_idx\", inplace=True)\n",
    "    timegate.drop(columns=\"MSM_present\", inplace=True)\n",
    "    timegate_inputs = timegate[timegate.columns[:-3]].to_numpy()\n",
    "    timegate_targets = timegate[timegate.columns[-3:]].to_numpy()\n",
    "\n",
    "    train_inputs.append(timegate_inputs)\n",
    "    train_targets.append(timegate_targets)\n",
    "    \n",
    "    mettler_toledo = pd.read_csv(os.path.join(path, files[2]))\n",
    "\n",
    "    mettler_toledo.drop(columns=\"fold_idx\", inplace=True)\n",
    "    mettler_toledo.drop(columns=\"MSM_present\", inplace=True)\n",
    "    mettler_toledo_inputs = mettler_toledo[mettler_toledo.columns[:-3]].to_numpy()\n",
    "    mettler_toledo_targets = mettler_toledo[mettler_toledo.columns[-3:]].to_numpy()\n",
    "\n",
    "    train_inputs.append(mettler_toledo_inputs)\n",
    "    train_targets.append(mettler_toledo_targets)\n",
    "    \n",
    "    kaiser = pd.read_csv(os.path.join(path, files[3]))\n",
    "\n",
    "    kaiser.drop(columns=\"fold_idx\", inplace=True)\n",
    "    kaiser.drop(columns=\"MSM_present\", inplace=True)\n",
    "    kaiser_inputs = kaiser[kaiser.columns[:-3]].to_numpy()\n",
    "    kaiser_targets = kaiser[kaiser.columns[-3:]].to_numpy()\n",
    "\n",
    "    train_inputs.append(kaiser_inputs)\n",
    "    train_targets.append(kaiser_targets)\n",
    "    \n",
    "    anton = pd.read_csv(os.path.join(path, files[4]))\n",
    "\n",
    "    anton.drop(columns=\"fold_idx\", inplace=True)\n",
    "    anton.drop(columns=\"MSM_present\", inplace=True)\n",
    "    anton_inputs = anton[anton.columns[:-3]].to_numpy()\n",
    "    anton_targets = anton[anton.columns[-3:]].to_numpy()\n",
    "\n",
    "    train_inputs.append(anton_inputs)\n",
    "    train_targets.append(anton_targets)\n",
    "    \n",
    "    tornado = pd.read_csv(os.path.join(path, files[7]))\n",
    "\n",
    "    tornado.drop(columns=\"fold_idx\", inplace=True)\n",
    "    tornado.drop(columns=\"MSM_present\", inplace=True)\n",
    "    tornado_inputs = tornado[tornado.columns[:-3]].to_numpy()\n",
    "    tornado_targets = tornado[tornado.columns[-3:]].to_numpy()\n",
    "\n",
    "    train_inputs.append(tornado_inputs)\n",
    "    train_targets.append(tornado_targets)\n",
    "    \n",
    "    csv_path = os.path.join(path, files[8])\n",
    "    tec5 = pd.read_csv(csv_path)\n",
    "\n",
    "    tec5.drop(columns=\"fold_idx\", inplace=True)\n",
    "    tec5.drop(columns=\"MSM_present\", inplace=True)\n",
    "    tec5_inputs = tec5[tec5.columns[:-3]].to_numpy()\n",
    "    tec5_targets = tec5[tec5.columns[-3:]].to_numpy()\n",
    "\n",
    "    train_inputs.append(tec5_inputs)\n",
    "    train_targets.append(tec5_targets)\n",
    "    \n",
    "    csv_path = os.path.join(path, files[9])\n",
    "    metrohm = pd.read_csv(csv_path)\n",
    "\n",
    "    metrohm.drop(columns=\"fold_idx\", inplace=True)\n",
    "    metrohm.drop(columns=\"MSM_present\", inplace=True)\n",
    "    metrohm_inputs = metrohm[metrohm.columns[:-3]].to_numpy()\n",
    "    metrohm_targets = metrohm[metrohm.columns[-3:]].to_numpy()\n",
    "\n",
    "    train_inputs.append(metrohm_inputs)\n",
    "    train_targets.append(metrohm_targets)\n",
    "    \n",
    "    csv_path = os.path.join(path, files[10])\n",
    "    anton785 = pd.read_csv(csv_path)\n",
    "\n",
    "    anton785.drop(columns=\"fold_idx\", inplace=True)\n",
    "    anton785.drop(columns=\"MSM_present\", inplace=True)\n",
    "    anton785_inputs = anton785[anton785.columns[:-3]].to_numpy()\n",
    "    anton785_targets = anton785[anton785.columns[-3:]].to_numpy()\n",
    "\n",
    "    train_inputs.append(anton785_inputs)\n",
    "    train_targets.append(anton785_targets)\n",
    "    \n",
    "    return train_inputs, train_targets\n",
    "\n",
    "inputs_list, targets_list = load_all_datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "40aa78b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    for i in range(len(inputs_list)):\n",
    "        indices = get_indices(inputs_list[i], 96)\n",
    "        inputs_list[i] = inputs_list[i][indices]\n",
    "        targets_list[i] = targets_list[i][indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "33584f53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e659fcd20fcc457587d2e3676a27701d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/133 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dea2bf447c1c4646b01c3aa5e32aa93b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/275 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddd1da12864343d98f3f44d5db5cb6f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/134 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14ffe05badd849b08d4c5e22e101e2c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/270 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f0fc6209b1445be83771e5015a51fe5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/385 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d39d4e0003e4da7a45313edcb060329",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/395 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ada5e4933c2e46ef8701ef79917f1574",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/399 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1179af746ec41fb8bfa3fbe254b14f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/270 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[(133, 2, 511),\n",
       " (275, 2, 2901),\n",
       " (134, 2, 6593),\n",
       " (270, 2, 1651),\n",
       " (385, 2, 3001),\n",
       " (395, 2, 3126),\n",
       " (399, 2, 1917),\n",
       " (270, 2, 1101)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_list = [get_spectra_features(inputs_list[i]) for i in range(len(inputs_list))]\n",
    "[i.shape for i in inputs_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "04b147b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([torch.Size([133, 2, 2048]),\n",
       "  torch.Size([275, 2, 2048]),\n",
       "  torch.Size([134, 2, 2048]),\n",
       "  torch.Size([270, 2, 2048]),\n",
       "  torch.Size([385, 2, 2048]),\n",
       "  torch.Size([395, 2, 2048]),\n",
       "  torch.Size([399, 2, 2048]),\n",
       "  torch.Size([270, 2, 2048])],\n",
       " [torch.Size([133, 3]),\n",
       "  torch.Size([275, 3]),\n",
       "  torch.Size([134, 3]),\n",
       "  torch.Size([270, 3]),\n",
       "  torch.Size([385, 3]),\n",
       "  torch.Size([395, 3]),\n",
       "  torch.Size([399, 3]),\n",
       "  torch.Size([270, 3])])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "def foo(inputs, targets):\n",
    "    for i in range(len(inputs)):\n",
    "        x = inputs[i]\n",
    "        x = torch.tensor(x)\n",
    "        inputs[i] = F.interpolate(x, size=2048, mode=\"nearest-exact\")\n",
    "\n",
    "    #inputs = torch.cat(inputs)\n",
    "    targets = [torch.tensor(t) for t in targets]\n",
    "    #targets = torch.cat(targets)\n",
    "    return inputs, targets\n",
    "    \n",
    "inputs_list, targets_list = foo(inputs_list, targets_list)\n",
    "[i.shape for i in inputs_list], [i.shape for i in targets_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b16a1447",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "if False:\n",
    "    for i in range(len(inputs_list)):\n",
    "        inputs = inputs_list[i]\n",
    "        targets = targets_list[i]\n",
    "        train_inputs, eval_inputs, train_targets, eval_targets = split(inputs, targets, SEED)\n",
    "        \n",
    "        inputs_list[i] = (train_inputs, eval_inputs)\n",
    "        targets_list[i] = (train_targets, eval_targets)\n",
    "        \n",
    "    def foo(inputs, targets):\n",
    "        for i in range(len(inputs)):\n",
    "            train_inputs, eval_inputs = inputs[i]\n",
    "            train_inputs = torch.tensor(train_inputs)\n",
    "            eval_inputs = torch.tensor(eval_inputs)\n",
    "            train_inputs = F.interpolate(train_inputs, size=2048, mode=\"nearest-exact\")\n",
    "            eval_inputs = F.interpolate(eval_inputs, size=2048, mode=\"nearest-exact\")   \n",
    "            inputs[i] = (train_inputs, eval_inputs)\n",
    "\n",
    "        train_inputs = [i[0] for i in inputs]\n",
    "        eval_inputs = [i[1] for i in inputs]\n",
    "        train_inputs = torch.cat(train_inputs)\n",
    "        eval_inputs = torch.cat(eval_inputs)\n",
    "        \n",
    "        train_targets = [torch.tensor(t[0]) for t in targets]\n",
    "        eval_targets = [torch.tensor(t[1]) for t in targets]\n",
    "        train_targets = torch.cat(train_targets)\n",
    "        eval_targets = torch.cat(eval_targets)\n",
    "\n",
    "        return train_inputs, eval_inputs, train_targets, eval_targets\n",
    "        \n",
    "    train_inputs, eval_inputs, train_targets, eval_targets = foo(inputs_list, targets_list)\n",
    "    train_inputs.shape, eval_inputs.shape, train_targets.shape, eval_targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "74ef9524",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1de66aea044411082022a7ee3756d3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/96 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "transfer_inputs, transfer_targets = load_transfer_data()\n",
    "transfer_inputs = get_spectra_features(transfer_inputs)\n",
    "#train_transfer_inputs, eval_transfer_inputs, train_transfer_targets, eval_transfer_targets = split(transfer_inputs, transfer_targets, SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6ac83271",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 9)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_list.append(torch.tensor(transfer_inputs))\n",
    "targets_list.append(torch.tensor(transfer_targets))\n",
    "len(targets_list), len(inputs_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5f970b1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([torch.Size([133, 2, 2048]),\n",
       "  torch.Size([275, 2, 2048]),\n",
       "  torch.Size([134, 2, 2048]),\n",
       "  torch.Size([270, 2, 2048]),\n",
       "  torch.Size([385, 2, 2048]),\n",
       "  torch.Size([395, 2, 2048]),\n",
       "  torch.Size([399, 2, 2048]),\n",
       "  torch.Size([270, 2, 2048]),\n",
       "  torch.Size([96, 2, 2048])],\n",
       " [torch.Size([133, 3]),\n",
       "  torch.Size([275, 3]),\n",
       "  torch.Size([134, 3]),\n",
       "  torch.Size([270, 3]),\n",
       "  torch.Size([385, 3]),\n",
       "  torch.Size([395, 3]),\n",
       "  torch.Size([399, 3]),\n",
       "  torch.Size([270, 3]),\n",
       "  torch.Size([96, 3])])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i.shape for i in inputs_list], [i.shape for i in targets_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2304b01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    train_inputs = torch.cat([train_inputs, torch.tensor(train_transfer_inputs)])\n",
    "    eval_inputs = torch.cat([eval_inputs, torch.tensor(eval_transfer_inputs)])\n",
    "    train_targets = torch.cat([train_targets, torch.tensor(train_transfer_targets)])\n",
    "    eval_targets = torch.cat([eval_targets, torch.tensor(eval_transfer_targets)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2788ef81",
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    min, max, mu, sigma = get_stats(train_inputs, r=True)\n",
    "    train_inputs = zscore(train_inputs)\n",
    "    eval_inputs = zscore(eval_inputs)\n",
    "    get_stats(train_inputs), get_stats(eval_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bf4e0457",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "if False:\n",
    "    train_ds = TensorDataset(train_inputs.float(), train_targets.float())\n",
    "    eval_ds = TensorDataset(eval_inputs.float(), eval_targets.float())\n",
    "    len(train_ds), len(eval_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "982956a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "def build_loader(\n",
    "    SEED,\n",
    "    ds,\n",
    "    train=True,\n",
    "    batch_size=1,\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    "    drop_last=True,\n",
    "    pin_memory=True,\n",
    "    persistent_workers=False,\n",
    "):\n",
    "    def seed_worker(worker_id):\n",
    "        worker_seed = torch.initial_seed() % 2**32\n",
    "        np.random.seed(worker_seed)\n",
    "        random.seed(worker_seed)\n",
    "\n",
    "    generator = torch.Generator()\n",
    "    generator.manual_seed(SEED if train else SEED+5232)\n",
    "\n",
    "    return DataLoader(\n",
    "        ds,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=pin_memory,\n",
    "        drop_last=drop_last,\n",
    "        persistent_workers=persistent_workers,\n",
    "        worker_init_fn=seed_worker,\n",
    "        generator=generator,\n",
    "        #sampler=DistributedSampler(\n",
    "        #    train_ds,\n",
    "        #    shuffle=True,\n",
    "        #    drop_last=True,\n",
    "        #    seed=config.seed\n",
    "        #)\n",
    "    )\n",
    "    \n",
    "    \n",
    "def return_dls(train_ds, eval_ds, train_batch_size, eval_batch_size):\n",
    "    train_dl = build_loader(\n",
    "        SEED,\n",
    "        train_ds,\n",
    "        train=True,\n",
    "        batch_size=train_batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=0,\n",
    "        drop_last=False,\n",
    "        pin_memory=True,\n",
    "        persistent_workers=False,\n",
    "    )\n",
    "\n",
    "    eval_dl = build_loader(\n",
    "        SEED,\n",
    "        eval_ds,\n",
    "        train=False,\n",
    "        batch_size=eval_batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=0,\n",
    "        drop_last=False,\n",
    "        pin_memory=True,\n",
    "        persistent_workers=False,\n",
    "    )\n",
    "    \n",
    "    return train_dl, eval_dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0ac2d7d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import neptune\n",
    "\n",
    "\n",
    "def setup_neptune():\n",
    "    if not RESUME:\n",
    "        neptune_run = neptune.init_run(\n",
    "            project=\"arbaaz/kaggle-spect\",\n",
    "            name=MODEL_NAME,\n",
    "            api_token=\"eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiJlOGE2YjNiZS1mZGUyLTRjYjItYTg5Yy1mZWJkZTIzNzE1NmIifQ==\"\n",
    "        )\n",
    "\n",
    "        neptune_run[\"h_parameters\"] = {\n",
    "            \"seed\": SEED,\n",
    "            \"model_name\": MODEL_NAME,\n",
    "            \"optimizer_name\": \"nadam\",\n",
    "            \"learning_rate\": LR,\n",
    "            \"scheduler_name\": \"default\",\n",
    "            \"weight_decay\": WD,\n",
    "            \"num_epochs\": EPOCHS,\n",
    "            \"batch_size\": BATCH_SIZE,\n",
    "        }\n",
    "        if DROPOUT: neptune_run[\"h_parameters\"] = {\"dropout\": DROPOUT}\n",
    "        if DROP_PATH_RATE: neptune_run[\"h_parameters\"] = {\"drop_path_rate\": DROP_PATH_RATE}\n",
    "    else:\n",
    "        neptune_run = neptune.init_run(\n",
    "            project=\"arbaaz/crunchdao-structural-break\",\n",
    "            with_id=config.with_id,\n",
    "            api_token=\"eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiJlOGE2YjNiZS1mZGUyLTRjYjItYTg5Yy1mZWJkZTIzNzE1NmIifQ==\"\n",
    "        )\n",
    "\n",
    "    return neptune_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "560637b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "\n",
    "def loss_fn(logits, targets):\n",
    "    logits = logits.view(-1)\n",
    "    targets = targets.view(-1)\n",
    "    return F.mse_loss(logits, targets)\n",
    "\n",
    "\n",
    "def metric_fn(logits, targets):\n",
    "    preds = logits.cpu().detach().numpy()\n",
    "    targets = targets.cpu().detach().numpy()\n",
    "    \n",
    "    dim1 = r2_score(targets[:, 0], preds[:, 0])\n",
    "    dim2 = r2_score(targets[:, 1], preds[:, 1])\n",
    "    dim3 = r2_score(targets[:, 2], preds[:, 2])\n",
    "    \n",
    "    mean_r2 = (dim1 + dim2 + dim3) / 3\n",
    "    \n",
    "    return dim1, dim2, dim3, mean_r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "47e91d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    \"\"\"A residual block with two 1D convolutional layers.\"\"\"\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels, out_channels, kernel_size, stride, padding=kernel_size//2)\n",
    "        self.bn1 = nn.BatchNorm1d(out_channels)\n",
    "        self.elu = nn.ELU()\n",
    "        self.conv2 = nn.Conv1d(out_channels, out_channels, kernel_size, padding=kernel_size//2)\n",
    "        self.bn2 = nn.BatchNorm1d(out_channels)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv1d(in_channels, out_channels, kernel_size=1, stride=stride),\n",
    "                nn.BatchNorm1d(out_channels)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.elu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = self.elu(out)\n",
    "        return out\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    \"\"\"A deeper ResNet-style 1D CNN for Raman spectra.\"\"\"\n",
    "    def __init__(self, dropout, input_channels=3, num_classes=3):\n",
    "        super().__init__()\n",
    "        self.in_channels = 64\n",
    "        self.conv1 = nn.Conv1d(input_channels, 64, kernel_size=7, stride=2, padding=3)\n",
    "        self.bn1 = nn.BatchNorm1d(64)\n",
    "        self.elu = nn.GELU()\n",
    "        self.maxpool = nn.MaxPool1d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        self.layer1 = self._make_layer(64, 2, stride=1)\n",
    "        self.layer2 = self._make_layer(128, 2, stride=2)\n",
    "        self.layer3 = self._make_layer(256, 2, stride=2)\n",
    "        self.layer4 = self._make_layer(512, 2, stride=2)\n",
    "\n",
    "        self.avgpool = nn.AdaptiveAvgPool1d(1)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ELU(),\n",
    "            nn.Dropout(dropout), # Increased dropout for better regularization\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "\n",
    "    def _make_layer(self, out_channels, num_blocks, stride):\n",
    "        strides = [stride] + [1] * (num_blocks - 1)\n",
    "        layers = []\n",
    "        for s in strides:\n",
    "            layers.append(ResidualBlock(self.in_channels, out_channels, stride=s))\n",
    "            self.in_channels = out_channels\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.elu(self.bn1(self.conv1(x)))\n",
    "        x = self.maxpool(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26cd0209",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "def train(\n",
    "    model, \n",
    "    optimizer,\n",
    "    device,\n",
    "    scaler, \n",
    "    scheduler,\n",
    "    train_dl,\n",
    "    eval_dl,\n",
    "    epochs,\n",
    "    checkpoint_name,\n",
    "    score=-float(\"inf\"),\n",
    "    neptune_run=None,\n",
    "    p=True,\n",
    "):  \n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "        all_logits = []\n",
    "        all_targets = []\n",
    "        \n",
    "        for inputs, targets in train_dl:\n",
    "            inputs = inputs.to(device, non_blocking=True)\n",
    "            targets = targets.to(device, non_blocking=True)\n",
    "            \n",
    "            with torch.amp.autocast(device_type=device, dtype=torch.float16, cache_enabled=True):\n",
    "                logits = model(inputs)\n",
    "                loss = loss_fn(logits, targets)\n",
    "            \n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            optimizer.zero_grad()\n",
    "            scheduler.step()\n",
    "            if neptune_run is not None:  neptune_run[\"lr_step\"].append(scheduler.get_last_lr()[0])\n",
    "            \n",
    "            total_loss += loss.detach().cpu()\n",
    "            all_logits.append(logits.detach().cpu())\n",
    "            all_targets.append(targets.detach().cpu())\n",
    "        \n",
    "        all_logits = torch.cat(all_logits)\n",
    "        all_targets = torch.cat(all_targets)\n",
    "\n",
    "        one, two, three, r2 = metric_fn(all_logits, all_targets)\n",
    "        total_loss = total_loss / len(train_dl)\n",
    "        \n",
    "        model.eval()\n",
    "        eval_total_loss = 0.0\n",
    "        eval_all_logits = []\n",
    "        eval_all_targets = []\n",
    "\n",
    "        for inputs, targets in eval_dl:\n",
    "            inputs = inputs.to(device, non_blocking=True)\n",
    "            targets = targets.to(device, non_blocking=True)\n",
    "\n",
    "            with torch.inference_mode():\n",
    "                #with torch.amp.autocast(device_type=device, dtype=torch.float16, cache_enabled=True):\n",
    "                logits = model(inputs)\n",
    "                loss = loss_fn(logits, targets)\n",
    "\n",
    "            eval_total_loss += loss.detach().cpu()\n",
    "            eval_all_logits.append(logits.detach().cpu())\n",
    "            eval_all_targets.append(targets.detach().cpu())\n",
    "        \n",
    "        eval_all_logits = torch.cat(eval_all_logits)\n",
    "        eval_all_targets = torch.cat(eval_all_targets)\n",
    "\n",
    "        eval_one, eval_two, eval_three, eval_r2 = metric_fn(eval_all_logits, eval_all_targets)\n",
    "        eval_total_loss = eval_total_loss / len(eval_dl)\n",
    "        \n",
    "        if eval_r2 > score:\n",
    "            score = eval_r2\n",
    "            data = {\"state_dict\": model.state_dict()}\n",
    "            data[\"epoch\"] = epoch \n",
    "            data[\"score\"] = score\n",
    "            torch.save(data, f\"/kaggle/working/{checkpoint_name}\")\n",
    "        \n",
    "        if neptune_run is not None:\n",
    "            neptune_run[\"train/loss\"].append(total_loss)\n",
    "            neptune_run[\"eval/loss\"].append(eval_total_loss)\n",
    "            neptune_run[\"train/r2\"].append(r2)\n",
    "            neptune_run[\"eval/r2\"].append(eval_r2)\n",
    "            neptune_run[\"train/one\"].append(one)\n",
    "            neptune_run[\"train/two\"].append(two)\n",
    "            neptune_run[\"train/three\"].append(three)\n",
    "            neptune_run[\"eval/one\"].append(eval_one)\n",
    "            neptune_run[\"eval/two\"].append(eval_two)\n",
    "            neptune_run[\"eval/three\"].append(eval_three)\n",
    "            \n",
    "        if p and epoch % 5 == 0:\n",
    "            print(\n",
    "                f\"Epoch: {epoch}, \"\n",
    "                f\"train/loss: {total_loss:.4f}, \"\n",
    "                f\"eval/loss: {eval_total_loss:.4f}, \"\n",
    "                f\"train/r2: {r2:.4f}, \"\n",
    "                f\"eval/r2: {eval_r2:.4f}, \"\n",
    "                f\"train/one: {one:.4f}, \"\n",
    "                f\"train/two: {two:.4f}, \"\n",
    "                f\"train/three: {three:.4f}, \"\n",
    "                f\"eval/one: {eval_one:.4f}, \"\n",
    "                f\"eval/two: {eval_two:.4f}, \"\n",
    "                f\"eval/three: {eval_three:.4f} \"\n",
    "            )\n",
    "            \n",
    "    if neptune_run is not None: neptune_run.stop()\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c6678e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings#; warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "EPOCHS = 500\n",
    "WD = 1e-3\n",
    "LR = 1e-4\n",
    "\n",
    "DROPOUT = 0.5\n",
    "DROP_PATH_RATE = None\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "RESUME = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "853355ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.981251\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[neptune] [warning] NeptuneWarning: By default, these monitoring options are disabled in interactive sessions: 'capture_stdout', 'capture_stderr', 'capture_traceback', 'capture_hardware_metrics'. You can set them to 'True' when initializing the run and the monitoring will continue until you call run.stop() or the kernel stops. NOTE: To track the source files, pass their paths to the 'source_code' argument. For help, see: https://docs-legacy.neptune.ai/logging/source_code/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[neptune] [info   ] Neptune initialized. Open in the app: https://app.neptune.ai/arbaaz/kaggle-spect/e/KAG-114\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2391dad5588a439592ec98266aab2918",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:227: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, train/loss: 11.0416, eval/loss: 9.4729, train/r2: -0.9566, eval/r2: -0.9271, train/one: -0.7141, train/two: -1.6191, train/three: -0.5366, eval/one: -0.6079, eval/two: -1.4475, eval/three: -0.7258 \n",
      "Epoch: 5, train/loss: 10.6536, eval/loss: 9.4778, train/r2: -0.8838, eval/r2: -0.8994, train/one: -0.6500, train/two: -1.4700, train/three: -0.5316, eval/one: -0.6124, eval/two: -1.3693, eval/three: -0.7165 \n",
      "Epoch: 10, train/loss: 9.1302, eval/loss: 9.4590, train/r2: -0.6715, eval/r2: -0.8666, train/one: -0.4057, train/two: -1.2400, train/three: -0.3689, eval/one: -0.6113, eval/two: -1.2693, eval/three: -0.7191 \n",
      "Epoch: 15, train/loss: 7.4438, eval/loss: 8.8476, train/r2: -0.4246, eval/r2: -0.7274, train/one: -0.1354, train/two: -0.9428, train/three: -0.1957, eval/one: -0.5088, eval/two: -1.0642, eval/three: -0.6091 \n",
      "Epoch: 20, train/loss: 6.3145, eval/loss: 6.2564, train/r2: -0.2026, eval/r2: -0.2295, train/one: 0.0452, train/two: -0.5357, train/three: -0.1173, eval/one: -0.0617, eval/two: -0.4451, eval/three: -0.1816 \n",
      "Epoch: 25, train/loss: 5.8651, eval/loss: 6.3403, train/r2: -0.0793, eval/r2: -0.0424, train/one: 0.1081, train/two: -0.3397, train/three: -0.0063, eval/one: -0.1095, eval/two: 0.0372, eval/three: -0.0549 \n",
      "Epoch: 30, train/loss: 5.9353, eval/loss: 8.9477, train/r2: -0.1334, eval/r2: -0.4166, train/one: 0.0982, train/two: -0.5012, train/three: 0.0029, eval/one: -0.5844, eval/two: -0.3101, eval/three: -0.3554 \n",
      "Epoch: 35, train/loss: 5.5983, eval/loss: 7.1682, train/r2: -0.0294, eval/r2: -0.1717, train/one: 0.1467, train/two: -0.2965, train/three: 0.0616, eval/one: -0.2467, eval/two: 0.0063, eval/three: -0.2749 \n",
      "Epoch: 40, train/loss: 5.4098, eval/loss: 5.3726, train/r2: 0.0390, eval/r2: 0.0035, train/one: 0.1669, train/two: -0.2191, train/three: 0.1692, eval/one: 0.0843, eval/two: -0.0431, eval/three: -0.0308 \n",
      "Epoch: 45, train/loss: 5.1227, eval/loss: 5.4351, train/r2: 0.0286, eval/r2: 0.0196, train/one: 0.2233, train/two: -0.2528, train/three: 0.1153, eval/one: 0.0683, eval/two: 0.0061, eval/three: -0.0156 \n",
      "Epoch: 50, train/loss: 4.7435, eval/loss: 4.9895, train/r2: 0.0892, eval/r2: 0.0921, train/one: 0.2825, train/two: -0.1836, train/three: 0.1686, eval/one: 0.1438, eval/two: 0.0490, eval/three: 0.0836 \n",
      "Epoch: 55, train/loss: 4.7742, eval/loss: 4.4525, train/r2: 0.0559, eval/r2: 0.1673, train/one: 0.2840, train/two: -0.2274, train/three: 0.1111, eval/one: 0.2377, eval/two: 0.0781, eval/three: 0.1862 \n",
      "Epoch: 60, train/loss: 4.2957, eval/loss: 4.2178, train/r2: 0.0894, eval/r2: 0.2044, train/one: 0.3641, train/two: -0.2444, train/three: 0.1484, eval/one: 0.2793, eval/two: 0.1124, eval/three: 0.2214 \n",
      "Epoch: 65, train/loss: 3.9922, eval/loss: 4.0707, train/r2: 0.1344, eval/r2: 0.1983, train/one: 0.4103, train/two: -0.2147, train/three: 0.2075, eval/one: 0.3091, eval/two: 0.0516, eval/three: 0.2342 \n",
      "Epoch: 70, train/loss: 3.8022, eval/loss: 4.1288, train/r2: 0.1431, eval/r2: 0.1872, train/one: 0.4420, train/two: -0.2401, train/three: 0.2276, eval/one: 0.2970, eval/two: 0.0201, eval/three: 0.2446 \n",
      "Epoch: 75, train/loss: 3.6120, eval/loss: 4.3589, train/r2: 0.1985, eval/r2: 0.1979, train/one: 0.4671, train/two: -0.1617, train/three: 0.2900, eval/one: 0.2435, eval/two: 0.0578, eval/three: 0.2923 \n",
      "Epoch: 80, train/loss: 3.5831, eval/loss: 4.3233, train/r2: 0.1955, eval/r2: 0.2102, train/one: 0.4710, train/two: -0.1910, train/three: 0.3065, eval/one: 0.2461, eval/two: 0.0573, eval/three: 0.3273 \n",
      "Epoch: 85, train/loss: 3.3383, eval/loss: 4.5975, train/r2: 0.2357, eval/r2: 0.2120, train/one: 0.5089, train/two: -0.1465, train/three: 0.3448, eval/one: 0.1859, eval/two: 0.0908, eval/three: 0.3595 \n",
      "Epoch: 90, train/loss: 3.2952, eval/loss: 4.4904, train/r2: 0.2418, eval/r2: 0.2249, train/one: 0.5118, train/two: -0.1823, train/three: 0.3959, eval/one: 0.2047, eval/two: 0.0897, eval/three: 0.3804 \n",
      "Epoch: 95, train/loss: 3.0576, eval/loss: 4.3290, train/r2: 0.2831, eval/r2: 0.2371, train/one: 0.5490, train/two: -0.1260, train/three: 0.4262, eval/one: 0.2343, eval/two: 0.0699, eval/three: 0.4071 \n",
      "Epoch: 100, train/loss: 3.0813, eval/loss: 5.1995, train/r2: 0.2621, eval/r2: 0.2107, train/one: 0.5455, train/two: -0.1924, train/three: 0.4331, eval/one: 0.0473, eval/two: 0.0879, eval/three: 0.4969 \n",
      "Epoch: 105, train/loss: 3.0068, eval/loss: 4.7976, train/r2: 0.2959, eval/r2: 0.2397, train/one: 0.5535, train/two: -0.1368, train/three: 0.4711, eval/one: 0.1285, eval/two: 0.0995, eval/three: 0.4910 \n",
      "Epoch: 110, train/loss: 2.9907, eval/loss: 3.3487, train/r2: 0.2874, eval/r2: 0.3342, train/one: 0.5564, train/two: -0.1714, train/three: 0.4772, eval/one: 0.4223, eval/two: 0.1127, eval/three: 0.4676 \n",
      "Epoch: 115, train/loss: 2.8989, eval/loss: 3.4633, train/r2: 0.2969, eval/r2: 0.2863, train/one: 0.5724, train/two: -0.1555, train/three: 0.4739, eval/one: 0.4129, eval/two: 0.0761, eval/three: 0.3700 \n",
      "Epoch: 120, train/loss: 2.7833, eval/loss: 3.5879, train/r2: 0.3154, eval/r2: 0.1973, train/one: 0.5906, train/two: -0.1325, train/three: 0.4882, eval/one: 0.4202, eval/two: 0.0457, eval/three: 0.1260 \n",
      "Epoch: 125, train/loss: 2.6695, eval/loss: 3.4247, train/r2: 0.3277, eval/r2: 0.3168, train/one: 0.6101, train/two: -0.1154, train/three: 0.4882, eval/one: 0.4071, eval/two: 0.0657, eval/three: 0.4776 \n",
      "Epoch: 130, train/loss: 2.7551, eval/loss: 4.1421, train/r2: 0.3121, eval/r2: 0.3007, train/one: 0.5927, train/two: -0.1822, train/three: 0.5259, eval/one: 0.2504, eval/two: 0.0800, eval/three: 0.5717 \n",
      "Epoch: 135, train/loss: 3.9037, eval/loss: 11.2506, train/r2: 0.2535, eval/r2: -0.2160, train/one: 0.3902, train/two: -0.1732, train/three: 0.5436, eval/one: -1.1678, eval/two: 0.0142, eval/three: 0.5056 \n",
      "Epoch: 140, train/loss: 2.7518, eval/loss: 4.2765, train/r2: 0.3129, eval/r2: 0.2738, train/one: 0.5969, train/two: -0.1403, train/three: 0.4821, eval/one: 0.2342, eval/two: 0.1055, eval/three: 0.4817 \n",
      "Epoch: 145, train/loss: 2.7195, eval/loss: 3.7203, train/r2: 0.3263, eval/r2: 0.2711, train/one: 0.5947, train/two: -0.1829, train/three: 0.5670, eval/one: 0.3649, eval/two: 0.1160, eval/three: 0.3326 \n",
      "Epoch: 150, train/loss: 2.6583, eval/loss: 3.5041, train/r2: 0.2991, eval/r2: 0.3589, train/one: 0.6106, train/two: -0.2417, train/three: 0.5285, eval/one: 0.3749, eval/two: 0.1079, eval/three: 0.5940 \n",
      "Epoch: 155, train/loss: 2.5454, eval/loss: 3.7036, train/r2: 0.3597, eval/r2: 0.3351, train/one: 0.6237, train/two: -0.1102, train/three: 0.5657, eval/one: 0.3337, eval/two: 0.0564, eval/three: 0.6151 \n",
      "Epoch: 160, train/loss: 2.3499, eval/loss: 3.8278, train/r2: 0.3848, eval/r2: 0.2152, train/one: 0.6553, train/two: -0.0862, train/three: 0.5852, eval/one: 0.3604, eval/two: 0.0763, eval/three: 0.2088 \n",
      "Epoch: 165, train/loss: 2.3038, eval/loss: 3.6885, train/r2: 0.3916, eval/r2: 0.2563, train/one: 0.6625, train/two: -0.0803, train/three: 0.5926, eval/one: 0.3749, eval/two: 0.0815, eval/three: 0.3125 \n",
      "Epoch: 170, train/loss: 2.2733, eval/loss: 3.4590, train/r2: 0.3825, eval/r2: 0.3388, train/one: 0.6670, train/two: -0.1296, train/three: 0.6102, eval/one: 0.3880, eval/two: 0.0522, eval/three: 0.5762 \n",
      "Epoch: 175, train/loss: 2.1223, eval/loss: 3.1952, train/r2: 0.4032, eval/r2: 0.3920, train/one: 0.6914, train/two: -0.1055, train/three: 0.6237, eval/one: 0.4309, eval/two: 0.1020, eval/three: 0.6432 \n",
      "Epoch: 180, train/loss: 2.1522, eval/loss: 3.4562, train/r2: 0.4234, eval/r2: 0.3725, train/one: 0.6816, train/two: -0.0736, train/three: 0.6621, eval/one: 0.3815, eval/two: 0.1211, eval/three: 0.6148 \n",
      "Epoch: 185, train/loss: 2.1151, eval/loss: 3.6598, train/r2: 0.4157, eval/r2: 0.3333, train/one: 0.6889, train/two: -0.1012, train/three: 0.6593, eval/one: 0.3491, eval/two: 0.0963, eval/three: 0.5547 \n",
      "Epoch: 190, train/loss: 2.2807, eval/loss: 6.0317, train/r2: 0.3903, eval/r2: 0.1740, train/one: 0.6617, train/two: -0.1423, train/three: 0.6517, eval/one: -0.1316, eval/two: 0.0595, eval/three: 0.5941 \n",
      "Epoch: 195, train/loss: 2.1454, eval/loss: 4.0190, train/r2: 0.4254, eval/r2: 0.2984, train/one: 0.6831, train/two: -0.0638, train/three: 0.6569, eval/one: 0.2862, eval/two: 0.1361, eval/three: 0.4729 \n",
      "Epoch: 200, train/loss: 2.2868, eval/loss: 3.8464, train/r2: 0.3973, eval/r2: 0.3279, train/one: 0.6639, train/two: -0.0795, train/three: 0.6077, eval/one: 0.3137, eval/two: 0.1429, eval/three: 0.5272 \n",
      "Epoch: 205, train/loss: 2.0902, eval/loss: 3.2382, train/r2: 0.4286, eval/r2: 0.3844, train/one: 0.6917, train/two: -0.0749, train/three: 0.6691, eval/one: 0.4245, eval/two: 0.1037, eval/three: 0.6249 \n",
      "Epoch: 210, train/loss: 2.0247, eval/loss: 3.9401, train/r2: 0.4314, eval/r2: 0.1581, train/one: 0.7016, train/two: -0.0956, train/three: 0.6882, eval/one: 0.3587, eval/two: 0.0665, eval/three: 0.0490 \n",
      "Epoch: 215, train/loss: 1.9651, eval/loss: 3.2124, train/r2: 0.4457, eval/r2: 0.3901, train/one: 0.7116, train/two: -0.0591, train/three: 0.6846, eval/one: 0.4231, eval/two: 0.0608, eval/three: 0.6864 \n",
      "Epoch: 220, train/loss: 1.9314, eval/loss: 3.6108, train/r2: 0.4478, eval/r2: 0.3374, train/one: 0.7195, train/two: -0.0376, train/three: 0.6615, eval/one: 0.3550, eval/two: 0.0647, eval/three: 0.5927 \n",
      "Epoch: 225, train/loss: 1.8314, eval/loss: 3.3760, train/r2: 0.4399, eval/r2: 0.3990, train/one: 0.7338, train/two: -0.1235, train/three: 0.7093, eval/one: 0.3868, eval/two: 0.1086, eval/three: 0.7016 \n",
      "Epoch: 230, train/loss: 1.8368, eval/loss: 3.0899, train/r2: 0.4559, eval/r2: 0.4240, train/one: 0.7327, train/two: -0.0634, train/three: 0.6984, eval/one: 0.4408, eval/two: 0.1004, eval/three: 0.7309 \n",
      "Epoch: 235, train/loss: 1.7882, eval/loss: 3.0705, train/r2: 0.4603, eval/r2: 0.4229, train/one: 0.7392, train/two: -0.0794, train/three: 0.7210, eval/one: 0.4446, eval/two: 0.0901, eval/three: 0.7340 \n",
      "Epoch: 240, train/loss: 1.7445, eval/loss: 3.0930, train/r2: 0.4832, eval/r2: 0.4190, train/one: 0.7458, train/two: -0.0134, train/three: 0.7173, eval/one: 0.4433, eval/two: 0.1092, eval/three: 0.7046 \n",
      "Epoch: 245, train/loss: 1.7433, eval/loss: 3.0605, train/r2: 0.4798, eval/r2: 0.4265, train/one: 0.7448, train/two: -0.0393, train/three: 0.7338, eval/one: 0.4476, eval/two: 0.1101, eval/three: 0.7220 \n",
      "Epoch: 250, train/loss: 1.7102, eval/loss: 3.2136, train/r2: 0.4541, eval/r2: 0.4152, train/one: 0.7542, train/two: -0.1040, train/three: 0.7120, eval/one: 0.4154, eval/two: 0.0937, eval/three: 0.7366 \n",
      "Epoch: 255, train/loss: 1.7033, eval/loss: 3.0724, train/r2: 0.4418, eval/r2: 0.4212, train/one: 0.7552, train/two: -0.1542, train/three: 0.7243, eval/one: 0.4445, eval/two: 0.0862, eval/three: 0.7329 \n",
      "Epoch: 260, train/loss: 1.6991, eval/loss: 2.9492, train/r2: 0.4877, eval/r2: 0.4352, train/one: 0.7527, train/two: -0.0180, train/three: 0.7283, eval/one: 0.4662, eval/two: 0.0818, eval/three: 0.7576 \n",
      "Epoch: 265, train/loss: 1.6530, eval/loss: 3.1682, train/r2: 0.4728, eval/r2: 0.3103, train/one: 0.7621, train/two: -0.0693, train/three: 0.7255, eval/one: 0.4696, eval/two: 0.0693, eval/three: 0.3920 \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_84/216427500.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0mscheduler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_scheduler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m     score = train(\n\u001b[0m\u001b[1;32m     38\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_84/3464677131.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, optimizer, device, scaler, scheduler, train_dl, eval_dl, epochs, checkpoint_name, score, neptune_run, p)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m             \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m             \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/amp/grad_scaler.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, optimizer, *args, **kwargs)\u001b[0m\n\u001b[1;32m    455\u001b[0m         ), \"No inf checks were recorded for this optimizer.\"\n\u001b[1;32m    456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m         \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_opt_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m         \u001b[0moptimizer_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"stage\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOptState\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSTEPPED\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/amp/grad_scaler.py\u001b[0m in \u001b[0;36m_maybe_opt_step\u001b[0;34m(self, optimizer, optimizer_state, *args, **kwargs)\u001b[0m\n\u001b[1;32m    349\u001b[0m     ) -> Optional[float]:\n\u001b[1;32m    350\u001b[0m         \u001b[0mretval\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 351\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moptimizer_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"found_inf_per_device\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    352\u001b[0m             \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mretval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/amp/grad_scaler.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    349\u001b[0m     ) -> Optional[float]:\n\u001b[1;32m    350\u001b[0m         \u001b[0mretval\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 351\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moptimizer_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"found_inf_per_device\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    352\u001b[0m             \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mretval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[neptune] [info   ] Shutting down background jobs, please wait a moment...\n",
      "[neptune] [info   ] Done!\n",
      "[neptune] [info   ] Waiting for the remaining 143 operations to synchronize with Neptune. Do not kill this process.\n",
      "[neptune] [info   ] All 143 operations synced, thanks for waiting!\n",
      "[neptune] [info   ] Explore the metadata in the Neptune app: https://app.neptune.ai/arbaaz/kaggle-spect/e/KAG-114/metadata\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "\n",
    "mus, sigmas = [], []\n",
    "scores = []\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=SEED)\n",
    "splits = kfold.split(range(96))\n",
    "\n",
    "for fold, (train_idx, eval_idx) in enumerate(splits):\n",
    "    MODEL_NAME = f\"resnet.pretrain.fold.{fold}\"\n",
    "    checkpoint_name = f\"pretrain.fold.{fold}.pt\"\n",
    "    \n",
    "    train_inputs = torch.cat([inputs_list[i][train_idx] for i in range(len(inputs_list))])\n",
    "    train_targets = torch.cat([targets_list[i][train_idx] for i in range(len(inputs_list))])\n",
    "    eval_inputs = torch.cat([inputs_list[i][eval_idx] for i in range(len(inputs_list))])\n",
    "    eval_targets = torch.cat([targets_list[i][eval_idx] for i in range(len(inputs_list))])\n",
    "\n",
    "    mu, sigma = get_stats(train_inputs, p=False, r=True)\n",
    "    train_inputs = zscore(train_inputs, mu, sigma)\n",
    "    eval_inputs = zscore(eval_inputs, mu, sigma)\n",
    "    mus.append(mu)\n",
    "    sigmas.append(sigma)\n",
    "    \n",
    "    train_ds = TensorDataset(train_inputs.float(), train_targets.float())\n",
    "    eval_ds = TensorDataset(eval_inputs.float(), eval_targets.float())\n",
    "    \n",
    "    BATCH_SIZE = len(train_ds)\n",
    "    train_dl, eval_dl = return_dls(train_ds, eval_ds, BATCH_SIZE, len(eval_ds))\n",
    "    \n",
    "    model = ResNet(input_channels=2, dropout=DROPOUT).to(device)\n",
    "    if fold == 0: print(get_model_size(model))\n",
    "    \n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=LR, weight_decay=WD, foreach=True)\n",
    "    scaler = torch.amp.GradScaler(device)\n",
    "    scheduler = get_scheduler(optimizer, train_dl, EPOCHS)\n",
    "    \n",
    "    score = train(\n",
    "            model, \n",
    "            optimizer, \n",
    "            device,\n",
    "            scaler,\n",
    "            scheduler,\n",
    "            train_dl, \n",
    "            eval_dl,\n",
    "            EPOCHS,\n",
    "            checkpoint_name,\n",
    "            neptune_run=setup_neptune(),\n",
    "        )\n",
    "    \n",
    "    scores.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "27adf0a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5431315108096543,\n",
       " 0.5373212199292232,\n",
       " 0.5625938858971476,\n",
       " 0.5611233230776563,\n",
       " 0.5471325694126035]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[m.item() for m in mus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8f0e6135",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[249.05215723502948,\n",
       " 248.6726517269414,\n",
       " 247.84789229685813,\n",
       " 247.65868506084584,\n",
       " 248.16012425733976]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[s.item() for s in sigmas]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d63d1321",
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_path = f\"/kaggle/working/{checkpoint_name}\"\n",
    "ckpt = torch.load(ckpt_path, weights_only=False)\n",
    "ckpt[\"epoch\"], ckpt[\"score\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc86886e",
   "metadata": {},
   "outputs": [],
   "source": [
    "(443, 0.4866819899481086)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b99917",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = load_test_data()\n",
    "get_stats(test)\n",
    "test = get_spectra_features(test)\n",
    "test = torch.tensor(test)\n",
    "test = zscore(test, mu, sigma).float()\n",
    "test.shape, test.dtype, get_stats(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc6d0b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet(input_channels=2).to(device)\n",
    "model.load_state_dict(ckpt[\"state_dict\"])\n",
    "model.eval()\n",
    "\n",
    "with torch.inference_mode():\n",
    "    preds = model(test.cuda())\n",
    "\n",
    "preds = preds.cpu().detach().double().numpy()\n",
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3273410",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_stats(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62f94bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = ['Glucose', 'Sodium Acetate', 'Magnesium Sulfate']\n",
    "preds_df = pd.DataFrame(preds, columns=column_names)\n",
    "preds_df.insert(0, 'ID', [i+1 for i in range(len(preds_df))])\n",
    "preds_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a49bf07",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = MODEL_NAME+\".finetune.transfer.in.pretrain.csv\"\n",
    "preds_df.to_csv(name, index=False)\n",
    "f = pd.read_csv(f\"/kaggle/working/{name}\")\n",
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc35f1cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
